I0426 10:57:13.154399      23 e2e.go:116] Starting e2e run "e803992f-bfbe-4749-88d1-ca8f68f31e73" on Ginkgo node 1
Apr 26 10:57:13.159: INFO: Enabling in-tree volume drivers
Running Suite: Kubernetes e2e suite - /usr/local/bin
====================================================
Random Seed: 1714129032 - will randomize all specs

Will run 360 of 7066 specs
------------------------------
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
{"msg":"Test Suite starting","completed":0,"skipped":0,"failed":0}
Apr 26 10:57:13.473: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 10:57:13.474: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 26 10:57:13.510: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 26 10:57:13.602: INFO: 31 / 31 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 26 10:57:13.602: INFO: expected 13 pod replicas in namespace 'kube-system', 13 are Running and Ready.
Apr 26 10:57:13.602: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 26 10:57:13.621: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'apiserver-proxy' (0 seconds elapsed)
Apr 26 10:57:13.621: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr 26 10:57:13.621: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-driver-node' (0 seconds elapsed)
Apr 26 10:57:13.621: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy-worker-6a5hr-1-v1.25.16' (0 seconds elapsed)
Apr 26 10:57:13.621: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Apr 26 10:57:13.621: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Apr 26 10:57:13.621: INFO: e2e test version: v1.25.16
Apr 26 10:57:13.624: INFO: kube-apiserver version: v1.25.16
[SynchronizedBeforeSuite] TOP-LEVEL
  test/e2e/e2e.go:76
Apr 26 10:57:13.624: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 10:57:13.631: INFO: Cluster IP family: ipv4
------------------------------
[SynchronizedBeforeSuite] PASSED [0.158 seconds]
[SynchronizedBeforeSuite] 
test/e2e/e2e.go:76

  Begin Captured GinkgoWriter Output >>
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Apr 26 10:57:13.473: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 10:57:13.474: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
    Apr 26 10:57:13.510: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
    Apr 26 10:57:13.602: INFO: 31 / 31 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
    Apr 26 10:57:13.602: INFO: expected 13 pod replicas in namespace 'kube-system', 13 are Running and Ready.
    Apr 26 10:57:13.602: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
    Apr 26 10:57:13.621: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'apiserver-proxy' (0 seconds elapsed)
    Apr 26 10:57:13.621: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
    Apr 26 10:57:13.621: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'csi-driver-node' (0 seconds elapsed)
    Apr 26 10:57:13.621: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy-worker-6a5hr-1-v1.25.16' (0 seconds elapsed)
    Apr 26 10:57:13.621: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
    Apr 26 10:57:13.621: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
    Apr 26 10:57:13.621: INFO: e2e test version: v1.25.16
    Apr 26 10:57:13.624: INFO: kube-apiserver version: v1.25.16
    [SynchronizedBeforeSuite] TOP-LEVEL
      test/e2e/e2e.go:76
    Apr 26 10:57:13.624: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 10:57:13.631: INFO: Cluster IP family: ipv4
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with readOnlyRootFilesystem
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:57:13.648
Apr 26 10:57:13.649: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename security-context-test 04/26/24 10:57:13.649
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:13.67
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:13.678
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:485
Apr 26 10:57:13.702: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-bf9b4aab-fcaf-4557-915a-65a969a5b26a" in namespace "security-context-test-2595" to be "Succeeded or Failed"
Apr 26 10:57:13.707: INFO: Pod "busybox-readonly-false-bf9b4aab-fcaf-4557-915a-65a969a5b26a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.485375ms
Apr 26 10:57:15.736: INFO: Pod "busybox-readonly-false-bf9b4aab-fcaf-4557-915a-65a969a5b26a": Phase="Running", Reason="", readiness=true. Elapsed: 2.033383991s
Apr 26 10:57:17.714: INFO: Pod "busybox-readonly-false-bf9b4aab-fcaf-4557-915a-65a969a5b26a": Phase="Running", Reason="", readiness=false. Elapsed: 4.011228568s
Apr 26 10:57:19.715: INFO: Pod "busybox-readonly-false-bf9b4aab-fcaf-4557-915a-65a969a5b26a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012370898s
Apr 26 10:57:19.715: INFO: Pod "busybox-readonly-false-bf9b4aab-fcaf-4557-915a-65a969a5b26a" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 26 10:57:19.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2595" for this suite. 04/26/24 10:57:19.724
{"msg":"PASSED [sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]","completed":1,"skipped":20,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.082 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with readOnlyRootFilesystem
  test/e2e/common/node/security_context.go:429
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:485

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:57:13.648
    Apr 26 10:57:13.649: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename security-context-test 04/26/24 10:57:13.649
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:13.67
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:13.678
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:485
    Apr 26 10:57:13.702: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-bf9b4aab-fcaf-4557-915a-65a969a5b26a" in namespace "security-context-test-2595" to be "Succeeded or Failed"
    Apr 26 10:57:13.707: INFO: Pod "busybox-readonly-false-bf9b4aab-fcaf-4557-915a-65a969a5b26a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.485375ms
    Apr 26 10:57:15.736: INFO: Pod "busybox-readonly-false-bf9b4aab-fcaf-4557-915a-65a969a5b26a": Phase="Running", Reason="", readiness=true. Elapsed: 2.033383991s
    Apr 26 10:57:17.714: INFO: Pod "busybox-readonly-false-bf9b4aab-fcaf-4557-915a-65a969a5b26a": Phase="Running", Reason="", readiness=false. Elapsed: 4.011228568s
    Apr 26 10:57:19.715: INFO: Pod "busybox-readonly-false-bf9b4aab-fcaf-4557-915a-65a969a5b26a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012370898s
    Apr 26 10:57:19.715: INFO: Pod "busybox-readonly-false-bf9b4aab-fcaf-4557-915a-65a969a5b26a" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 26 10:57:19.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-2595" for this suite. 04/26/24 10:57:19.724
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:57:19.731
Apr 26 10:57:19.731: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 10:57:19.732
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:19.745
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:19.752
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441
STEP: set up a multi version CRD 04/26/24 10:57:19.758
Apr 26 10:57:19.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: mark a version not serverd 04/26/24 10:57:26.292
STEP: check the unserved version gets removed 04/26/24 10:57:26.318
STEP: check the other version is not changed 04/26/24 10:57:27.99
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 10:57:32.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2394" for this suite. 04/26/24 10:57:32.862
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]","completed":2,"skipped":22,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.137 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:441

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:57:19.731
    Apr 26 10:57:19.731: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 10:57:19.732
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:19.745
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:19.752
    [It] removes definition from spec when one version gets changed to not be served [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:441
    STEP: set up a multi version CRD 04/26/24 10:57:19.758
    Apr 26 10:57:19.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: mark a version not serverd 04/26/24 10:57:26.292
    STEP: check the unserved version gets removed 04/26/24 10:57:26.318
    STEP: check the other version is not changed 04/26/24 10:57:27.99
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 10:57:32.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2394" for this suite. 04/26/24 10:57:32.862
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:57:32.871
Apr 26 10:57:32.872: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 10:57:32.872
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:32.9
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:32.907
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-376 04/26/24 10:57:32.921
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/26/24 10:57:32.942
STEP: creating service externalsvc in namespace services-376 04/26/24 10:57:32.942
STEP: creating replication controller externalsvc in namespace services-376 04/26/24 10:57:32.966
I0426 10:57:32.973853      23 runners.go:193] Created replication controller with name: externalsvc, namespace: services-376, replica count: 2
I0426 10:57:36.025744      23 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0426 10:57:39.026500      23 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName 04/26/24 10:57:39.034
Apr 26 10:57:39.100: INFO: Creating new exec pod
Apr 26 10:57:39.131: INFO: Waiting up to 5m0s for pod "execpod79dkn" in namespace "services-376" to be "running"
Apr 26 10:57:39.144: INFO: Pod "execpod79dkn": Phase="Pending", Reason="", readiness=false. Elapsed: 13.726085ms
Apr 26 10:57:41.151: INFO: Pod "execpod79dkn": Phase="Running", Reason="", readiness=true. Elapsed: 2.020073347s
Apr 26 10:57:41.151: INFO: Pod "execpod79dkn" satisfied condition "running"
Apr 26 10:57:41.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-376 exec execpod79dkn -- /bin/sh -x -c nslookup clusterip-service.services-376.svc.cluster.local'
Apr 26 10:57:41.843: INFO: stderr: "+ nslookup clusterip-service.services-376.svc.cluster.local\n"
Apr 26 10:57:41.843: INFO: stdout: "Server:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nclusterip-service.services-376.svc.cluster.local\tcanonical name = externalsvc.services-376.svc.cluster.local.\nName:\texternalsvc.services-376.svc.cluster.local\nAddress: 100.64.197.134\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-376, will wait for the garbage collector to delete the pods 04/26/24 10:57:41.843
Apr 26 10:57:41.909: INFO: Deleting ReplicationController externalsvc took: 8.983441ms
Apr 26 10:57:42.009: INFO: Terminating ReplicationController externalsvc pods took: 100.177539ms
Apr 26 10:57:43.937: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 10:57:43.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-376" for this suite. 04/26/24 10:57:43.963
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]","completed":3,"skipped":57,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.099 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  test/e2e/network/service.go:1481

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:57:32.871
    Apr 26 10:57:32.872: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 10:57:32.872
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:32.9
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:32.907
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ClusterIP to ExternalName [Conformance]
      test/e2e/network/service.go:1481
    STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-376 04/26/24 10:57:32.921
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/26/24 10:57:32.942
    STEP: creating service externalsvc in namespace services-376 04/26/24 10:57:32.942
    STEP: creating replication controller externalsvc in namespace services-376 04/26/24 10:57:32.966
    I0426 10:57:32.973853      23 runners.go:193] Created replication controller with name: externalsvc, namespace: services-376, replica count: 2
    I0426 10:57:36.025744      23 runners.go:193] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0426 10:57:39.026500      23 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the ClusterIP service to type=ExternalName 04/26/24 10:57:39.034
    Apr 26 10:57:39.100: INFO: Creating new exec pod
    Apr 26 10:57:39.131: INFO: Waiting up to 5m0s for pod "execpod79dkn" in namespace "services-376" to be "running"
    Apr 26 10:57:39.144: INFO: Pod "execpod79dkn": Phase="Pending", Reason="", readiness=false. Elapsed: 13.726085ms
    Apr 26 10:57:41.151: INFO: Pod "execpod79dkn": Phase="Running", Reason="", readiness=true. Elapsed: 2.020073347s
    Apr 26 10:57:41.151: INFO: Pod "execpod79dkn" satisfied condition "running"
    Apr 26 10:57:41.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-376 exec execpod79dkn -- /bin/sh -x -c nslookup clusterip-service.services-376.svc.cluster.local'
    Apr 26 10:57:41.843: INFO: stderr: "+ nslookup clusterip-service.services-376.svc.cluster.local\n"
    Apr 26 10:57:41.843: INFO: stdout: "Server:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nclusterip-service.services-376.svc.cluster.local\tcanonical name = externalsvc.services-376.svc.cluster.local.\nName:\texternalsvc.services-376.svc.cluster.local\nAddress: 100.64.197.134\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-376, will wait for the garbage collector to delete the pods 04/26/24 10:57:41.843
    Apr 26 10:57:41.909: INFO: Deleting ReplicationController externalsvc took: 8.983441ms
    Apr 26 10:57:42.009: INFO: Terminating ReplicationController externalsvc pods took: 100.177539ms
    Apr 26 10:57:43.937: INFO: Cleaning up the ClusterIP to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 10:57:43.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-376" for this suite. 04/26/24 10:57:43.963
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:57:43.978
Apr 26 10:57:43.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pods 04/26/24 10:57:43.979
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:43.994
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:44
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203
STEP: creating pod 04/26/24 10:57:44.006
Apr 26 10:57:44.020: INFO: Waiting up to 5m0s for pod "pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13" in namespace "pods-6944" to be "running and ready"
Apr 26 10:57:44.025: INFO: Pod "pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13": Phase="Pending", Reason="", readiness=false. Elapsed: 5.133858ms
Apr 26 10:57:44.025: INFO: The phase of Pod pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 10:57:46.033: INFO: Pod "pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13": Phase="Running", Reason="", readiness=true. Elapsed: 2.013061647s
Apr 26 10:57:46.033: INFO: The phase of Pod pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13 is Running (Ready = true)
Apr 26 10:57:46.033: INFO: Pod "pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13" satisfied condition "running and ready"
Apr 26 10:57:46.043: INFO: Pod pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13 has hostIP: 10.250.2.248
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 26 10:57:46.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6944" for this suite. 04/26/24 10:57:46.054
{"msg":"PASSED [sig-node] Pods should get a host IP [NodeConformance] [Conformance]","completed":4,"skipped":114,"failed":0}
------------------------------
â€¢ [2.084 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should get a host IP [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:203

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:57:43.978
    Apr 26 10:57:43.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pods 04/26/24 10:57:43.979
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:43.994
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:44
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should get a host IP [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:203
    STEP: creating pod 04/26/24 10:57:44.006
    Apr 26 10:57:44.020: INFO: Waiting up to 5m0s for pod "pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13" in namespace "pods-6944" to be "running and ready"
    Apr 26 10:57:44.025: INFO: Pod "pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13": Phase="Pending", Reason="", readiness=false. Elapsed: 5.133858ms
    Apr 26 10:57:44.025: INFO: The phase of Pod pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 10:57:46.033: INFO: Pod "pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13": Phase="Running", Reason="", readiness=true. Elapsed: 2.013061647s
    Apr 26 10:57:46.033: INFO: The phase of Pod pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13 is Running (Ready = true)
    Apr 26 10:57:46.033: INFO: Pod "pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13" satisfied condition "running and ready"
    Apr 26 10:57:46.043: INFO: Pod pod-hostip-2882d0c4-e517-4d5d-9624-7a1878bb2a13 has hostIP: 10.250.2.248
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 26 10:57:46.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-6944" for this suite. 04/26/24 10:57:46.054
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:57:46.064
Apr 26 10:57:46.064: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 10:57:46.066
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:46.082
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:46.088
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266
STEP: Creating a pod to test downward api env vars 04/26/24 10:57:46.094
Apr 26 10:57:46.109: INFO: Waiting up to 5m0s for pod "downward-api-7045760c-8820-4660-a806-65d885ccbe10" in namespace "downward-api-3078" to be "Succeeded or Failed"
Apr 26 10:57:46.115: INFO: Pod "downward-api-7045760c-8820-4660-a806-65d885ccbe10": Phase="Pending", Reason="", readiness=false. Elapsed: 5.796604ms
Apr 26 10:57:48.161: INFO: Pod "downward-api-7045760c-8820-4660-a806-65d885ccbe10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051732274s
Apr 26 10:57:50.125: INFO: Pod "downward-api-7045760c-8820-4660-a806-65d885ccbe10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015599692s
STEP: Saw pod success 04/26/24 10:57:50.125
Apr 26 10:57:50.125: INFO: Pod "downward-api-7045760c-8820-4660-a806-65d885ccbe10" satisfied condition "Succeeded or Failed"
Apr 26 10:57:50.130: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w pod downward-api-7045760c-8820-4660-a806-65d885ccbe10 container dapi-container: <nil>
STEP: delete the pod 04/26/24 10:57:50.143
Apr 26 10:57:50.163: INFO: Waiting for pod downward-api-7045760c-8820-4660-a806-65d885ccbe10 to disappear
Apr 26 10:57:50.167: INFO: Pod downward-api-7045760c-8820-4660-a806-65d885ccbe10 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 26 10:57:50.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3078" for this suite. 04/26/24 10:57:50.179
{"msg":"PASSED [sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]","completed":5,"skipped":141,"failed":0}
------------------------------
â€¢ [4.121 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod UID as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:266

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:57:46.064
    Apr 26 10:57:46.064: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 10:57:46.066
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:46.082
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:46.088
    [It] should provide pod UID as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:266
    STEP: Creating a pod to test downward api env vars 04/26/24 10:57:46.094
    Apr 26 10:57:46.109: INFO: Waiting up to 5m0s for pod "downward-api-7045760c-8820-4660-a806-65d885ccbe10" in namespace "downward-api-3078" to be "Succeeded or Failed"
    Apr 26 10:57:46.115: INFO: Pod "downward-api-7045760c-8820-4660-a806-65d885ccbe10": Phase="Pending", Reason="", readiness=false. Elapsed: 5.796604ms
    Apr 26 10:57:48.161: INFO: Pod "downward-api-7045760c-8820-4660-a806-65d885ccbe10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051732274s
    Apr 26 10:57:50.125: INFO: Pod "downward-api-7045760c-8820-4660-a806-65d885ccbe10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015599692s
    STEP: Saw pod success 04/26/24 10:57:50.125
    Apr 26 10:57:50.125: INFO: Pod "downward-api-7045760c-8820-4660-a806-65d885ccbe10" satisfied condition "Succeeded or Failed"
    Apr 26 10:57:50.130: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w pod downward-api-7045760c-8820-4660-a806-65d885ccbe10 container dapi-container: <nil>
    STEP: delete the pod 04/26/24 10:57:50.143
    Apr 26 10:57:50.163: INFO: Waiting for pod downward-api-7045760c-8820-4660-a806-65d885ccbe10 to disappear
    Apr 26 10:57:50.167: INFO: Pod downward-api-7045760c-8820-4660-a806-65d885ccbe10 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 26 10:57:50.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3078" for this suite. 04/26/24 10:57:50.179
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:57:50.186
Apr 26 10:57:50.186: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pods 04/26/24 10:57:50.187
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:50.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:50.254
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343
STEP: creating the pod 04/26/24 10:57:50.261
STEP: submitting the pod to kubernetes 04/26/24 10:57:50.261
Apr 26 10:57:50.272: INFO: Waiting up to 5m0s for pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799" in namespace "pods-4550" to be "running and ready"
Apr 26 10:57:50.301: INFO: Pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799": Phase="Pending", Reason="", readiness=false. Elapsed: 28.966962ms
Apr 26 10:57:50.301: INFO: The phase of Pod pod-update-d80abfbe-c48e-4606-b8af-79d110e45799 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 10:57:52.310: INFO: Pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799": Phase="Running", Reason="", readiness=true. Elapsed: 2.037266809s
Apr 26 10:57:52.310: INFO: The phase of Pod pod-update-d80abfbe-c48e-4606-b8af-79d110e45799 is Running (Ready = true)
Apr 26 10:57:52.310: INFO: Pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 04/26/24 10:57:52.316
STEP: updating the pod 04/26/24 10:57:52.322
Apr 26 10:57:52.837: INFO: Successfully updated pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799"
Apr 26 10:57:52.838: INFO: Waiting up to 5m0s for pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799" in namespace "pods-4550" to be "running"
Apr 26 10:57:52.844: INFO: Pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799": Phase="Running", Reason="", readiness=true. Elapsed: 6.884253ms
Apr 26 10:57:52.845: INFO: Pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799" satisfied condition "running"
STEP: verifying the updated pod is in kubernetes 04/26/24 10:57:52.845
Apr 26 10:57:52.850: INFO: Pod update OK
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 26 10:57:52.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4550" for this suite. 04/26/24 10:57:52.862
{"msg":"PASSED [sig-node] Pods should be updated [NodeConformance] [Conformance]","completed":6,"skipped":168,"failed":0}
------------------------------
â€¢ [2.682 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:343

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:57:50.186
    Apr 26 10:57:50.186: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pods 04/26/24 10:57:50.187
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:50.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:50.254
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:343
    STEP: creating the pod 04/26/24 10:57:50.261
    STEP: submitting the pod to kubernetes 04/26/24 10:57:50.261
    Apr 26 10:57:50.272: INFO: Waiting up to 5m0s for pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799" in namespace "pods-4550" to be "running and ready"
    Apr 26 10:57:50.301: INFO: Pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799": Phase="Pending", Reason="", readiness=false. Elapsed: 28.966962ms
    Apr 26 10:57:50.301: INFO: The phase of Pod pod-update-d80abfbe-c48e-4606-b8af-79d110e45799 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 10:57:52.310: INFO: Pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799": Phase="Running", Reason="", readiness=true. Elapsed: 2.037266809s
    Apr 26 10:57:52.310: INFO: The phase of Pod pod-update-d80abfbe-c48e-4606-b8af-79d110e45799 is Running (Ready = true)
    Apr 26 10:57:52.310: INFO: Pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 04/26/24 10:57:52.316
    STEP: updating the pod 04/26/24 10:57:52.322
    Apr 26 10:57:52.837: INFO: Successfully updated pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799"
    Apr 26 10:57:52.838: INFO: Waiting up to 5m0s for pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799" in namespace "pods-4550" to be "running"
    Apr 26 10:57:52.844: INFO: Pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799": Phase="Running", Reason="", readiness=true. Elapsed: 6.884253ms
    Apr 26 10:57:52.845: INFO: Pod "pod-update-d80abfbe-c48e-4606-b8af-79d110e45799" satisfied condition "running"
    STEP: verifying the updated pod is in kubernetes 04/26/24 10:57:52.845
    Apr 26 10:57:52.850: INFO: Pod update OK
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 26 10:57:52.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4550" for this suite. 04/26/24 10:57:52.862
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:57:52.869
Apr 26 10:57:52.869: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 10:57:52.87
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:52.89
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:52.897
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56
STEP: Creating secret with name secret-test-7b982562-3435-4f19-be0c-529e87d8b64a 04/26/24 10:57:52.903
STEP: Creating a pod to test consume secrets 04/26/24 10:57:52.909
Apr 26 10:57:52.920: INFO: Waiting up to 5m0s for pod "pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5" in namespace "secrets-6769" to be "Succeeded or Failed"
Apr 26 10:57:52.927: INFO: Pod "pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.951843ms
Apr 26 10:57:54.935: INFO: Pod "pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014109375s
Apr 26 10:57:56.934: INFO: Pod "pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013161634s
STEP: Saw pod success 04/26/24 10:57:56.934
Apr 26 10:57:56.934: INFO: Pod "pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5" satisfied condition "Succeeded or Failed"
Apr 26 10:57:56.939: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5 container secret-volume-test: <nil>
STEP: delete the pod 04/26/24 10:57:57
Apr 26 10:57:57.016: INFO: Waiting for pod pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5 to disappear
Apr 26 10:57:57.020: INFO: Pod pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 26 10:57:57.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6769" for this suite. 04/26/24 10:57:57.031
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":7,"skipped":173,"failed":0}
------------------------------
â€¢ [4.169 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:57:52.869
    Apr 26 10:57:52.869: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 10:57:52.87
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:52.89
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:52.897
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:56
    STEP: Creating secret with name secret-test-7b982562-3435-4f19-be0c-529e87d8b64a 04/26/24 10:57:52.903
    STEP: Creating a pod to test consume secrets 04/26/24 10:57:52.909
    Apr 26 10:57:52.920: INFO: Waiting up to 5m0s for pod "pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5" in namespace "secrets-6769" to be "Succeeded or Failed"
    Apr 26 10:57:52.927: INFO: Pod "pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.951843ms
    Apr 26 10:57:54.935: INFO: Pod "pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014109375s
    Apr 26 10:57:56.934: INFO: Pod "pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013161634s
    STEP: Saw pod success 04/26/24 10:57:56.934
    Apr 26 10:57:56.934: INFO: Pod "pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5" satisfied condition "Succeeded or Failed"
    Apr 26 10:57:56.939: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5 container secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 10:57:57
    Apr 26 10:57:57.016: INFO: Waiting for pod pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5 to disappear
    Apr 26 10:57:57.020: INFO: Pod pod-secrets-6d1339d2-15ef-4095-9f32-0f3c019170a5 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 10:57:57.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6769" for this suite. 04/26/24 10:57:57.031
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:57:57.039
Apr 26 10:57:57.039: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename statefulset 04/26/24 10:57:57.04
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:57.054
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:57.06
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-8173 04/26/24 10:57:57.065
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  test/e2e/apps/statefulset.go:695
STEP: Creating stateful set ss in namespace statefulset-8173 04/26/24 10:57:57.07
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8173 04/26/24 10:57:57.078
Apr 26 10:57:57.082: INFO: Found 0 stateful pods, waiting for 1
Apr 26 10:58:07.093: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 04/26/24 10:58:07.093
Apr 26 10:58:07.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 26 10:58:07.631: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 26 10:58:07.631: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 26 10:58:07.631: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 26 10:58:07.637: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 26 10:58:17.645: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 26 10:58:17.645: INFO: Waiting for statefulset status.replicas updated to 0
Apr 26 10:58:17.667: INFO: POD   NODE                                                   PHASE    GRACE  CONDITIONS
Apr 26 10:58:17.667: INFO: ss-0  shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:57:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:57:57 +0000 UTC  }]
Apr 26 10:58:17.667: INFO: 
Apr 26 10:58:17.667: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 26 10:58:18.675: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994160557s
Apr 26 10:58:19.773: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.897566377s
Apr 26 10:58:20.801: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.888422536s
Apr 26 10:58:21.809: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.861414162s
Apr 26 10:58:22.817: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.853042157s
Apr 26 10:58:23.832: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.843688813s
Apr 26 10:58:24.843: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.830068691s
Apr 26 10:58:25.851: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.819207804s
Apr 26 10:58:26.858: INFO: Verifying statefulset ss doesn't scale past 3 for another 811.198305ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8173 04/26/24 10:58:27.858
Apr 26 10:58:27.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 26 10:58:28.369: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 26 10:58:28.369: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 26 10:58:28.369: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 26 10:58:28.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 26 10:58:28.877: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 26 10:58:28.877: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 26 10:58:28.877: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 26 10:58:28.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 26 10:58:29.413: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 26 10:58:29.413: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 26 10:58:29.413: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 26 10:58:29.420: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 26 10:58:29.420: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 26 10:58:29.420: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod 04/26/24 10:58:29.42
Apr 26 10:58:29.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 26 10:58:29.885: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 26 10:58:29.885: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 26 10:58:29.885: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 26 10:58:29.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 26 10:58:30.401: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 26 10:58:30.401: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 26 10:58:30.401: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 26 10:58:30.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 26 10:58:30.930: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 26 10:58:30.930: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 26 10:58:30.930: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 26 10:58:30.930: INFO: Waiting for statefulset status.replicas updated to 0
Apr 26 10:58:30.949: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 26 10:58:40.972: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 26 10:58:40.972: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 26 10:58:40.972: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 26 10:58:40.988: INFO: POD   NODE                                                   PHASE    GRACE  CONDITIONS
Apr 26 10:58:40.988: INFO: ss-0  shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:57:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:57:57 +0000 UTC  }]
Apr 26 10:58:40.988: INFO: ss-1  shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:17 +0000 UTC  }]
Apr 26 10:58:40.988: INFO: ss-2  shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:17 +0000 UTC  }]
Apr 26 10:58:40.988: INFO: 
Apr 26 10:58:40.988: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 26 10:58:41.997: INFO: POD   NODE                                                   PHASE    GRACE  CONDITIONS
Apr 26 10:58:41.997: INFO: ss-2  shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:17 +0000 UTC  }]
Apr 26 10:58:41.997: INFO: 
Apr 26 10:58:41.997: INFO: StatefulSet ss has not reached scale 0, at 1
Apr 26 10:58:43.003: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.984284997s
Apr 26 10:58:44.010: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.978427711s
Apr 26 10:58:45.016: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.971740502s
Apr 26 10:58:46.021: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.966452483s
Apr 26 10:58:47.027: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.96079676s
Apr 26 10:58:48.034: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.955006133s
Apr 26 10:58:49.040: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.947860733s
Apr 26 10:58:50.083: INFO: Verifying statefulset ss doesn't scale past 0 for another 942.000562ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8173 04/26/24 10:58:51.084
Apr 26 10:58:51.114: INFO: Scaling statefulset ss to 0
Apr 26 10:58:51.185: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 26 10:58:51.190: INFO: Deleting all statefulset in ns statefulset-8173
Apr 26 10:58:51.196: INFO: Scaling statefulset ss to 0
Apr 26 10:58:51.211: INFO: Waiting for statefulset status.replicas updated to 0
Apr 26 10:58:51.216: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 26 10:58:51.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8173" for this suite. 04/26/24 10:58:51.26
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]","completed":8,"skipped":187,"failed":0}
------------------------------
â€¢ [SLOW TEST] [54.228 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    test/e2e/apps/statefulset.go:695

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:57:57.039
    Apr 26 10:57:57.039: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename statefulset 04/26/24 10:57:57.04
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:57:57.054
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:57:57.06
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-8173 04/26/24 10:57:57.065
    [It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
      test/e2e/apps/statefulset.go:695
    STEP: Creating stateful set ss in namespace statefulset-8173 04/26/24 10:57:57.07
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8173 04/26/24 10:57:57.078
    Apr 26 10:57:57.082: INFO: Found 0 stateful pods, waiting for 1
    Apr 26 10:58:07.093: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod 04/26/24 10:58:07.093
    Apr 26 10:58:07.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 26 10:58:07.631: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 26 10:58:07.631: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 26 10:58:07.631: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 26 10:58:07.637: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Apr 26 10:58:17.645: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 26 10:58:17.645: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 26 10:58:17.667: INFO: POD   NODE                                                   PHASE    GRACE  CONDITIONS
    Apr 26 10:58:17.667: INFO: ss-0  shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:57:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:57:57 +0000 UTC  }]
    Apr 26 10:58:17.667: INFO: 
    Apr 26 10:58:17.667: INFO: StatefulSet ss has not reached scale 3, at 1
    Apr 26 10:58:18.675: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994160557s
    Apr 26 10:58:19.773: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.897566377s
    Apr 26 10:58:20.801: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.888422536s
    Apr 26 10:58:21.809: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.861414162s
    Apr 26 10:58:22.817: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.853042157s
    Apr 26 10:58:23.832: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.843688813s
    Apr 26 10:58:24.843: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.830068691s
    Apr 26 10:58:25.851: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.819207804s
    Apr 26 10:58:26.858: INFO: Verifying statefulset ss doesn't scale past 3 for another 811.198305ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8173 04/26/24 10:58:27.858
    Apr 26 10:58:27.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 26 10:58:28.369: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 26 10:58:28.369: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 26 10:58:28.369: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 26 10:58:28.369: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 26 10:58:28.877: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Apr 26 10:58:28.877: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 26 10:58:28.877: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 26 10:58:28.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 26 10:58:29.413: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
    Apr 26 10:58:29.413: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 26 10:58:29.413: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 26 10:58:29.420: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 26 10:58:29.420: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 26 10:58:29.420: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Scale down will not halt with unhealthy stateful pod 04/26/24 10:58:29.42
    Apr 26 10:58:29.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 26 10:58:29.885: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 26 10:58:29.885: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 26 10:58:29.885: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 26 10:58:29.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 26 10:58:30.401: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 26 10:58:30.401: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 26 10:58:30.401: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 26 10:58:30.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-8173 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 26 10:58:30.930: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 26 10:58:30.930: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 26 10:58:30.930: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 26 10:58:30.930: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 26 10:58:30.949: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
    Apr 26 10:58:40.972: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 26 10:58:40.972: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Apr 26 10:58:40.972: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Apr 26 10:58:40.988: INFO: POD   NODE                                                   PHASE    GRACE  CONDITIONS
    Apr 26 10:58:40.988: INFO: ss-0  shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:57:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:57:57 +0000 UTC  }]
    Apr 26 10:58:40.988: INFO: ss-1  shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:17 +0000 UTC  }]
    Apr 26 10:58:40.988: INFO: ss-2  shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:17 +0000 UTC  }]
    Apr 26 10:58:40.988: INFO: 
    Apr 26 10:58:40.988: INFO: StatefulSet ss has not reached scale 0, at 3
    Apr 26 10:58:41.997: INFO: POD   NODE                                                   PHASE    GRACE  CONDITIONS
    Apr 26 10:58:41.997: INFO: ss-2  shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:17 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 10:58:17 +0000 UTC  }]
    Apr 26 10:58:41.997: INFO: 
    Apr 26 10:58:41.997: INFO: StatefulSet ss has not reached scale 0, at 1
    Apr 26 10:58:43.003: INFO: Verifying statefulset ss doesn't scale past 0 for another 7.984284997s
    Apr 26 10:58:44.010: INFO: Verifying statefulset ss doesn't scale past 0 for another 6.978427711s
    Apr 26 10:58:45.016: INFO: Verifying statefulset ss doesn't scale past 0 for another 5.971740502s
    Apr 26 10:58:46.021: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.966452483s
    Apr 26 10:58:47.027: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.96079676s
    Apr 26 10:58:48.034: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.955006133s
    Apr 26 10:58:49.040: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.947860733s
    Apr 26 10:58:50.083: INFO: Verifying statefulset ss doesn't scale past 0 for another 942.000562ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8173 04/26/24 10:58:51.084
    Apr 26 10:58:51.114: INFO: Scaling statefulset ss to 0
    Apr 26 10:58:51.185: INFO: Waiting for statefulset status.replicas updated to 0
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 26 10:58:51.190: INFO: Deleting all statefulset in ns statefulset-8173
    Apr 26 10:58:51.196: INFO: Scaling statefulset ss to 0
    Apr 26 10:58:51.211: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 26 10:58:51.216: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 26 10:58:51.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-8173" for this suite. 04/26/24 10:58:51.26
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:58:51.267
Apr 26 10:58:51.267: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 10:58:51.268
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:58:51.283
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:58:51.288
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52
STEP: Creating a pod to test downward API volume plugin 04/26/24 10:58:51.294
Apr 26 10:58:51.306: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356" in namespace "projected-982" to be "Succeeded or Failed"
Apr 26 10:58:51.311: INFO: Pod "downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356": Phase="Pending", Reason="", readiness=false. Elapsed: 4.863235ms
Apr 26 10:58:53.318: INFO: Pod "downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01198369s
Apr 26 10:58:55.319: INFO: Pod "downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012488787s
STEP: Saw pod success 04/26/24 10:58:55.319
Apr 26 10:58:55.319: INFO: Pod "downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356" satisfied condition "Succeeded or Failed"
Apr 26 10:58:55.331: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356 container client-container: <nil>
STEP: delete the pod 04/26/24 10:58:55.346
Apr 26 10:58:55.368: INFO: Waiting for pod downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356 to disappear
Apr 26 10:58:55.373: INFO: Pod downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 26 10:58:55.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-982" for this suite. 04/26/24 10:58:55.387
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]","completed":9,"skipped":197,"failed":0}
------------------------------
â€¢ [4.126 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:58:51.267
    Apr 26 10:58:51.267: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 10:58:51.268
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:58:51.283
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:58:51.288
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:52
    STEP: Creating a pod to test downward API volume plugin 04/26/24 10:58:51.294
    Apr 26 10:58:51.306: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356" in namespace "projected-982" to be "Succeeded or Failed"
    Apr 26 10:58:51.311: INFO: Pod "downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356": Phase="Pending", Reason="", readiness=false. Elapsed: 4.863235ms
    Apr 26 10:58:53.318: INFO: Pod "downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01198369s
    Apr 26 10:58:55.319: INFO: Pod "downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012488787s
    STEP: Saw pod success 04/26/24 10:58:55.319
    Apr 26 10:58:55.319: INFO: Pod "downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356" satisfied condition "Succeeded or Failed"
    Apr 26 10:58:55.331: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356 container client-container: <nil>
    STEP: delete the pod 04/26/24 10:58:55.346
    Apr 26 10:58:55.368: INFO: Waiting for pod downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356 to disappear
    Apr 26 10:58:55.373: INFO: Pod downwardapi-volume-d768a891-0174-43a1-80f1-468f23f85356 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 26 10:58:55.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-982" for this suite. 04/26/24 10:58:55.387
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:58:55.394
Apr 26 10:58:55.394: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename proxy 04/26/24 10:58:55.395
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:58:55.412
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:58:55.417
[It] should proxy through a service and a pod  [Conformance]
  test/e2e/network/proxy.go:101
STEP: starting an echo server on multiple ports 04/26/24 10:58:55.452
STEP: creating replication controller proxy-service-fmfpr in namespace proxy-3545 04/26/24 10:58:55.452
I0426 10:58:55.464804      23 runners.go:193] Created replication controller with name: proxy-service-fmfpr, namespace: proxy-3545, replica count: 1
I0426 10:58:56.515709      23 runners.go:193] proxy-service-fmfpr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0426 10:58:57.516897      23 runners.go:193] proxy-service-fmfpr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0426 10:58:58.517098      23 runners.go:193] proxy-service-fmfpr Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 26 10:58:58.523: INFO: setup took 3.096930422s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts 04/26/24 10:58:58.523
Apr 26 10:58:58.563: INFO: (0) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 39.811143ms)
Apr 26 10:58:58.563: INFO: (0) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 39.843722ms)
Apr 26 10:58:58.565: INFO: (0) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 41.042777ms)
Apr 26 10:58:58.568: INFO: (0) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 43.874667ms)
Apr 26 10:58:58.570: INFO: (0) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 46.276333ms)
Apr 26 10:58:58.572: INFO: (0) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 48.394901ms)
Apr 26 10:58:58.575: INFO: (0) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 51.338764ms)
Apr 26 10:58:58.577: INFO: (0) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 52.865136ms)
Apr 26 10:58:58.577: INFO: (0) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 53.931563ms)
Apr 26 10:58:58.578: INFO: (0) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 54.495456ms)
Apr 26 10:58:58.578: INFO: (0) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 54.372735ms)
Apr 26 10:58:58.578: INFO: (0) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 54.43018ms)
Apr 26 10:58:58.587: INFO: (0) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 63.136066ms)
Apr 26 10:58:58.587: INFO: (0) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 63.08238ms)
Apr 26 10:58:58.595: INFO: (0) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 71.733108ms)
Apr 26 10:58:58.598: INFO: (0) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 74.100302ms)
Apr 26 10:58:58.613: INFO: (1) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 15.360297ms)
Apr 26 10:58:58.615: INFO: (1) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 17.226983ms)
Apr 26 10:58:58.615: INFO: (1) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 17.327192ms)
Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 22.965296ms)
Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 23.016429ms)
Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.981645ms)
Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 23.063532ms)
Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 23.252422ms)
Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 23.248417ms)
Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 23.259937ms)
Apr 26 10:58:58.622: INFO: (1) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 23.693144ms)
Apr 26 10:58:58.622: INFO: (1) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 23.737805ms)
Apr 26 10:58:58.623: INFO: (1) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 25.328764ms)
Apr 26 10:58:58.625: INFO: (1) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 27.120244ms)
Apr 26 10:58:58.625: INFO: (1) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 27.279621ms)
Apr 26 10:58:58.627: INFO: (1) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 28.912795ms)
Apr 26 10:58:58.644: INFO: (2) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 17.118699ms)
Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.785763ms)
Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 23.116006ms)
Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 22.906721ms)
Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 22.880443ms)
Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.815817ms)
Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 23.130623ms)
Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 23.460255ms)
Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 23.316256ms)
Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 23.296421ms)
Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 23.217629ms)
Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 23.174803ms)
Apr 26 10:58:58.657: INFO: (2) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 29.424815ms)
Apr 26 10:58:58.657: INFO: (2) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 29.332088ms)
Apr 26 10:58:58.657: INFO: (2) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 29.435185ms)
Apr 26 10:58:58.657: INFO: (2) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 29.575497ms)
Apr 26 10:58:58.679: INFO: (3) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 21.867583ms)
Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.103798ms)
Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 22.472731ms)
Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 22.474985ms)
Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 22.687718ms)
Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 22.381347ms)
Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 22.403867ms)
Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 22.627498ms)
Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 23.121036ms)
Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 23.350869ms)
Apr 26 10:58:58.681: INFO: (3) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.999037ms)
Apr 26 10:58:58.681: INFO: (3) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 23.240309ms)
Apr 26 10:58:58.686: INFO: (3) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 28.522394ms)
Apr 26 10:58:58.686: INFO: (3) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 28.427313ms)
Apr 26 10:58:58.686: INFO: (3) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 28.685408ms)
Apr 26 10:58:58.686: INFO: (3) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 28.458709ms)
Apr 26 10:58:58.710: INFO: (4) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 23.562019ms)
Apr 26 10:58:58.711: INFO: (4) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 24.265264ms)
Apr 26 10:58:58.711: INFO: (4) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 24.512307ms)
Apr 26 10:58:58.711: INFO: (4) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 24.467756ms)
Apr 26 10:58:58.711: INFO: (4) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 25.081341ms)
Apr 26 10:58:58.711: INFO: (4) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 24.852308ms)
Apr 26 10:58:58.711: INFO: (4) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 24.911966ms)
Apr 26 10:58:58.712: INFO: (4) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 25.04312ms)
Apr 26 10:58:58.712: INFO: (4) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 25.486287ms)
Apr 26 10:58:58.712: INFO: (4) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 25.401765ms)
Apr 26 10:58:58.712: INFO: (4) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 25.041428ms)
Apr 26 10:58:58.712: INFO: (4) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 25.50976ms)
Apr 26 10:58:58.716: INFO: (4) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 29.482941ms)
Apr 26 10:58:58.716: INFO: (4) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 29.401735ms)
Apr 26 10:58:58.716: INFO: (4) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 29.896444ms)
Apr 26 10:58:58.716: INFO: (4) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 29.754889ms)
Apr 26 10:58:58.739: INFO: (5) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 22.363125ms)
Apr 26 10:58:58.739: INFO: (5) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 22.476156ms)
Apr 26 10:58:58.739: INFO: (5) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 22.628801ms)
Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 25.145495ms)
Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 25.409189ms)
Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 25.415259ms)
Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 25.501776ms)
Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 25.452626ms)
Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 25.487309ms)
Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 25.457425ms)
Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 25.504741ms)
Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 25.688752ms)
Apr 26 10:58:58.749: INFO: (5) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 32.34233ms)
Apr 26 10:58:58.749: INFO: (5) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 32.907276ms)
Apr 26 10:58:58.750: INFO: (5) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 32.917132ms)
Apr 26 10:58:58.750: INFO: (5) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 33.042428ms)
Apr 26 10:58:58.767: INFO: (6) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 16.962988ms)
Apr 26 10:58:58.772: INFO: (6) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.528822ms)
Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 22.937906ms)
Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.825615ms)
Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.950329ms)
Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 23.093716ms)
Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 23.38511ms)
Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 23.011269ms)
Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 23.327707ms)
Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 23.447112ms)
Apr 26 10:58:58.774: INFO: (6) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 24.618768ms)
Apr 26 10:58:58.774: INFO: (6) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 24.477543ms)
Apr 26 10:58:58.774: INFO: (6) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 24.558229ms)
Apr 26 10:58:58.777: INFO: (6) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 27.318ms)
Apr 26 10:58:58.781: INFO: (6) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 30.66781ms)
Apr 26 10:58:58.781: INFO: (6) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 30.845259ms)
Apr 26 10:58:58.798: INFO: (7) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 17.335237ms)
Apr 26 10:58:58.799: INFO: (7) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 17.98248ms)
Apr 26 10:58:58.799: INFO: (7) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 17.828393ms)
Apr 26 10:58:58.799: INFO: (7) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 18.012124ms)
Apr 26 10:58:58.800: INFO: (7) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 18.838799ms)
Apr 26 10:58:58.800: INFO: (7) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 18.812392ms)
Apr 26 10:58:58.800: INFO: (7) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 19.017411ms)
Apr 26 10:58:58.807: INFO: (7) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 26.560238ms)
Apr 26 10:58:58.807: INFO: (7) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 26.729982ms)
Apr 26 10:58:58.807: INFO: (7) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 26.637736ms)
Apr 26 10:58:58.807: INFO: (7) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 26.576787ms)
Apr 26 10:58:58.807: INFO: (7) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 26.835622ms)
Apr 26 10:58:58.807: INFO: (7) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 26.60664ms)
Apr 26 10:58:58.808: INFO: (7) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 26.742806ms)
Apr 26 10:58:58.808: INFO: (7) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 26.704788ms)
Apr 26 10:58:58.817: INFO: (7) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 35.916444ms)
Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 23.244978ms)
Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 23.375051ms)
Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 23.118291ms)
Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 23.226325ms)
Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 23.41249ms)
Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 23.355837ms)
Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 23.332507ms)
Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 23.433718ms)
Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 23.562929ms)
Apr 26 10:58:58.841: INFO: (8) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 23.484069ms)
Apr 26 10:58:58.841: INFO: (8) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 23.577006ms)
Apr 26 10:58:58.841: INFO: (8) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 24.232664ms)
Apr 26 10:58:58.844: INFO: (8) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 26.951099ms)
Apr 26 10:58:58.847: INFO: (8) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 29.465088ms)
Apr 26 10:58:58.847: INFO: (8) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 29.634393ms)
Apr 26 10:58:58.847: INFO: (8) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 29.593149ms)
Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 27.09035ms)
Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 27.26816ms)
Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 27.247843ms)
Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 27.238367ms)
Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 27.160286ms)
Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 26.950288ms)
Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 27.473627ms)
Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 27.388917ms)
Apr 26 10:58:58.875: INFO: (9) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 27.671154ms)
Apr 26 10:58:58.875: INFO: (9) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 27.699966ms)
Apr 26 10:58:58.875: INFO: (9) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 28.278806ms)
Apr 26 10:58:58.875: INFO: (9) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 28.044665ms)
Apr 26 10:58:58.880: INFO: (9) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 32.522874ms)
Apr 26 10:58:58.880: INFO: (9) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 33.131838ms)
Apr 26 10:58:58.881: INFO: (9) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 33.738419ms)
Apr 26 10:58:58.881: INFO: (9) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 33.995281ms)
Apr 26 10:58:58.909: INFO: (10) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 28.23667ms)
Apr 26 10:58:58.909: INFO: (10) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 28.226282ms)
Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 28.810761ms)
Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 28.245787ms)
Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 28.735116ms)
Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 28.880819ms)
Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 28.662717ms)
Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 28.691359ms)
Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 28.699702ms)
Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 29.047838ms)
Apr 26 10:58:58.918: INFO: (10) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 37.148618ms)
Apr 26 10:58:58.920: INFO: (10) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 38.626654ms)
Apr 26 10:58:58.920: INFO: (10) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 38.518259ms)
Apr 26 10:58:58.922: INFO: (10) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 40.908106ms)
Apr 26 10:58:58.922: INFO: (10) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 40.99353ms)
Apr 26 10:58:58.922: INFO: (10) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 40.883811ms)
Apr 26 10:58:58.946: INFO: (11) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 23.946099ms)
Apr 26 10:58:58.947: INFO: (11) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 24.311075ms)
Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 26.123803ms)
Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 26.035786ms)
Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 26.159106ms)
Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 26.265207ms)
Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 26.252945ms)
Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 26.200049ms)
Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 26.700229ms)
Apr 26 10:58:58.950: INFO: (11) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 27.400649ms)
Apr 26 10:58:58.950: INFO: (11) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 27.499435ms)
Apr 26 10:58:58.950: INFO: (11) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 27.660955ms)
Apr 26 10:58:58.950: INFO: (11) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 27.648444ms)
Apr 26 10:58:58.950: INFO: (11) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 27.490329ms)
Apr 26 10:58:58.958: INFO: (11) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 35.08497ms)
Apr 26 10:58:58.958: INFO: (11) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 35.142624ms)
Apr 26 10:58:58.998: INFO: (12) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 39.895245ms)
Apr 26 10:58:58.998: INFO: (12) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 39.743282ms)
Apr 26 10:58:58.998: INFO: (12) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 39.923386ms)
Apr 26 10:58:58.998: INFO: (12) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 40.19289ms)
Apr 26 10:58:58.998: INFO: (12) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 40.122514ms)
Apr 26 10:58:58.998: INFO: (12) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 40.391977ms)
Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 45.835832ms)
Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 45.792574ms)
Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 45.844637ms)
Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 45.82928ms)
Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 45.96825ms)
Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 46.058663ms)
Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 46.254193ms)
Apr 26 10:58:59.013: INFO: (12) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 54.818167ms)
Apr 26 10:58:59.013: INFO: (12) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 54.898551ms)
Apr 26 10:58:59.013: INFO: (12) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 55.244053ms)
Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 32.954545ms)
Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 32.936984ms)
Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 33.160916ms)
Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 33.092413ms)
Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 33.289097ms)
Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 33.125092ms)
Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 33.096681ms)
Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 33.146591ms)
Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 33.259714ms)
Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 33.351919ms)
Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 33.10781ms)
Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 33.64159ms)
Apr 26 10:58:59.052: INFO: (13) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 38.966641ms)
Apr 26 10:58:59.052: INFO: (13) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 38.639053ms)
Apr 26 10:58:59.053: INFO: (13) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 39.242808ms)
Apr 26 10:58:59.053: INFO: (13) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 38.811422ms)
Apr 26 10:58:59.075: INFO: (14) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 22.334036ms)
Apr 26 10:58:59.075: INFO: (14) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 22.478935ms)
Apr 26 10:58:59.076: INFO: (14) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.733744ms)
Apr 26 10:58:59.076: INFO: (14) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 22.637931ms)
Apr 26 10:58:59.076: INFO: (14) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.758598ms)
Apr 26 10:58:59.080: INFO: (14) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 27.332971ms)
Apr 26 10:58:59.080: INFO: (14) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 27.378633ms)
Apr 26 10:58:59.081: INFO: (14) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 27.529413ms)
Apr 26 10:58:59.081: INFO: (14) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 27.392827ms)
Apr 26 10:58:59.081: INFO: (14) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 27.582209ms)
Apr 26 10:58:59.081: INFO: (14) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 27.592658ms)
Apr 26 10:58:59.083: INFO: (14) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 30.635977ms)
Apr 26 10:58:59.084: INFO: (14) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 30.505884ms)
Apr 26 10:58:59.083: INFO: (14) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 30.449592ms)
Apr 26 10:58:59.085: INFO: (14) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 32.510136ms)
Apr 26 10:58:59.086: INFO: (14) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 32.290251ms)
Apr 26 10:58:59.103: INFO: (15) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 17.09622ms)
Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.195566ms)
Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 22.100045ms)
Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 22.410732ms)
Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 22.210262ms)
Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 22.756735ms)
Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 22.591748ms)
Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.479266ms)
Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 22.718165ms)
Apr 26 10:58:59.109: INFO: (15) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 22.651116ms)
Apr 26 10:58:59.109: INFO: (15) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 23.435895ms)
Apr 26 10:58:59.110: INFO: (15) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 23.672661ms)
Apr 26 10:58:59.110: INFO: (15) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 24.100951ms)
Apr 26 10:58:59.112: INFO: (15) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 26.778814ms)
Apr 26 10:58:59.116: INFO: (15) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 30.163277ms)
Apr 26 10:58:59.116: INFO: (15) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 30.396497ms)
Apr 26 10:58:59.134: INFO: (16) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 17.971102ms)
Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 22.629888ms)
Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.39213ms)
Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.500164ms)
Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.410893ms)
Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 22.506715ms)
Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 22.4976ms)
Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 22.723736ms)
Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 22.504351ms)
Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 22.742279ms)
Apr 26 10:58:59.141: INFO: (16) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 24.116499ms)
Apr 26 10:58:59.141: INFO: (16) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 24.217211ms)
Apr 26 10:58:59.142: INFO: (16) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 25.94722ms)
Apr 26 10:58:59.144: INFO: (16) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 28.283499ms)
Apr 26 10:58:59.145: INFO: (16) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 28.470645ms)
Apr 26 10:58:59.146: INFO: (16) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 29.089108ms)
Apr 26 10:58:59.166: INFO: (17) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 20.46145ms)
Apr 26 10:58:59.167: INFO: (17) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 21.604282ms)
Apr 26 10:58:59.167: INFO: (17) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 21.571303ms)
Apr 26 10:58:59.167: INFO: (17) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 21.596439ms)
Apr 26 10:58:59.168: INFO: (17) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 21.760925ms)
Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 27.525316ms)
Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 27.619296ms)
Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 27.713013ms)
Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 27.624154ms)
Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 27.840323ms)
Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 27.852033ms)
Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 27.928672ms)
Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 28.175866ms)
Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 28.445139ms)
Apr 26 10:58:59.216: INFO: (17) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 70.458199ms)
Apr 26 10:58:59.218: INFO: (17) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 72.525033ms)
Apr 26 10:58:59.243: INFO: (18) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 24.656679ms)
Apr 26 10:58:59.244: INFO: (18) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 24.924701ms)
Apr 26 10:58:59.244: INFO: (18) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 24.70697ms)
Apr 26 10:58:59.244: INFO: (18) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 25.060345ms)
Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 33.124821ms)
Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 32.780391ms)
Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 33.286702ms)
Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 33.026836ms)
Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 33.479469ms)
Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 33.24624ms)
Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 33.379289ms)
Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 33.211307ms)
Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 33.208231ms)
Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 33.193704ms)
Apr 26 10:58:59.263: INFO: (18) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 43.757172ms)
Apr 26 10:58:59.263: INFO: (18) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 44.308083ms)
Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 17.888606ms)
Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 18.043012ms)
Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 17.80243ms)
Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 18.023317ms)
Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 17.883696ms)
Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 18.006687ms)
Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 18.018868ms)
Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 18.198714ms)
Apr 26 10:58:59.286: INFO: (19) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 21.980079ms)
Apr 26 10:58:59.286: INFO: (19) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 21.999573ms)
Apr 26 10:58:59.286: INFO: (19) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.045718ms)
Apr 26 10:58:59.286: INFO: (19) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 22.086531ms)
Apr 26 10:58:59.293: INFO: (19) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 29.294205ms)
Apr 26 10:58:59.293: INFO: (19) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 29.722457ms)
Apr 26 10:58:59.294: INFO: (19) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 29.798573ms)
Apr 26 10:58:59.294: INFO: (19) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 29.741441ms)
STEP: deleting ReplicationController proxy-service-fmfpr in namespace proxy-3545, will wait for the garbage collector to delete the pods 04/26/24 10:58:59.294
Apr 26 10:58:59.357: INFO: Deleting ReplicationController proxy-service-fmfpr took: 7.880314ms
Apr 26 10:58:59.457: INFO: Terminating ReplicationController proxy-service-fmfpr pods took: 100.173081ms
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 26 10:59:00.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3545" for this suite. 04/26/24 10:59:00.873
{"msg":"PASSED [sig-network] Proxy version v1 should proxy through a service and a pod  [Conformance]","completed":10,"skipped":208,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.486 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    should proxy through a service and a pod  [Conformance]
    test/e2e/network/proxy.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:58:55.394
    Apr 26 10:58:55.394: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename proxy 04/26/24 10:58:55.395
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:58:55.412
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:58:55.417
    [It] should proxy through a service and a pod  [Conformance]
      test/e2e/network/proxy.go:101
    STEP: starting an echo server on multiple ports 04/26/24 10:58:55.452
    STEP: creating replication controller proxy-service-fmfpr in namespace proxy-3545 04/26/24 10:58:55.452
    I0426 10:58:55.464804      23 runners.go:193] Created replication controller with name: proxy-service-fmfpr, namespace: proxy-3545, replica count: 1
    I0426 10:58:56.515709      23 runners.go:193] proxy-service-fmfpr Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0426 10:58:57.516897      23 runners.go:193] proxy-service-fmfpr Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
    I0426 10:58:58.517098      23 runners.go:193] proxy-service-fmfpr Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 26 10:58:58.523: INFO: setup took 3.096930422s, starting test cases
    STEP: running 16 cases, 20 attempts per case, 320 total attempts 04/26/24 10:58:58.523
    Apr 26 10:58:58.563: INFO: (0) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 39.811143ms)
    Apr 26 10:58:58.563: INFO: (0) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 39.843722ms)
    Apr 26 10:58:58.565: INFO: (0) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 41.042777ms)
    Apr 26 10:58:58.568: INFO: (0) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 43.874667ms)
    Apr 26 10:58:58.570: INFO: (0) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 46.276333ms)
    Apr 26 10:58:58.572: INFO: (0) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 48.394901ms)
    Apr 26 10:58:58.575: INFO: (0) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 51.338764ms)
    Apr 26 10:58:58.577: INFO: (0) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 52.865136ms)
    Apr 26 10:58:58.577: INFO: (0) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 53.931563ms)
    Apr 26 10:58:58.578: INFO: (0) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 54.495456ms)
    Apr 26 10:58:58.578: INFO: (0) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 54.372735ms)
    Apr 26 10:58:58.578: INFO: (0) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 54.43018ms)
    Apr 26 10:58:58.587: INFO: (0) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 63.136066ms)
    Apr 26 10:58:58.587: INFO: (0) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 63.08238ms)
    Apr 26 10:58:58.595: INFO: (0) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 71.733108ms)
    Apr 26 10:58:58.598: INFO: (0) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 74.100302ms)
    Apr 26 10:58:58.613: INFO: (1) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 15.360297ms)
    Apr 26 10:58:58.615: INFO: (1) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 17.226983ms)
    Apr 26 10:58:58.615: INFO: (1) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 17.327192ms)
    Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 22.965296ms)
    Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 23.016429ms)
    Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.981645ms)
    Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 23.063532ms)
    Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 23.252422ms)
    Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 23.248417ms)
    Apr 26 10:58:58.621: INFO: (1) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 23.259937ms)
    Apr 26 10:58:58.622: INFO: (1) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 23.693144ms)
    Apr 26 10:58:58.622: INFO: (1) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 23.737805ms)
    Apr 26 10:58:58.623: INFO: (1) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 25.328764ms)
    Apr 26 10:58:58.625: INFO: (1) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 27.120244ms)
    Apr 26 10:58:58.625: INFO: (1) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 27.279621ms)
    Apr 26 10:58:58.627: INFO: (1) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 28.912795ms)
    Apr 26 10:58:58.644: INFO: (2) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 17.118699ms)
    Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.785763ms)
    Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 23.116006ms)
    Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 22.906721ms)
    Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 22.880443ms)
    Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.815817ms)
    Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 23.130623ms)
    Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 23.460255ms)
    Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 23.316256ms)
    Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 23.296421ms)
    Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 23.217629ms)
    Apr 26 10:58:58.650: INFO: (2) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 23.174803ms)
    Apr 26 10:58:58.657: INFO: (2) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 29.424815ms)
    Apr 26 10:58:58.657: INFO: (2) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 29.332088ms)
    Apr 26 10:58:58.657: INFO: (2) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 29.435185ms)
    Apr 26 10:58:58.657: INFO: (2) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 29.575497ms)
    Apr 26 10:58:58.679: INFO: (3) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 21.867583ms)
    Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.103798ms)
    Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 22.472731ms)
    Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 22.474985ms)
    Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 22.687718ms)
    Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 22.381347ms)
    Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 22.403867ms)
    Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 22.627498ms)
    Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 23.121036ms)
    Apr 26 10:58:58.680: INFO: (3) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 23.350869ms)
    Apr 26 10:58:58.681: INFO: (3) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.999037ms)
    Apr 26 10:58:58.681: INFO: (3) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 23.240309ms)
    Apr 26 10:58:58.686: INFO: (3) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 28.522394ms)
    Apr 26 10:58:58.686: INFO: (3) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 28.427313ms)
    Apr 26 10:58:58.686: INFO: (3) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 28.685408ms)
    Apr 26 10:58:58.686: INFO: (3) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 28.458709ms)
    Apr 26 10:58:58.710: INFO: (4) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 23.562019ms)
    Apr 26 10:58:58.711: INFO: (4) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 24.265264ms)
    Apr 26 10:58:58.711: INFO: (4) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 24.512307ms)
    Apr 26 10:58:58.711: INFO: (4) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 24.467756ms)
    Apr 26 10:58:58.711: INFO: (4) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 25.081341ms)
    Apr 26 10:58:58.711: INFO: (4) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 24.852308ms)
    Apr 26 10:58:58.711: INFO: (4) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 24.911966ms)
    Apr 26 10:58:58.712: INFO: (4) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 25.04312ms)
    Apr 26 10:58:58.712: INFO: (4) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 25.486287ms)
    Apr 26 10:58:58.712: INFO: (4) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 25.401765ms)
    Apr 26 10:58:58.712: INFO: (4) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 25.041428ms)
    Apr 26 10:58:58.712: INFO: (4) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 25.50976ms)
    Apr 26 10:58:58.716: INFO: (4) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 29.482941ms)
    Apr 26 10:58:58.716: INFO: (4) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 29.401735ms)
    Apr 26 10:58:58.716: INFO: (4) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 29.896444ms)
    Apr 26 10:58:58.716: INFO: (4) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 29.754889ms)
    Apr 26 10:58:58.739: INFO: (5) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 22.363125ms)
    Apr 26 10:58:58.739: INFO: (5) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 22.476156ms)
    Apr 26 10:58:58.739: INFO: (5) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 22.628801ms)
    Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 25.145495ms)
    Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 25.409189ms)
    Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 25.415259ms)
    Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 25.501776ms)
    Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 25.452626ms)
    Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 25.487309ms)
    Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 25.457425ms)
    Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 25.504741ms)
    Apr 26 10:58:58.742: INFO: (5) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 25.688752ms)
    Apr 26 10:58:58.749: INFO: (5) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 32.34233ms)
    Apr 26 10:58:58.749: INFO: (5) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 32.907276ms)
    Apr 26 10:58:58.750: INFO: (5) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 32.917132ms)
    Apr 26 10:58:58.750: INFO: (5) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 33.042428ms)
    Apr 26 10:58:58.767: INFO: (6) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 16.962988ms)
    Apr 26 10:58:58.772: INFO: (6) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.528822ms)
    Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 22.937906ms)
    Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.825615ms)
    Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.950329ms)
    Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 23.093716ms)
    Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 23.38511ms)
    Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 23.011269ms)
    Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 23.327707ms)
    Apr 26 10:58:58.773: INFO: (6) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 23.447112ms)
    Apr 26 10:58:58.774: INFO: (6) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 24.618768ms)
    Apr 26 10:58:58.774: INFO: (6) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 24.477543ms)
    Apr 26 10:58:58.774: INFO: (6) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 24.558229ms)
    Apr 26 10:58:58.777: INFO: (6) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 27.318ms)
    Apr 26 10:58:58.781: INFO: (6) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 30.66781ms)
    Apr 26 10:58:58.781: INFO: (6) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 30.845259ms)
    Apr 26 10:58:58.798: INFO: (7) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 17.335237ms)
    Apr 26 10:58:58.799: INFO: (7) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 17.98248ms)
    Apr 26 10:58:58.799: INFO: (7) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 17.828393ms)
    Apr 26 10:58:58.799: INFO: (7) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 18.012124ms)
    Apr 26 10:58:58.800: INFO: (7) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 18.838799ms)
    Apr 26 10:58:58.800: INFO: (7) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 18.812392ms)
    Apr 26 10:58:58.800: INFO: (7) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 19.017411ms)
    Apr 26 10:58:58.807: INFO: (7) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 26.560238ms)
    Apr 26 10:58:58.807: INFO: (7) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 26.729982ms)
    Apr 26 10:58:58.807: INFO: (7) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 26.637736ms)
    Apr 26 10:58:58.807: INFO: (7) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 26.576787ms)
    Apr 26 10:58:58.807: INFO: (7) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 26.835622ms)
    Apr 26 10:58:58.807: INFO: (7) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 26.60664ms)
    Apr 26 10:58:58.808: INFO: (7) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 26.742806ms)
    Apr 26 10:58:58.808: INFO: (7) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 26.704788ms)
    Apr 26 10:58:58.817: INFO: (7) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 35.916444ms)
    Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 23.244978ms)
    Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 23.375051ms)
    Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 23.118291ms)
    Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 23.226325ms)
    Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 23.41249ms)
    Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 23.355837ms)
    Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 23.332507ms)
    Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 23.433718ms)
    Apr 26 10:58:58.840: INFO: (8) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 23.562929ms)
    Apr 26 10:58:58.841: INFO: (8) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 23.484069ms)
    Apr 26 10:58:58.841: INFO: (8) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 23.577006ms)
    Apr 26 10:58:58.841: INFO: (8) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 24.232664ms)
    Apr 26 10:58:58.844: INFO: (8) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 26.951099ms)
    Apr 26 10:58:58.847: INFO: (8) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 29.465088ms)
    Apr 26 10:58:58.847: INFO: (8) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 29.634393ms)
    Apr 26 10:58:58.847: INFO: (8) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 29.593149ms)
    Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 27.09035ms)
    Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 27.26816ms)
    Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 27.247843ms)
    Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 27.238367ms)
    Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 27.160286ms)
    Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 26.950288ms)
    Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 27.473627ms)
    Apr 26 10:58:58.874: INFO: (9) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 27.388917ms)
    Apr 26 10:58:58.875: INFO: (9) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 27.671154ms)
    Apr 26 10:58:58.875: INFO: (9) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 27.699966ms)
    Apr 26 10:58:58.875: INFO: (9) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 28.278806ms)
    Apr 26 10:58:58.875: INFO: (9) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 28.044665ms)
    Apr 26 10:58:58.880: INFO: (9) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 32.522874ms)
    Apr 26 10:58:58.880: INFO: (9) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 33.131838ms)
    Apr 26 10:58:58.881: INFO: (9) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 33.738419ms)
    Apr 26 10:58:58.881: INFO: (9) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 33.995281ms)
    Apr 26 10:58:58.909: INFO: (10) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 28.23667ms)
    Apr 26 10:58:58.909: INFO: (10) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 28.226282ms)
    Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 28.810761ms)
    Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 28.245787ms)
    Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 28.735116ms)
    Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 28.880819ms)
    Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 28.662717ms)
    Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 28.691359ms)
    Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 28.699702ms)
    Apr 26 10:58:58.910: INFO: (10) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 29.047838ms)
    Apr 26 10:58:58.918: INFO: (10) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 37.148618ms)
    Apr 26 10:58:58.920: INFO: (10) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 38.626654ms)
    Apr 26 10:58:58.920: INFO: (10) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 38.518259ms)
    Apr 26 10:58:58.922: INFO: (10) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 40.908106ms)
    Apr 26 10:58:58.922: INFO: (10) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 40.99353ms)
    Apr 26 10:58:58.922: INFO: (10) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 40.883811ms)
    Apr 26 10:58:58.946: INFO: (11) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 23.946099ms)
    Apr 26 10:58:58.947: INFO: (11) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 24.311075ms)
    Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 26.123803ms)
    Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 26.035786ms)
    Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 26.159106ms)
    Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 26.265207ms)
    Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 26.252945ms)
    Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 26.200049ms)
    Apr 26 10:58:58.949: INFO: (11) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 26.700229ms)
    Apr 26 10:58:58.950: INFO: (11) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 27.400649ms)
    Apr 26 10:58:58.950: INFO: (11) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 27.499435ms)
    Apr 26 10:58:58.950: INFO: (11) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 27.660955ms)
    Apr 26 10:58:58.950: INFO: (11) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 27.648444ms)
    Apr 26 10:58:58.950: INFO: (11) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 27.490329ms)
    Apr 26 10:58:58.958: INFO: (11) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 35.08497ms)
    Apr 26 10:58:58.958: INFO: (11) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 35.142624ms)
    Apr 26 10:58:58.998: INFO: (12) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 39.895245ms)
    Apr 26 10:58:58.998: INFO: (12) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 39.743282ms)
    Apr 26 10:58:58.998: INFO: (12) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 39.923386ms)
    Apr 26 10:58:58.998: INFO: (12) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 40.19289ms)
    Apr 26 10:58:58.998: INFO: (12) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 40.122514ms)
    Apr 26 10:58:58.998: INFO: (12) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 40.391977ms)
    Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 45.835832ms)
    Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 45.792574ms)
    Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 45.844637ms)
    Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 45.82928ms)
    Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 45.96825ms)
    Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 46.058663ms)
    Apr 26 10:58:59.004: INFO: (12) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 46.254193ms)
    Apr 26 10:58:59.013: INFO: (12) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 54.818167ms)
    Apr 26 10:58:59.013: INFO: (12) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 54.898551ms)
    Apr 26 10:58:59.013: INFO: (12) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 55.244053ms)
    Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 32.954545ms)
    Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 32.936984ms)
    Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 33.160916ms)
    Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 33.092413ms)
    Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 33.289097ms)
    Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 33.125092ms)
    Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 33.096681ms)
    Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 33.146591ms)
    Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 33.259714ms)
    Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 33.351919ms)
    Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 33.10781ms)
    Apr 26 10:58:59.047: INFO: (13) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 33.64159ms)
    Apr 26 10:58:59.052: INFO: (13) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 38.966641ms)
    Apr 26 10:58:59.052: INFO: (13) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 38.639053ms)
    Apr 26 10:58:59.053: INFO: (13) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 39.242808ms)
    Apr 26 10:58:59.053: INFO: (13) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 38.811422ms)
    Apr 26 10:58:59.075: INFO: (14) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 22.334036ms)
    Apr 26 10:58:59.075: INFO: (14) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 22.478935ms)
    Apr 26 10:58:59.076: INFO: (14) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.733744ms)
    Apr 26 10:58:59.076: INFO: (14) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 22.637931ms)
    Apr 26 10:58:59.076: INFO: (14) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.758598ms)
    Apr 26 10:58:59.080: INFO: (14) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 27.332971ms)
    Apr 26 10:58:59.080: INFO: (14) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 27.378633ms)
    Apr 26 10:58:59.081: INFO: (14) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 27.529413ms)
    Apr 26 10:58:59.081: INFO: (14) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 27.392827ms)
    Apr 26 10:58:59.081: INFO: (14) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 27.582209ms)
    Apr 26 10:58:59.081: INFO: (14) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 27.592658ms)
    Apr 26 10:58:59.083: INFO: (14) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 30.635977ms)
    Apr 26 10:58:59.084: INFO: (14) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 30.505884ms)
    Apr 26 10:58:59.083: INFO: (14) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 30.449592ms)
    Apr 26 10:58:59.085: INFO: (14) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 32.510136ms)
    Apr 26 10:58:59.086: INFO: (14) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 32.290251ms)
    Apr 26 10:58:59.103: INFO: (15) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 17.09622ms)
    Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.195566ms)
    Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 22.100045ms)
    Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 22.410732ms)
    Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 22.210262ms)
    Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 22.756735ms)
    Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 22.591748ms)
    Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.479266ms)
    Apr 26 10:58:59.108: INFO: (15) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 22.718165ms)
    Apr 26 10:58:59.109: INFO: (15) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 22.651116ms)
    Apr 26 10:58:59.109: INFO: (15) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 23.435895ms)
    Apr 26 10:58:59.110: INFO: (15) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 23.672661ms)
    Apr 26 10:58:59.110: INFO: (15) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 24.100951ms)
    Apr 26 10:58:59.112: INFO: (15) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 26.778814ms)
    Apr 26 10:58:59.116: INFO: (15) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 30.163277ms)
    Apr 26 10:58:59.116: INFO: (15) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 30.396497ms)
    Apr 26 10:58:59.134: INFO: (16) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 17.971102ms)
    Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 22.629888ms)
    Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.39213ms)
    Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.500164ms)
    Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 22.410893ms)
    Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 22.506715ms)
    Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 22.4976ms)
    Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 22.723736ms)
    Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 22.504351ms)
    Apr 26 10:58:59.139: INFO: (16) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 22.742279ms)
    Apr 26 10:58:59.141: INFO: (16) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 24.116499ms)
    Apr 26 10:58:59.141: INFO: (16) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 24.217211ms)
    Apr 26 10:58:59.142: INFO: (16) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 25.94722ms)
    Apr 26 10:58:59.144: INFO: (16) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 28.283499ms)
    Apr 26 10:58:59.145: INFO: (16) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 28.470645ms)
    Apr 26 10:58:59.146: INFO: (16) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 29.089108ms)
    Apr 26 10:58:59.166: INFO: (17) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 20.46145ms)
    Apr 26 10:58:59.167: INFO: (17) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 21.604282ms)
    Apr 26 10:58:59.167: INFO: (17) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 21.571303ms)
    Apr 26 10:58:59.167: INFO: (17) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 21.596439ms)
    Apr 26 10:58:59.168: INFO: (17) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 21.760925ms)
    Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 27.525316ms)
    Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 27.619296ms)
    Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 27.713013ms)
    Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 27.624154ms)
    Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 27.840323ms)
    Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 27.852033ms)
    Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 27.928672ms)
    Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 28.175866ms)
    Apr 26 10:58:59.174: INFO: (17) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 28.445139ms)
    Apr 26 10:58:59.216: INFO: (17) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 70.458199ms)
    Apr 26 10:58:59.218: INFO: (17) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 72.525033ms)
    Apr 26 10:58:59.243: INFO: (18) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 24.656679ms)
    Apr 26 10:58:59.244: INFO: (18) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 24.924701ms)
    Apr 26 10:58:59.244: INFO: (18) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 24.70697ms)
    Apr 26 10:58:59.244: INFO: (18) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 25.060345ms)
    Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 33.124821ms)
    Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 32.780391ms)
    Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 33.286702ms)
    Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 33.026836ms)
    Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 33.479469ms)
    Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 33.24624ms)
    Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 33.379289ms)
    Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 33.211307ms)
    Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 33.208231ms)
    Apr 26 10:58:59.252: INFO: (18) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 33.193704ms)
    Apr 26 10:58:59.263: INFO: (18) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 43.757172ms)
    Apr 26 10:58:59.263: INFO: (18) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 44.308083ms)
    Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr/proxy/rewriteme">test</a> (200; 17.888606ms)
    Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname2/proxy/: bar (200; 18.043012ms)
    Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">... (200; 17.80243ms)
    Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname2/proxy/: tls qux (200; 18.023317ms)
    Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 17.883696ms)
    Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:462/proxy/: tls qux (200; 18.006687ms)
    Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 18.018868ms)
    Apr 26 10:58:59.282: INFO: (19) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:160/proxy/: foo (200; 18.198714ms)
    Apr 26 10:58:59.286: INFO: (19) /api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/proxy-service-fmfpr-lngkr:1080/proxy/rewriteme">test<... (200; 21.980079ms)
    Apr 26 10:58:59.286: INFO: (19) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/: <a href="/api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:443/proxy/tlsrewritem... (200; 21.999573ms)
    Apr 26 10:58:59.286: INFO: (19) /api/v1/namespaces/proxy-3545/pods/https:proxy-service-fmfpr-lngkr:460/proxy/: tls baz (200; 22.045718ms)
    Apr 26 10:58:59.286: INFO: (19) /api/v1/namespaces/proxy-3545/services/https:proxy-service-fmfpr:tlsportname1/proxy/: tls baz (200; 22.086531ms)
    Apr 26 10:58:59.293: INFO: (19) /api/v1/namespaces/proxy-3545/services/http:proxy-service-fmfpr:portname1/proxy/: foo (200; 29.294205ms)
    Apr 26 10:58:59.293: INFO: (19) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname1/proxy/: foo (200; 29.722457ms)
    Apr 26 10:58:59.294: INFO: (19) /api/v1/namespaces/proxy-3545/pods/http:proxy-service-fmfpr-lngkr:162/proxy/: bar (200; 29.798573ms)
    Apr 26 10:58:59.294: INFO: (19) /api/v1/namespaces/proxy-3545/services/proxy-service-fmfpr:portname2/proxy/: bar (200; 29.741441ms)
    STEP: deleting ReplicationController proxy-service-fmfpr in namespace proxy-3545, will wait for the garbage collector to delete the pods 04/26/24 10:58:59.294
    Apr 26 10:58:59.357: INFO: Deleting ReplicationController proxy-service-fmfpr took: 7.880314ms
    Apr 26 10:58:59.457: INFO: Terminating ReplicationController proxy-service-fmfpr pods took: 100.173081ms
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 26 10:59:00.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-3545" for this suite. 04/26/24 10:59:00.873
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:59:00.881
Apr 26 10:59:00.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 10:59:00.882
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:00.934
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:00.944
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156
STEP: Creating a pod to test emptydir volume type on node default medium 04/26/24 10:59:00.951
Apr 26 10:59:00.966: INFO: Waiting up to 5m0s for pod "pod-4af96ea4-c15e-4d3e-b824-4e31a952412e" in namespace "emptydir-8128" to be "Succeeded or Failed"
Apr 26 10:59:00.973: INFO: Pod "pod-4af96ea4-c15e-4d3e-b824-4e31a952412e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.240218ms
Apr 26 10:59:02.983: INFO: Pod "pod-4af96ea4-c15e-4d3e-b824-4e31a952412e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01607415s
Apr 26 10:59:04.980: INFO: Pod "pod-4af96ea4-c15e-4d3e-b824-4e31a952412e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013245465s
STEP: Saw pod success 04/26/24 10:59:04.98
Apr 26 10:59:04.980: INFO: Pod "pod-4af96ea4-c15e-4d3e-b824-4e31a952412e" satisfied condition "Succeeded or Failed"
Apr 26 10:59:04.985: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-4af96ea4-c15e-4d3e-b824-4e31a952412e container test-container: <nil>
STEP: delete the pod 04/26/24 10:59:05.001
Apr 26 10:59:05.020: INFO: Waiting for pod pod-4af96ea4-c15e-4d3e-b824-4e31a952412e to disappear
Apr 26 10:59:05.026: INFO: Pod pod-4af96ea4-c15e-4d3e-b824-4e31a952412e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 10:59:05.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8128" for this suite. 04/26/24 10:59:05.037
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":11,"skipped":240,"failed":0}
------------------------------
â€¢ [4.164 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:59:00.881
    Apr 26 10:59:00.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 10:59:00.882
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:00.934
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:00.944
    [It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:156
    STEP: Creating a pod to test emptydir volume type on node default medium 04/26/24 10:59:00.951
    Apr 26 10:59:00.966: INFO: Waiting up to 5m0s for pod "pod-4af96ea4-c15e-4d3e-b824-4e31a952412e" in namespace "emptydir-8128" to be "Succeeded or Failed"
    Apr 26 10:59:00.973: INFO: Pod "pod-4af96ea4-c15e-4d3e-b824-4e31a952412e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.240218ms
    Apr 26 10:59:02.983: INFO: Pod "pod-4af96ea4-c15e-4d3e-b824-4e31a952412e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01607415s
    Apr 26 10:59:04.980: INFO: Pod "pod-4af96ea4-c15e-4d3e-b824-4e31a952412e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013245465s
    STEP: Saw pod success 04/26/24 10:59:04.98
    Apr 26 10:59:04.980: INFO: Pod "pod-4af96ea4-c15e-4d3e-b824-4e31a952412e" satisfied condition "Succeeded or Failed"
    Apr 26 10:59:04.985: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-4af96ea4-c15e-4d3e-b824-4e31a952412e container test-container: <nil>
    STEP: delete the pod 04/26/24 10:59:05.001
    Apr 26 10:59:05.020: INFO: Waiting for pod pod-4af96ea4-c15e-4d3e-b824-4e31a952412e to disappear
    Apr 26 10:59:05.026: INFO: Pod pod-4af96ea4-c15e-4d3e-b824-4e31a952412e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 10:59:05.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8128" for this suite. 04/26/24 10:59:05.037
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:59:05.045
Apr 26 10:59:05.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 10:59:05.046
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:05.068
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:05.073
[It] works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68
Apr 26 10:59:05.078: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 04/26/24 10:59:08.318
Apr 26 10:59:08.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 create -f -'
Apr 26 10:59:08.887: INFO: stderr: ""
Apr 26 10:59:08.887: INFO: stdout: "e2e-test-crd-publish-openapi-5475-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 26 10:59:08.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 delete e2e-test-crd-publish-openapi-5475-crds test-foo'
Apr 26 10:59:08.961: INFO: stderr: ""
Apr 26 10:59:08.961: INFO: stdout: "e2e-test-crd-publish-openapi-5475-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr 26 10:59:08.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 apply -f -'
Apr 26 10:59:09.134: INFO: stderr: ""
Apr 26 10:59:09.134: INFO: stdout: "e2e-test-crd-publish-openapi-5475-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 26 10:59:09.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 delete e2e-test-crd-publish-openapi-5475-crds test-foo'
Apr 26 10:59:09.204: INFO: stderr: ""
Apr 26 10:59:09.204: INFO: stdout: "e2e-test-crd-publish-openapi-5475-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 04/26/24 10:59:09.204
Apr 26 10:59:09.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 create -f -'
Apr 26 10:59:09.338: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 04/26/24 10:59:09.338
Apr 26 10:59:09.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 create -f -'
Apr 26 10:59:09.488: INFO: rc: 1
Apr 26 10:59:09.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 apply -f -'
Apr 26 10:59:09.639: INFO: rc: 1
STEP: kubectl validation (kubectl create and apply) rejects request without required properties 04/26/24 10:59:09.639
Apr 26 10:59:09.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 create -f -'
Apr 26 10:59:10.004: INFO: rc: 1
Apr 26 10:59:10.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 apply -f -'
Apr 26 10:59:10.163: INFO: rc: 1
STEP: kubectl explain works to explain CR properties 04/26/24 10:59:10.163
Apr 26 10:59:10.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 explain e2e-test-crd-publish-openapi-5475-crds'
Apr 26 10:59:10.302: INFO: stderr: ""
Apr 26 10:59:10.302: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5475-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively 04/26/24 10:59:10.302
Apr 26 10:59:10.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 explain e2e-test-crd-publish-openapi-5475-crds.metadata'
Apr 26 10:59:10.545: INFO: stderr: ""
Apr 26 10:59:10.545: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5475-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr 26 10:59:10.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 explain e2e-test-crd-publish-openapi-5475-crds.spec'
Apr 26 10:59:10.687: INFO: stderr: ""
Apr 26 10:59:10.687: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5475-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr 26 10:59:10.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 explain e2e-test-crd-publish-openapi-5475-crds.spec.bars'
Apr 26 10:59:10.831: INFO: stderr: ""
Apr 26 10:59:10.831: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5475-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist 04/26/24 10:59:10.831
Apr 26 10:59:10.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 explain e2e-test-crd-publish-openapi-5475-crds.spec.bars2'
Apr 26 10:59:10.972: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 10:59:13.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5561" for this suite. 04/26/24 10:59:13.167
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]","completed":12,"skipped":243,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.130 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:59:05.045
    Apr 26 10:59:05.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 10:59:05.046
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:05.068
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:05.073
    [It] works for CRD with validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:68
    Apr 26 10:59:05.078: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: kubectl validation (kubectl create and apply) allows request with known and required properties 04/26/24 10:59:08.318
    Apr 26 10:59:08.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 create -f -'
    Apr 26 10:59:08.887: INFO: stderr: ""
    Apr 26 10:59:08.887: INFO: stdout: "e2e-test-crd-publish-openapi-5475-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Apr 26 10:59:08.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 delete e2e-test-crd-publish-openapi-5475-crds test-foo'
    Apr 26 10:59:08.961: INFO: stderr: ""
    Apr 26 10:59:08.961: INFO: stdout: "e2e-test-crd-publish-openapi-5475-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    Apr 26 10:59:08.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 apply -f -'
    Apr 26 10:59:09.134: INFO: stderr: ""
    Apr 26 10:59:09.134: INFO: stdout: "e2e-test-crd-publish-openapi-5475-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
    Apr 26 10:59:09.134: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 delete e2e-test-crd-publish-openapi-5475-crds test-foo'
    Apr 26 10:59:09.204: INFO: stderr: ""
    Apr 26 10:59:09.204: INFO: stdout: "e2e-test-crd-publish-openapi-5475-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
    STEP: kubectl validation (kubectl create and apply) rejects request with value outside defined enum values 04/26/24 10:59:09.204
    Apr 26 10:59:09.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 create -f -'
    Apr 26 10:59:09.338: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema 04/26/24 10:59:09.338
    Apr 26 10:59:09.338: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 create -f -'
    Apr 26 10:59:09.488: INFO: rc: 1
    Apr 26 10:59:09.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 apply -f -'
    Apr 26 10:59:09.639: INFO: rc: 1
    STEP: kubectl validation (kubectl create and apply) rejects request without required properties 04/26/24 10:59:09.639
    Apr 26 10:59:09.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 create -f -'
    Apr 26 10:59:10.004: INFO: rc: 1
    Apr 26 10:59:10.004: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 --namespace=crd-publish-openapi-5561 apply -f -'
    Apr 26 10:59:10.163: INFO: rc: 1
    STEP: kubectl explain works to explain CR properties 04/26/24 10:59:10.163
    Apr 26 10:59:10.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 explain e2e-test-crd-publish-openapi-5475-crds'
    Apr 26 10:59:10.302: INFO: stderr: ""
    Apr 26 10:59:10.302: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5475-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
    STEP: kubectl explain works to explain CR properties recursively 04/26/24 10:59:10.302
    Apr 26 10:59:10.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 explain e2e-test-crd-publish-openapi-5475-crds.metadata'
    Apr 26 10:59:10.545: INFO: stderr: ""
    Apr 26 10:59:10.545: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5475-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC.\n\n     Populated by the system. Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested.\n\n     Populated by the system when a graceful deletion is requested. Read-only.\n     More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed. Finalizers may be processed and removed in\n     any order. Order is NOT enforced because it introduces significant risk of\n     stuck finalizers. finalizers is a shared field, any actor with permission\n     can reorder it. If the finalizer list is processed in order, then this can\n     lead to a situation in which the component responsible for the first\n     finalizer in the list is waiting for a signal (field value, external\n     system, or other) produced by a component responsible for a finalizer later\n     in the list, resulting in a deadlock. Without enforced ordering finalizers\n     are free to order amongst themselves and are not vulnerable to ordering\n     changes in the list.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server.\n\n     If this field is specified and the generated name exists, the server will\n     return a 409.\n\n     Applied only if Name is not specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within which each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty.\n\n     Must be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources.\n\n     Populated by the system. Read-only. Value must be treated as opaque by\n     clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     Deprecated: selfLink is a legacy read-only field that is no longer\n     populated by the system.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations.\n\n     Populated by the system. Read-only. More info:\n     http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
    Apr 26 10:59:10.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 explain e2e-test-crd-publish-openapi-5475-crds.spec'
    Apr 26 10:59:10.687: INFO: stderr: ""
    Apr 26 10:59:10.687: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5475-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
    Apr 26 10:59:10.687: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 explain e2e-test-crd-publish-openapi-5475-crds.spec.bars'
    Apr 26 10:59:10.831: INFO: stderr: ""
    Apr 26 10:59:10.831: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5475-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   feeling\t<string>\n     Whether Bar is feeling great.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
    STEP: kubectl explain works to return error when explain is called on property that doesn't exist 04/26/24 10:59:10.831
    Apr 26 10:59:10.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-5561 explain e2e-test-crd-publish-openapi-5475-crds.spec.bars2'
    Apr 26 10:59:10.972: INFO: rc: 1
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 10:59:13.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-5561" for this suite. 04/26/24 10:59:13.167
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:59:13.176
Apr 26 10:59:13.177: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename disruption 04/26/24 10:59:13.177
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:13.197
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:13.202
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163
STEP: Waiting for the pdb to be processed 04/26/24 10:59:13.212
STEP: Updating PodDisruptionBudget status 04/26/24 10:59:15.221
STEP: Waiting for all pods to be running 04/26/24 10:59:15.233
Apr 26 10:59:15.239: INFO: running pods: 0 < 1
STEP: locating a running pod 04/26/24 10:59:17.245
STEP: Waiting for the pdb to be processed 04/26/24 10:59:17.265
STEP: Patching PodDisruptionBudget status 04/26/24 10:59:17.277
STEP: Waiting for the pdb to be processed 04/26/24 10:59:17.287
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 26 10:59:17.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2518" for this suite. 04/26/24 10:59:17.299
{"msg":"PASSED [sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]","completed":13,"skipped":270,"failed":0}
------------------------------
â€¢ [4.128 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should update/patch PodDisruptionBudget status [Conformance]
  test/e2e/apps/disruption.go:163

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:59:13.176
    Apr 26 10:59:13.177: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename disruption 04/26/24 10:59:13.177
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:13.197
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:13.202
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should update/patch PodDisruptionBudget status [Conformance]
      test/e2e/apps/disruption.go:163
    STEP: Waiting for the pdb to be processed 04/26/24 10:59:13.212
    STEP: Updating PodDisruptionBudget status 04/26/24 10:59:15.221
    STEP: Waiting for all pods to be running 04/26/24 10:59:15.233
    Apr 26 10:59:15.239: INFO: running pods: 0 < 1
    STEP: locating a running pod 04/26/24 10:59:17.245
    STEP: Waiting for the pdb to be processed 04/26/24 10:59:17.265
    STEP: Patching PodDisruptionBudget status 04/26/24 10:59:17.277
    STEP: Waiting for the pdb to be processed 04/26/24 10:59:17.287
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 26 10:59:17.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2518" for this suite. 04/26/24 10:59:17.299
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:59:17.305
Apr 26 10:59:17.305: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename subpath 04/26/24 10:59:17.306
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:17.319
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:17.323
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/26/24 10:59:17.328
[It] should support subpaths with configmap pod [Conformance]
  test/e2e/storage/subpath.go:70
STEP: Creating pod pod-subpath-test-configmap-l2vt 04/26/24 10:59:17.356
STEP: Creating a pod to test atomic-volume-subpath 04/26/24 10:59:17.356
Apr 26 10:59:17.370: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-l2vt" in namespace "subpath-7032" to be "Succeeded or Failed"
Apr 26 10:59:17.376: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Pending", Reason="", readiness=false. Elapsed: 6.131761ms
Apr 26 10:59:19.382: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 2.012547571s
Apr 26 10:59:21.404: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 4.03419016s
Apr 26 10:59:23.384: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 6.014301152s
Apr 26 10:59:25.384: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 8.014159943s
Apr 26 10:59:27.383: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 10.012881637s
Apr 26 10:59:29.383: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 12.01330296s
Apr 26 10:59:31.383: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 14.013084243s
Apr 26 10:59:33.383: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 16.013182062s
Apr 26 10:59:35.387: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 18.017278253s
Apr 26 10:59:37.383: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 20.013618797s
Apr 26 10:59:39.384: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=false. Elapsed: 22.013957878s
Apr 26 10:59:41.382: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012487936s
STEP: Saw pod success 04/26/24 10:59:41.383
Apr 26 10:59:41.383: INFO: Pod "pod-subpath-test-configmap-l2vt" satisfied condition "Succeeded or Failed"
Apr 26 10:59:41.388: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-subpath-test-configmap-l2vt container test-container-subpath-configmap-l2vt: <nil>
STEP: delete the pod 04/26/24 10:59:41.408
Apr 26 10:59:41.427: INFO: Waiting for pod pod-subpath-test-configmap-l2vt to disappear
Apr 26 10:59:41.434: INFO: Pod pod-subpath-test-configmap-l2vt no longer exists
STEP: Deleting pod pod-subpath-test-configmap-l2vt 04/26/24 10:59:41.434
Apr 26 10:59:41.434: INFO: Deleting pod "pod-subpath-test-configmap-l2vt" in namespace "subpath-7032"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 26 10:59:41.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7032" for this suite. 04/26/24 10:59:41.447
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]","completed":14,"skipped":272,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.150 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod [Conformance]
    test/e2e/storage/subpath.go:70

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:59:17.305
    Apr 26 10:59:17.305: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename subpath 04/26/24 10:59:17.306
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:17.319
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:17.323
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/26/24 10:59:17.328
    [It] should support subpaths with configmap pod [Conformance]
      test/e2e/storage/subpath.go:70
    STEP: Creating pod pod-subpath-test-configmap-l2vt 04/26/24 10:59:17.356
    STEP: Creating a pod to test atomic-volume-subpath 04/26/24 10:59:17.356
    Apr 26 10:59:17.370: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-l2vt" in namespace "subpath-7032" to be "Succeeded or Failed"
    Apr 26 10:59:17.376: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Pending", Reason="", readiness=false. Elapsed: 6.131761ms
    Apr 26 10:59:19.382: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 2.012547571s
    Apr 26 10:59:21.404: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 4.03419016s
    Apr 26 10:59:23.384: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 6.014301152s
    Apr 26 10:59:25.384: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 8.014159943s
    Apr 26 10:59:27.383: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 10.012881637s
    Apr 26 10:59:29.383: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 12.01330296s
    Apr 26 10:59:31.383: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 14.013084243s
    Apr 26 10:59:33.383: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 16.013182062s
    Apr 26 10:59:35.387: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 18.017278253s
    Apr 26 10:59:37.383: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=true. Elapsed: 20.013618797s
    Apr 26 10:59:39.384: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Running", Reason="", readiness=false. Elapsed: 22.013957878s
    Apr 26 10:59:41.382: INFO: Pod "pod-subpath-test-configmap-l2vt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.012487936s
    STEP: Saw pod success 04/26/24 10:59:41.383
    Apr 26 10:59:41.383: INFO: Pod "pod-subpath-test-configmap-l2vt" satisfied condition "Succeeded or Failed"
    Apr 26 10:59:41.388: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-subpath-test-configmap-l2vt container test-container-subpath-configmap-l2vt: <nil>
    STEP: delete the pod 04/26/24 10:59:41.408
    Apr 26 10:59:41.427: INFO: Waiting for pod pod-subpath-test-configmap-l2vt to disappear
    Apr 26 10:59:41.434: INFO: Pod pod-subpath-test-configmap-l2vt no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-l2vt 04/26/24 10:59:41.434
    Apr 26 10:59:41.434: INFO: Deleting pod "pod-subpath-test-configmap-l2vt" in namespace "subpath-7032"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 26 10:59:41.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-7032" for this suite. 04/26/24 10:59:41.447
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Downward API
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:59:41.455
Apr 26 10:59:41.456: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 10:59:41.457
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:41.477
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:41.484
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43
STEP: Creating a pod to test downward api env vars 04/26/24 10:59:41.489
Apr 26 10:59:41.503: INFO: Waiting up to 5m0s for pod "downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8" in namespace "downward-api-9238" to be "Succeeded or Failed"
Apr 26 10:59:41.511: INFO: Pod "downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.425176ms
Apr 26 10:59:43.518: INFO: Pod "downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014722425s
Apr 26 10:59:45.520: INFO: Pod "downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016284575s
STEP: Saw pod success 04/26/24 10:59:45.52
Apr 26 10:59:45.520: INFO: Pod "downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8" satisfied condition "Succeeded or Failed"
Apr 26 10:59:45.525: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8 container dapi-container: <nil>
STEP: delete the pod 04/26/24 10:59:45.54
Apr 26 10:59:45.564: INFO: Waiting for pod downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8 to disappear
Apr 26 10:59:45.568: INFO: Pod downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 26 10:59:45.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9238" for this suite. 04/26/24 10:59:45.576
{"msg":"PASSED [sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]","completed":15,"skipped":273,"failed":0}
------------------------------
â€¢ [4.126 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:59:41.455
    Apr 26 10:59:41.456: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 10:59:41.457
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:41.477
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:41.484
    [It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:43
    STEP: Creating a pod to test downward api env vars 04/26/24 10:59:41.489
    Apr 26 10:59:41.503: INFO: Waiting up to 5m0s for pod "downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8" in namespace "downward-api-9238" to be "Succeeded or Failed"
    Apr 26 10:59:41.511: INFO: Pod "downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8": Phase="Pending", Reason="", readiness=false. Elapsed: 7.425176ms
    Apr 26 10:59:43.518: INFO: Pod "downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014722425s
    Apr 26 10:59:45.520: INFO: Pod "downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016284575s
    STEP: Saw pod success 04/26/24 10:59:45.52
    Apr 26 10:59:45.520: INFO: Pod "downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8" satisfied condition "Succeeded or Failed"
    Apr 26 10:59:45.525: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8 container dapi-container: <nil>
    STEP: delete the pod 04/26/24 10:59:45.54
    Apr 26 10:59:45.564: INFO: Waiting for pod downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8 to disappear
    Apr 26 10:59:45.568: INFO: Pod downward-api-7ba1224e-3276-43aa-8a08-54ef41e27bf8 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 26 10:59:45.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9238" for this suite. 04/26/24 10:59:45.576
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:59:45.583
Apr 26 10:59:45.583: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pods 04/26/24 10:59:45.584
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:45.598
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:45.604
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535
Apr 26 10:59:45.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: creating the pod 04/26/24 10:59:45.611
STEP: submitting the pod to kubernetes 04/26/24 10:59:45.611
Apr 26 10:59:45.624: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-d0fc5385-5bf8-4701-8744-a4087f074c80" in namespace "pods-7953" to be "running and ready"
Apr 26 10:59:45.628: INFO: Pod "pod-exec-websocket-d0fc5385-5bf8-4701-8744-a4087f074c80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.745975ms
Apr 26 10:59:45.628: INFO: The phase of Pod pod-exec-websocket-d0fc5385-5bf8-4701-8744-a4087f074c80 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 10:59:47.634: INFO: Pod "pod-exec-websocket-d0fc5385-5bf8-4701-8744-a4087f074c80": Phase="Running", Reason="", readiness=true. Elapsed: 2.010337218s
Apr 26 10:59:47.634: INFO: The phase of Pod pod-exec-websocket-d0fc5385-5bf8-4701-8744-a4087f074c80 is Running (Ready = true)
Apr 26 10:59:47.634: INFO: Pod "pod-exec-websocket-d0fc5385-5bf8-4701-8744-a4087f074c80" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 26 10:59:47.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7953" for this suite. 04/26/24 10:59:47.852
{"msg":"PASSED [sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]","completed":16,"skipped":289,"failed":0}
------------------------------
â€¢ [2.277 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support remote command execution over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:535

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:59:45.583
    Apr 26 10:59:45.583: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pods 04/26/24 10:59:45.584
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:45.598
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:45.604
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support remote command execution over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:535
    Apr 26 10:59:45.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: creating the pod 04/26/24 10:59:45.611
    STEP: submitting the pod to kubernetes 04/26/24 10:59:45.611
    Apr 26 10:59:45.624: INFO: Waiting up to 5m0s for pod "pod-exec-websocket-d0fc5385-5bf8-4701-8744-a4087f074c80" in namespace "pods-7953" to be "running and ready"
    Apr 26 10:59:45.628: INFO: Pod "pod-exec-websocket-d0fc5385-5bf8-4701-8744-a4087f074c80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.745975ms
    Apr 26 10:59:45.628: INFO: The phase of Pod pod-exec-websocket-d0fc5385-5bf8-4701-8744-a4087f074c80 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 10:59:47.634: INFO: Pod "pod-exec-websocket-d0fc5385-5bf8-4701-8744-a4087f074c80": Phase="Running", Reason="", readiness=true. Elapsed: 2.010337218s
    Apr 26 10:59:47.634: INFO: The phase of Pod pod-exec-websocket-d0fc5385-5bf8-4701-8744-a4087f074c80 is Running (Ready = true)
    Apr 26 10:59:47.634: INFO: Pod "pod-exec-websocket-d0fc5385-5bf8-4701-8744-a4087f074c80" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 26 10:59:47.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7953" for this suite. 04/26/24 10:59:47.852
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 10:59:47.863
Apr 26 10:59:47.864: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-probe 04/26/24 10:59:47.865
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:47.878
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:47.883
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131
STEP: Creating pod busybox-53a3a7d1-02d4-442b-b266-971fea13db6e in namespace container-probe-2423 04/26/24 10:59:47.887
Apr 26 10:59:47.899: INFO: Waiting up to 5m0s for pod "busybox-53a3a7d1-02d4-442b-b266-971fea13db6e" in namespace "container-probe-2423" to be "not pending"
Apr 26 10:59:47.906: INFO: Pod "busybox-53a3a7d1-02d4-442b-b266-971fea13db6e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.145429ms
Apr 26 10:59:49.913: INFO: Pod "busybox-53a3a7d1-02d4-442b-b266-971fea13db6e": Phase="Running", Reason="", readiness=true. Elapsed: 2.014553511s
Apr 26 10:59:49.913: INFO: Pod "busybox-53a3a7d1-02d4-442b-b266-971fea13db6e" satisfied condition "not pending"
Apr 26 10:59:49.913: INFO: Started pod busybox-53a3a7d1-02d4-442b-b266-971fea13db6e in namespace container-probe-2423
STEP: checking the pod's current state and verifying that restartCount is present 04/26/24 10:59:49.913
Apr 26 10:59:49.918: INFO: Initial restart count of pod busybox-53a3a7d1-02d4-442b-b266-971fea13db6e is 0
Apr 26 11:00:40.107: INFO: Restart count of pod container-probe-2423/busybox-53a3a7d1-02d4-442b-b266-971fea13db6e is now 1 (50.188636749s elapsed)
STEP: deleting the pod 04/26/24 11:00:40.107
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 26 11:00:40.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2423" for this suite. 04/26/24 11:00:40.129
{"msg":"PASSED [sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":17,"skipped":315,"failed":0}
------------------------------
â€¢ [SLOW TEST] [52.272 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 10:59:47.863
    Apr 26 10:59:47.864: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-probe 04/26/24 10:59:47.865
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 10:59:47.878
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 10:59:47.883
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:131
    STEP: Creating pod busybox-53a3a7d1-02d4-442b-b266-971fea13db6e in namespace container-probe-2423 04/26/24 10:59:47.887
    Apr 26 10:59:47.899: INFO: Waiting up to 5m0s for pod "busybox-53a3a7d1-02d4-442b-b266-971fea13db6e" in namespace "container-probe-2423" to be "not pending"
    Apr 26 10:59:47.906: INFO: Pod "busybox-53a3a7d1-02d4-442b-b266-971fea13db6e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.145429ms
    Apr 26 10:59:49.913: INFO: Pod "busybox-53a3a7d1-02d4-442b-b266-971fea13db6e": Phase="Running", Reason="", readiness=true. Elapsed: 2.014553511s
    Apr 26 10:59:49.913: INFO: Pod "busybox-53a3a7d1-02d4-442b-b266-971fea13db6e" satisfied condition "not pending"
    Apr 26 10:59:49.913: INFO: Started pod busybox-53a3a7d1-02d4-442b-b266-971fea13db6e in namespace container-probe-2423
    STEP: checking the pod's current state and verifying that restartCount is present 04/26/24 10:59:49.913
    Apr 26 10:59:49.918: INFO: Initial restart count of pod busybox-53a3a7d1-02d4-442b-b266-971fea13db6e is 0
    Apr 26 11:00:40.107: INFO: Restart count of pod container-probe-2423/busybox-53a3a7d1-02d4-442b-b266-971fea13db6e is now 1 (50.188636749s elapsed)
    STEP: deleting the pod 04/26/24 11:00:40.107
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 26 11:00:40.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2423" for this suite. 04/26/24 11:00:40.129
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:00:40.136
Apr 26 11:00:40.137: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename resourcequota 04/26/24 11:00:40.138
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:00:40.153
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:00:40.158
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150
STEP: Discovering how many secrets are in namespace by default 04/26/24 11:00:40.163
STEP: Counting existing ResourceQuota 04/26/24 11:00:45.168
STEP: Creating a ResourceQuota 04/26/24 11:00:50.173
STEP: Ensuring resource quota status is calculated 04/26/24 11:00:50.178
STEP: Creating a Secret 04/26/24 11:00:52.183
STEP: Ensuring resource quota status captures secret creation 04/26/24 11:00:52.194
STEP: Deleting a secret 04/26/24 11:00:54.199
STEP: Ensuring resource quota status released usage 04/26/24 11:00:54.205
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 26 11:00:56.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4107" for this suite. 04/26/24 11:00:56.224
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]","completed":18,"skipped":323,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.095 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  test/e2e/apimachinery/resource_quota.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:00:40.136
    Apr 26 11:00:40.137: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename resourcequota 04/26/24 11:00:40.138
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:00:40.153
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:00:40.158
    [It] should create a ResourceQuota and capture the life of a secret. [Conformance]
      test/e2e/apimachinery/resource_quota.go:150
    STEP: Discovering how many secrets are in namespace by default 04/26/24 11:00:40.163
    STEP: Counting existing ResourceQuota 04/26/24 11:00:45.168
    STEP: Creating a ResourceQuota 04/26/24 11:00:50.173
    STEP: Ensuring resource quota status is calculated 04/26/24 11:00:50.178
    STEP: Creating a Secret 04/26/24 11:00:52.183
    STEP: Ensuring resource quota status captures secret creation 04/26/24 11:00:52.194
    STEP: Deleting a secret 04/26/24 11:00:54.199
    STEP: Ensuring resource quota status released usage 04/26/24 11:00:54.205
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 26 11:00:56.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-4107" for this suite. 04/26/24 11:00:56.224
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a read only busybox container
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:00:56.233
Apr 26 11:00:56.233: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubelet-test 04/26/24 11:00:56.234
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:00:56.247
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:00:56.252
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:184
Apr 26 11:00:56.267: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsea4e0ef8-90d0-4a3b-a51b-d05323bd37fe" in namespace "kubelet-test-9595" to be "running and ready"
Apr 26 11:00:56.272: INFO: Pod "busybox-readonly-fsea4e0ef8-90d0-4a3b-a51b-d05323bd37fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.678481ms
Apr 26 11:00:56.272: INFO: The phase of Pod busybox-readonly-fsea4e0ef8-90d0-4a3b-a51b-d05323bd37fe is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:00:58.277: INFO: Pod "busybox-readonly-fsea4e0ef8-90d0-4a3b-a51b-d05323bd37fe": Phase="Running", Reason="", readiness=true. Elapsed: 2.010378698s
Apr 26 11:00:58.277: INFO: The phase of Pod busybox-readonly-fsea4e0ef8-90d0-4a3b-a51b-d05323bd37fe is Running (Ready = true)
Apr 26 11:00:58.277: INFO: Pod "busybox-readonly-fsea4e0ef8-90d0-4a3b-a51b-d05323bd37fe" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 26 11:00:58.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9595" for this suite. 04/26/24 11:00:58.354
{"msg":"PASSED [sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]","completed":19,"skipped":363,"failed":0}
------------------------------
â€¢ [2.130 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a read only busybox container
  test/e2e/common/node/kubelet.go:175
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:00:56.233
    Apr 26 11:00:56.233: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubelet-test 04/26/24 11:00:56.234
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:00:56.247
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:00:56.252
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:184
    Apr 26 11:00:56.267: INFO: Waiting up to 5m0s for pod "busybox-readonly-fsea4e0ef8-90d0-4a3b-a51b-d05323bd37fe" in namespace "kubelet-test-9595" to be "running and ready"
    Apr 26 11:00:56.272: INFO: Pod "busybox-readonly-fsea4e0ef8-90d0-4a3b-a51b-d05323bd37fe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.678481ms
    Apr 26 11:00:56.272: INFO: The phase of Pod busybox-readonly-fsea4e0ef8-90d0-4a3b-a51b-d05323bd37fe is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:00:58.277: INFO: Pod "busybox-readonly-fsea4e0ef8-90d0-4a3b-a51b-d05323bd37fe": Phase="Running", Reason="", readiness=true. Elapsed: 2.010378698s
    Apr 26 11:00:58.277: INFO: The phase of Pod busybox-readonly-fsea4e0ef8-90d0-4a3b-a51b-d05323bd37fe is Running (Ready = true)
    Apr 26 11:00:58.277: INFO: Pod "busybox-readonly-fsea4e0ef8-90d0-4a3b-a51b-d05323bd37fe" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 26 11:00:58.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-9595" for this suite. 04/26/24 11:00:58.354
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:00:58.363
Apr 26 11:00:58.363: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 11:00:58.364
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:00:58.378
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:00:58.384
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 11:00:58.403
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:00:58.514
STEP: Deploying the webhook pod 04/26/24 11:00:58.523
STEP: Wait for the deployment to be ready 04/26/24 11:00:58.536
Apr 26 11:00:58.545: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Apr 26 11:01:00.560: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 0, 58, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 0, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 0, 58, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 0, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/26/24 11:01:02.565
STEP: Verifying the service has paired with the endpoint 04/26/24 11:01:02.587
Apr 26 11:01:03.588: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340
Apr 26 11:01:03.593: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-743-crds.webhook.example.com via the AdmissionRegistration API 04/26/24 11:01:04.11
STEP: Creating a custom resource that should be mutated by the webhook 04/26/24 11:01:04.242
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:01:06.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5339" for this suite. 04/26/24 11:01:06.967
STEP: Destroying namespace "webhook-5339-markers" for this suite. 04/26/24 11:01:06.973
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]","completed":20,"skipped":369,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.750 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  test/e2e/apimachinery/webhook.go:340

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:00:58.363
    Apr 26 11:00:58.363: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 11:00:58.364
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:00:58.378
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:00:58.384
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 11:00:58.403
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:00:58.514
    STEP: Deploying the webhook pod 04/26/24 11:00:58.523
    STEP: Wait for the deployment to be ready 04/26/24 11:00:58.536
    Apr 26 11:00:58.545: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    Apr 26 11:01:00.560: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 0, 58, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 0, 58, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 0, 58, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 0, 58, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-5d85dd8cdb\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/26/24 11:01:02.565
    STEP: Verifying the service has paired with the endpoint 04/26/24 11:01:02.587
    Apr 26 11:01:03.588: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with pruning [Conformance]
      test/e2e/apimachinery/webhook.go:340
    Apr 26 11:01:03.593: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-743-crds.webhook.example.com via the AdmissionRegistration API 04/26/24 11:01:04.11
    STEP: Creating a custom resource that should be mutated by the webhook 04/26/24 11:01:04.242
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:01:06.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-5339" for this suite. 04/26/24 11:01:06.967
    STEP: Destroying namespace "webhook-5339-markers" for this suite. 04/26/24 11:01:06.973
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] ConfigMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:01:07.114
Apr 26 11:01:07.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 11:01:07.115
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:01:07.146
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:01:07.152
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123
STEP: Creating configMap with name configmap-test-upd-51f4370d-3404-4b25-9928-90c4596a0549 04/26/24 11:01:07.168
STEP: Creating the pod 04/26/24 11:01:07.173
Apr 26 11:01:07.189: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba284f25-d975-43cf-8c89-b67d9aaf8639" in namespace "configmap-2121" to be "running and ready"
Apr 26 11:01:07.202: INFO: Pod "pod-configmaps-ba284f25-d975-43cf-8c89-b67d9aaf8639": Phase="Pending", Reason="", readiness=false. Elapsed: 11.522377ms
Apr 26 11:01:07.202: INFO: The phase of Pod pod-configmaps-ba284f25-d975-43cf-8c89-b67d9aaf8639 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:01:09.208: INFO: Pod "pod-configmaps-ba284f25-d975-43cf-8c89-b67d9aaf8639": Phase="Running", Reason="", readiness=true. Elapsed: 2.018062639s
Apr 26 11:01:09.208: INFO: The phase of Pod pod-configmaps-ba284f25-d975-43cf-8c89-b67d9aaf8639 is Running (Ready = true)
Apr 26 11:01:09.208: INFO: Pod "pod-configmaps-ba284f25-d975-43cf-8c89-b67d9aaf8639" satisfied condition "running and ready"
STEP: Updating configmap configmap-test-upd-51f4370d-3404-4b25-9928-90c4596a0549 04/26/24 11:01:09.227
STEP: waiting to observe update in volume 04/26/24 11:01:09.233
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 11:02:17.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2121" for this suite. 04/26/24 11:02:17.988
{"msg":"PASSED [sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":21,"skipped":369,"failed":0}
------------------------------
â€¢ [SLOW TEST] [70.884 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:01:07.114
    Apr 26 11:01:07.114: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 11:01:07.115
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:01:07.146
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:01:07.152
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:123
    STEP: Creating configMap with name configmap-test-upd-51f4370d-3404-4b25-9928-90c4596a0549 04/26/24 11:01:07.168
    STEP: Creating the pod 04/26/24 11:01:07.173
    Apr 26 11:01:07.189: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba284f25-d975-43cf-8c89-b67d9aaf8639" in namespace "configmap-2121" to be "running and ready"
    Apr 26 11:01:07.202: INFO: Pod "pod-configmaps-ba284f25-d975-43cf-8c89-b67d9aaf8639": Phase="Pending", Reason="", readiness=false. Elapsed: 11.522377ms
    Apr 26 11:01:07.202: INFO: The phase of Pod pod-configmaps-ba284f25-d975-43cf-8c89-b67d9aaf8639 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:01:09.208: INFO: Pod "pod-configmaps-ba284f25-d975-43cf-8c89-b67d9aaf8639": Phase="Running", Reason="", readiness=true. Elapsed: 2.018062639s
    Apr 26 11:01:09.208: INFO: The phase of Pod pod-configmaps-ba284f25-d975-43cf-8c89-b67d9aaf8639 is Running (Ready = true)
    Apr 26 11:01:09.208: INFO: Pod "pod-configmaps-ba284f25-d975-43cf-8c89-b67d9aaf8639" satisfied condition "running and ready"
    STEP: Updating configmap configmap-test-upd-51f4370d-3404-4b25-9928-90c4596a0549 04/26/24 11:01:09.227
    STEP: waiting to observe update in volume 04/26/24 11:01:09.233
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 11:02:17.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-2121" for this suite. 04/26/24 11:02:17.988
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:02:17.999
Apr 26 11:02:17.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename gc 04/26/24 11:02:18
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:02:18.012
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:02:18.021
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650
STEP: create the rc 04/26/24 11:02:18.033
STEP: delete the rc 04/26/24 11:02:23.052
STEP: wait for the rc to be deleted 04/26/24 11:02:23.059
Apr 26 11:02:24.100: INFO: 90 pods remaining
Apr 26 11:02:24.100: INFO: 90 pods has nil DeletionTimestamp
Apr 26 11:02:24.100: INFO: 
Apr 26 11:02:25.089: INFO: 70 pods remaining
Apr 26 11:02:25.089: INFO: 70 pods has nil DeletionTimestamp
Apr 26 11:02:25.089: INFO: 
Apr 26 11:02:26.091: INFO: 69 pods remaining
Apr 26 11:02:26.091: INFO: 69 pods has nil DeletionTimestamp
Apr 26 11:02:26.091: INFO: 
Apr 26 11:02:27.084: INFO: 40 pods remaining
Apr 26 11:02:27.084: INFO: 40 pods has nil DeletionTimestamp
Apr 26 11:02:27.084: INFO: 
Apr 26 11:02:28.087: INFO: 40 pods remaining
Apr 26 11:02:28.087: INFO: 40 pods has nil DeletionTimestamp
Apr 26 11:02:28.087: INFO: 
Apr 26 11:02:29.082: INFO: 11 pods remaining
Apr 26 11:02:29.082: INFO: 11 pods has nil DeletionTimestamp
Apr 26 11:02:29.082: INFO: 
STEP: Gathering metrics 04/26/24 11:02:30.068
W0426 11:02:30.096722      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 26 11:02:30.096: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 26 11:02:30.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-314" for this suite. 04/26/24 11:02:30.107
{"msg":"PASSED [sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]","completed":22,"skipped":373,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.115 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:02:17.999
    Apr 26 11:02:17.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename gc 04/26/24 11:02:18
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:02:18.012
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:02:18.021
    [It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:650
    STEP: create the rc 04/26/24 11:02:18.033
    STEP: delete the rc 04/26/24 11:02:23.052
    STEP: wait for the rc to be deleted 04/26/24 11:02:23.059
    Apr 26 11:02:24.100: INFO: 90 pods remaining
    Apr 26 11:02:24.100: INFO: 90 pods has nil DeletionTimestamp
    Apr 26 11:02:24.100: INFO: 
    Apr 26 11:02:25.089: INFO: 70 pods remaining
    Apr 26 11:02:25.089: INFO: 70 pods has nil DeletionTimestamp
    Apr 26 11:02:25.089: INFO: 
    Apr 26 11:02:26.091: INFO: 69 pods remaining
    Apr 26 11:02:26.091: INFO: 69 pods has nil DeletionTimestamp
    Apr 26 11:02:26.091: INFO: 
    Apr 26 11:02:27.084: INFO: 40 pods remaining
    Apr 26 11:02:27.084: INFO: 40 pods has nil DeletionTimestamp
    Apr 26 11:02:27.084: INFO: 
    Apr 26 11:02:28.087: INFO: 40 pods remaining
    Apr 26 11:02:28.087: INFO: 40 pods has nil DeletionTimestamp
    Apr 26 11:02:28.087: INFO: 
    Apr 26 11:02:29.082: INFO: 11 pods remaining
    Apr 26 11:02:29.082: INFO: 11 pods has nil DeletionTimestamp
    Apr 26 11:02:29.082: INFO: 
    STEP: Gathering metrics 04/26/24 11:02:30.068
    W0426 11:02:30.096722      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 26 11:02:30.096: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 26 11:02:30.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-314" for this suite. 04/26/24 11:02:30.107
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:02:30.117
Apr 26 11:02:30.117: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 11:02:30.117
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:02:30.133
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:02:30.138
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196
STEP: Creating a pod to test emptydir 0644 on node default medium 04/26/24 11:02:30.143
Apr 26 11:02:30.157: INFO: Waiting up to 5m0s for pod "pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448" in namespace "emptydir-3461" to be "Succeeded or Failed"
Apr 26 11:02:30.161: INFO: Pod "pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448": Phase="Pending", Reason="", readiness=false. Elapsed: 3.890495ms
Apr 26 11:02:32.169: INFO: Pod "pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012036796s
Apr 26 11:02:34.167: INFO: Pod "pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010065854s
STEP: Saw pod success 04/26/24 11:02:34.167
Apr 26 11:02:34.167: INFO: Pod "pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448" satisfied condition "Succeeded or Failed"
Apr 26 11:02:34.172: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448 container test-container: <nil>
STEP: delete the pod 04/26/24 11:02:34.226
Apr 26 11:02:34.242: INFO: Waiting for pod pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448 to disappear
Apr 26 11:02:34.245: INFO: Pod pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 11:02:34.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3461" for this suite. 04/26/24 11:02:34.252
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":23,"skipped":392,"failed":0}
------------------------------
â€¢ [4.144 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:02:30.117
    Apr 26 11:02:30.117: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 11:02:30.117
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:02:30.133
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:02:30.138
    [It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:196
    STEP: Creating a pod to test emptydir 0644 on node default medium 04/26/24 11:02:30.143
    Apr 26 11:02:30.157: INFO: Waiting up to 5m0s for pod "pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448" in namespace "emptydir-3461" to be "Succeeded or Failed"
    Apr 26 11:02:30.161: INFO: Pod "pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448": Phase="Pending", Reason="", readiness=false. Elapsed: 3.890495ms
    Apr 26 11:02:32.169: INFO: Pod "pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012036796s
    Apr 26 11:02:34.167: INFO: Pod "pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010065854s
    STEP: Saw pod success 04/26/24 11:02:34.167
    Apr 26 11:02:34.167: INFO: Pod "pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448" satisfied condition "Succeeded or Failed"
    Apr 26 11:02:34.172: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448 container test-container: <nil>
    STEP: delete the pod 04/26/24 11:02:34.226
    Apr 26 11:02:34.242: INFO: Waiting for pod pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448 to disappear
    Apr 26 11:02:34.245: INFO: Pod pod-7a945987-3a0d-44e0-88d4-9e7f05a3f448 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 11:02:34.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3461" for this suite. 04/26/24 11:02:34.252
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should delete a job [Conformance]
  test/e2e/apps/job.go:309
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:02:34.264
Apr 26 11:02:34.264: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename job 04/26/24 11:02:34.265
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:02:34.28
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:02:34.285
[It] should delete a job [Conformance]
  test/e2e/apps/job.go:309
STEP: Creating a job 04/26/24 11:02:34.291
STEP: Ensuring active pods == parallelism 04/26/24 11:02:34.297
STEP: delete a job 04/26/24 11:02:36.305
STEP: deleting Job.batch foo in namespace job-3394, will wait for the garbage collector to delete the pods 04/26/24 11:02:36.305
Apr 26 11:02:36.367: INFO: Deleting Job.batch foo took: 6.222087ms
Apr 26 11:02:36.468: INFO: Terminating Job.batch foo pods took: 100.668041ms
STEP: Ensuring job was deleted 04/26/24 11:03:08.968
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 26 11:03:08.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3394" for this suite. 04/26/24 11:03:08.986
{"msg":"PASSED [sig-apps] Job should delete a job [Conformance]","completed":24,"skipped":459,"failed":0}
------------------------------
â€¢ [SLOW TEST] [34.729 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  test/e2e/apps/job.go:309

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:02:34.264
    Apr 26 11:02:34.264: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename job 04/26/24 11:02:34.265
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:02:34.28
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:02:34.285
    [It] should delete a job [Conformance]
      test/e2e/apps/job.go:309
    STEP: Creating a job 04/26/24 11:02:34.291
    STEP: Ensuring active pods == parallelism 04/26/24 11:02:34.297
    STEP: delete a job 04/26/24 11:02:36.305
    STEP: deleting Job.batch foo in namespace job-3394, will wait for the garbage collector to delete the pods 04/26/24 11:02:36.305
    Apr 26 11:02:36.367: INFO: Deleting Job.batch foo took: 6.222087ms
    Apr 26 11:02:36.468: INFO: Terminating Job.batch foo pods took: 100.668041ms
    STEP: Ensuring job was deleted 04/26/24 11:03:08.968
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 26 11:03:08.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3394" for this suite. 04/26/24 11:03:08.986
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:03:08.993
Apr 26 11:03:08.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:03:08.995
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:03:09.01
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:03:09.016
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98
STEP: Creating configMap with name projected-configmap-test-volume-map-15a1f4f5-1464-4642-867f-2840ef18f3ba 04/26/24 11:03:09.023
STEP: Creating a pod to test consume configMaps 04/26/24 11:03:09.028
Apr 26 11:03:09.041: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0" in namespace "projected-5636" to be "Succeeded or Failed"
Apr 26 11:03:09.046: INFO: Pod "pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.394723ms
Apr 26 11:03:11.054: INFO: Pod "pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01343075s
Apr 26 11:03:13.053: INFO: Pod "pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012435386s
STEP: Saw pod success 04/26/24 11:03:13.053
Apr 26 11:03:13.054: INFO: Pod "pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0" satisfied condition "Succeeded or Failed"
Apr 26 11:03:13.058: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0 container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:03:13.116
Apr 26 11:03:13.131: INFO: Waiting for pod pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0 to disappear
Apr 26 11:03:13.136: INFO: Pod pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 26 11:03:13.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5636" for this suite. 04/26/24 11:03:13.145
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":25,"skipped":467,"failed":0}
------------------------------
â€¢ [4.159 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:03:08.993
    Apr 26 11:03:08.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:03:08.995
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:03:09.01
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:03:09.016
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:98
    STEP: Creating configMap with name projected-configmap-test-volume-map-15a1f4f5-1464-4642-867f-2840ef18f3ba 04/26/24 11:03:09.023
    STEP: Creating a pod to test consume configMaps 04/26/24 11:03:09.028
    Apr 26 11:03:09.041: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0" in namespace "projected-5636" to be "Succeeded or Failed"
    Apr 26 11:03:09.046: INFO: Pod "pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0": Phase="Pending", Reason="", readiness=false. Elapsed: 5.394723ms
    Apr 26 11:03:11.054: INFO: Pod "pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01343075s
    Apr 26 11:03:13.053: INFO: Pod "pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012435386s
    STEP: Saw pod success 04/26/24 11:03:13.053
    Apr 26 11:03:13.054: INFO: Pod "pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0" satisfied condition "Succeeded or Failed"
    Apr 26 11:03:13.058: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0 container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:03:13.116
    Apr 26 11:03:13.131: INFO: Waiting for pod pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0 to disappear
    Apr 26 11:03:13.136: INFO: Pod pod-projected-configmaps-53579608-a6c5-42ad-b9a0-12f09a5b09d0 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 26 11:03:13.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5636" for this suite. 04/26/24 11:03:13.145
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Single Pod [Serial]
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:03:13.16
Apr 26 11:03:13.160: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename taint-single-pod 04/26/24 11:03:13.161
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:03:13.175
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:03:13.181
[BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/node/taints.go:166
Apr 26 11:03:13.187: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 26 11:04:13.234: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289
Apr 26 11:04:13.238: INFO: Starting informer...
STEP: Starting pod... 04/26/24 11:04:13.238
Apr 26 11:04:13.460: INFO: Pod is running on shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp. Tainting Node
STEP: Trying to apply a taint on the Node 04/26/24 11:04:13.46
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/26/24 11:04:13.482
STEP: Waiting short time to make sure Pod is queued for deletion 04/26/24 11:04:13.51
Apr 26 11:04:13.510: INFO: Pod wasn't evicted. Proceeding
Apr 26 11:04:13.510: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/26/24 11:04:13.529
STEP: Waiting some time to make sure that toleration time passed. 04/26/24 11:04:13.565
Apr 26 11:05:28.566: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:05:28.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-6421" for this suite. 04/26/24 11:05:28.592
{"msg":"PASSED [sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]","completed":26,"skipped":532,"failed":0}
------------------------------
â€¢ [SLOW TEST] [135.438 seconds]
[sig-node] NoExecuteTaintManager Single Pod [Serial]
test/e2e/node/framework.go:23
  removing taint cancels eviction [Disruptive] [Conformance]
  test/e2e/node/taints.go:289

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:03:13.16
    Apr 26 11:03:13.160: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename taint-single-pod 04/26/24 11:03:13.161
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:03:13.175
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:03:13.181
    [BeforeEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/node/taints.go:166
    Apr 26 11:03:13.187: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 26 11:04:13.234: INFO: Waiting for terminating namespaces to be deleted...
    [It] removing taint cancels eviction [Disruptive] [Conformance]
      test/e2e/node/taints.go:289
    Apr 26 11:04:13.238: INFO: Starting informer...
    STEP: Starting pod... 04/26/24 11:04:13.238
    Apr 26 11:04:13.460: INFO: Pod is running on shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp. Tainting Node
    STEP: Trying to apply a taint on the Node 04/26/24 11:04:13.46
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/26/24 11:04:13.482
    STEP: Waiting short time to make sure Pod is queued for deletion 04/26/24 11:04:13.51
    Apr 26 11:04:13.510: INFO: Pod wasn't evicted. Proceeding
    Apr 26 11:04:13.510: INFO: Removing taint from Node
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/26/24 11:04:13.529
    STEP: Waiting some time to make sure that toleration time passed. 04/26/24 11:04:13.565
    Apr 26 11:05:28.566: INFO: Pod wasn't evicted. Test successful
    [AfterEach] [sig-node] NoExecuteTaintManager Single Pod [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:05:28.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-single-pod-6421" for this suite. 04/26/24 11:05:28.592
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:05:28.598
Apr 26 11:05:28.598: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-lifecycle-hook 04/26/24 11:05:28.599
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:05:28.635
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:05:28.643
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/26/24 11:05:28.659
Apr 26 11:05:28.671: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-545" to be "running and ready"
Apr 26 11:05:28.678: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.712999ms
Apr 26 11:05:28.678: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:05:30.684: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.012504574s
Apr 26 11:05:30.684: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 26 11:05:30.684: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:130
STEP: create the pod with lifecycle hook 04/26/24 11:05:30.69
Apr 26 11:05:30.700: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-545" to be "running and ready"
Apr 26 11:05:30.707: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.968031ms
Apr 26 11:05:30.707: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:05:32.714: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.013312984s
Apr 26 11:05:32.714: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
Apr 26 11:05:32.714: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
STEP: check poststart hook 04/26/24 11:05:32.719
STEP: delete the pod with lifecycle hook 04/26/24 11:05:32.777
Apr 26 11:05:32.787: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 26 11:05:32.793: INFO: Pod pod-with-poststart-http-hook still exists
Apr 26 11:05:34.793: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 26 11:05:34.800: INFO: Pod pod-with-poststart-http-hook still exists
Apr 26 11:05:36.795: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 26 11:05:36.800: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 26 11:05:36.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-545" for this suite. 04/26/24 11:05:36.809
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]","completed":27,"skipped":532,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.218 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:130

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:05:28.598
    Apr 26 11:05:28.598: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/26/24 11:05:28.599
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:05:28.635
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:05:28.643
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/26/24 11:05:28.659
    Apr 26 11:05:28.671: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-545" to be "running and ready"
    Apr 26 11:05:28.678: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.712999ms
    Apr 26 11:05:28.678: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:05:30.684: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.012504574s
    Apr 26 11:05:30.684: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 26 11:05:30.684: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:130
    STEP: create the pod with lifecycle hook 04/26/24 11:05:30.69
    Apr 26 11:05:30.700: INFO: Waiting up to 5m0s for pod "pod-with-poststart-http-hook" in namespace "container-lifecycle-hook-545" to be "running and ready"
    Apr 26 11:05:30.707: INFO: Pod "pod-with-poststart-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 6.968031ms
    Apr 26 11:05:30.707: INFO: The phase of Pod pod-with-poststart-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:05:32.714: INFO: Pod "pod-with-poststart-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.013312984s
    Apr 26 11:05:32.714: INFO: The phase of Pod pod-with-poststart-http-hook is Running (Ready = true)
    Apr 26 11:05:32.714: INFO: Pod "pod-with-poststart-http-hook" satisfied condition "running and ready"
    STEP: check poststart hook 04/26/24 11:05:32.719
    STEP: delete the pod with lifecycle hook 04/26/24 11:05:32.777
    Apr 26 11:05:32.787: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 26 11:05:32.793: INFO: Pod pod-with-poststart-http-hook still exists
    Apr 26 11:05:34.793: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 26 11:05:34.800: INFO: Pod pod-with-poststart-http-hook still exists
    Apr 26 11:05:36.795: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
    Apr 26 11:05:36.800: INFO: Pod pod-with-poststart-http-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 26 11:05:36.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-545" for this suite. 04/26/24 11:05:36.809
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] CronJob
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:05:36.817
Apr 26 11:05:36.817: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename cronjob 04/26/24 11:05:36.818
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:05:36.841
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:05:36.846
[It] should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160
STEP: Creating a ReplaceConcurrent cronjob 04/26/24 11:05:36.851
STEP: Ensuring a job is scheduled 04/26/24 11:05:36.858
STEP: Ensuring exactly one is scheduled 04/26/24 11:06:00.865
STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/26/24 11:06:00.872
STEP: Ensuring the job is replaced with a new one 04/26/24 11:06:00.877
STEP: Removing cronjob 04/26/24 11:07:00.885
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 26 11:07:00.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-6802" for this suite. 04/26/24 11:07:00.903
{"msg":"PASSED [sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]","completed":28,"skipped":537,"failed":0}
------------------------------
â€¢ [SLOW TEST] [84.102 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should replace jobs when ReplaceConcurrent [Conformance]
  test/e2e/apps/cronjob.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:05:36.817
    Apr 26 11:05:36.817: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename cronjob 04/26/24 11:05:36.818
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:05:36.841
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:05:36.846
    [It] should replace jobs when ReplaceConcurrent [Conformance]
      test/e2e/apps/cronjob.go:160
    STEP: Creating a ReplaceConcurrent cronjob 04/26/24 11:05:36.851
    STEP: Ensuring a job is scheduled 04/26/24 11:05:36.858
    STEP: Ensuring exactly one is scheduled 04/26/24 11:06:00.865
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/26/24 11:06:00.872
    STEP: Ensuring the job is replaced with a new one 04/26/24 11:06:00.877
    STEP: Removing cronjob 04/26/24 11:07:00.885
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 26 11:07:00.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-6802" for this suite. 04/26/24 11:07:00.903
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:07:00.921
Apr 26 11:07:00.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 11:07:00.923
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:07:00.96
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:07:00.965
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 11:07:00.991
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:07:01.146
STEP: Deploying the webhook pod 04/26/24 11:07:01.154
STEP: Wait for the deployment to be ready 04/26/24 11:07:01.164
Apr 26 11:07:01.175: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 11:07:03.193
STEP: Verifying the service has paired with the endpoint 04/26/24 11:07:03.259
Apr 26 11:07:04.260: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412
STEP: Creating a validating webhook configuration 04/26/24 11:07:04.267
STEP: Creating a configMap that does not comply to the validation webhook rules 04/26/24 11:07:04.398
STEP: Updating a validating webhook configuration's rules to not include the create operation 04/26/24 11:07:04.515
STEP: Creating a configMap that does not comply to the validation webhook rules 04/26/24 11:07:04.526
STEP: Patching a validating webhook configuration's rules to include the create operation 04/26/24 11:07:04.564
STEP: Creating a configMap that does not comply to the validation webhook rules 04/26/24 11:07:04.586
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:07:04.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-376" for this suite. 04/26/24 11:07:04.631
STEP: Destroying namespace "webhook-376-markers" for this suite. 04/26/24 11:07:04.638
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]","completed":29,"skipped":554,"failed":0}
------------------------------
â€¢ [3.776 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:412

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:07:00.921
    Apr 26 11:07:00.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 11:07:00.923
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:07:00.96
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:07:00.965
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 11:07:00.991
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:07:01.146
    STEP: Deploying the webhook pod 04/26/24 11:07:01.154
    STEP: Wait for the deployment to be ready 04/26/24 11:07:01.164
    Apr 26 11:07:01.175: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 11:07:03.193
    STEP: Verifying the service has paired with the endpoint 04/26/24 11:07:03.259
    Apr 26 11:07:04.260: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a validating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:412
    STEP: Creating a validating webhook configuration 04/26/24 11:07:04.267
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/26/24 11:07:04.398
    STEP: Updating a validating webhook configuration's rules to not include the create operation 04/26/24 11:07:04.515
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/26/24 11:07:04.526
    STEP: Patching a validating webhook configuration's rules to include the create operation 04/26/24 11:07:04.564
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/26/24 11:07:04.586
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:07:04.621: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-376" for this suite. 04/26/24 11:07:04.631
    STEP: Destroying namespace "webhook-376-markers" for this suite. 04/26/24 11:07:04.638
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:07:04.698
Apr 26 11:07:04.698: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename dns 04/26/24 11:07:04.699
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:07:04.719
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:07:04.725
[It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193
STEP: Creating a test headless service 04/26/24 11:07:04.73
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8470 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8470;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8470 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8470;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8470.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8470.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8470.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8470.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8470.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8470.svc;check="$$(dig +notcp +noall +answer +search 249.133.70.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.70.133.249_udp@PTR;check="$$(dig +tcp +noall +answer +search 249.133.70.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.70.133.249_tcp@PTR;sleep 1; done
 04/26/24 11:07:04.757
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8470 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8470;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8470 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8470;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8470.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8470.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8470.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8470.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8470.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8470.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8470.svc;check="$$(dig +notcp +noall +answer +search 249.133.70.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.70.133.249_udp@PTR;check="$$(dig +tcp +noall +answer +search 249.133.70.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.70.133.249_tcp@PTR;sleep 1; done
 04/26/24 11:07:04.757
STEP: creating a pod to probe DNS 04/26/24 11:07:04.758
STEP: submitting the pod to kubernetes 04/26/24 11:07:04.758
Apr 26 11:07:04.786: INFO: Waiting up to 15m0s for pod "dns-test-8313befe-543c-47f7-accb-e01fa6f039ce" in namespace "dns-8470" to be "running"
Apr 26 11:07:04.799: INFO: Pod "dns-test-8313befe-543c-47f7-accb-e01fa6f039ce": Phase="Pending", Reason="", readiness=false. Elapsed: 12.628815ms
Apr 26 11:07:06.807: INFO: Pod "dns-test-8313befe-543c-47f7-accb-e01fa6f039ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020000188s
Apr 26 11:07:08.807: INFO: Pod "dns-test-8313befe-543c-47f7-accb-e01fa6f039ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020362743s
Apr 26 11:07:10.808: INFO: Pod "dns-test-8313befe-543c-47f7-accb-e01fa6f039ce": Phase="Running", Reason="", readiness=true. Elapsed: 6.021513453s
Apr 26 11:07:10.808: INFO: Pod "dns-test-8313befe-543c-47f7-accb-e01fa6f039ce" satisfied condition "running"
STEP: retrieving the pod 04/26/24 11:07:10.808
STEP: looking for the results for each expected name from probers 04/26/24 11:07:10.814
Apr 26 11:07:10.849: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:10.893: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:10.903: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:10.912: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:10.922: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:10.933: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:10.944: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:10.953: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:11.008: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:11.017: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:11.026: INFO: Unable to read jessie_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:11.035: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:11.043: INFO: Unable to read jessie_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:11.051: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:11.060: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:11.071: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:11.117: INFO: Lookups using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8470 wheezy_tcp@dns-test-service.dns-8470 wheezy_udp@dns-test-service.dns-8470.svc wheezy_tcp@dns-test-service.dns-8470.svc wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8470 jessie_tcp@dns-test-service.dns-8470 jessie_udp@dns-test-service.dns-8470.svc jessie_tcp@dns-test-service.dns-8470.svc jessie_udp@_http._tcp.dns-test-service.dns-8470.svc jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc]

Apr 26 11:07:16.127: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.174: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.187: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.197: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.210: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.223: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.232: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.243: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.292: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.301: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.311: INFO: Unable to read jessie_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.318: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.328: INFO: Unable to read jessie_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.340: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.352: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.408: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:16.484: INFO: Lookups using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8470 wheezy_tcp@dns-test-service.dns-8470 wheezy_udp@dns-test-service.dns-8470.svc wheezy_tcp@dns-test-service.dns-8470.svc wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8470 jessie_tcp@dns-test-service.dns-8470 jessie_udp@dns-test-service.dns-8470.svc jessie_tcp@dns-test-service.dns-8470.svc jessie_udp@_http._tcp.dns-test-service.dns-8470.svc jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc]

Apr 26 11:07:21.172: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.268: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.359: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.405: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.413: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.422: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.431: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.440: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.488: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.498: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.507: INFO: Unable to read jessie_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.517: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.526: INFO: Unable to read jessie_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.536: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.550: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.559: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:21.597: INFO: Lookups using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8470 wheezy_tcp@dns-test-service.dns-8470 wheezy_udp@dns-test-service.dns-8470.svc wheezy_tcp@dns-test-service.dns-8470.svc wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8470 jessie_tcp@dns-test-service.dns-8470 jessie_udp@dns-test-service.dns-8470.svc jessie_tcp@dns-test-service.dns-8470.svc jessie_udp@_http._tcp.dns-test-service.dns-8470.svc jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc]

Apr 26 11:07:26.141: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.190: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.202: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.211: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.221: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.230: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.244: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.253: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.298: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.311: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.321: INFO: Unable to read jessie_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.331: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.340: INFO: Unable to read jessie_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.349: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.363: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.377: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:26.419: INFO: Lookups using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8470 wheezy_tcp@dns-test-service.dns-8470 wheezy_udp@dns-test-service.dns-8470.svc wheezy_tcp@dns-test-service.dns-8470.svc wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8470 jessie_tcp@dns-test-service.dns-8470 jessie_udp@dns-test-service.dns-8470.svc jessie_tcp@dns-test-service.dns-8470.svc jessie_udp@_http._tcp.dns-test-service.dns-8470.svc jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc]

Apr 26 11:07:31.130: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.177: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.191: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.201: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.210: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.221: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.230: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.237: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.277: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.287: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.296: INFO: Unable to read jessie_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.305: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.315: INFO: Unable to read jessie_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.325: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.334: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.345: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:31.384: INFO: Lookups using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8470 wheezy_tcp@dns-test-service.dns-8470 wheezy_udp@dns-test-service.dns-8470.svc wheezy_tcp@dns-test-service.dns-8470.svc wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8470 jessie_tcp@dns-test-service.dns-8470 jessie_udp@dns-test-service.dns-8470.svc jessie_tcp@dns-test-service.dns-8470.svc jessie_udp@_http._tcp.dns-test-service.dns-8470.svc jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc]

Apr 26 11:07:36.237: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:36.335: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:36.343: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
Apr 26 11:07:36.392: INFO: Lookups using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce failed for: [wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc jessie_udp@_http._tcp.dns-test-service.dns-8470.svc jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc]

Apr 26 11:07:41.433: INFO: DNS probes using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce succeeded

STEP: deleting the pod 04/26/24 11:07:41.433
STEP: deleting the test service 04/26/24 11:07:41.453
STEP: deleting the test headless service 04/26/24 11:07:41.481
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 26 11:07:41.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8470" for this suite. 04/26/24 11:07:41.501
{"msg":"PASSED [sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]","completed":30,"skipped":565,"failed":0}
------------------------------
â€¢ [SLOW TEST] [36.813 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
  test/e2e/network/dns.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:07:04.698
    Apr 26 11:07:04.698: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename dns 04/26/24 11:07:04.699
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:07:04.719
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:07:04.725
    [It] should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]
      test/e2e/network/dns.go:193
    STEP: Creating a test headless service 04/26/24 11:07:04.73
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8470 A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8470;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8470 A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8470;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8470.svc A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8470.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8470.svc A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8470.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8470.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8470.svc;check="$$(dig +notcp +noall +answer +search 249.133.70.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.70.133.249_udp@PTR;check="$$(dig +tcp +noall +answer +search 249.133.70.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.70.133.249_tcp@PTR;sleep 1; done
     04/26/24 11:07:04.757
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service;check="$$(dig +tcp +noall +answer +search dns-test-service A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8470 A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8470;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8470 A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8470;check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8470.svc A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8470.svc;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8470.svc A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8470.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8470.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8470.svc;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8470.svc SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8470.svc;check="$$(dig +notcp +noall +answer +search 249.133.70.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.70.133.249_udp@PTR;check="$$(dig +tcp +noall +answer +search 249.133.70.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.70.133.249_tcp@PTR;sleep 1; done
     04/26/24 11:07:04.757
    STEP: creating a pod to probe DNS 04/26/24 11:07:04.758
    STEP: submitting the pod to kubernetes 04/26/24 11:07:04.758
    Apr 26 11:07:04.786: INFO: Waiting up to 15m0s for pod "dns-test-8313befe-543c-47f7-accb-e01fa6f039ce" in namespace "dns-8470" to be "running"
    Apr 26 11:07:04.799: INFO: Pod "dns-test-8313befe-543c-47f7-accb-e01fa6f039ce": Phase="Pending", Reason="", readiness=false. Elapsed: 12.628815ms
    Apr 26 11:07:06.807: INFO: Pod "dns-test-8313befe-543c-47f7-accb-e01fa6f039ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020000188s
    Apr 26 11:07:08.807: INFO: Pod "dns-test-8313befe-543c-47f7-accb-e01fa6f039ce": Phase="Pending", Reason="", readiness=false. Elapsed: 4.020362743s
    Apr 26 11:07:10.808: INFO: Pod "dns-test-8313befe-543c-47f7-accb-e01fa6f039ce": Phase="Running", Reason="", readiness=true. Elapsed: 6.021513453s
    Apr 26 11:07:10.808: INFO: Pod "dns-test-8313befe-543c-47f7-accb-e01fa6f039ce" satisfied condition "running"
    STEP: retrieving the pod 04/26/24 11:07:10.808
    STEP: looking for the results for each expected name from probers 04/26/24 11:07:10.814
    Apr 26 11:07:10.849: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:10.893: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:10.903: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:10.912: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:10.922: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:10.933: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:10.944: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:10.953: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:11.008: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:11.017: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:11.026: INFO: Unable to read jessie_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:11.035: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:11.043: INFO: Unable to read jessie_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:11.051: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:11.060: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:11.071: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:11.117: INFO: Lookups using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8470 wheezy_tcp@dns-test-service.dns-8470 wheezy_udp@dns-test-service.dns-8470.svc wheezy_tcp@dns-test-service.dns-8470.svc wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8470 jessie_tcp@dns-test-service.dns-8470 jessie_udp@dns-test-service.dns-8470.svc jessie_tcp@dns-test-service.dns-8470.svc jessie_udp@_http._tcp.dns-test-service.dns-8470.svc jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc]

    Apr 26 11:07:16.127: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.174: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.187: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.197: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.210: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.223: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.232: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.243: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.292: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.301: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.311: INFO: Unable to read jessie_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.318: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.328: INFO: Unable to read jessie_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.340: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.352: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.408: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:16.484: INFO: Lookups using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8470 wheezy_tcp@dns-test-service.dns-8470 wheezy_udp@dns-test-service.dns-8470.svc wheezy_tcp@dns-test-service.dns-8470.svc wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8470 jessie_tcp@dns-test-service.dns-8470 jessie_udp@dns-test-service.dns-8470.svc jessie_tcp@dns-test-service.dns-8470.svc jessie_udp@_http._tcp.dns-test-service.dns-8470.svc jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc]

    Apr 26 11:07:21.172: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.268: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.359: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.405: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.413: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.422: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.431: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.440: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.488: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.498: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.507: INFO: Unable to read jessie_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.517: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.526: INFO: Unable to read jessie_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.536: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.550: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.559: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:21.597: INFO: Lookups using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8470 wheezy_tcp@dns-test-service.dns-8470 wheezy_udp@dns-test-service.dns-8470.svc wheezy_tcp@dns-test-service.dns-8470.svc wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8470 jessie_tcp@dns-test-service.dns-8470 jessie_udp@dns-test-service.dns-8470.svc jessie_tcp@dns-test-service.dns-8470.svc jessie_udp@_http._tcp.dns-test-service.dns-8470.svc jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc]

    Apr 26 11:07:26.141: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.190: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.202: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.211: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.221: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.230: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.244: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.253: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.298: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.311: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.321: INFO: Unable to read jessie_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.331: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.340: INFO: Unable to read jessie_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.349: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.363: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.377: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:26.419: INFO: Lookups using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8470 wheezy_tcp@dns-test-service.dns-8470 wheezy_udp@dns-test-service.dns-8470.svc wheezy_tcp@dns-test-service.dns-8470.svc wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8470 jessie_tcp@dns-test-service.dns-8470 jessie_udp@dns-test-service.dns-8470.svc jessie_tcp@dns-test-service.dns-8470.svc jessie_udp@_http._tcp.dns-test-service.dns-8470.svc jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc]

    Apr 26 11:07:31.130: INFO: Unable to read wheezy_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.177: INFO: Unable to read wheezy_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.191: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.201: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.210: INFO: Unable to read wheezy_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.221: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.230: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.237: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.277: INFO: Unable to read jessie_udp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.287: INFO: Unable to read jessie_tcp@dns-test-service from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.296: INFO: Unable to read jessie_udp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.305: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470 from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.315: INFO: Unable to read jessie_udp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.325: INFO: Unable to read jessie_tcp@dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.334: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.345: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:31.384: INFO: Lookups using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce failed for: [wheezy_udp@dns-test-service wheezy_tcp@dns-test-service wheezy_udp@dns-test-service.dns-8470 wheezy_tcp@dns-test-service.dns-8470 wheezy_udp@dns-test-service.dns-8470.svc wheezy_tcp@dns-test-service.dns-8470.svc wheezy_udp@_http._tcp.dns-test-service.dns-8470.svc wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc jessie_udp@dns-test-service jessie_tcp@dns-test-service jessie_udp@dns-test-service.dns-8470 jessie_tcp@dns-test-service.dns-8470 jessie_udp@dns-test-service.dns-8470.svc jessie_tcp@dns-test-service.dns-8470.svc jessie_udp@_http._tcp.dns-test-service.dns-8470.svc jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc]

    Apr 26 11:07:36.237: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:36.335: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:36.343: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc from pod dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce: the server could not find the requested resource (get pods dns-test-8313befe-543c-47f7-accb-e01fa6f039ce)
    Apr 26 11:07:36.392: INFO: Lookups using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce failed for: [wheezy_tcp@_http._tcp.dns-test-service.dns-8470.svc jessie_udp@_http._tcp.dns-test-service.dns-8470.svc jessie_tcp@_http._tcp.dns-test-service.dns-8470.svc]

    Apr 26 11:07:41.433: INFO: DNS probes using dns-8470/dns-test-8313befe-543c-47f7-accb-e01fa6f039ce succeeded

    STEP: deleting the pod 04/26/24 11:07:41.433
    STEP: deleting the test service 04/26/24 11:07:41.453
    STEP: deleting the test headless service 04/26/24 11:07:41.481
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 26 11:07:41.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8470" for this suite. 04/26/24 11:07:41.501
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:07:41.515
Apr 26 11:07:41.515: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename init-container 04/26/24 11:07:41.516
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:07:41.536
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:07:41.543
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333
STEP: creating the pod 04/26/24 11:07:41.548
Apr 26 11:07:41.549: INFO: PodSpec: initContainers in spec.initContainers
Apr 26 11:08:20.671: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c14308af-b255-4896-adae-54de108bd3e7", GenerateName:"", Namespace:"init-container-1407", SelfLink:"", UID:"2810e927-c37c-400a-a5f8-433e9041a5ff", ResourceVersion:"20157", Generation:0, CreationTimestamp:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"549073577"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"0ad74486b3902c5bca48832143036a57c2ec1f37d4a39ee573c30ef80e26e82f", "cni.projectcalico.org/podIP":"100.96.1.64/32", "cni.projectcalico.org/podIPs":"100.96.1.64/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0012fa060), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 26, 11, 7, 42, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0012fa108), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 26, 11, 8, 20, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0012fa138), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-9nsqh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc005a120c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.conf-125.thomas.internal.emk.fuga.cloud", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-9nsqh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.conf-125.thomas.internal.emk.fuga.cloud", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-9nsqh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.conf-125.thomas.internal.emk.fuga.cloud", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-9nsqh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004c34118), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00036c000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004c34190)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004c341c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004c341c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004c341cc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0033aa070), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.2.248", PodIP:"100.96.1.64", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.96.1.64"}}, StartTime:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0012fa180), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00036c150)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://761588ca24836789a5a5243182a6cdc43a83c5ac21d3bf42f4fd1d5ac136b9d9", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc005a122c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc005a12240), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc004c3425f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 26 11:08:20.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1407" for this suite. 04/26/24 11:08:20.683
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]","completed":31,"skipped":576,"failed":0}
------------------------------
â€¢ [SLOW TEST] [39.175 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:07:41.515
    Apr 26 11:07:41.515: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename init-container 04/26/24 11:07:41.516
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:07:41.536
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:07:41.543
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:333
    STEP: creating the pod 04/26/24 11:07:41.548
    Apr 26 11:07:41.549: INFO: PodSpec: initContainers in spec.initContainers
    Apr 26 11:08:20.671: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-c14308af-b255-4896-adae-54de108bd3e7", GenerateName:"", Namespace:"init-container-1407", SelfLink:"", UID:"2810e927-c37c-400a-a5f8-433e9041a5ff", ResourceVersion:"20157", Generation:0, CreationTimestamp:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), DeletionTimestamp:<nil>, DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"549073577"}, Annotations:map[string]string{"cni.projectcalico.org/containerID":"0ad74486b3902c5bca48832143036a57c2ec1f37d4a39ee573c30ef80e26e82f", "cni.projectcalico.org/podIP":"100.96.1.64/32", "cni.projectcalico.org/podIPs":"100.96.1.64/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ManagedFields:[]v1.ManagedFieldsEntry{v1.ManagedFieldsEntry{Manager:"e2e.test", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0012fa060), Subresource:""}, v1.ManagedFieldsEntry{Manager:"calico", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 26, 11, 7, 42, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0012fa108), Subresource:"status"}, v1.ManagedFieldsEntry{Manager:"kubelet", Operation:"Update", APIVersion:"v1", Time:time.Date(2024, time.April, 26, 11, 8, 20, 0, time.Local), FieldsType:"FieldsV1", FieldsV1:(*v1.FieldsV1)(0xc0012fa138), Subresource:"status"}}}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"kube-api-access-9nsqh", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(nil), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(0xc005a120c0), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil), Ephemeral:(*v1.EphemeralVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.conf-125.thomas.internal.emk.fuga.cloud", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-9nsqh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.conf-125.thomas.internal.emk.fuga.cloud", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-9nsqh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"registry.k8s.io/pause:3.8", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar{v1.EnvVar{Name:"KUBERNETES_SERVICE_HOST", Value:"api.conf-125.thomas.internal.emk.fuga.cloud", ValueFrom:(*v1.EnvVarSource)(nil)}}, Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"kube-api-access-9nsqh", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004c34118), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00036c000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004c34190)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004c341c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004c341c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc004c341cc), PreemptionPolicy:(*v1.PreemptionPolicy)(0xc0033aa070), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil), SetHostnameAsFQDN:(*bool)(nil), OS:(*v1.PodOS)(nil), HostUsers:(*bool)(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.2.248", PodIP:"100.96.1.64", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.96.1.64"}}, StartTime:time.Date(2024, time.April, 26, 11, 7, 41, 0, time.Local), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0012fa180), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00036c150)}, Ready:false, RestartCount:3, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"registry.k8s.io/e2e-test-images/busybox@sha256:c318242786b139d18676b1c09a0ad7f15fc17f8f16a5b2e625cd0dc8c9703daf", ContainerID:"containerd://761588ca24836789a5a5243182a6cdc43a83c5ac21d3bf42f4fd1d5ac136b9d9", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc005a122c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/e2e-test-images/busybox:1.29-2", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc005a12240), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"registry.k8s.io/pause:3.8", ImageID:"", ContainerID:"", Started:(*bool)(0xc004c3425f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 26 11:08:20.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-1407" for this suite. 04/26/24 11:08:20.683
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] Downward API volume
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:08:20.691
Apr 26 11:08:20.691: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 11:08:20.692
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:20.726
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:20.732
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161
STEP: Creating the pod 04/26/24 11:08:20.737
Apr 26 11:08:20.751: INFO: Waiting up to 5m0s for pod "annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4" in namespace "downward-api-2459" to be "running and ready"
Apr 26 11:08:20.759: INFO: Pod "annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.00989ms
Apr 26 11:08:20.759: INFO: The phase of Pod annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:08:22.766: INFO: Pod "annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4": Phase="Running", Reason="", readiness=true. Elapsed: 2.014437339s
Apr 26 11:08:22.766: INFO: The phase of Pod annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4 is Running (Ready = true)
Apr 26 11:08:22.766: INFO: Pod "annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4" satisfied condition "running and ready"
Apr 26 11:08:23.305: INFO: Successfully updated pod "annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 26 11:08:25.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2459" for this suite. 04/26/24 11:08:25.384
{"msg":"PASSED [sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]","completed":32,"skipped":576,"failed":0}
------------------------------
â€¢ [4.700 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:08:20.691
    Apr 26 11:08:20.691: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 11:08:20.692
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:20.726
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:20.732
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:161
    STEP: Creating the pod 04/26/24 11:08:20.737
    Apr 26 11:08:20.751: INFO: Waiting up to 5m0s for pod "annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4" in namespace "downward-api-2459" to be "running and ready"
    Apr 26 11:08:20.759: INFO: Pod "annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.00989ms
    Apr 26 11:08:20.759: INFO: The phase of Pod annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:08:22.766: INFO: Pod "annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4": Phase="Running", Reason="", readiness=true. Elapsed: 2.014437339s
    Apr 26 11:08:22.766: INFO: The phase of Pod annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4 is Running (Ready = true)
    Apr 26 11:08:22.766: INFO: Pod "annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4" satisfied condition "running and ready"
    Apr 26 11:08:23.305: INFO: Successfully updated pod "annotationupdate20b5e9e1-aeed-4b25-89ac-4e6cd3df2cb4"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 26 11:08:25.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2459" for this suite. 04/26/24 11:08:25.384
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:08:25.391
Apr 26 11:08:25.391: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename endpointslice 04/26/24 11:08:25.392
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:25.412
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:25.416
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65
Apr 26 11:08:25.436: INFO: Endpoints addresses: [10.241.45.203] , ports: [443]
Apr 26 11:08:25.436: INFO: EndpointSlices addresses: [10.241.45.203] , ports: [443]
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 26 11:08:25.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6404" for this suite. 04/26/24 11:08:25.444
{"msg":"PASSED [sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]","completed":33,"skipped":586,"failed":0}
------------------------------
â€¢ [0.059 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should have Endpoints and EndpointSlices pointing to API Server [Conformance]
  test/e2e/network/endpointslice.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:08:25.391
    Apr 26 11:08:25.391: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename endpointslice 04/26/24 11:08:25.392
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:25.412
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:25.416
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should have Endpoints and EndpointSlices pointing to API Server [Conformance]
      test/e2e/network/endpointslice.go:65
    Apr 26 11:08:25.436: INFO: Endpoints addresses: [10.241.45.203] , ports: [443]
    Apr 26 11:08:25.436: INFO: EndpointSlices addresses: [10.241.45.203] , ports: [443]
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 26 11:08:25.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-6404" for this suite. 04/26/24 11:08:25.444
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:08:25.451
Apr 26 11:08:25.451: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 11:08:25.452
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:25.47
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:25.477
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106
STEP: Creating a pod to test emptydir 0666 on tmpfs 04/26/24 11:08:25.481
Apr 26 11:08:25.492: INFO: Waiting up to 5m0s for pod "pod-f6b9003c-b9f1-4a1a-990d-2931c366c961" in namespace "emptydir-1368" to be "Succeeded or Failed"
Apr 26 11:08:25.500: INFO: Pod "pod-f6b9003c-b9f1-4a1a-990d-2931c366c961": Phase="Pending", Reason="", readiness=false. Elapsed: 7.631351ms
Apr 26 11:08:27.510: INFO: Pod "pod-f6b9003c-b9f1-4a1a-990d-2931c366c961": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017508158s
Apr 26 11:08:29.505: INFO: Pod "pod-f6b9003c-b9f1-4a1a-990d-2931c366c961": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013207685s
STEP: Saw pod success 04/26/24 11:08:29.505
Apr 26 11:08:29.506: INFO: Pod "pod-f6b9003c-b9f1-4a1a-990d-2931c366c961" satisfied condition "Succeeded or Failed"
Apr 26 11:08:29.511: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-f6b9003c-b9f1-4a1a-990d-2931c366c961 container test-container: <nil>
STEP: delete the pod 04/26/24 11:08:29.526
Apr 26 11:08:29.536: INFO: Waiting for pod pod-f6b9003c-b9f1-4a1a-990d-2931c366c961 to disappear
Apr 26 11:08:29.540: INFO: Pod pod-f6b9003c-b9f1-4a1a-990d-2931c366c961 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 11:08:29.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1368" for this suite. 04/26/24 11:08:29.551
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":34,"skipped":597,"failed":0}
------------------------------
â€¢ [4.108 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:08:25.451
    Apr 26 11:08:25.451: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 11:08:25.452
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:25.47
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:25.477
    [It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:106
    STEP: Creating a pod to test emptydir 0666 on tmpfs 04/26/24 11:08:25.481
    Apr 26 11:08:25.492: INFO: Waiting up to 5m0s for pod "pod-f6b9003c-b9f1-4a1a-990d-2931c366c961" in namespace "emptydir-1368" to be "Succeeded or Failed"
    Apr 26 11:08:25.500: INFO: Pod "pod-f6b9003c-b9f1-4a1a-990d-2931c366c961": Phase="Pending", Reason="", readiness=false. Elapsed: 7.631351ms
    Apr 26 11:08:27.510: INFO: Pod "pod-f6b9003c-b9f1-4a1a-990d-2931c366c961": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017508158s
    Apr 26 11:08:29.505: INFO: Pod "pod-f6b9003c-b9f1-4a1a-990d-2931c366c961": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013207685s
    STEP: Saw pod success 04/26/24 11:08:29.505
    Apr 26 11:08:29.506: INFO: Pod "pod-f6b9003c-b9f1-4a1a-990d-2931c366c961" satisfied condition "Succeeded or Failed"
    Apr 26 11:08:29.511: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-f6b9003c-b9f1-4a1a-990d-2931c366c961 container test-container: <nil>
    STEP: delete the pod 04/26/24 11:08:29.526
    Apr 26 11:08:29.536: INFO: Waiting for pod pod-f6b9003c-b9f1-4a1a-990d-2931c366c961 to disappear
    Apr 26 11:08:29.540: INFO: Pod pod-f6b9003c-b9f1-4a1a-990d-2931c366c961 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 11:08:29.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1368" for this suite. 04/26/24 11:08:29.551
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:08:29.56
Apr 26 11:08:29.560: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename var-expansion 04/26/24 11:08:29.561
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:29.575
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:29.579
[It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185
Apr 26 11:08:29.597: INFO: Waiting up to 2m0s for pod "var-expansion-1b25aca4-1b09-4709-9d8e-924ec483c7d2" in namespace "var-expansion-3275" to be "container 0 failed with reason CreateContainerConfigError"
Apr 26 11:08:29.603: INFO: Pod "var-expansion-1b25aca4-1b09-4709-9d8e-924ec483c7d2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.649372ms
Apr 26 11:08:31.611: INFO: Pod "var-expansion-1b25aca4-1b09-4709-9d8e-924ec483c7d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014212859s
Apr 26 11:08:31.611: INFO: Pod "var-expansion-1b25aca4-1b09-4709-9d8e-924ec483c7d2" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Apr 26 11:08:31.611: INFO: Deleting pod "var-expansion-1b25aca4-1b09-4709-9d8e-924ec483c7d2" in namespace "var-expansion-3275"
Apr 26 11:08:31.620: INFO: Wait up to 5m0s for pod "var-expansion-1b25aca4-1b09-4709-9d8e-924ec483c7d2" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 26 11:08:35.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3275" for this suite. 04/26/24 11:08:35.643
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]","completed":35,"skipped":599,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.092 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
  test/e2e/common/node/expansion.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:08:29.56
    Apr 26 11:08:29.560: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename var-expansion 04/26/24 11:08:29.561
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:29.575
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:29.579
    [It] should fail substituting values in a volume subpath with absolute path [Slow] [Conformance]
      test/e2e/common/node/expansion.go:185
    Apr 26 11:08:29.597: INFO: Waiting up to 2m0s for pod "var-expansion-1b25aca4-1b09-4709-9d8e-924ec483c7d2" in namespace "var-expansion-3275" to be "container 0 failed with reason CreateContainerConfigError"
    Apr 26 11:08:29.603: INFO: Pod "var-expansion-1b25aca4-1b09-4709-9d8e-924ec483c7d2": Phase="Pending", Reason="", readiness=false. Elapsed: 6.649372ms
    Apr 26 11:08:31.611: INFO: Pod "var-expansion-1b25aca4-1b09-4709-9d8e-924ec483c7d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014212859s
    Apr 26 11:08:31.611: INFO: Pod "var-expansion-1b25aca4-1b09-4709-9d8e-924ec483c7d2" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Apr 26 11:08:31.611: INFO: Deleting pod "var-expansion-1b25aca4-1b09-4709-9d8e-924ec483c7d2" in namespace "var-expansion-3275"
    Apr 26 11:08:31.620: INFO: Wait up to 5m0s for pod "var-expansion-1b25aca4-1b09-4709-9d8e-924ec483c7d2" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 26 11:08:35.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-3275" for this suite. 04/26/24 11:08:35.643
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:08:35.655
Apr 26 11:08:35.655: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 11:08:35.656
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:35.671
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:35.677
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210
STEP: creating an Endpoint 04/26/24 11:08:35.687
STEP: waiting for available Endpoint 04/26/24 11:08:35.692
STEP: listing all Endpoints 04/26/24 11:08:35.695
STEP: updating the Endpoint 04/26/24 11:08:35.7
STEP: fetching the Endpoint 04/26/24 11:08:35.713
STEP: patching the Endpoint 04/26/24 11:08:35.717
STEP: fetching the Endpoint 04/26/24 11:08:35.727
STEP: deleting the Endpoint by Collection 04/26/24 11:08:35.731
STEP: waiting for Endpoint deletion 04/26/24 11:08:35.741
STEP: fetching the Endpoint 04/26/24 11:08:35.744
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 11:08:35.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3561" for this suite. 04/26/24 11:08:35.756
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should test the lifecycle of an Endpoint [Conformance]","completed":36,"skipped":655,"failed":0}
------------------------------
â€¢ [0.109 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should test the lifecycle of an Endpoint [Conformance]
  test/e2e/network/service.go:3210

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:08:35.655
    Apr 26 11:08:35.655: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 11:08:35.656
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:35.671
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:35.677
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should test the lifecycle of an Endpoint [Conformance]
      test/e2e/network/service.go:3210
    STEP: creating an Endpoint 04/26/24 11:08:35.687
    STEP: waiting for available Endpoint 04/26/24 11:08:35.692
    STEP: listing all Endpoints 04/26/24 11:08:35.695
    STEP: updating the Endpoint 04/26/24 11:08:35.7
    STEP: fetching the Endpoint 04/26/24 11:08:35.713
    STEP: patching the Endpoint 04/26/24 11:08:35.717
    STEP: fetching the Endpoint 04/26/24 11:08:35.727
    STEP: deleting the Endpoint by Collection 04/26/24 11:08:35.731
    STEP: waiting for Endpoint deletion 04/26/24 11:08:35.741
    STEP: fetching the Endpoint 04/26/24 11:08:35.744
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 11:08:35.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3561" for this suite. 04/26/24 11:08:35.756
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:08:35.768
Apr 26 11:08:35.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename var-expansion 04/26/24 11:08:35.769
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:35.782
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:35.787
[It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151
Apr 26 11:08:35.803: INFO: Waiting up to 2m0s for pod "var-expansion-8251b654-9119-4650-aa81-72b12e891eb6" in namespace "var-expansion-2586" to be "container 0 failed with reason CreateContainerConfigError"
Apr 26 11:08:35.812: INFO: Pod "var-expansion-8251b654-9119-4650-aa81-72b12e891eb6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.17296ms
Apr 26 11:08:37.818: INFO: Pod "var-expansion-8251b654-9119-4650-aa81-72b12e891eb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014140454s
Apr 26 11:08:37.818: INFO: Pod "var-expansion-8251b654-9119-4650-aa81-72b12e891eb6" satisfied condition "container 0 failed with reason CreateContainerConfigError"
Apr 26 11:08:37.818: INFO: Deleting pod "var-expansion-8251b654-9119-4650-aa81-72b12e891eb6" in namespace "var-expansion-2586"
Apr 26 11:08:37.826: INFO: Wait up to 5m0s for pod "var-expansion-8251b654-9119-4650-aa81-72b12e891eb6" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 26 11:08:39.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2586" for this suite. 04/26/24 11:08:39.88
{"msg":"PASSED [sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Slow] [Conformance]","completed":37,"skipped":711,"failed":0}
------------------------------
â€¢ [4.118 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
  test/e2e/common/node/expansion.go:151

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:08:35.768
    Apr 26 11:08:35.768: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename var-expansion 04/26/24 11:08:35.769
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:35.782
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:35.787
    [It] should fail substituting values in a volume subpath with backticks [Slow] [Conformance]
      test/e2e/common/node/expansion.go:151
    Apr 26 11:08:35.803: INFO: Waiting up to 2m0s for pod "var-expansion-8251b654-9119-4650-aa81-72b12e891eb6" in namespace "var-expansion-2586" to be "container 0 failed with reason CreateContainerConfigError"
    Apr 26 11:08:35.812: INFO: Pod "var-expansion-8251b654-9119-4650-aa81-72b12e891eb6": Phase="Pending", Reason="", readiness=false. Elapsed: 8.17296ms
    Apr 26 11:08:37.818: INFO: Pod "var-expansion-8251b654-9119-4650-aa81-72b12e891eb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014140454s
    Apr 26 11:08:37.818: INFO: Pod "var-expansion-8251b654-9119-4650-aa81-72b12e891eb6" satisfied condition "container 0 failed with reason CreateContainerConfigError"
    Apr 26 11:08:37.818: INFO: Deleting pod "var-expansion-8251b654-9119-4650-aa81-72b12e891eb6" in namespace "var-expansion-2586"
    Apr 26 11:08:37.826: INFO: Wait up to 5m0s for pod "var-expansion-8251b654-9119-4650-aa81-72b12e891eb6" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 26 11:08:39.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2586" for this suite. 04/26/24 11:08:39.88
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-apps] DisruptionController
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:08:39.886
Apr 26 11:08:39.886: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename disruption 04/26/24 11:08:39.887
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:39.899
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:39.904
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346
STEP: Creating a pdb that targets all three pods in a test replica set 04/26/24 11:08:39.908
STEP: Waiting for the pdb to be processed 04/26/24 11:08:39.913
STEP: First trying to evict a pod which shouldn't be evictable 04/26/24 11:08:41.93
STEP: Waiting for all pods to be running 04/26/24 11:08:41.93
Apr 26 11:08:41.935: INFO: pods: 0 < 3
STEP: locating a running pod 04/26/24 11:08:43.944
STEP: Updating the pdb to allow a pod to be evicted 04/26/24 11:08:43.971
STEP: Waiting for the pdb to be processed 04/26/24 11:08:43.982
STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/26/24 11:08:45.993
STEP: Waiting for all pods to be running 04/26/24 11:08:45.993
STEP: Waiting for the pdb to observed all healthy pods 04/26/24 11:08:45.999
STEP: Patching the pdb to disallow a pod to be evicted 04/26/24 11:08:46.021
STEP: Waiting for the pdb to be processed 04/26/24 11:08:46.034
STEP: Waiting for all pods to be running 04/26/24 11:08:48.048
STEP: locating a running pod 04/26/24 11:08:48.053
STEP: Deleting the pdb to allow a pod to be evicted 04/26/24 11:08:48.064
STEP: Waiting for the pdb to be deleted 04/26/24 11:08:48.07
STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/26/24 11:08:48.075
STEP: Waiting for all pods to be running 04/26/24 11:08:48.075
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 26 11:08:48.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-192" for this suite. 04/26/24 11:08:48.104
{"msg":"PASSED [sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]","completed":38,"skipped":716,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.228 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should block an eviction until the PDB is updated to allow it [Conformance]
  test/e2e/apps/disruption.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:08:39.886
    Apr 26 11:08:39.886: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename disruption 04/26/24 11:08:39.887
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:39.899
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:39.904
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should block an eviction until the PDB is updated to allow it [Conformance]
      test/e2e/apps/disruption.go:346
    STEP: Creating a pdb that targets all three pods in a test replica set 04/26/24 11:08:39.908
    STEP: Waiting for the pdb to be processed 04/26/24 11:08:39.913
    STEP: First trying to evict a pod which shouldn't be evictable 04/26/24 11:08:41.93
    STEP: Waiting for all pods to be running 04/26/24 11:08:41.93
    Apr 26 11:08:41.935: INFO: pods: 0 < 3
    STEP: locating a running pod 04/26/24 11:08:43.944
    STEP: Updating the pdb to allow a pod to be evicted 04/26/24 11:08:43.971
    STEP: Waiting for the pdb to be processed 04/26/24 11:08:43.982
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/26/24 11:08:45.993
    STEP: Waiting for all pods to be running 04/26/24 11:08:45.993
    STEP: Waiting for the pdb to observed all healthy pods 04/26/24 11:08:45.999
    STEP: Patching the pdb to disallow a pod to be evicted 04/26/24 11:08:46.021
    STEP: Waiting for the pdb to be processed 04/26/24 11:08:46.034
    STEP: Waiting for all pods to be running 04/26/24 11:08:48.048
    STEP: locating a running pod 04/26/24 11:08:48.053
    STEP: Deleting the pdb to allow a pod to be evicted 04/26/24 11:08:48.064
    STEP: Waiting for the pdb to be deleted 04/26/24 11:08:48.07
    STEP: Trying to evict the same pod we tried earlier which should now be evictable 04/26/24 11:08:48.075
    STEP: Waiting for all pods to be running 04/26/24 11:08:48.075
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 26 11:08:48.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-192" for this suite. 04/26/24 11:08:48.104
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Container Runtime blackbox test when starting a container that exits
  should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:08:48.115
Apr 26 11:08:48.116: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-runtime 04/26/24 11:08:48.117
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:48.134
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:48.14
[It] should run with the expected status [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:51
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 04/26/24 11:08:48.175
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 04/26/24 11:09:03.326
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 04/26/24 11:09:03.33
STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 04/26/24 11:09:03.34
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 04/26/24 11:09:03.34
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 04/26/24 11:09:03.373
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 04/26/24 11:09:06.399
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 04/26/24 11:09:08.426
STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 04/26/24 11:09:08.443
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 04/26/24 11:09:08.443
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 04/26/24 11:09:08.472
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 04/26/24 11:09:09.487
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 04/26/24 11:09:12.513
STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 04/26/24 11:09:12.525
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 04/26/24 11:09:12.525
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 26 11:09:12.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1577" for this suite. 04/26/24 11:09:12.571
{"msg":"PASSED [sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]","completed":39,"skipped":716,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.466 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    when starting a container that exits
    test/e2e/common/node/runtime.go:44
      should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:08:48.115
    Apr 26 11:08:48.116: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-runtime 04/26/24 11:08:48.117
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:08:48.134
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:08:48.14
    [It] should run with the expected status [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:51
    STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount' 04/26/24 11:08:48.175
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase' 04/26/24 11:09:03.326
    STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition 04/26/24 11:09:03.33
    STEP: Container 'terminate-cmd-rpa': should get the expected 'State' 04/26/24 11:09:03.34
    STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance] 04/26/24 11:09:03.34
    STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount' 04/26/24 11:09:03.373
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase' 04/26/24 11:09:06.399
    STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition 04/26/24 11:09:08.426
    STEP: Container 'terminate-cmd-rpof': should get the expected 'State' 04/26/24 11:09:08.443
    STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance] 04/26/24 11:09:08.443
    STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount' 04/26/24 11:09:08.472
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase' 04/26/24 11:09:09.487
    STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition 04/26/24 11:09:12.513
    STEP: Container 'terminate-cmd-rpn': should get the expected 'State' 04/26/24 11:09:12.525
    STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance] 04/26/24 11:09:12.525
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 26 11:09:12.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-1577" for this suite. 04/26/24 11:09:12.571
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:09:12.584
Apr 26 11:09:12.584: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename namespaces 04/26/24 11:09:12.585
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:09:12.6
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:09:12.605
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250
STEP: Creating a test namespace 04/26/24 11:09:12.61
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:09:12.636
STEP: Creating a service in the namespace 04/26/24 11:09:12.643
STEP: Deleting the namespace 04/26/24 11:09:12.686
STEP: Waiting for the namespace to be removed. 04/26/24 11:09:12.708
STEP: Recreating the namespace 04/26/24 11:09:18.715
STEP: Verifying there is no service in the namespace 04/26/24 11:09:18.729
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:09:18.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4591" for this suite. 04/26/24 11:09:18.742
STEP: Destroying namespace "nsdeletetest-8311" for this suite. 04/26/24 11:09:18.75
Apr 26 11:09:18.755: INFO: Namespace nsdeletetest-8311 was already deleted
STEP: Destroying namespace "nsdeletetest-7484" for this suite. 04/26/24 11:09:18.755
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]","completed":40,"skipped":720,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.176 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:250

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:09:12.584
    Apr 26 11:09:12.584: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename namespaces 04/26/24 11:09:12.585
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:09:12.6
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:09:12.605
    [It] should ensure that all services are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:250
    STEP: Creating a test namespace 04/26/24 11:09:12.61
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:09:12.636
    STEP: Creating a service in the namespace 04/26/24 11:09:12.643
    STEP: Deleting the namespace 04/26/24 11:09:12.686
    STEP: Waiting for the namespace to be removed. 04/26/24 11:09:12.708
    STEP: Recreating the namespace 04/26/24 11:09:18.715
    STEP: Verifying there is no service in the namespace 04/26/24 11:09:18.729
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:09:18.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-4591" for this suite. 04/26/24 11:09:18.742
    STEP: Destroying namespace "nsdeletetest-8311" for this suite. 04/26/24 11:09:18.75
    Apr 26 11:09:18.755: INFO: Namespace nsdeletetest-8311 was already deleted
    STEP: Destroying namespace "nsdeletetest-7484" for this suite. 04/26/24 11:09:18.755
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:09:18.761
Apr 26 11:09:18.761: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-runtime 04/26/24 11:09:18.761
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:09:18.776
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:09:18.781
[It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:194
STEP: create the container 04/26/24 11:09:18.786
STEP: wait for the container to reach Succeeded 04/26/24 11:09:18.798
STEP: get the container status 04/26/24 11:09:22.83
STEP: the container should be terminated 04/26/24 11:09:22.836
STEP: the termination message should be set 04/26/24 11:09:22.837
Apr 26 11:09:22.837: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 04/26/24 11:09:22.837
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 26 11:09:22.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5227" for this suite. 04/26/24 11:09:22.86
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]","completed":41,"skipped":731,"failed":0}
------------------------------
â€¢ [4.107 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:09:18.761
    Apr 26 11:09:18.761: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-runtime 04/26/24 11:09:18.761
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:09:18.776
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:09:18.781
    [It] should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:194
    STEP: create the container 04/26/24 11:09:18.786
    STEP: wait for the container to reach Succeeded 04/26/24 11:09:18.798
    STEP: get the container status 04/26/24 11:09:22.83
    STEP: the container should be terminated 04/26/24 11:09:22.836
    STEP: the termination message should be set 04/26/24 11:09:22.837
    Apr 26 11:09:22.837: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 04/26/24 11:09:22.837
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 26 11:09:22.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-5227" for this suite. 04/26/24 11:09:22.86
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:09:22.875
Apr 26 11:09:22.876: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pods 04/26/24 11:09:22.877
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:09:22.893
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:09:22.899
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895
STEP: creating a Pod with a static label 04/26/24 11:09:22.931
STEP: watching for Pod to be ready 04/26/24 11:09:22.941
Apr 26 11:09:22.945: INFO: observed Pod pod-test in namespace pods-2532 in phase Pending with labels: map[test-pod-static:true] & conditions []
Apr 26 11:09:22.945: INFO: observed Pod pod-test in namespace pods-2532 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  }]
Apr 26 11:09:22.962: INFO: observed Pod pod-test in namespace pods-2532 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  }]
Apr 26 11:09:23.384: INFO: observed Pod pod-test in namespace pods-2532 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  }]
Apr 26 11:09:23.889: INFO: Found Pod pod-test in namespace pods-2532 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  }]
STEP: patching the Pod with a new Label and updated data 04/26/24 11:09:23.893
STEP: getting the Pod and ensuring that it's patched 04/26/24 11:09:23.906
STEP: replacing the Pod's status Ready condition to False 04/26/24 11:09:23.91
STEP: check the Pod again to ensure its Ready conditions are False 04/26/24 11:09:23.926
STEP: deleting the Pod via a Collection with a LabelSelector 04/26/24 11:09:23.926
STEP: watching for the Pod to be deleted 04/26/24 11:09:23.935
Apr 26 11:09:23.938: INFO: observed event type MODIFIED
Apr 26 11:09:25.900: INFO: observed event type MODIFIED
Apr 26 11:09:26.094: INFO: observed event type MODIFIED
Apr 26 11:09:26.901: INFO: observed event type MODIFIED
Apr 26 11:09:26.909: INFO: observed event type MODIFIED
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 26 11:09:26.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2532" for this suite. 04/26/24 11:09:26.926
{"msg":"PASSED [sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]","completed":42,"skipped":806,"failed":0}
------------------------------
â€¢ [4.057 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should run through the lifecycle of Pods and PodStatus [Conformance]
  test/e2e/common/node/pods.go:895

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:09:22.875
    Apr 26 11:09:22.876: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pods 04/26/24 11:09:22.877
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:09:22.893
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:09:22.899
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should run through the lifecycle of Pods and PodStatus [Conformance]
      test/e2e/common/node/pods.go:895
    STEP: creating a Pod with a static label 04/26/24 11:09:22.931
    STEP: watching for Pod to be ready 04/26/24 11:09:22.941
    Apr 26 11:09:22.945: INFO: observed Pod pod-test in namespace pods-2532 in phase Pending with labels: map[test-pod-static:true] & conditions []
    Apr 26 11:09:22.945: INFO: observed Pod pod-test in namespace pods-2532 in phase Pending with labels: map[test-pod-static:true] & conditions [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  }]
    Apr 26 11:09:22.962: INFO: observed Pod pod-test in namespace pods-2532 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  }]
    Apr 26 11:09:23.384: INFO: observed Pod pod-test in namespace pods-2532 in phase Pending with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC ContainersNotReady containers with unready status: [pod-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  }]
    Apr 26 11:09:23.889: INFO: Found Pod pod-test in namespace pods-2532 in phase Running with labels: map[test-pod-static:true] & conditions [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  } {Ready True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:23 +0000 UTC  } {ContainersReady True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:23 +0000 UTC  } {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:09:22 +0000 UTC  }]
    STEP: patching the Pod with a new Label and updated data 04/26/24 11:09:23.893
    STEP: getting the Pod and ensuring that it's patched 04/26/24 11:09:23.906
    STEP: replacing the Pod's status Ready condition to False 04/26/24 11:09:23.91
    STEP: check the Pod again to ensure its Ready conditions are False 04/26/24 11:09:23.926
    STEP: deleting the Pod via a Collection with a LabelSelector 04/26/24 11:09:23.926
    STEP: watching for the Pod to be deleted 04/26/24 11:09:23.935
    Apr 26 11:09:23.938: INFO: observed event type MODIFIED
    Apr 26 11:09:25.900: INFO: observed event type MODIFIED
    Apr 26 11:09:26.094: INFO: observed event type MODIFIED
    Apr 26 11:09:26.901: INFO: observed event type MODIFIED
    Apr 26 11:09:26.909: INFO: observed event type MODIFIED
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 26 11:09:26.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-2532" for this suite. 04/26/24 11:09:26.926
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:09:26.934
Apr 26 11:09:26.934: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 11:09:26.935
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:09:26.951
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:09:26.96
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 11:09:26.976
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:09:27.143
STEP: Deploying the webhook pod 04/26/24 11:09:27.155
STEP: Wait for the deployment to be ready 04/26/24 11:09:27.165
Apr 26 11:09:27.174: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 11:09:29.188
STEP: Verifying the service has paired with the endpoint 04/26/24 11:09:29.208
Apr 26 11:09:30.208: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 04/26/24 11:09:30.214
STEP: create a namespace for the webhook 04/26/24 11:09:30.343
STEP: create a configmap should be unconditionally rejected by the webhook 04/26/24 11:09:30.35
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:09:30.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9013" for this suite. 04/26/24 11:09:30.409
STEP: Destroying namespace "webhook-9013-markers" for this suite. 04/26/24 11:09:30.416
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]","completed":43,"skipped":833,"failed":0}
------------------------------
â€¢ [3.575 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  test/e2e/apimachinery/webhook.go:238

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:09:26.934
    Apr 26 11:09:26.934: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 11:09:26.935
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:09:26.951
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:09:26.96
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 11:09:26.976
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:09:27.143
    STEP: Deploying the webhook pod 04/26/24 11:09:27.155
    STEP: Wait for the deployment to be ready 04/26/24 11:09:27.165
    Apr 26 11:09:27.174: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 11:09:29.188
    STEP: Verifying the service has paired with the endpoint 04/26/24 11:09:29.208
    Apr 26 11:09:30.208: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should unconditionally reject operations on fail closed webhook [Conformance]
      test/e2e/apimachinery/webhook.go:238
    STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API 04/26/24 11:09:30.214
    STEP: create a namespace for the webhook 04/26/24 11:09:30.343
    STEP: create a configmap should be unconditionally rejected by the webhook 04/26/24 11:09:30.35
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:09:30.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9013" for this suite. 04/26/24 11:09:30.409
    STEP: Destroying namespace "webhook-9013-markers" for this suite. 04/26/24 11:09:30.416
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath
  runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:09:30.512
Apr 26 11:09:30.512: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename sched-preemption 04/26/24 11:09:30.514
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:09:30.531
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:09:30.537
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 26 11:09:30.557: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 26 11:10:30.605: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:10:30.61
Apr 26 11:10:30.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename sched-preemption-path 04/26/24 11:10:30.611
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:10:30.626
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:10:30.631
[BeforeEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:496
STEP: Finding an available node 04/26/24 11:10:30.636
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/26/24 11:10:30.636
Apr 26 11:10:30.648: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-697" to be "running"
Apr 26 11:10:30.656: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 7.642918ms
Apr 26 11:10:32.663: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.014814711s
Apr 26 11:10:32.663: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/26/24 11:10:32.669
Apr 26 11:10:32.685: INFO: found a healthy node: shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
[It] runs ReplicaSets to verify preemption running path [Conformance]
  test/e2e/scheduling/preemption.go:543
Apr 26 11:10:46.795: INFO: pods created so far: [1 1 1]
Apr 26 11:10:46.795: INFO: length of pods created so far: 3
Apr 26 11:10:48.815: INFO: pods created so far: [2 2 1]
[AfterEach] PreemptionExecutionPath
  test/e2e/framework/framework.go:187
Apr 26 11:10:55.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-697" for this suite. 04/26/24 11:10:55.825
[AfterEach] PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:470
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:10:55.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-3981" for this suite. 04/26/24 11:10:55.908
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]","completed":44,"skipped":844,"failed":0}
------------------------------
â€¢ [SLOW TEST] [85.478 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PreemptionExecutionPath
  test/e2e/scheduling/preemption.go:458
    runs ReplicaSets to verify preemption running path [Conformance]
    test/e2e/scheduling/preemption.go:543

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:09:30.512
    Apr 26 11:09:30.512: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename sched-preemption 04/26/24 11:09:30.514
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:09:30.531
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:09:30.537
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 26 11:09:30.557: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 26 11:10:30.605: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:10:30.61
    Apr 26 11:10:30.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename sched-preemption-path 04/26/24 11:10:30.611
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:10:30.626
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:10:30.631
    [BeforeEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:496
    STEP: Finding an available node 04/26/24 11:10:30.636
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/26/24 11:10:30.636
    Apr 26 11:10:30.648: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-preemption-path-697" to be "running"
    Apr 26 11:10:30.656: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 7.642918ms
    Apr 26 11:10:32.663: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.014814711s
    Apr 26 11:10:32.663: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/26/24 11:10:32.669
    Apr 26 11:10:32.685: INFO: found a healthy node: shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
    [It] runs ReplicaSets to verify preemption running path [Conformance]
      test/e2e/scheduling/preemption.go:543
    Apr 26 11:10:46.795: INFO: pods created so far: [1 1 1]
    Apr 26 11:10:46.795: INFO: length of pods created so far: 3
    Apr 26 11:10:48.815: INFO: pods created so far: [2 2 1]
    [AfterEach] PreemptionExecutionPath
      test/e2e/framework/framework.go:187
    Apr 26 11:10:55.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-697" for this suite. 04/26/24 11:10:55.825
    [AfterEach] PreemptionExecutionPath
      test/e2e/scheduling/preemption.go:470
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:10:55.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-3981" for this suite. 04/26/24 11:10:55.908
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:10:55.991
Apr 26 11:10:55.992: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 11:10:55.992
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:10:56.006
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:10:56.01
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108
STEP: Creating configMap with name configmap-test-volume-map-dba15f15-b9fc-4582-be69-ee5766d6a104 04/26/24 11:10:56.016
STEP: Creating a pod to test consume configMaps 04/26/24 11:10:56.02
Apr 26 11:10:56.031: INFO: Waiting up to 5m0s for pod "pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c" in namespace "configmap-5445" to be "Succeeded or Failed"
Apr 26 11:10:56.036: INFO: Pod "pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.621894ms
Apr 26 11:10:58.043: INFO: Pod "pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012046045s
Apr 26 11:11:00.044: INFO: Pod "pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013263235s
STEP: Saw pod success 04/26/24 11:11:00.044
Apr 26 11:11:00.044: INFO: Pod "pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c" satisfied condition "Succeeded or Failed"
Apr 26 11:11:00.051: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:11:00.108
Apr 26 11:11:00.124: INFO: Waiting for pod pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c to disappear
Apr 26 11:11:00.128: INFO: Pod pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 11:11:00.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5445" for this suite. 04/26/24 11:11:00.138
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":45,"skipped":852,"failed":0}
------------------------------
â€¢ [4.153 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:10:55.991
    Apr 26 11:10:55.992: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 11:10:55.992
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:10:56.006
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:10:56.01
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:108
    STEP: Creating configMap with name configmap-test-volume-map-dba15f15-b9fc-4582-be69-ee5766d6a104 04/26/24 11:10:56.016
    STEP: Creating a pod to test consume configMaps 04/26/24 11:10:56.02
    Apr 26 11:10:56.031: INFO: Waiting up to 5m0s for pod "pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c" in namespace "configmap-5445" to be "Succeeded or Failed"
    Apr 26 11:10:56.036: INFO: Pod "pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.621894ms
    Apr 26 11:10:58.043: INFO: Pod "pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012046045s
    Apr 26 11:11:00.044: INFO: Pod "pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013263235s
    STEP: Saw pod success 04/26/24 11:11:00.044
    Apr 26 11:11:00.044: INFO: Pod "pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c" satisfied condition "Succeeded or Failed"
    Apr 26 11:11:00.051: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:11:00.108
    Apr 26 11:11:00.124: INFO: Waiting for pod pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c to disappear
    Apr 26 11:11:00.128: INFO: Pod pod-configmaps-d62b2a90-e49f-4d27-95e1-495eff24394c no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 11:11:00.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5445" for this suite. 04/26/24 11:11:00.138
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:11:00.148
Apr 26 11:11:00.149: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 11:11:00.149
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:11:00.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:11:00.168
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206
STEP: Creating a pod to test downward API volume plugin 04/26/24 11:11:00.173
Apr 26 11:11:00.185: INFO: Waiting up to 5m0s for pod "downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59" in namespace "downward-api-223" to be "Succeeded or Failed"
Apr 26 11:11:00.194: INFO: Pod "downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59": Phase="Pending", Reason="", readiness=false. Elapsed: 8.655703ms
Apr 26 11:11:02.229: INFO: Pod "downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043595646s
Apr 26 11:11:04.201: INFO: Pod "downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015261317s
STEP: Saw pod success 04/26/24 11:11:04.201
Apr 26 11:11:04.201: INFO: Pod "downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59" satisfied condition "Succeeded or Failed"
Apr 26 11:11:04.207: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59 container client-container: <nil>
STEP: delete the pod 04/26/24 11:11:04.226
Apr 26 11:11:04.242: INFO: Waiting for pod downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59 to disappear
Apr 26 11:11:04.246: INFO: Pod downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 26 11:11:04.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-223" for this suite. 04/26/24 11:11:04.255
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]","completed":46,"skipped":882,"failed":0}
------------------------------
â€¢ [4.112 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:11:00.148
    Apr 26 11:11:00.149: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 11:11:00.149
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:11:00.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:11:00.168
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:206
    STEP: Creating a pod to test downward API volume plugin 04/26/24 11:11:00.173
    Apr 26 11:11:00.185: INFO: Waiting up to 5m0s for pod "downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59" in namespace "downward-api-223" to be "Succeeded or Failed"
    Apr 26 11:11:00.194: INFO: Pod "downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59": Phase="Pending", Reason="", readiness=false. Elapsed: 8.655703ms
    Apr 26 11:11:02.229: INFO: Pod "downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043595646s
    Apr 26 11:11:04.201: INFO: Pod "downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015261317s
    STEP: Saw pod success 04/26/24 11:11:04.201
    Apr 26 11:11:04.201: INFO: Pod "downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59" satisfied condition "Succeeded or Failed"
    Apr 26 11:11:04.207: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59 container client-container: <nil>
    STEP: delete the pod 04/26/24 11:11:04.226
    Apr 26 11:11:04.242: INFO: Waiting for pod downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59 to disappear
    Apr 26 11:11:04.246: INFO: Pod downwardapi-volume-393cef7c-3b7b-4da3-a164-25b5526bfa59 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 26 11:11:04.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-223" for this suite. 04/26/24 11:11:04.255
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:11:04.263
Apr 26 11:11:04.263: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename custom-resource-definition 04/26/24 11:11:04.263
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:11:04.276
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:11:04.282
[It] listing custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:85
Apr 26 11:11:04.288: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:11:10.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1868" for this suite. 04/26/24 11:11:10.728
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works  [Conformance]","completed":47,"skipped":892,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.472 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    listing custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:85

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:11:04.263
    Apr 26 11:11:04.263: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename custom-resource-definition 04/26/24 11:11:04.263
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:11:04.276
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:11:04.282
    [It] listing custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:85
    Apr 26 11:11:04.288: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:11:10.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-1868" for this suite. 04/26/24 11:11:10.728
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Probing container
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:11:10.735
Apr 26 11:11:10.735: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-probe 04/26/24 11:11:10.736
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:11:10.753
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:11:10.76
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68
Apr 26 11:11:10.776: INFO: Waiting up to 5m0s for pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc" in namespace "container-probe-2189" to be "running and ready"
Apr 26 11:11:10.784: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.82515ms
Apr 26 11:11:10.784: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:11:12.791: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 2.014838465s
Apr 26 11:11:12.791: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
Apr 26 11:11:14.791: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 4.014725218s
Apr 26 11:11:14.791: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
Apr 26 11:11:16.790: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 6.013327426s
Apr 26 11:11:16.790: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
Apr 26 11:11:18.794: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 8.018018032s
Apr 26 11:11:18.794: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
Apr 26 11:11:20.793: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 10.016893332s
Apr 26 11:11:20.793: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
Apr 26 11:11:22.790: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 12.013582679s
Apr 26 11:11:22.790: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
Apr 26 11:11:24.791: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 14.014590283s
Apr 26 11:11:24.791: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
Apr 26 11:11:26.790: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 16.014162444s
Apr 26 11:11:26.790: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
Apr 26 11:11:28.791: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 18.014678563s
Apr 26 11:11:28.791: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
Apr 26 11:11:30.791: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 20.014730568s
Apr 26 11:11:30.791: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
Apr 26 11:11:32.794: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=true. Elapsed: 22.018064499s
Apr 26 11:11:32.794: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = true)
Apr 26 11:11:32.794: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc" satisfied condition "running and ready"
Apr 26 11:11:32.800: INFO: Container started at 2024-04-26 11:11:11 +0000 UTC, pod became ready at 2024-04-26 11:11:31 +0000 UTC
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 26 11:11:32.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2189" for this suite. 04/26/24 11:11:32.809
{"msg":"PASSED [sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]","completed":48,"skipped":896,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.082 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:68

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:11:10.735
    Apr 26 11:11:10.735: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-probe 04/26/24 11:11:10.736
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:11:10.753
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:11:10.76
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:68
    Apr 26 11:11:10.776: INFO: Waiting up to 5m0s for pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc" in namespace "container-probe-2189" to be "running and ready"
    Apr 26 11:11:10.784: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.82515ms
    Apr 26 11:11:10.784: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:11:12.791: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 2.014838465s
    Apr 26 11:11:12.791: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
    Apr 26 11:11:14.791: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 4.014725218s
    Apr 26 11:11:14.791: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
    Apr 26 11:11:16.790: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 6.013327426s
    Apr 26 11:11:16.790: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
    Apr 26 11:11:18.794: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 8.018018032s
    Apr 26 11:11:18.794: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
    Apr 26 11:11:20.793: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 10.016893332s
    Apr 26 11:11:20.793: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
    Apr 26 11:11:22.790: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 12.013582679s
    Apr 26 11:11:22.790: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
    Apr 26 11:11:24.791: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 14.014590283s
    Apr 26 11:11:24.791: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
    Apr 26 11:11:26.790: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 16.014162444s
    Apr 26 11:11:26.790: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
    Apr 26 11:11:28.791: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 18.014678563s
    Apr 26 11:11:28.791: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
    Apr 26 11:11:30.791: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=false. Elapsed: 20.014730568s
    Apr 26 11:11:30.791: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = false)
    Apr 26 11:11:32.794: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc": Phase="Running", Reason="", readiness=true. Elapsed: 22.018064499s
    Apr 26 11:11:32.794: INFO: The phase of Pod test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc is Running (Ready = true)
    Apr 26 11:11:32.794: INFO: Pod "test-webserver-83d2f753-fbbb-4205-a1d8-11d552c268dc" satisfied condition "running and ready"
    Apr 26 11:11:32.800: INFO: Container started at 2024-04-26 11:11:11 +0000 UTC, pod became ready at 2024-04-26 11:11:31 +0000 UTC
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 26 11:11:32.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2189" for this suite. 04/26/24 11:11:32.809
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:11:32.818
Apr 26 11:11:32.818: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename subpath 04/26/24 11:11:32.819
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:11:32.837
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:11:32.842
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/26/24 11:11:32.847
[It] should support subpaths with projected pod [Conformance]
  test/e2e/storage/subpath.go:106
STEP: Creating pod pod-subpath-test-projected-dkjg 04/26/24 11:11:32.856
STEP: Creating a pod to test atomic-volume-subpath 04/26/24 11:11:32.857
Apr 26 11:11:32.870: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-dkjg" in namespace "subpath-7574" to be "Succeeded or Failed"
Apr 26 11:11:32.877: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.838068ms
Apr 26 11:11:34.913: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 2.042614617s
Apr 26 11:11:36.884: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 4.013889757s
Apr 26 11:11:38.883: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 6.012799428s
Apr 26 11:11:40.884: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 8.014338276s
Apr 26 11:11:42.892: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 10.022119426s
Apr 26 11:11:44.884: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 12.014109153s
Apr 26 11:11:46.883: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 14.013259659s
Apr 26 11:11:48.886: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 16.015435201s
Apr 26 11:11:50.883: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 18.013058909s
Apr 26 11:11:52.883: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 20.013031108s
Apr 26 11:11:54.886: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=false. Elapsed: 22.015609505s
Apr 26 11:11:56.884: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.01340475s
STEP: Saw pod success 04/26/24 11:11:56.884
Apr 26 11:11:56.884: INFO: Pod "pod-subpath-test-projected-dkjg" satisfied condition "Succeeded or Failed"
Apr 26 11:11:56.890: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-subpath-test-projected-dkjg container test-container-subpath-projected-dkjg: <nil>
STEP: delete the pod 04/26/24 11:11:56.909
Apr 26 11:11:56.921: INFO: Waiting for pod pod-subpath-test-projected-dkjg to disappear
Apr 26 11:11:56.929: INFO: Pod pod-subpath-test-projected-dkjg no longer exists
STEP: Deleting pod pod-subpath-test-projected-dkjg 04/26/24 11:11:56.929
Apr 26 11:11:56.929: INFO: Deleting pod "pod-subpath-test-projected-dkjg" in namespace "subpath-7574"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 26 11:11:56.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7574" for this suite. 04/26/24 11:11:56.944
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]","completed":49,"skipped":914,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.135 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with projected pod [Conformance]
    test/e2e/storage/subpath.go:106

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:11:32.818
    Apr 26 11:11:32.818: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename subpath 04/26/24 11:11:32.819
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:11:32.837
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:11:32.842
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/26/24 11:11:32.847
    [It] should support subpaths with projected pod [Conformance]
      test/e2e/storage/subpath.go:106
    STEP: Creating pod pod-subpath-test-projected-dkjg 04/26/24 11:11:32.856
    STEP: Creating a pod to test atomic-volume-subpath 04/26/24 11:11:32.857
    Apr 26 11:11:32.870: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-dkjg" in namespace "subpath-7574" to be "Succeeded or Failed"
    Apr 26 11:11:32.877: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Pending", Reason="", readiness=false. Elapsed: 6.838068ms
    Apr 26 11:11:34.913: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 2.042614617s
    Apr 26 11:11:36.884: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 4.013889757s
    Apr 26 11:11:38.883: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 6.012799428s
    Apr 26 11:11:40.884: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 8.014338276s
    Apr 26 11:11:42.892: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 10.022119426s
    Apr 26 11:11:44.884: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 12.014109153s
    Apr 26 11:11:46.883: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 14.013259659s
    Apr 26 11:11:48.886: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 16.015435201s
    Apr 26 11:11:50.883: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 18.013058909s
    Apr 26 11:11:52.883: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=true. Elapsed: 20.013031108s
    Apr 26 11:11:54.886: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Running", Reason="", readiness=false. Elapsed: 22.015609505s
    Apr 26 11:11:56.884: INFO: Pod "pod-subpath-test-projected-dkjg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.01340475s
    STEP: Saw pod success 04/26/24 11:11:56.884
    Apr 26 11:11:56.884: INFO: Pod "pod-subpath-test-projected-dkjg" satisfied condition "Succeeded or Failed"
    Apr 26 11:11:56.890: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-subpath-test-projected-dkjg container test-container-subpath-projected-dkjg: <nil>
    STEP: delete the pod 04/26/24 11:11:56.909
    Apr 26 11:11:56.921: INFO: Waiting for pod pod-subpath-test-projected-dkjg to disappear
    Apr 26 11:11:56.929: INFO: Pod pod-subpath-test-projected-dkjg no longer exists
    STEP: Deleting pod pod-subpath-test-projected-dkjg 04/26/24 11:11:56.929
    Apr 26 11:11:56.929: INFO: Deleting pod "pod-subpath-test-projected-dkjg" in namespace "subpath-7574"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 26 11:11:56.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-7574" for this suite. 04/26/24 11:11:56.944
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] RuntimeClass
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:11:56.953
Apr 26 11:11:56.953: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename runtimeclass 04/26/24 11:11:56.954
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:11:56.994
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:11:57
[It]  should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189
STEP: getting /apis 04/26/24 11:11:57.019
STEP: getting /apis/node.k8s.io 04/26/24 11:11:57.025
STEP: getting /apis/node.k8s.io/v1 04/26/24 11:11:57.027
STEP: creating 04/26/24 11:11:57.029
STEP: watching 04/26/24 11:11:57.044
Apr 26 11:11:57.044: INFO: starting watch
STEP: getting 04/26/24 11:11:57.051
STEP: listing 04/26/24 11:11:57.054
STEP: patching 04/26/24 11:11:57.058
STEP: updating 04/26/24 11:11:57.063
Apr 26 11:11:57.068: INFO: waiting for watch events with expected annotations
STEP: deleting 04/26/24 11:11:57.068
STEP: deleting a collection 04/26/24 11:11:57.081
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 26 11:11:57.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-2043" for this suite. 04/26/24 11:11:57.103
{"msg":"PASSED [sig-node] RuntimeClass  should support RuntimeClasses API operations [Conformance]","completed":50,"skipped":921,"failed":0}
------------------------------
â€¢ [0.157 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
   should support RuntimeClasses API operations [Conformance]
  test/e2e/common/node/runtimeclass.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:11:56.953
    Apr 26 11:11:56.953: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename runtimeclass 04/26/24 11:11:56.954
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:11:56.994
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:11:57
    [It]  should support RuntimeClasses API operations [Conformance]
      test/e2e/common/node/runtimeclass.go:189
    STEP: getting /apis 04/26/24 11:11:57.019
    STEP: getting /apis/node.k8s.io 04/26/24 11:11:57.025
    STEP: getting /apis/node.k8s.io/v1 04/26/24 11:11:57.027
    STEP: creating 04/26/24 11:11:57.029
    STEP: watching 04/26/24 11:11:57.044
    Apr 26 11:11:57.044: INFO: starting watch
    STEP: getting 04/26/24 11:11:57.051
    STEP: listing 04/26/24 11:11:57.054
    STEP: patching 04/26/24 11:11:57.058
    STEP: updating 04/26/24 11:11:57.063
    Apr 26 11:11:57.068: INFO: waiting for watch events with expected annotations
    STEP: deleting 04/26/24 11:11:57.068
    STEP: deleting a collection 04/26/24 11:11:57.081
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 26 11:11:57.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-2043" for this suite. 04/26/24 11:11:57.103
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:11:57.11
Apr 26 11:11:57.110: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 11:11:57.111
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:11:57.123
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:11:57.128
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46
STEP: Creating configMap with name configmap-test-volume-9b38cb07-81ca-409a-b7e4-db981ec473c8 04/26/24 11:11:57.133
STEP: Creating a pod to test consume configMaps 04/26/24 11:11:57.137
Apr 26 11:11:57.149: INFO: Waiting up to 5m0s for pod "pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318" in namespace "configmap-838" to be "Succeeded or Failed"
Apr 26 11:11:57.155: INFO: Pod "pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318": Phase="Pending", Reason="", readiness=false. Elapsed: 5.394073ms
Apr 26 11:11:59.165: INFO: Pod "pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015058557s
Apr 26 11:12:01.161: INFO: Pod "pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011627857s
STEP: Saw pod success 04/26/24 11:12:01.161
Apr 26 11:12:01.161: INFO: Pod "pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318" satisfied condition "Succeeded or Failed"
Apr 26 11:12:01.165: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318 container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:12:01.18
Apr 26 11:12:01.244: INFO: Waiting for pod pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318 to disappear
Apr 26 11:12:01.282: INFO: Pod pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 11:12:01.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-838" for this suite. 04/26/24 11:12:01.292
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":51,"skipped":926,"failed":0}
------------------------------
â€¢ [4.188 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:11:57.11
    Apr 26 11:11:57.110: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 11:11:57.111
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:11:57.123
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:11:57.128
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:46
    STEP: Creating configMap with name configmap-test-volume-9b38cb07-81ca-409a-b7e4-db981ec473c8 04/26/24 11:11:57.133
    STEP: Creating a pod to test consume configMaps 04/26/24 11:11:57.137
    Apr 26 11:11:57.149: INFO: Waiting up to 5m0s for pod "pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318" in namespace "configmap-838" to be "Succeeded or Failed"
    Apr 26 11:11:57.155: INFO: Pod "pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318": Phase="Pending", Reason="", readiness=false. Elapsed: 5.394073ms
    Apr 26 11:11:59.165: INFO: Pod "pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015058557s
    Apr 26 11:12:01.161: INFO: Pod "pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011627857s
    STEP: Saw pod success 04/26/24 11:12:01.161
    Apr 26 11:12:01.161: INFO: Pod "pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318" satisfied condition "Succeeded or Failed"
    Apr 26 11:12:01.165: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318 container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:12:01.18
    Apr 26 11:12:01.244: INFO: Waiting for pod pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318 to disappear
    Apr 26 11:12:01.282: INFO: Pod pod-configmaps-8dd1b4c1-ecf0-49a2-b516-27a67c7ce318 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 11:12:01.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-838" for this suite. 04/26/24 11:12:01.292
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:01.299
Apr 26 11:12:01.300: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename proxy 04/26/24 11:12:01.3
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:01.313
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:01.317
[It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
  test/e2e/network/proxy.go:286
Apr 26 11:12:01.322: INFO: Creating pod...
Apr 26 11:12:01.335: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3134" to be "running"
Apr 26 11:12:01.346: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 11.650315ms
Apr 26 11:12:03.353: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.017920984s
Apr 26 11:12:03.353: INFO: Pod "agnhost" satisfied condition "running"
Apr 26 11:12:03.353: INFO: Creating service...
Apr 26 11:12:03.393: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/DELETE
Apr 26 11:12:03.537: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 26 11:12:03.537: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/GET
Apr 26 11:12:03.585: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 26 11:12:03.585: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/HEAD
Apr 26 11:12:03.594: INFO: http.Client request:HEAD | StatusCode:200
Apr 26 11:12:03.594: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/OPTIONS
Apr 26 11:12:03.603: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 26 11:12:03.604: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/PATCH
Apr 26 11:12:03.612: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 26 11:12:03.612: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/POST
Apr 26 11:12:03.621: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 26 11:12:03.621: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/PUT
Apr 26 11:12:03.631: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 26 11:12:03.631: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/DELETE
Apr 26 11:12:03.640: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 26 11:12:03.641: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/GET
Apr 26 11:12:03.650: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
Apr 26 11:12:03.650: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/HEAD
Apr 26 11:12:03.660: INFO: http.Client request:HEAD | StatusCode:200
Apr 26 11:12:03.660: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/OPTIONS
Apr 26 11:12:03.672: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 26 11:12:03.672: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/PATCH
Apr 26 11:12:03.681: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 26 11:12:03.681: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/POST
Apr 26 11:12:03.693: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 26 11:12:03.693: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/PUT
Apr 26 11:12:03.704: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 26 11:12:03.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3134" for this suite. 04/26/24 11:12:03.717
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]","completed":52,"skipped":939,"failed":0}
------------------------------
â€¢ [2.425 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
    test/e2e/network/proxy.go:286

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:01.299
    Apr 26 11:12:01.300: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename proxy 04/26/24 11:12:01.3
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:01.313
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:01.317
    [It] A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]
      test/e2e/network/proxy.go:286
    Apr 26 11:12:01.322: INFO: Creating pod...
    Apr 26 11:12:01.335: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-3134" to be "running"
    Apr 26 11:12:01.346: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 11.650315ms
    Apr 26 11:12:03.353: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.017920984s
    Apr 26 11:12:03.353: INFO: Pod "agnhost" satisfied condition "running"
    Apr 26 11:12:03.353: INFO: Creating service...
    Apr 26 11:12:03.393: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/DELETE
    Apr 26 11:12:03.537: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 26 11:12:03.537: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/GET
    Apr 26 11:12:03.585: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Apr 26 11:12:03.585: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/HEAD
    Apr 26 11:12:03.594: INFO: http.Client request:HEAD | StatusCode:200
    Apr 26 11:12:03.594: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/OPTIONS
    Apr 26 11:12:03.603: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 26 11:12:03.604: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/PATCH
    Apr 26 11:12:03.612: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 26 11:12:03.612: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/POST
    Apr 26 11:12:03.621: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 26 11:12:03.621: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/pods/agnhost/proxy/some/path/with/PUT
    Apr 26 11:12:03.631: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 26 11:12:03.631: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/DELETE
    Apr 26 11:12:03.640: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 26 11:12:03.641: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/GET
    Apr 26 11:12:03.650: INFO: http.Client request:GET | StatusCode:200 | Response:foo | Method:GET
    Apr 26 11:12:03.650: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/HEAD
    Apr 26 11:12:03.660: INFO: http.Client request:HEAD | StatusCode:200
    Apr 26 11:12:03.660: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/OPTIONS
    Apr 26 11:12:03.672: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 26 11:12:03.672: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/PATCH
    Apr 26 11:12:03.681: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 26 11:12:03.681: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/POST
    Apr 26 11:12:03.693: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 26 11:12:03.693: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-3134/services/test-service/proxy/some/path/with/PUT
    Apr 26 11:12:03.704: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 26 11:12:03.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-3134" for this suite. 04/26/24 11:12:03.717
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:03.725
Apr 26 11:12:03.725: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 11:12:03.726
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:03.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:03.762
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 11:12:03.779
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:12:03.982
STEP: Deploying the webhook pod 04/26/24 11:12:03.992
STEP: Wait for the deployment to be ready 04/26/24 11:12:04.004
Apr 26 11:12:04.015: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 11:12:06.033
STEP: Verifying the service has paired with the endpoint 04/26/24 11:12:06.054
Apr 26 11:12:07.054: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116
STEP: fetching the /apis discovery document 04/26/24 11:12:07.059
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 04/26/24 11:12:07.062
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 04/26/24 11:12:07.062
STEP: fetching the /apis/admissionregistration.k8s.io discovery document 04/26/24 11:12:07.062
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 04/26/24 11:12:07.065
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 04/26/24 11:12:07.065
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 04/26/24 11:12:07.068
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:12:07.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1128" for this suite. 04/26/24 11:12:07.077
STEP: Destroying namespace "webhook-1128-markers" for this suite. 04/26/24 11:12:07.083
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]","completed":53,"skipped":949,"failed":0}
------------------------------
â€¢ [3.411 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  test/e2e/apimachinery/webhook.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:03.725
    Apr 26 11:12:03.725: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 11:12:03.726
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:03.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:03.762
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 11:12:03.779
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:12:03.982
    STEP: Deploying the webhook pod 04/26/24 11:12:03.992
    STEP: Wait for the deployment to be ready 04/26/24 11:12:04.004
    Apr 26 11:12:04.015: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 11:12:06.033
    STEP: Verifying the service has paired with the endpoint 04/26/24 11:12:06.054
    Apr 26 11:12:07.054: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should include webhook resources in discovery documents [Conformance]
      test/e2e/apimachinery/webhook.go:116
    STEP: fetching the /apis discovery document 04/26/24 11:12:07.059
    STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document 04/26/24 11:12:07.062
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document 04/26/24 11:12:07.062
    STEP: fetching the /apis/admissionregistration.k8s.io discovery document 04/26/24 11:12:07.062
    STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document 04/26/24 11:12:07.065
    STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document 04/26/24 11:12:07.065
    STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document 04/26/24 11:12:07.068
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:12:07.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1128" for this suite. 04/26/24 11:12:07.077
    STEP: Destroying namespace "webhook-1128-markers" for this suite. 04/26/24 11:12:07.083
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:07.138
Apr 26 11:12:07.139: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:12:07.14
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:07.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:07.167
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248
STEP: Creating a pod to test downward API volume plugin 04/26/24 11:12:07.171
Apr 26 11:12:07.186: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798" in namespace "projected-9137" to be "Succeeded or Failed"
Apr 26 11:12:07.194: INFO: Pod "downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798": Phase="Pending", Reason="", readiness=false. Elapsed: 7.736902ms
Apr 26 11:12:09.200: INFO: Pod "downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014319369s
Apr 26 11:12:11.200: INFO: Pod "downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013844391s
STEP: Saw pod success 04/26/24 11:12:11.2
Apr 26 11:12:11.200: INFO: Pod "downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798" satisfied condition "Succeeded or Failed"
Apr 26 11:12:11.203: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798 container client-container: <nil>
STEP: delete the pod 04/26/24 11:12:11.216
Apr 26 11:12:11.226: INFO: Waiting for pod downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798 to disappear
Apr 26 11:12:11.231: INFO: Pod downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 26 11:12:11.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9137" for this suite. 04/26/24 11:12:11.238
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":54,"skipped":964,"failed":0}
------------------------------
â€¢ [4.121 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:07.138
    Apr 26 11:12:07.139: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:12:07.14
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:07.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:07.167
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:248
    STEP: Creating a pod to test downward API volume plugin 04/26/24 11:12:07.171
    Apr 26 11:12:07.186: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798" in namespace "projected-9137" to be "Succeeded or Failed"
    Apr 26 11:12:07.194: INFO: Pod "downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798": Phase="Pending", Reason="", readiness=false. Elapsed: 7.736902ms
    Apr 26 11:12:09.200: INFO: Pod "downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014319369s
    Apr 26 11:12:11.200: INFO: Pod "downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013844391s
    STEP: Saw pod success 04/26/24 11:12:11.2
    Apr 26 11:12:11.200: INFO: Pod "downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798" satisfied condition "Succeeded or Failed"
    Apr 26 11:12:11.203: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798 container client-container: <nil>
    STEP: delete the pod 04/26/24 11:12:11.216
    Apr 26 11:12:11.226: INFO: Waiting for pod downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798 to disappear
    Apr 26 11:12:11.231: INFO: Pod downwardapi-volume-6924c8c4-f665-422c-b996-7459132f1798 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 26 11:12:11.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9137" for this suite. 04/26/24 11:12:11.238
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:11.261
Apr 26 11:12:11.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename dns 04/26/24 11:12:11.263
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:11.304
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:11.31
[It] should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 04/26/24 11:12:11.316
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
 04/26/24 11:12:11.316
STEP: creating a pod to probe DNS 04/26/24 11:12:11.316
STEP: submitting the pod to kubernetes 04/26/24 11:12:11.316
Apr 26 11:12:11.333: INFO: Waiting up to 15m0s for pod "dns-test-ee047b6e-3568-45bf-bd4e-5b6c785e4e17" in namespace "dns-79" to be "running"
Apr 26 11:12:11.341: INFO: Pod "dns-test-ee047b6e-3568-45bf-bd4e-5b6c785e4e17": Phase="Pending", Reason="", readiness=false. Elapsed: 8.044427ms
Apr 26 11:12:13.350: INFO: Pod "dns-test-ee047b6e-3568-45bf-bd4e-5b6c785e4e17": Phase="Running", Reason="", readiness=true. Elapsed: 2.017371995s
Apr 26 11:12:13.350: INFO: Pod "dns-test-ee047b6e-3568-45bf-bd4e-5b6c785e4e17" satisfied condition "running"
STEP: retrieving the pod 04/26/24 11:12:13.35
STEP: looking for the results for each expected name from probers 04/26/24 11:12:13.355
Apr 26 11:12:13.495: INFO: DNS probes using dns-79/dns-test-ee047b6e-3568-45bf-bd4e-5b6c785e4e17 succeeded

STEP: deleting the pod 04/26/24 11:12:13.495
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 26 11:12:13.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-79" for this suite. 04/26/24 11:12:13.545
{"msg":"PASSED [sig-network] DNS should provide DNS for the cluster  [Conformance]","completed":55,"skipped":976,"failed":0}
------------------------------
â€¢ [2.291 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for the cluster  [Conformance]
  test/e2e/network/dns.go:50

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:11.261
    Apr 26 11:12:11.262: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename dns 04/26/24 11:12:11.263
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:11.304
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:11.31
    [It] should provide DNS for the cluster  [Conformance]
      test/e2e/network/dns.go:50
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     04/26/24 11:12:11.316
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;sleep 1; done
     04/26/24 11:12:11.316
    STEP: creating a pod to probe DNS 04/26/24 11:12:11.316
    STEP: submitting the pod to kubernetes 04/26/24 11:12:11.316
    Apr 26 11:12:11.333: INFO: Waiting up to 15m0s for pod "dns-test-ee047b6e-3568-45bf-bd4e-5b6c785e4e17" in namespace "dns-79" to be "running"
    Apr 26 11:12:11.341: INFO: Pod "dns-test-ee047b6e-3568-45bf-bd4e-5b6c785e4e17": Phase="Pending", Reason="", readiness=false. Elapsed: 8.044427ms
    Apr 26 11:12:13.350: INFO: Pod "dns-test-ee047b6e-3568-45bf-bd4e-5b6c785e4e17": Phase="Running", Reason="", readiness=true. Elapsed: 2.017371995s
    Apr 26 11:12:13.350: INFO: Pod "dns-test-ee047b6e-3568-45bf-bd4e-5b6c785e4e17" satisfied condition "running"
    STEP: retrieving the pod 04/26/24 11:12:13.35
    STEP: looking for the results for each expected name from probers 04/26/24 11:12:13.355
    Apr 26 11:12:13.495: INFO: DNS probes using dns-79/dns-test-ee047b6e-3568-45bf-bd4e-5b6c785e4e17 succeeded

    STEP: deleting the pod 04/26/24 11:12:13.495
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 26 11:12:13.535: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-79" for this suite. 04/26/24 11:12:13.545
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:13.555
Apr 26 11:12:13.555: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename watch 04/26/24 11:12:13.556
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:13.584
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:13.59
[It] should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334
STEP: getting a starting resourceVersion 04/26/24 11:12:13.598
STEP: starting a background goroutine to produce watch events 04/26/24 11:12:13.621
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 04/26/24 11:12:13.621
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 26 11:12:16.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2340" for this suite. 04/26/24 11:12:16.418
{"msg":"PASSED [sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]","completed":56,"skipped":998,"failed":0}
------------------------------
â€¢ [2.907 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  test/e2e/apimachinery/watch.go:334

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:13.555
    Apr 26 11:12:13.555: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename watch 04/26/24 11:12:13.556
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:13.584
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:13.59
    [It] should receive events on concurrent watches in same order [Conformance]
      test/e2e/apimachinery/watch.go:334
    STEP: getting a starting resourceVersion 04/26/24 11:12:13.598
    STEP: starting a background goroutine to produce watch events 04/26/24 11:12:13.621
    STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order 04/26/24 11:12:13.621
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 26 11:12:16.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2340" for this suite. 04/26/24 11:12:16.418
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces
  should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:16.464
Apr 26 11:12:16.464: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename disruption 04/26/24 11:12:16.465
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:16.494
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:16.502
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[BeforeEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:16.508
Apr 26 11:12:16.508: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename disruption-2 04/26/24 11:12:16.509
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:16.526
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:16.531
[It] should list and delete a collection of PodDisruptionBudgets [Conformance]
  test/e2e/apps/disruption.go:86
STEP: Waiting for the pdb to be processed 04/26/24 11:12:16.54
STEP: Waiting for the pdb to be processed 04/26/24 11:12:18.557
STEP: Waiting for the pdb to be processed 04/26/24 11:12:20.573
STEP: listing a collection of PDBs across all namespaces 04/26/24 11:12:20.579
STEP: listing a collection of PDBs in namespace disruption-5146 04/26/24 11:12:20.585
STEP: deleting a collection of PDBs 04/26/24 11:12:20.59
STEP: Waiting for the PDB collection to be deleted 04/26/24 11:12:20.603
[AfterEach] Listing PodDisruptionBudgets for all namespaces
  test/e2e/framework/framework.go:187
Apr 26 11:12:20.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2-5108" for this suite. 04/26/24 11:12:20.617
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 26 11:12:20.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-5146" for this suite. 04/26/24 11:12:20.629
{"msg":"PASSED [sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]","completed":57,"skipped":1019,"failed":0}
------------------------------
â€¢ [4.171 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  Listing PodDisruptionBudgets for all namespaces
  test/e2e/apps/disruption.go:77
    should list and delete a collection of PodDisruptionBudgets [Conformance]
    test/e2e/apps/disruption.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:16.464
    Apr 26 11:12:16.464: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename disruption 04/26/24 11:12:16.465
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:16.494
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:16.502
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [BeforeEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:16.508
    Apr 26 11:12:16.508: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename disruption-2 04/26/24 11:12:16.509
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:16.526
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:16.531
    [It] should list and delete a collection of PodDisruptionBudgets [Conformance]
      test/e2e/apps/disruption.go:86
    STEP: Waiting for the pdb to be processed 04/26/24 11:12:16.54
    STEP: Waiting for the pdb to be processed 04/26/24 11:12:18.557
    STEP: Waiting for the pdb to be processed 04/26/24 11:12:20.573
    STEP: listing a collection of PDBs across all namespaces 04/26/24 11:12:20.579
    STEP: listing a collection of PDBs in namespace disruption-5146 04/26/24 11:12:20.585
    STEP: deleting a collection of PDBs 04/26/24 11:12:20.59
    STEP: Waiting for the PDB collection to be deleted 04/26/24 11:12:20.603
    [AfterEach] Listing PodDisruptionBudgets for all namespaces
      test/e2e/framework/framework.go:187
    Apr 26 11:12:20.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2-5108" for this suite. 04/26/24 11:12:20.617
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 26 11:12:20.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-5146" for this suite. 04/26/24 11:12:20.629
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:20.638
Apr 26 11:12:20.638: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-probe 04/26/24 11:12:20.639
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:20.685
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:20.69
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165
STEP: Creating pod liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87 in namespace container-probe-2267 04/26/24 11:12:20.696
Apr 26 11:12:20.714: INFO: Waiting up to 5m0s for pod "liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87" in namespace "container-probe-2267" to be "not pending"
Apr 26 11:12:20.723: INFO: Pod "liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87": Phase="Pending", Reason="", readiness=false. Elapsed: 8.374916ms
Apr 26 11:12:22.729: INFO: Pod "liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87": Phase="Running", Reason="", readiness=true. Elapsed: 2.014338479s
Apr 26 11:12:22.729: INFO: Pod "liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87" satisfied condition "not pending"
Apr 26 11:12:22.729: INFO: Started pod liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87 in namespace container-probe-2267
STEP: checking the pod's current state and verifying that restartCount is present 04/26/24 11:12:22.729
Apr 26 11:12:22.734: INFO: Initial restart count of pod liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87 is 0
Apr 26 11:12:42.844: INFO: Restart count of pod container-probe-2267/liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87 is now 1 (20.110408911s elapsed)
STEP: deleting the pod 04/26/24 11:12:42.844
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 26 11:12:42.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2267" for this suite. 04/26/24 11:12:42.872
{"msg":"PASSED [sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":58,"skipped":1035,"failed":0}
------------------------------
â€¢ [SLOW TEST] [22.241 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:20.638
    Apr 26 11:12:20.638: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-probe 04/26/24 11:12:20.639
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:20.685
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:20.69
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:165
    STEP: Creating pod liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87 in namespace container-probe-2267 04/26/24 11:12:20.696
    Apr 26 11:12:20.714: INFO: Waiting up to 5m0s for pod "liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87" in namespace "container-probe-2267" to be "not pending"
    Apr 26 11:12:20.723: INFO: Pod "liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87": Phase="Pending", Reason="", readiness=false. Elapsed: 8.374916ms
    Apr 26 11:12:22.729: INFO: Pod "liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87": Phase="Running", Reason="", readiness=true. Elapsed: 2.014338479s
    Apr 26 11:12:22.729: INFO: Pod "liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87" satisfied condition "not pending"
    Apr 26 11:12:22.729: INFO: Started pod liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87 in namespace container-probe-2267
    STEP: checking the pod's current state and verifying that restartCount is present 04/26/24 11:12:22.729
    Apr 26 11:12:22.734: INFO: Initial restart count of pod liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87 is 0
    Apr 26 11:12:42.844: INFO: Restart count of pod container-probe-2267/liveness-f1ce5a91-c5e7-44e0-808c-1305416aff87 is now 1 (20.110408911s elapsed)
    STEP: deleting the pod 04/26/24 11:12:42.844
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 26 11:12:42.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-2267" for this suite. 04/26/24 11:12:42.872
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:42.88
Apr 26 11:12:42.880: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 11:12:42.881
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:42.896
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:42.902
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116
STEP: Creating a pod to test emptydir 0777 on tmpfs 04/26/24 11:12:42.907
Apr 26 11:12:42.925: INFO: Waiting up to 5m0s for pod "pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf" in namespace "emptydir-323" to be "Succeeded or Failed"
Apr 26 11:12:42.938: INFO: Pod "pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.714968ms
Apr 26 11:12:44.945: INFO: Pod "pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019378367s
Apr 26 11:12:46.948: INFO: Pod "pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022526367s
STEP: Saw pod success 04/26/24 11:12:46.948
Apr 26 11:12:46.948: INFO: Pod "pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf" satisfied condition "Succeeded or Failed"
Apr 26 11:12:46.952: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf container test-container: <nil>
STEP: delete the pod 04/26/24 11:12:47.007
Apr 26 11:12:47.019: INFO: Waiting for pod pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf to disappear
Apr 26 11:12:47.023: INFO: Pod pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 11:12:47.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-323" for this suite. 04/26/24 11:12:47.031
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":59,"skipped":1043,"failed":0}
------------------------------
â€¢ [4.158 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:116

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:42.88
    Apr 26 11:12:42.880: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 11:12:42.881
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:42.896
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:42.902
    [It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:116
    STEP: Creating a pod to test emptydir 0777 on tmpfs 04/26/24 11:12:42.907
    Apr 26 11:12:42.925: INFO: Waiting up to 5m0s for pod "pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf" in namespace "emptydir-323" to be "Succeeded or Failed"
    Apr 26 11:12:42.938: INFO: Pod "pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.714968ms
    Apr 26 11:12:44.945: INFO: Pod "pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019378367s
    Apr 26 11:12:46.948: INFO: Pod "pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022526367s
    STEP: Saw pod success 04/26/24 11:12:46.948
    Apr 26 11:12:46.948: INFO: Pod "pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf" satisfied condition "Succeeded or Failed"
    Apr 26 11:12:46.952: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf container test-container: <nil>
    STEP: delete the pod 04/26/24 11:12:47.007
    Apr 26 11:12:47.019: INFO: Waiting for pod pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf to disappear
    Apr 26 11:12:47.023: INFO: Pod pod-52ad6a4b-a88a-48a4-a0f8-e6bf5b2399bf no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 11:12:47.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-323" for this suite. 04/26/24 11:12:47.031
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:47.043
Apr 26 11:12:47.043: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 11:12:47.044
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:47.06
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:47.066
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support proxy with --port 0  [Conformance]
  test/e2e/kubectl/kubectl.go:1785
STEP: starting the proxy server 04/26/24 11:12:47.071
Apr 26 11:12:47.072: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-8994 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output 04/26/24 11:12:47.103
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 11:12:47.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8994" for this suite. 04/26/24 11:12:47.132
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support proxy with --port 0  [Conformance]","completed":60,"skipped":1078,"failed":0}
------------------------------
â€¢ [0.097 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support proxy with --port 0  [Conformance]
    test/e2e/kubectl/kubectl.go:1785

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:47.043
    Apr 26 11:12:47.043: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 11:12:47.044
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:47.06
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:47.066
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support proxy with --port 0  [Conformance]
      test/e2e/kubectl/kubectl.go:1785
    STEP: starting the proxy server 04/26/24 11:12:47.071
    Apr 26 11:12:47.072: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-8994 proxy -p 0 --disable-filter'
    STEP: curling proxy /api/ output 04/26/24 11:12:47.103
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 11:12:47.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8994" for this suite. 04/26/24 11:12:47.132
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:47.141
Apr 26 11:12:47.141: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename containers 04/26/24 11:12:47.142
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:47.155
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:47.16
[It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72
STEP: Creating a pod to test override command 04/26/24 11:12:47.164
Apr 26 11:12:47.179: INFO: Waiting up to 5m0s for pod "client-containers-923c0266-02d3-42d0-a709-06e84442c409" in namespace "containers-8993" to be "Succeeded or Failed"
Apr 26 11:12:47.185: INFO: Pod "client-containers-923c0266-02d3-42d0-a709-06e84442c409": Phase="Pending", Reason="", readiness=false. Elapsed: 6.769848ms
Apr 26 11:12:49.191: INFO: Pod "client-containers-923c0266-02d3-42d0-a709-06e84442c409": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012527356s
Apr 26 11:12:51.191: INFO: Pod "client-containers-923c0266-02d3-42d0-a709-06e84442c409": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012658789s
STEP: Saw pod success 04/26/24 11:12:51.191
Apr 26 11:12:51.192: INFO: Pod "client-containers-923c0266-02d3-42d0-a709-06e84442c409" satisfied condition "Succeeded or Failed"
Apr 26 11:12:51.196: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod client-containers-923c0266-02d3-42d0-a709-06e84442c409 container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:12:51.231
Apr 26 11:12:51.245: INFO: Waiting for pod client-containers-923c0266-02d3-42d0-a709-06e84442c409 to disappear
Apr 26 11:12:51.249: INFO: Pod client-containers-923c0266-02d3-42d0-a709-06e84442c409 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 26 11:12:51.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8993" for this suite. 04/26/24 11:12:51.256
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]","completed":61,"skipped":1082,"failed":0}
------------------------------
â€¢ [4.121 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:47.141
    Apr 26 11:12:47.141: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename containers 04/26/24 11:12:47.142
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:47.155
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:47.16
    [It] should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:72
    STEP: Creating a pod to test override command 04/26/24 11:12:47.164
    Apr 26 11:12:47.179: INFO: Waiting up to 5m0s for pod "client-containers-923c0266-02d3-42d0-a709-06e84442c409" in namespace "containers-8993" to be "Succeeded or Failed"
    Apr 26 11:12:47.185: INFO: Pod "client-containers-923c0266-02d3-42d0-a709-06e84442c409": Phase="Pending", Reason="", readiness=false. Elapsed: 6.769848ms
    Apr 26 11:12:49.191: INFO: Pod "client-containers-923c0266-02d3-42d0-a709-06e84442c409": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012527356s
    Apr 26 11:12:51.191: INFO: Pod "client-containers-923c0266-02d3-42d0-a709-06e84442c409": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012658789s
    STEP: Saw pod success 04/26/24 11:12:51.191
    Apr 26 11:12:51.192: INFO: Pod "client-containers-923c0266-02d3-42d0-a709-06e84442c409" satisfied condition "Succeeded or Failed"
    Apr 26 11:12:51.196: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod client-containers-923c0266-02d3-42d0-a709-06e84442c409 container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:12:51.231
    Apr 26 11:12:51.245: INFO: Waiting for pod client-containers-923c0266-02d3-42d0-a709-06e84442c409 to disappear
    Apr 26 11:12:51.249: INFO: Pod client-containers-923c0266-02d3-42d0-a709-06e84442c409 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 26 11:12:51.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-8993" for this suite. 04/26/24 11:12:51.256
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:51.263
Apr 26 11:12:51.263: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 11:12:51.264
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:51.278
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:51.283
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52
STEP: Creating a pod to test downward API volume plugin 04/26/24 11:12:51.289
Apr 26 11:12:51.302: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb" in namespace "downward-api-4915" to be "Succeeded or Failed"
Apr 26 11:12:51.309: INFO: Pod "downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.221977ms
Apr 26 11:12:53.315: INFO: Pod "downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012848144s
Apr 26 11:12:55.314: INFO: Pod "downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012075499s
STEP: Saw pod success 04/26/24 11:12:55.315
Apr 26 11:12:55.315: INFO: Pod "downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb" satisfied condition "Succeeded or Failed"
Apr 26 11:12:55.319: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb container client-container: <nil>
STEP: delete the pod 04/26/24 11:12:55.379
Apr 26 11:12:55.394: INFO: Waiting for pod downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb to disappear
Apr 26 11:12:55.399: INFO: Pod downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 26 11:12:55.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4915" for this suite. 04/26/24 11:12:55.409
{"msg":"PASSED [sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]","completed":62,"skipped":1101,"failed":0}
------------------------------
â€¢ [4.152 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide podname only [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:51.263
    Apr 26 11:12:51.263: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 11:12:51.264
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:51.278
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:51.283
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide podname only [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:52
    STEP: Creating a pod to test downward API volume plugin 04/26/24 11:12:51.289
    Apr 26 11:12:51.302: INFO: Waiting up to 5m0s for pod "downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb" in namespace "downward-api-4915" to be "Succeeded or Failed"
    Apr 26 11:12:51.309: INFO: Pod "downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.221977ms
    Apr 26 11:12:53.315: INFO: Pod "downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012848144s
    Apr 26 11:12:55.314: INFO: Pod "downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012075499s
    STEP: Saw pod success 04/26/24 11:12:55.315
    Apr 26 11:12:55.315: INFO: Pod "downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb" satisfied condition "Succeeded or Failed"
    Apr 26 11:12:55.319: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb container client-container: <nil>
    STEP: delete the pod 04/26/24 11:12:55.379
    Apr 26 11:12:55.394: INFO: Waiting for pod downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb to disappear
    Apr 26 11:12:55.399: INFO: Pod downwardapi-volume-72c7c429-ea46-4b21-bf99-d95954edfafb no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 26 11:12:55.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4915" for this suite. 04/26/24 11:12:55.409
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:12:55.423
Apr 26 11:12:55.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename job 04/26/24 11:12:55.424
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:55.441
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:55.447
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254
STEP: Creating a job 04/26/24 11:12:55.452
STEP: Ensuring job reaches completions 04/26/24 11:12:55.458
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 26 11:13:07.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3447" for this suite. 04/26/24 11:13:07.551
{"msg":"PASSED [sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]","completed":63,"skipped":1132,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.135 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  test/e2e/apps/job.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:12:55.423
    Apr 26 11:12:55.423: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename job 04/26/24 11:12:55.424
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:12:55.441
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:12:55.447
    [It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
      test/e2e/apps/job.go:254
    STEP: Creating a job 04/26/24 11:12:55.452
    STEP: Ensuring job reaches completions 04/26/24 11:12:55.458
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 26 11:13:07.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-3447" for this suite. 04/26/24 11:13:07.551
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:13:07.559
Apr 26 11:13:07.559: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 11:13:07.56
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:13:07.575
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:13:07.581
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192
STEP: Creating a pod to test downward API volume plugin 04/26/24 11:13:07.586
Apr 26 11:13:07.600: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4" in namespace "downward-api-9977" to be "Succeeded or Failed"
Apr 26 11:13:07.606: INFO: Pod "downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.569249ms
Apr 26 11:13:09.613: INFO: Pod "downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013604608s
Apr 26 11:13:11.614: INFO: Pod "downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014389148s
STEP: Saw pod success 04/26/24 11:13:11.614
Apr 26 11:13:11.614: INFO: Pod "downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4" satisfied condition "Succeeded or Failed"
Apr 26 11:13:11.620: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4 container client-container: <nil>
STEP: delete the pod 04/26/24 11:13:11.639
Apr 26 11:13:11.651: INFO: Waiting for pod downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4 to disappear
Apr 26 11:13:11.656: INFO: Pod downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 26 11:13:11.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9977" for this suite. 04/26/24 11:13:11.665
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]","completed":64,"skipped":1141,"failed":0}
------------------------------
â€¢ [4.114 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:13:07.559
    Apr 26 11:13:07.559: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 11:13:07.56
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:13:07.575
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:13:07.581
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:192
    STEP: Creating a pod to test downward API volume plugin 04/26/24 11:13:07.586
    Apr 26 11:13:07.600: INFO: Waiting up to 5m0s for pod "downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4" in namespace "downward-api-9977" to be "Succeeded or Failed"
    Apr 26 11:13:07.606: INFO: Pod "downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.569249ms
    Apr 26 11:13:09.613: INFO: Pod "downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013604608s
    Apr 26 11:13:11.614: INFO: Pod "downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014389148s
    STEP: Saw pod success 04/26/24 11:13:11.614
    Apr 26 11:13:11.614: INFO: Pod "downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4" satisfied condition "Succeeded or Failed"
    Apr 26 11:13:11.620: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4 container client-container: <nil>
    STEP: delete the pod 04/26/24 11:13:11.639
    Apr 26 11:13:11.651: INFO: Waiting for pod downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4 to disappear
    Apr 26 11:13:11.656: INFO: Pod downwardapi-volume-52febdf5-bda0-47ec-a55c-c929749285a4 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 26 11:13:11.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-9977" for this suite. 04/26/24 11:13:11.665
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:13:11.675
Apr 26 11:13:11.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 11:13:11.676
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:13:11.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:13:11.696
[It] works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 04/26/24 11:13:11.701
Apr 26 11:13:11.702: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 04/26/24 11:13:23.559
Apr 26 11:13:23.559: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:13:25.801: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:13:36.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4656" for this suite. 04/26/24 11:13:36.056
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]","completed":65,"skipped":1158,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.388 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:308

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:13:11.675
    Apr 26 11:13:11.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 11:13:11.676
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:13:11.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:13:11.696
    [It] works for multiple CRDs of same group but different versions [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:308
    STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation 04/26/24 11:13:11.701
    Apr 26 11:13:11.702: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation 04/26/24 11:13:23.559
    Apr 26 11:13:23.559: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:13:25.801: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:13:36.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-4656" for this suite. 04/26/24 11:13:36.056
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:13:36.066
Apr 26 11:13:36.066: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename svcaccounts 04/26/24 11:13:36.067
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:13:36.082
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:13:36.088
[It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528
Apr 26 11:13:36.111: INFO: created pod
Apr 26 11:13:36.111: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-4688" to be "Succeeded or Failed"
Apr 26 11:13:36.119: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 7.54657ms
Apr 26 11:13:38.148: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037176514s
Apr 26 11:13:40.125: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014307434s
STEP: Saw pod success 04/26/24 11:13:40.125
Apr 26 11:13:40.125: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
Apr 26 11:14:10.126: INFO: polling logs
Apr 26 11:14:10.147: INFO: Pod logs: 
I0426 11:13:36.769390       1 log.go:195] OK: Got token
I0426 11:13:36.769422       1 log.go:195] validating with in-cluster discovery
I0426 11:13:36.769635       1 log.go:195] OK: got issuer https://api.conf-125.thomas.internal.emk.fuga.cloud
I0426 11:13:36.769663       1 log.go:195] Full, not-validated claims: 
openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://api.conf-125.thomas.internal.emk.fuga.cloud", Subject:"system:serviceaccount:svcaccounts-4688:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1714130616, NotBefore:1714130016, IssuedAt:1714130016, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4688", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"99aad712-b5cd-494d-af9a-71bc683f31c7"}}}
I0426 11:13:36.789997       1 log.go:195] OK: Constructed OIDC provider for issuer https://api.conf-125.thomas.internal.emk.fuga.cloud
I0426 11:13:36.793897       1 log.go:195] OK: Validated signature on JWT
I0426 11:13:36.794013       1 log.go:195] OK: Got valid claims from token!
I0426 11:13:36.794041       1 log.go:195] Full, validated claims: 
&openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://api.conf-125.thomas.internal.emk.fuga.cloud", Subject:"system:serviceaccount:svcaccounts-4688:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1714130616, NotBefore:1714130016, IssuedAt:1714130016, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4688", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"99aad712-b5cd-494d-af9a-71bc683f31c7"}}}

Apr 26 11:14:10.147: INFO: completed pod
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 26 11:14:10.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4688" for this suite. 04/26/24 11:14:10.162
{"msg":"PASSED [sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]","completed":66,"skipped":1192,"failed":0}
------------------------------
â€¢ [SLOW TEST] [34.102 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
  test/e2e/auth/service_accounts.go:528

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:13:36.066
    Apr 26 11:13:36.066: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename svcaccounts 04/26/24 11:13:36.067
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:13:36.082
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:13:36.088
    [It] ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]
      test/e2e/auth/service_accounts.go:528
    Apr 26 11:13:36.111: INFO: created pod
    Apr 26 11:13:36.111: INFO: Waiting up to 5m0s for pod "oidc-discovery-validator" in namespace "svcaccounts-4688" to be "Succeeded or Failed"
    Apr 26 11:13:36.119: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 7.54657ms
    Apr 26 11:13:38.148: INFO: Pod "oidc-discovery-validator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037176514s
    Apr 26 11:13:40.125: INFO: Pod "oidc-discovery-validator": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014307434s
    STEP: Saw pod success 04/26/24 11:13:40.125
    Apr 26 11:13:40.125: INFO: Pod "oidc-discovery-validator" satisfied condition "Succeeded or Failed"
    Apr 26 11:14:10.126: INFO: polling logs
    Apr 26 11:14:10.147: INFO: Pod logs: 
    I0426 11:13:36.769390       1 log.go:195] OK: Got token
    I0426 11:13:36.769422       1 log.go:195] validating with in-cluster discovery
    I0426 11:13:36.769635       1 log.go:195] OK: got issuer https://api.conf-125.thomas.internal.emk.fuga.cloud
    I0426 11:13:36.769663       1 log.go:195] Full, not-validated claims: 
    openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://api.conf-125.thomas.internal.emk.fuga.cloud", Subject:"system:serviceaccount:svcaccounts-4688:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1714130616, NotBefore:1714130016, IssuedAt:1714130016, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4688", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"99aad712-b5cd-494d-af9a-71bc683f31c7"}}}
    I0426 11:13:36.789997       1 log.go:195] OK: Constructed OIDC provider for issuer https://api.conf-125.thomas.internal.emk.fuga.cloud
    I0426 11:13:36.793897       1 log.go:195] OK: Validated signature on JWT
    I0426 11:13:36.794013       1 log.go:195] OK: Got valid claims from token!
    I0426 11:13:36.794041       1 log.go:195] Full, validated claims: 
    &openidmetadata.claims{Claims:jwt.Claims{Issuer:"https://api.conf-125.thomas.internal.emk.fuga.cloud", Subject:"system:serviceaccount:svcaccounts-4688:default", Audience:jwt.Audience{"oidc-discovery-test"}, Expiry:1714130616, NotBefore:1714130016, IssuedAt:1714130016, ID:""}, Kubernetes:openidmetadata.kubeClaims{Namespace:"svcaccounts-4688", ServiceAccount:openidmetadata.kubeName{Name:"default", UID:"99aad712-b5cd-494d-af9a-71bc683f31c7"}}}

    Apr 26 11:14:10.147: INFO: completed pod
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 26 11:14:10.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4688" for this suite. 04/26/24 11:14:10.162
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] EndpointSliceMirroring
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:10.168
Apr 26 11:14:10.168: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename endpointslicemirroring 04/26/24 11:14:10.169
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:10.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:10.19
[BeforeEach] [sig-network] EndpointSliceMirroring
  test/e2e/network/endpointslicemirroring.go:41
[It] should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53
STEP: mirroring a new custom Endpoint 04/26/24 11:14:10.208
Apr 26 11:14:10.219: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
STEP: mirroring an update to a custom Endpoint 04/26/24 11:14:12.225
STEP: mirroring deletion of a custom Endpoint 04/26/24 11:14:12.237
[AfterEach] [sig-network] EndpointSliceMirroring
  test/e2e/framework/framework.go:187
Apr 26 11:14:12.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslicemirroring-3113" for this suite. 04/26/24 11:14:12.252
{"msg":"PASSED [sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]","completed":67,"skipped":1203,"failed":0}
------------------------------
â€¢ [2.089 seconds]
[sig-network] EndpointSliceMirroring
test/e2e/network/common/framework.go:23
  should mirror a custom Endpoints resource through create update and delete [Conformance]
  test/e2e/network/endpointslicemirroring.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:10.168
    Apr 26 11:14:10.168: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename endpointslicemirroring 04/26/24 11:14:10.169
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:10.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:10.19
    [BeforeEach] [sig-network] EndpointSliceMirroring
      test/e2e/network/endpointslicemirroring.go:41
    [It] should mirror a custom Endpoints resource through create update and delete [Conformance]
      test/e2e/network/endpointslicemirroring.go:53
    STEP: mirroring a new custom Endpoint 04/26/24 11:14:10.208
    Apr 26 11:14:10.219: INFO: Waiting for at least 1 EndpointSlice to exist, got 0
    STEP: mirroring an update to a custom Endpoint 04/26/24 11:14:12.225
    STEP: mirroring deletion of a custom Endpoint 04/26/24 11:14:12.237
    [AfterEach] [sig-network] EndpointSliceMirroring
      test/e2e/framework/framework.go:187
    Apr 26 11:14:12.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslicemirroring-3113" for this suite. 04/26/24 11:14:12.252
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-instrumentation] Events API
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:12.258
Apr 26 11:14:12.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename events 04/26/24 11:14:12.259
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:12.272
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:12.278
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207
STEP: Create set of events 04/26/24 11:14:12.284
STEP: get a list of Events with a label in the current namespace 04/26/24 11:14:12.303
STEP: delete a list of events 04/26/24 11:14:12.308
Apr 26 11:14:12.308: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 04/26/24 11:14:12.33
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Apr 26 11:14:12.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1817" for this suite. 04/26/24 11:14:12.343
{"msg":"PASSED [sig-instrumentation] Events API should delete a collection of events [Conformance]","completed":68,"skipped":1206,"failed":0}
------------------------------
â€¢ [0.092 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/events.go:207

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:12.258
    Apr 26 11:14:12.258: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename events 04/26/24 11:14:12.259
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:12.272
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:12.278
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/events.go:207
    STEP: Create set of events 04/26/24 11:14:12.284
    STEP: get a list of Events with a label in the current namespace 04/26/24 11:14:12.303
    STEP: delete a list of events 04/26/24 11:14:12.308
    Apr 26 11:14:12.308: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 04/26/24 11:14:12.33
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Apr 26 11:14:12.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-1817" for this suite. 04/26/24 11:14:12.343
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:12.351
Apr 26 11:14:12.351: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename resourcequota 04/26/24 11:14:12.352
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:12.369
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:12.375
[It] should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874
STEP: Creating a ResourceQuota 04/26/24 11:14:12.382
STEP: Getting a ResourceQuota 04/26/24 11:14:12.388
STEP: Updating a ResourceQuota 04/26/24 11:14:12.393
STEP: Verifying a ResourceQuota was modified 04/26/24 11:14:12.397
STEP: Deleting a ResourceQuota 04/26/24 11:14:12.403
STEP: Verifying the deleted ResourceQuota 04/26/24 11:14:12.409
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 26 11:14:12.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7630" for this suite. 04/26/24 11:14:12.423
{"msg":"PASSED [sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]","completed":69,"skipped":1220,"failed":0}
------------------------------
â€¢ [0.082 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  test/e2e/apimachinery/resource_quota.go:874

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:12.351
    Apr 26 11:14:12.351: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename resourcequota 04/26/24 11:14:12.352
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:12.369
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:12.375
    [It] should be able to update and delete ResourceQuota. [Conformance]
      test/e2e/apimachinery/resource_quota.go:874
    STEP: Creating a ResourceQuota 04/26/24 11:14:12.382
    STEP: Getting a ResourceQuota 04/26/24 11:14:12.388
    STEP: Updating a ResourceQuota 04/26/24 11:14:12.393
    STEP: Verifying a ResourceQuota was modified 04/26/24 11:14:12.397
    STEP: Deleting a ResourceQuota 04/26/24 11:14:12.403
    STEP: Verifying the deleted ResourceQuota 04/26/24 11:14:12.409
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 26 11:14:12.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7630" for this suite. 04/26/24 11:14:12.423
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:12.436
Apr 26 11:14:12.436: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:14:12.437
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:12.452
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:12.459
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374
STEP: Creating configMap with name projected-configmap-test-volume-7fb28904-35ff-49e2-96a8-6f8d261873d6 04/26/24 11:14:12.466
STEP: Creating a pod to test consume configMaps 04/26/24 11:14:12.472
Apr 26 11:14:12.484: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1" in namespace "projected-4959" to be "Succeeded or Failed"
Apr 26 11:14:12.494: INFO: Pod "pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.169889ms
Apr 26 11:14:14.505: INFO: Pod "pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021194043s
Apr 26 11:14:16.501: INFO: Pod "pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017358157s
STEP: Saw pod success 04/26/24 11:14:16.501
Apr 26 11:14:16.501: INFO: Pod "pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1" satisfied condition "Succeeded or Failed"
Apr 26 11:14:16.505: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1 container projected-configmap-volume-test: <nil>
STEP: delete the pod 04/26/24 11:14:16.519
Apr 26 11:14:16.532: INFO: Waiting for pod pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1 to disappear
Apr 26 11:14:16.537: INFO: Pod pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 26 11:14:16.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4959" for this suite. 04/26/24 11:14:16.545
{"msg":"PASSED [sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":70,"skipped":1225,"failed":0}
------------------------------
â€¢ [4.115 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:374

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:12.436
    Apr 26 11:14:12.436: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:14:12.437
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:12.452
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:12.459
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:374
    STEP: Creating configMap with name projected-configmap-test-volume-7fb28904-35ff-49e2-96a8-6f8d261873d6 04/26/24 11:14:12.466
    STEP: Creating a pod to test consume configMaps 04/26/24 11:14:12.472
    Apr 26 11:14:12.484: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1" in namespace "projected-4959" to be "Succeeded or Failed"
    Apr 26 11:14:12.494: INFO: Pod "pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.169889ms
    Apr 26 11:14:14.505: INFO: Pod "pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021194043s
    Apr 26 11:14:16.501: INFO: Pod "pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017358157s
    STEP: Saw pod success 04/26/24 11:14:16.501
    Apr 26 11:14:16.501: INFO: Pod "pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1" satisfied condition "Succeeded or Failed"
    Apr 26 11:14:16.505: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1 container projected-configmap-volume-test: <nil>
    STEP: delete the pod 04/26/24 11:14:16.519
    Apr 26 11:14:16.532: INFO: Waiting for pod pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1 to disappear
    Apr 26 11:14:16.537: INFO: Pod pod-projected-configmaps-54d2d139-ad39-4699-95d8-229c1706f6c1 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 26 11:14:16.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4959" for this suite. 04/26/24 11:14:16.545
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:16.553
Apr 26 11:14:16.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 11:14:16.554
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:16.569
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:16.575
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92
STEP: Creating configMap configmap-9829/configmap-test-d76c7da5-a0dd-4d4a-8ee6-2999cc521242 04/26/24 11:14:16.582
STEP: Creating a pod to test consume configMaps 04/26/24 11:14:16.587
Apr 26 11:14:16.599: INFO: Waiting up to 5m0s for pod "pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de" in namespace "configmap-9829" to be "Succeeded or Failed"
Apr 26 11:14:16.607: INFO: Pod "pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de": Phase="Pending", Reason="", readiness=false. Elapsed: 7.346685ms
Apr 26 11:14:18.613: INFO: Pod "pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013747661s
Apr 26 11:14:20.612: INFO: Pod "pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012921686s
STEP: Saw pod success 04/26/24 11:14:20.612
Apr 26 11:14:20.613: INFO: Pod "pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de" satisfied condition "Succeeded or Failed"
Apr 26 11:14:20.618: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de container env-test: <nil>
STEP: delete the pod 04/26/24 11:14:20.63
Apr 26 11:14:20.648: INFO: Waiting for pod pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de to disappear
Apr 26 11:14:20.653: INFO: Pod pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 11:14:20.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9829" for this suite. 04/26/24 11:14:20.661
{"msg":"PASSED [sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]","completed":71,"skipped":1239,"failed":0}
------------------------------
â€¢ [4.117 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:16.553
    Apr 26 11:14:16.553: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 11:14:16.554
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:16.569
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:16.575
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:92
    STEP: Creating configMap configmap-9829/configmap-test-d76c7da5-a0dd-4d4a-8ee6-2999cc521242 04/26/24 11:14:16.582
    STEP: Creating a pod to test consume configMaps 04/26/24 11:14:16.587
    Apr 26 11:14:16.599: INFO: Waiting up to 5m0s for pod "pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de" in namespace "configmap-9829" to be "Succeeded or Failed"
    Apr 26 11:14:16.607: INFO: Pod "pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de": Phase="Pending", Reason="", readiness=false. Elapsed: 7.346685ms
    Apr 26 11:14:18.613: INFO: Pod "pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013747661s
    Apr 26 11:14:20.612: INFO: Pod "pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012921686s
    STEP: Saw pod success 04/26/24 11:14:20.612
    Apr 26 11:14:20.613: INFO: Pod "pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de" satisfied condition "Succeeded or Failed"
    Apr 26 11:14:20.618: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de container env-test: <nil>
    STEP: delete the pod 04/26/24 11:14:20.63
    Apr 26 11:14:20.648: INFO: Waiting for pod pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de to disappear
    Apr 26 11:14:20.653: INFO: Pod pod-configmaps-3c886c89-4e8d-409d-bb06-99b54c1207de no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 11:14:20.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9829" for this suite. 04/26/24 11:14:20.661
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:20.674
Apr 26 11:14:20.674: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename security-context 04/26/24 11:14:20.676
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:20.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:20.698
[It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/26/24 11:14:20.705
Apr 26 11:14:20.720: INFO: Waiting up to 5m0s for pod "security-context-a647208b-561f-464f-b5df-f38f414800c5" in namespace "security-context-4604" to be "Succeeded or Failed"
Apr 26 11:14:20.730: INFO: Pod "security-context-a647208b-561f-464f-b5df-f38f414800c5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.334718ms
Apr 26 11:14:22.738: INFO: Pod "security-context-a647208b-561f-464f-b5df-f38f414800c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017808395s
Apr 26 11:14:24.740: INFO: Pod "security-context-a647208b-561f-464f-b5df-f38f414800c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019883054s
STEP: Saw pod success 04/26/24 11:14:24.74
Apr 26 11:14:24.740: INFO: Pod "security-context-a647208b-561f-464f-b5df-f38f414800c5" satisfied condition "Succeeded or Failed"
Apr 26 11:14:24.746: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod security-context-a647208b-561f-464f-b5df-f38f414800c5 container test-container: <nil>
STEP: delete the pod 04/26/24 11:14:24.759
Apr 26 11:14:24.776: INFO: Waiting for pod security-context-a647208b-561f-464f-b5df-f38f414800c5 to disappear
Apr 26 11:14:24.780: INFO: Pod security-context-a647208b-561f-464f-b5df-f38f414800c5 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 26 11:14:24.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-4604" for this suite. 04/26/24 11:14:24.787
{"msg":"PASSED [sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":72,"skipped":1266,"failed":0}
------------------------------
â€¢ [4.119 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:20.674
    Apr 26 11:14:20.674: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename security-context 04/26/24 11:14:20.676
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:20.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:20.698
    [It] should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:97
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/26/24 11:14:20.705
    Apr 26 11:14:20.720: INFO: Waiting up to 5m0s for pod "security-context-a647208b-561f-464f-b5df-f38f414800c5" in namespace "security-context-4604" to be "Succeeded or Failed"
    Apr 26 11:14:20.730: INFO: Pod "security-context-a647208b-561f-464f-b5df-f38f414800c5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.334718ms
    Apr 26 11:14:22.738: INFO: Pod "security-context-a647208b-561f-464f-b5df-f38f414800c5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017808395s
    Apr 26 11:14:24.740: INFO: Pod "security-context-a647208b-561f-464f-b5df-f38f414800c5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019883054s
    STEP: Saw pod success 04/26/24 11:14:24.74
    Apr 26 11:14:24.740: INFO: Pod "security-context-a647208b-561f-464f-b5df-f38f414800c5" satisfied condition "Succeeded or Failed"
    Apr 26 11:14:24.746: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod security-context-a647208b-561f-464f-b5df-f38f414800c5 container test-container: <nil>
    STEP: delete the pod 04/26/24 11:14:24.759
    Apr 26 11:14:24.776: INFO: Waiting for pod security-context-a647208b-561f-464f-b5df-f38f414800c5 to disappear
    Apr 26 11:14:24.780: INFO: Pod security-context-a647208b-561f-464f-b5df-f38f414800c5 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 26 11:14:24.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-4604" for this suite. 04/26/24 11:14:24.787
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:24.793
Apr 26 11:14:24.794: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 11:14:24.795
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:24.816
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:24.822
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234
STEP: Creating a pod to test downward API volume plugin 04/26/24 11:14:24.831
Apr 26 11:14:24.845: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43" in namespace "downward-api-199" to be "Succeeded or Failed"
Apr 26 11:14:24.860: INFO: Pod "downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43": Phase="Pending", Reason="", readiness=false. Elapsed: 14.452012ms
Apr 26 11:14:26.868: INFO: Pod "downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022546835s
Apr 26 11:14:28.867: INFO: Pod "downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021645187s
STEP: Saw pod success 04/26/24 11:14:28.867
Apr 26 11:14:28.867: INFO: Pod "downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43" satisfied condition "Succeeded or Failed"
Apr 26 11:14:28.878: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43 container client-container: <nil>
STEP: delete the pod 04/26/24 11:14:28.892
Apr 26 11:14:28.905: INFO: Waiting for pod downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43 to disappear
Apr 26 11:14:28.909: INFO: Pod downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 26 11:14:28.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-199" for this suite. 04/26/24 11:14:28.923
{"msg":"PASSED [sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]","completed":73,"skipped":1277,"failed":0}
------------------------------
â€¢ [4.136 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:24.793
    Apr 26 11:14:24.794: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 11:14:24.795
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:24.816
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:24.822
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:234
    STEP: Creating a pod to test downward API volume plugin 04/26/24 11:14:24.831
    Apr 26 11:14:24.845: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43" in namespace "downward-api-199" to be "Succeeded or Failed"
    Apr 26 11:14:24.860: INFO: Pod "downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43": Phase="Pending", Reason="", readiness=false. Elapsed: 14.452012ms
    Apr 26 11:14:26.868: INFO: Pod "downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022546835s
    Apr 26 11:14:28.867: INFO: Pod "downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021645187s
    STEP: Saw pod success 04/26/24 11:14:28.867
    Apr 26 11:14:28.867: INFO: Pod "downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43" satisfied condition "Succeeded or Failed"
    Apr 26 11:14:28.878: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43 container client-container: <nil>
    STEP: delete the pod 04/26/24 11:14:28.892
    Apr 26 11:14:28.905: INFO: Waiting for pod downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43 to disappear
    Apr 26 11:14:28.909: INFO: Pod downwardapi-volume-a7cb7136-5554-4c25-b744-f2656a7ece43 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 26 11:14:28.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-199" for this suite. 04/26/24 11:14:28.923
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:28.93
Apr 26 11:14:28.930: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename var-expansion 04/26/24 11:14:28.932
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:28.948
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:28.955
[It] should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111
STEP: Creating a pod to test substitution in volume subpath 04/26/24 11:14:28.961
Apr 26 11:14:28.974: INFO: Waiting up to 5m0s for pod "var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f" in namespace "var-expansion-516" to be "Succeeded or Failed"
Apr 26 11:14:28.981: INFO: Pod "var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.849288ms
Apr 26 11:14:30.987: INFO: Pod "var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013304579s
Apr 26 11:14:32.988: INFO: Pod "var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013516102s
STEP: Saw pod success 04/26/24 11:14:32.988
Apr 26 11:14:32.988: INFO: Pod "var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f" satisfied condition "Succeeded or Failed"
Apr 26 11:14:32.993: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f container dapi-container: <nil>
STEP: delete the pod 04/26/24 11:14:33.006
Apr 26 11:14:33.019: INFO: Waiting for pod var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f to disappear
Apr 26 11:14:33.024: INFO: Pod var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 26 11:14:33.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-516" for this suite. 04/26/24 11:14:33.03
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]","completed":74,"skipped":1283,"failed":0}
------------------------------
â€¢ [4.106 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a volume subpath [Conformance]
  test/e2e/common/node/expansion.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:28.93
    Apr 26 11:14:28.930: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename var-expansion 04/26/24 11:14:28.932
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:28.948
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:28.955
    [It] should allow substituting values in a volume subpath [Conformance]
      test/e2e/common/node/expansion.go:111
    STEP: Creating a pod to test substitution in volume subpath 04/26/24 11:14:28.961
    Apr 26 11:14:28.974: INFO: Waiting up to 5m0s for pod "var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f" in namespace "var-expansion-516" to be "Succeeded or Failed"
    Apr 26 11:14:28.981: INFO: Pod "var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.849288ms
    Apr 26 11:14:30.987: INFO: Pod "var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013304579s
    Apr 26 11:14:32.988: INFO: Pod "var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013516102s
    STEP: Saw pod success 04/26/24 11:14:32.988
    Apr 26 11:14:32.988: INFO: Pod "var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f" satisfied condition "Succeeded or Failed"
    Apr 26 11:14:32.993: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f container dapi-container: <nil>
    STEP: delete the pod 04/26/24 11:14:33.006
    Apr 26 11:14:33.019: INFO: Waiting for pod var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f to disappear
    Apr 26 11:14:33.024: INFO: Pod var-expansion-6c4a5527-2397-4367-99fb-25459c96e60f no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 26 11:14:33.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-516" for this suite. 04/26/24 11:14:33.03
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:33.038
Apr 26 11:14:33.038: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 11:14:33.039
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:33.053
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:33.062
[It] should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137
STEP: Creating configMap that has name configmap-test-emptyKey-41f6c2c9-5d71-4463-903a-35724540f103 04/26/24 11:14:33.069
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 11:14:33.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-947" for this suite. 04/26/24 11:14:33.081
{"msg":"PASSED [sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]","completed":75,"skipped":1306,"failed":0}
------------------------------
â€¢ [0.051 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should fail to create ConfigMap with empty key [Conformance]
  test/e2e/common/node/configmap.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:33.038
    Apr 26 11:14:33.038: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 11:14:33.039
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:33.053
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:33.062
    [It] should fail to create ConfigMap with empty key [Conformance]
      test/e2e/common/node/configmap.go:137
    STEP: Creating configMap that has name configmap-test-emptyKey-41f6c2c9-5d71-4463-903a-35724540f103 04/26/24 11:14:33.069
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 11:14:33.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-947" for this suite. 04/26/24 11:14:33.081
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:33.09
Apr 26 11:14:33.090: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:14:33.091
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:33.104
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:33.11
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260
STEP: Creating a pod to test downward API volume plugin 04/26/24 11:14:33.116
Apr 26 11:14:33.137: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1" in namespace "projected-5953" to be "Succeeded or Failed"
Apr 26 11:14:33.141: INFO: Pod "downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.099089ms
Apr 26 11:14:35.152: INFO: Pod "downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015008647s
Apr 26 11:14:37.150: INFO: Pod "downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01270293s
STEP: Saw pod success 04/26/24 11:14:37.15
Apr 26 11:14:37.150: INFO: Pod "downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1" satisfied condition "Succeeded or Failed"
Apr 26 11:14:37.154: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1 container client-container: <nil>
STEP: delete the pod 04/26/24 11:14:37.168
Apr 26 11:14:37.186: INFO: Waiting for pod downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1 to disappear
Apr 26 11:14:37.190: INFO: Pod downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 26 11:14:37.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5953" for this suite. 04/26/24 11:14:37.199
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":76,"skipped":1320,"failed":0}
------------------------------
â€¢ [4.114 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:33.09
    Apr 26 11:14:33.090: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:14:33.091
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:33.104
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:33.11
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:260
    STEP: Creating a pod to test downward API volume plugin 04/26/24 11:14:33.116
    Apr 26 11:14:33.137: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1" in namespace "projected-5953" to be "Succeeded or Failed"
    Apr 26 11:14:33.141: INFO: Pod "downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.099089ms
    Apr 26 11:14:35.152: INFO: Pod "downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015008647s
    Apr 26 11:14:37.150: INFO: Pod "downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01270293s
    STEP: Saw pod success 04/26/24 11:14:37.15
    Apr 26 11:14:37.150: INFO: Pod "downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1" satisfied condition "Succeeded or Failed"
    Apr 26 11:14:37.154: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1 container client-container: <nil>
    STEP: delete the pod 04/26/24 11:14:37.168
    Apr 26 11:14:37.186: INFO: Waiting for pod downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1 to disappear
    Apr 26 11:14:37.190: INFO: Pod downwardapi-volume-f14b3011-f962-41cc-b8dd-990f4f0413c1 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 26 11:14:37.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5953" for this suite. 04/26/24 11:14:37.199
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:37.207
Apr 26 11:14:37.207: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename podtemplate 04/26/24 11:14:37.208
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:37.223
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:37.23
[It] should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 26 11:14:37.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-5985" for this suite. 04/26/24 11:14:37.278
{"msg":"PASSED [sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]","completed":77,"skipped":1335,"failed":0}
------------------------------
â€¢ [0.078 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should run the lifecycle of PodTemplates [Conformance]
  test/e2e/common/node/podtemplates.go:53

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:37.207
    Apr 26 11:14:37.207: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename podtemplate 04/26/24 11:14:37.208
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:37.223
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:37.23
    [It] should run the lifecycle of PodTemplates [Conformance]
      test/e2e/common/node/podtemplates.go:53
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 26 11:14:37.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-5985" for this suite. 04/26/24 11:14:37.278
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:37.285
Apr 26 11:14:37.286: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 11:14:37.286
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:37.302
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:37.308
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78
STEP: Creating secret with name secret-test-map-df21e5ca-c238-413c-b0d0-10e762f7bfa6 04/26/24 11:14:37.316
STEP: Creating a pod to test consume secrets 04/26/24 11:14:37.326
Apr 26 11:14:37.338: INFO: Waiting up to 5m0s for pod "pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa" in namespace "secrets-1538" to be "Succeeded or Failed"
Apr 26 11:14:37.345: INFO: Pod "pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa": Phase="Pending", Reason="", readiness=false. Elapsed: 6.75326ms
Apr 26 11:14:39.351: INFO: Pod "pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013172853s
Apr 26 11:14:41.352: INFO: Pod "pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013440244s
STEP: Saw pod success 04/26/24 11:14:41.352
Apr 26 11:14:41.352: INFO: Pod "pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa" satisfied condition "Succeeded or Failed"
Apr 26 11:14:41.356: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa container secret-volume-test: <nil>
STEP: delete the pod 04/26/24 11:14:41.37
Apr 26 11:14:41.383: INFO: Waiting for pod pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa to disappear
Apr 26 11:14:41.388: INFO: Pod pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 26 11:14:41.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1538" for this suite. 04/26/24 11:14:41.397
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":78,"skipped":1346,"failed":0}
------------------------------
â€¢ [4.117 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:78

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:37.285
    Apr 26 11:14:37.286: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 11:14:37.286
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:37.302
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:37.308
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:78
    STEP: Creating secret with name secret-test-map-df21e5ca-c238-413c-b0d0-10e762f7bfa6 04/26/24 11:14:37.316
    STEP: Creating a pod to test consume secrets 04/26/24 11:14:37.326
    Apr 26 11:14:37.338: INFO: Waiting up to 5m0s for pod "pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa" in namespace "secrets-1538" to be "Succeeded or Failed"
    Apr 26 11:14:37.345: INFO: Pod "pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa": Phase="Pending", Reason="", readiness=false. Elapsed: 6.75326ms
    Apr 26 11:14:39.351: INFO: Pod "pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013172853s
    Apr 26 11:14:41.352: INFO: Pod "pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013440244s
    STEP: Saw pod success 04/26/24 11:14:41.352
    Apr 26 11:14:41.352: INFO: Pod "pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa" satisfied condition "Succeeded or Failed"
    Apr 26 11:14:41.356: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa container secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 11:14:41.37
    Apr 26 11:14:41.383: INFO: Waiting for pod pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa to disappear
    Apr 26 11:14:41.388: INFO: Pod pod-secrets-d2858175-9b0d-4b53-9069-37c5b63a96fa no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 11:14:41.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1538" for this suite. 04/26/24 11:14:41.397
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:41.405
Apr 26 11:14:41.405: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:14:41.406
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:41.42
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:41.427
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129
STEP: Creating the pod 04/26/24 11:14:41.434
Apr 26 11:14:41.447: INFO: Waiting up to 5m0s for pod "labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68" in namespace "projected-3597" to be "running and ready"
Apr 26 11:14:41.454: INFO: Pod "labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68": Phase="Pending", Reason="", readiness=false. Elapsed: 6.388179ms
Apr 26 11:14:41.454: INFO: The phase of Pod labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:14:43.461: INFO: Pod "labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68": Phase="Running", Reason="", readiness=true. Elapsed: 2.014294116s
Apr 26 11:14:43.462: INFO: The phase of Pod labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68 is Running (Ready = true)
Apr 26 11:14:43.462: INFO: Pod "labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68" satisfied condition "running and ready"
Apr 26 11:14:43.996: INFO: Successfully updated pod "labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 26 11:14:48.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3597" for this suite. 04/26/24 11:14:48.051
{"msg":"PASSED [sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]","completed":79,"skipped":1386,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.651 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:41.405
    Apr 26 11:14:41.405: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:14:41.406
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:41.42
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:41.427
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:129
    STEP: Creating the pod 04/26/24 11:14:41.434
    Apr 26 11:14:41.447: INFO: Waiting up to 5m0s for pod "labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68" in namespace "projected-3597" to be "running and ready"
    Apr 26 11:14:41.454: INFO: Pod "labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68": Phase="Pending", Reason="", readiness=false. Elapsed: 6.388179ms
    Apr 26 11:14:41.454: INFO: The phase of Pod labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:14:43.461: INFO: Pod "labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68": Phase="Running", Reason="", readiness=true. Elapsed: 2.014294116s
    Apr 26 11:14:43.462: INFO: The phase of Pod labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68 is Running (Ready = true)
    Apr 26 11:14:43.462: INFO: Pod "labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68" satisfied condition "running and ready"
    Apr 26 11:14:43.996: INFO: Successfully updated pod "labelsupdatecd3fcc78-c10f-4ef4-b99f-cb42e96c3c68"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 26 11:14:48.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3597" for this suite. 04/26/24 11:14:48.051
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Secrets
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:48.064
Apr 26 11:14:48.064: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 11:14:48.065
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:48.081
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:48.088
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45
STEP: Creating secret with name secret-test-cf33f06a-aa91-4e71-beed-2f674b5852db 04/26/24 11:14:48.095
STEP: Creating a pod to test consume secrets 04/26/24 11:14:48.099
Apr 26 11:14:48.112: INFO: Waiting up to 5m0s for pod "pod-secrets-4e64c095-46de-423a-a997-256d71404109" in namespace "secrets-7832" to be "Succeeded or Failed"
Apr 26 11:14:48.118: INFO: Pod "pod-secrets-4e64c095-46de-423a-a997-256d71404109": Phase="Pending", Reason="", readiness=false. Elapsed: 5.17924ms
Apr 26 11:14:50.124: INFO: Pod "pod-secrets-4e64c095-46de-423a-a997-256d71404109": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01180732s
Apr 26 11:14:52.125: INFO: Pod "pod-secrets-4e64c095-46de-423a-a997-256d71404109": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012137754s
STEP: Saw pod success 04/26/24 11:14:52.125
Apr 26 11:14:52.125: INFO: Pod "pod-secrets-4e64c095-46de-423a-a997-256d71404109" satisfied condition "Succeeded or Failed"
Apr 26 11:14:52.130: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-secrets-4e64c095-46de-423a-a997-256d71404109 container secret-env-test: <nil>
STEP: delete the pod 04/26/24 11:14:52.149
Apr 26 11:14:52.163: INFO: Waiting for pod pod-secrets-4e64c095-46de-423a-a997-256d71404109 to disappear
Apr 26 11:14:52.168: INFO: Pod pod-secrets-4e64c095-46de-423a-a997-256d71404109 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 26 11:14:52.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7832" for this suite. 04/26/24 11:14:52.177
{"msg":"PASSED [sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]","completed":80,"skipped":1411,"failed":0}
------------------------------
â€¢ [4.123 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:48.064
    Apr 26 11:14:48.064: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 11:14:48.065
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:48.081
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:48.088
    [It] should be consumable from pods in env vars [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:45
    STEP: Creating secret with name secret-test-cf33f06a-aa91-4e71-beed-2f674b5852db 04/26/24 11:14:48.095
    STEP: Creating a pod to test consume secrets 04/26/24 11:14:48.099
    Apr 26 11:14:48.112: INFO: Waiting up to 5m0s for pod "pod-secrets-4e64c095-46de-423a-a997-256d71404109" in namespace "secrets-7832" to be "Succeeded or Failed"
    Apr 26 11:14:48.118: INFO: Pod "pod-secrets-4e64c095-46de-423a-a997-256d71404109": Phase="Pending", Reason="", readiness=false. Elapsed: 5.17924ms
    Apr 26 11:14:50.124: INFO: Pod "pod-secrets-4e64c095-46de-423a-a997-256d71404109": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01180732s
    Apr 26 11:14:52.125: INFO: Pod "pod-secrets-4e64c095-46de-423a-a997-256d71404109": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012137754s
    STEP: Saw pod success 04/26/24 11:14:52.125
    Apr 26 11:14:52.125: INFO: Pod "pod-secrets-4e64c095-46de-423a-a997-256d71404109" satisfied condition "Succeeded or Failed"
    Apr 26 11:14:52.130: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-secrets-4e64c095-46de-423a-a997-256d71404109 container secret-env-test: <nil>
    STEP: delete the pod 04/26/24 11:14:52.149
    Apr 26 11:14:52.163: INFO: Waiting for pod pod-secrets-4e64c095-46de-423a-a997-256d71404109 to disappear
    Apr 26 11:14:52.168: INFO: Pod pod-secrets-4e64c095-46de-423a-a997-256d71404109 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 11:14:52.168: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-7832" for this suite. 04/26/24 11:14:52.177
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:14:52.189
Apr 26 11:14:52.189: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename resourcequota 04/26/24 11:14:52.19
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:52.206
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:52.212
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382
STEP: Counting existing ResourceQuota 04/26/24 11:14:52.22
STEP: Creating a ResourceQuota 04/26/24 11:14:57.226
STEP: Ensuring resource quota status is calculated 04/26/24 11:14:57.233
STEP: Creating a ReplicationController 04/26/24 11:14:59.24
STEP: Ensuring resource quota status captures replication controller creation 04/26/24 11:14:59.252
STEP: Deleting a ReplicationController 04/26/24 11:15:01.259
STEP: Ensuring resource quota status released usage 04/26/24 11:15:01.266
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 26 11:15:03.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7762" for this suite. 04/26/24 11:15:03.284
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]","completed":81,"skipped":1423,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.102 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  test/e2e/apimachinery/resource_quota.go:382

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:14:52.189
    Apr 26 11:14:52.189: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename resourcequota 04/26/24 11:14:52.19
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:14:52.206
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:14:52.212
    [It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
      test/e2e/apimachinery/resource_quota.go:382
    STEP: Counting existing ResourceQuota 04/26/24 11:14:52.22
    STEP: Creating a ResourceQuota 04/26/24 11:14:57.226
    STEP: Ensuring resource quota status is calculated 04/26/24 11:14:57.233
    STEP: Creating a ReplicationController 04/26/24 11:14:59.24
    STEP: Ensuring resource quota status captures replication controller creation 04/26/24 11:14:59.252
    STEP: Deleting a ReplicationController 04/26/24 11:15:01.259
    STEP: Ensuring resource quota status released usage 04/26/24 11:15:01.266
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 26 11:15:03.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7762" for this suite. 04/26/24 11:15:03.284
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicaSet
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:15:03.292
Apr 26 11:15:03.293: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename replicaset 04/26/24 11:15:03.294
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:15:03.329
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:15:03.337
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111
Apr 26 11:15:03.344: INFO: Creating ReplicaSet my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa
Apr 26 11:15:03.353: INFO: Pod name my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa: Found 0 pods out of 1
Apr 26 11:15:08.360: INFO: Pod name my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa: Found 1 pods out of 1
Apr 26 11:15:08.361: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa" is running
Apr 26 11:15:08.361: INFO: Waiting up to 5m0s for pod "my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa-fjssc" in namespace "replicaset-5430" to be "running"
Apr 26 11:15:08.385: INFO: Pod "my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa-fjssc": Phase="Running", Reason="", readiness=true. Elapsed: 24.228576ms
Apr 26 11:15:08.385: INFO: Pod "my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa-fjssc" satisfied condition "running"
Apr 26 11:15:08.385: INFO: Pod "my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa-fjssc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:15:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:15:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:15:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:15:03 +0000 UTC Reason: Message:}])
Apr 26 11:15:08.385: INFO: Trying to dial the pod
Apr 26 11:15:13.459: INFO: Controller my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa: Got expected result from replica 1 [my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa-fjssc]: "my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa-fjssc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 26 11:15:13.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5430" for this suite. 04/26/24 11:15:13.471
{"msg":"PASSED [sig-apps] ReplicaSet should serve a basic image on each replica with a public image  [Conformance]","completed":82,"skipped":1429,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.185 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/replica_set.go:111

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:15:03.292
    Apr 26 11:15:03.293: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename replicaset 04/26/24 11:15:03.294
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:15:03.329
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:15:03.337
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/replica_set.go:111
    Apr 26 11:15:03.344: INFO: Creating ReplicaSet my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa
    Apr 26 11:15:03.353: INFO: Pod name my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa: Found 0 pods out of 1
    Apr 26 11:15:08.360: INFO: Pod name my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa: Found 1 pods out of 1
    Apr 26 11:15:08.361: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa" is running
    Apr 26 11:15:08.361: INFO: Waiting up to 5m0s for pod "my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa-fjssc" in namespace "replicaset-5430" to be "running"
    Apr 26 11:15:08.385: INFO: Pod "my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa-fjssc": Phase="Running", Reason="", readiness=true. Elapsed: 24.228576ms
    Apr 26 11:15:08.385: INFO: Pod "my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa-fjssc" satisfied condition "running"
    Apr 26 11:15:08.385: INFO: Pod "my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa-fjssc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:15:03 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:15:04 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:15:04 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:15:03 +0000 UTC Reason: Message:}])
    Apr 26 11:15:08.385: INFO: Trying to dial the pod
    Apr 26 11:15:13.459: INFO: Controller my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa: Got expected result from replica 1 [my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa-fjssc]: "my-hostname-basic-eccb3242-e119-4ff0-ad89-3fbbc2186afa-fjssc", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 26 11:15:13.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5430" for this suite. 04/26/24 11:15:13.471
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:15:13.479
Apr 26 11:15:13.479: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename cronjob 04/26/24 11:15:13.48
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:15:13.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:15:13.506
[It] should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96
STEP: Creating a suspended cronjob 04/26/24 11:15:13.515
STEP: Ensuring no jobs are scheduled 04/26/24 11:15:13.527
STEP: Ensuring no job exists by listing jobs explicitly 04/26/24 11:20:13.542
STEP: Removing cronjob 04/26/24 11:20:13.548
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 26 11:20:13.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-5563" for this suite. 04/26/24 11:20:13.563
{"msg":"PASSED [sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]","completed":83,"skipped":1452,"failed":0}
------------------------------
â€¢ [SLOW TEST] [300.091 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule jobs when suspended [Slow] [Conformance]
  test/e2e/apps/cronjob.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:15:13.479
    Apr 26 11:15:13.479: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename cronjob 04/26/24 11:15:13.48
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:15:13.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:15:13.506
    [It] should not schedule jobs when suspended [Slow] [Conformance]
      test/e2e/apps/cronjob.go:96
    STEP: Creating a suspended cronjob 04/26/24 11:15:13.515
    STEP: Ensuring no jobs are scheduled 04/26/24 11:15:13.527
    STEP: Ensuring no job exists by listing jobs explicitly 04/26/24 11:20:13.542
    STEP: Removing cronjob 04/26/24 11:20:13.548
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 26 11:20:13.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-5563" for this suite. 04/26/24 11:20:13.563
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:20:13.571
Apr 26 11:20:13.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename replicaset 04/26/24 11:20:13.572
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:20:13.605
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:20:13.612
[It] should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165
STEP: Create a ReplicaSet 04/26/24 11:20:13.62
STEP: Verify that the required pods have come up 04/26/24 11:20:13.628
Apr 26 11:20:13.670: INFO: Pod name sample-pod: Found 0 pods out of 3
Apr 26 11:20:18.678: INFO: Pod name sample-pod: Found 3 pods out of 3
STEP: ensuring each pod is running 04/26/24 11:20:18.678
Apr 26 11:20:18.682: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
STEP: Listing all ReplicaSets 04/26/24 11:20:18.682
STEP: DeleteCollection of the ReplicaSets 04/26/24 11:20:18.688
STEP: After DeleteCollection verify that ReplicaSets have been deleted 04/26/24 11:20:18.695
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 26 11:20:18.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4493" for this suite. 04/26/24 11:20:18.708
{"msg":"PASSED [sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]","completed":84,"skipped":1465,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.143 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should list and delete a collection of ReplicaSets [Conformance]
  test/e2e/apps/replica_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:20:13.571
    Apr 26 11:20:13.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename replicaset 04/26/24 11:20:13.572
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:20:13.605
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:20:13.612
    [It] should list and delete a collection of ReplicaSets [Conformance]
      test/e2e/apps/replica_set.go:165
    STEP: Create a ReplicaSet 04/26/24 11:20:13.62
    STEP: Verify that the required pods have come up 04/26/24 11:20:13.628
    Apr 26 11:20:13.670: INFO: Pod name sample-pod: Found 0 pods out of 3
    Apr 26 11:20:18.678: INFO: Pod name sample-pod: Found 3 pods out of 3
    STEP: ensuring each pod is running 04/26/24 11:20:18.678
    Apr 26 11:20:18.682: INFO: Replica Status: {Replicas:3 FullyLabeledReplicas:3 ReadyReplicas:3 AvailableReplicas:3 ObservedGeneration:1 Conditions:[]}
    STEP: Listing all ReplicaSets 04/26/24 11:20:18.682
    STEP: DeleteCollection of the ReplicaSets 04/26/24 11:20:18.688
    STEP: After DeleteCollection verify that ReplicaSets have been deleted 04/26/24 11:20:18.695
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 26 11:20:18.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4493" for this suite. 04/26/24 11:20:18.708
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:20:18.714
Apr 26 11:20:18.714: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename statefulset 04/26/24 11:20:18.715
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:20:18.747
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:20:18.756
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7729 04/26/24 11:20:18.762
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  test/e2e/apps/statefulset.go:304
STEP: Creating a new StatefulSet 04/26/24 11:20:18.769
Apr 26 11:20:18.780: INFO: Found 0 stateful pods, waiting for 3
Apr 26 11:20:28.787: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 26 11:20:28.787: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 26 11:20:28.787: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 26 11:20:28.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-7729 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 26 11:20:29.214: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 26 11:20:29.214: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 26 11:20:29.214: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/26/24 11:20:39.238
Apr 26 11:20:39.261: INFO: Updating stateful set ss2
STEP: Creating a new revision 04/26/24 11:20:39.261
STEP: Updating Pods in reverse ordinal order 04/26/24 11:20:49.295
Apr 26 11:20:49.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-7729 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 26 11:20:49.820: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 26 11:20:49.820: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 26 11:20:49.820: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision 04/26/24 11:20:59.857
Apr 26 11:20:59.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-7729 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 26 11:21:00.384: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 26 11:21:00.384: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 26 11:21:00.384: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 26 11:21:10.429: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order 04/26/24 11:21:20.454
Apr 26 11:21:20.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-7729 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 26 11:21:21.001: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 26 11:21:21.001: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 26 11:21:21.001: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 26 11:21:31.039: INFO: Deleting all statefulset in ns statefulset-7729
Apr 26 11:21:31.043: INFO: Scaling statefulset ss2 to 0
Apr 26 11:21:41.072: INFO: Waiting for statefulset status.replicas updated to 0
Apr 26 11:21:41.077: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 26 11:21:41.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7729" for this suite. 04/26/24 11:21:41.105
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]","completed":85,"skipped":1469,"failed":0}
------------------------------
â€¢ [SLOW TEST] [82.397 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform rolling updates and roll backs of template modifications [Conformance]
    test/e2e/apps/statefulset.go:304

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:20:18.714
    Apr 26 11:20:18.714: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename statefulset 04/26/24 11:20:18.715
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:20:18.747
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:20:18.756
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7729 04/26/24 11:20:18.762
    [It] should perform rolling updates and roll backs of template modifications [Conformance]
      test/e2e/apps/statefulset.go:304
    STEP: Creating a new StatefulSet 04/26/24 11:20:18.769
    Apr 26 11:20:18.780: INFO: Found 0 stateful pods, waiting for 3
    Apr 26 11:20:28.787: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 26 11:20:28.787: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 26 11:20:28.787: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    Apr 26 11:20:28.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-7729 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 26 11:20:29.214: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 26 11:20:29.214: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 26 11:20:29.214: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    STEP: Updating StatefulSet template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/26/24 11:20:39.238
    Apr 26 11:20:39.261: INFO: Updating stateful set ss2
    STEP: Creating a new revision 04/26/24 11:20:39.261
    STEP: Updating Pods in reverse ordinal order 04/26/24 11:20:49.295
    Apr 26 11:20:49.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-7729 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 26 11:20:49.820: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 26 11:20:49.820: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 26 11:20:49.820: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    STEP: Rolling back to a previous revision 04/26/24 11:20:59.857
    Apr 26 11:20:59.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-7729 exec ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 26 11:21:00.384: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 26 11:21:00.384: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 26 11:21:00.384: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 26 11:21:10.429: INFO: Updating stateful set ss2
    STEP: Rolling back update in reverse ordinal order 04/26/24 11:21:20.454
    Apr 26 11:21:20.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-7729 exec ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 26 11:21:21.001: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 26 11:21:21.001: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 26 11:21:21.001: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 26 11:21:31.039: INFO: Deleting all statefulset in ns statefulset-7729
    Apr 26 11:21:31.043: INFO: Scaling statefulset ss2 to 0
    Apr 26 11:21:41.072: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 26 11:21:41.077: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 26 11:21:41.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7729" for this suite. 04/26/24 11:21:41.105
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod
  should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:21:41.118
Apr 26 11:21:41.118: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 11:21:41.119
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:21:41.133
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:21:41.14
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1698
[It] should create a pod from an image when restart is Never  [Conformance]
  test/e2e/kubectl/kubectl.go:1711
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/26/24 11:21:41.147
Apr 26 11:21:41.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-8312 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
Apr 26 11:21:41.237: INFO: stderr: ""
Apr 26 11:21:41.237: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created 04/26/24 11:21:41.237
[AfterEach] Kubectl run pod
  test/e2e/kubectl/kubectl.go:1702
Apr 26 11:21:41.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-8312 delete pods e2e-test-httpd-pod'
Apr 26 11:21:42.930: INFO: stderr: ""
Apr 26 11:21:42.930: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 11:21:42.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8312" for this suite. 04/26/24 11:21:42.939
{"msg":"PASSED [sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never  [Conformance]","completed":86,"skipped":1535,"failed":0}
------------------------------
â€¢ [1.827 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl run pod
  test/e2e/kubectl/kubectl.go:1695
    should create a pod from an image when restart is Never  [Conformance]
    test/e2e/kubectl/kubectl.go:1711

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:21:41.118
    Apr 26 11:21:41.118: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 11:21:41.119
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:21:41.133
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:21:41.14
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1698
    [It] should create a pod from an image when restart is Never  [Conformance]
      test/e2e/kubectl/kubectl.go:1711
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/26/24 11:21:41.147
    Apr 26 11:21:41.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-8312 run e2e-test-httpd-pod --restart=Never --pod-running-timeout=2m0s --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2'
    Apr 26 11:21:41.237: INFO: stderr: ""
    Apr 26 11:21:41.237: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod was created 04/26/24 11:21:41.237
    [AfterEach] Kubectl run pod
      test/e2e/kubectl/kubectl.go:1702
    Apr 26 11:21:41.243: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-8312 delete pods e2e-test-httpd-pod'
    Apr 26 11:21:42.930: INFO: stderr: ""
    Apr 26 11:21:42.930: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 11:21:42.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8312" for this suite. 04/26/24 11:21:42.939
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:21:42.946
Apr 26 11:21:42.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pod-network-test 04/26/24 11:21:42.947
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:21:42.964
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:21:42.971
[It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:93
STEP: Performing setup for networking test in namespace pod-network-test-361 04/26/24 11:21:42.978
STEP: creating a selector 04/26/24 11:21:42.979
STEP: Creating the service pods in kubernetes 04/26/24 11:21:42.979
Apr 26 11:21:42.979: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 26 11:21:43.036: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-361" to be "running and ready"
Apr 26 11:21:43.044: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.615176ms
Apr 26 11:21:43.044: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:21:45.050: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.014517851s
Apr 26 11:21:45.050: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 11:21:47.051: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.014982059s
Apr 26 11:21:47.051: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 11:21:49.050: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.014513129s
Apr 26 11:21:49.050: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 11:21:51.052: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.016683599s
Apr 26 11:21:51.052: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 11:21:53.054: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.018080262s
Apr 26 11:21:53.054: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 11:21:55.052: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.016171846s
Apr 26 11:21:55.052: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 26 11:21:55.052: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 26 11:21:55.057: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-361" to be "running and ready"
Apr 26 11:21:55.062: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.526109ms
Apr 26 11:21:55.063: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 26 11:21:55.063: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 26 11:21:55.068: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-361" to be "running and ready"
Apr 26 11:21:55.074: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 5.730844ms
Apr 26 11:21:55.074: INFO: The phase of Pod netserver-2 is Running (Ready = false)
Apr 26 11:21:57.082: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 2.013698006s
Apr 26 11:21:57.082: INFO: The phase of Pod netserver-2 is Running (Ready = false)
Apr 26 11:21:59.080: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 4.011903557s
Apr 26 11:21:59.080: INFO: The phase of Pod netserver-2 is Running (Ready = false)
Apr 26 11:22:01.082: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 6.013836919s
Apr 26 11:22:01.082: INFO: The phase of Pod netserver-2 is Running (Ready = false)
Apr 26 11:22:03.082: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 8.013617523s
Apr 26 11:22:03.082: INFO: The phase of Pod netserver-2 is Running (Ready = false)
Apr 26 11:22:05.080: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 10.012215365s
Apr 26 11:22:05.080: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 26 11:22:05.080: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/26/24 11:22:05.086
Apr 26 11:22:05.097: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-361" to be "running"
Apr 26 11:22:05.103: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035936ms
Apr 26 11:22:07.113: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.016043571s
Apr 26 11:22:07.113: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 26 11:22:07.119: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 26 11:22:07.119: INFO: Breadth first check of 100.96.2.49 on host 10.250.0.121...
Apr 26 11:22:07.129: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.116:9080/dial?request=hostname&protocol=udp&host=100.96.2.49&port=8081&tries=1'] Namespace:pod-network-test-361 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:22:07.129: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:22:07.130: INFO: ExecWithOptions: Clientset creation
Apr 26 11:22:07.131: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-361/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.1.116%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.2.49%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 26 11:22:07.567: INFO: Waiting for responses: map[]
Apr 26 11:22:07.567: INFO: reached 100.96.2.49 after 0/1 tries
Apr 26 11:22:07.567: INFO: Breadth first check of 100.96.1.115 on host 10.250.2.248...
Apr 26 11:22:07.572: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.116:9080/dial?request=hostname&protocol=udp&host=100.96.1.115&port=8081&tries=1'] Namespace:pod-network-test-361 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:22:07.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:22:07.573: INFO: ExecWithOptions: Clientset creation
Apr 26 11:22:07.573: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-361/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.1.116%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.1.115%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 26 11:22:08.076: INFO: Waiting for responses: map[]
Apr 26 11:22:08.076: INFO: reached 100.96.1.115 after 0/1 tries
Apr 26 11:22:08.076: INFO: Breadth first check of 100.96.0.53 on host 10.250.1.183...
Apr 26 11:22:08.082: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.116:9080/dial?request=hostname&protocol=udp&host=100.96.0.53&port=8081&tries=1'] Namespace:pod-network-test-361 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:22:08.082: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:22:08.083: INFO: ExecWithOptions: Clientset creation
Apr 26 11:22:08.083: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-361/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.1.116%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.0.53%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 26 11:22:08.594: INFO: Waiting for responses: map[]
Apr 26 11:22:08.595: INFO: reached 100.96.0.53 after 0/1 tries
Apr 26 11:22:08.595: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 26 11:22:08.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-361" for this suite. 04/26/24 11:22:08.605
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]","completed":87,"skipped":1547,"failed":0}
------------------------------
â€¢ [SLOW TEST] [25.666 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: udp [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:93

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:21:42.946
    Apr 26 11:21:42.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pod-network-test 04/26/24 11:21:42.947
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:21:42.964
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:21:42.971
    [It] should function for intra-pod communication: udp [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:93
    STEP: Performing setup for networking test in namespace pod-network-test-361 04/26/24 11:21:42.978
    STEP: creating a selector 04/26/24 11:21:42.979
    STEP: Creating the service pods in kubernetes 04/26/24 11:21:42.979
    Apr 26 11:21:42.979: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 26 11:21:43.036: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-361" to be "running and ready"
    Apr 26 11:21:43.044: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 8.615176ms
    Apr 26 11:21:43.044: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:21:45.050: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.014517851s
    Apr 26 11:21:45.050: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 11:21:47.051: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.014982059s
    Apr 26 11:21:47.051: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 11:21:49.050: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.014513129s
    Apr 26 11:21:49.050: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 11:21:51.052: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.016683599s
    Apr 26 11:21:51.052: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 11:21:53.054: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.018080262s
    Apr 26 11:21:53.054: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 11:21:55.052: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.016171846s
    Apr 26 11:21:55.052: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 26 11:21:55.052: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 26 11:21:55.057: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-361" to be "running and ready"
    Apr 26 11:21:55.062: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.526109ms
    Apr 26 11:21:55.063: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 26 11:21:55.063: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 26 11:21:55.068: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-361" to be "running and ready"
    Apr 26 11:21:55.074: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 5.730844ms
    Apr 26 11:21:55.074: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    Apr 26 11:21:57.082: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 2.013698006s
    Apr 26 11:21:57.082: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    Apr 26 11:21:59.080: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 4.011903557s
    Apr 26 11:21:59.080: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    Apr 26 11:22:01.082: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 6.013836919s
    Apr 26 11:22:01.082: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    Apr 26 11:22:03.082: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=false. Elapsed: 8.013617523s
    Apr 26 11:22:03.082: INFO: The phase of Pod netserver-2 is Running (Ready = false)
    Apr 26 11:22:05.080: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 10.012215365s
    Apr 26 11:22:05.080: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 26 11:22:05.080: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/26/24 11:22:05.086
    Apr 26 11:22:05.097: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-361" to be "running"
    Apr 26 11:22:05.103: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 6.035936ms
    Apr 26 11:22:07.113: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.016043571s
    Apr 26 11:22:07.113: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 26 11:22:07.119: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 26 11:22:07.119: INFO: Breadth first check of 100.96.2.49 on host 10.250.0.121...
    Apr 26 11:22:07.129: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.116:9080/dial?request=hostname&protocol=udp&host=100.96.2.49&port=8081&tries=1'] Namespace:pod-network-test-361 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:22:07.129: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:22:07.130: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:22:07.131: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-361/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.1.116%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.2.49%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 26 11:22:07.567: INFO: Waiting for responses: map[]
    Apr 26 11:22:07.567: INFO: reached 100.96.2.49 after 0/1 tries
    Apr 26 11:22:07.567: INFO: Breadth first check of 100.96.1.115 on host 10.250.2.248...
    Apr 26 11:22:07.572: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.116:9080/dial?request=hostname&protocol=udp&host=100.96.1.115&port=8081&tries=1'] Namespace:pod-network-test-361 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:22:07.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:22:07.573: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:22:07.573: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-361/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.1.116%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.1.115%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 26 11:22:08.076: INFO: Waiting for responses: map[]
    Apr 26 11:22:08.076: INFO: reached 100.96.1.115 after 0/1 tries
    Apr 26 11:22:08.076: INFO: Breadth first check of 100.96.0.53 on host 10.250.1.183...
    Apr 26 11:22:08.082: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.116:9080/dial?request=hostname&protocol=udp&host=100.96.0.53&port=8081&tries=1'] Namespace:pod-network-test-361 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:22:08.082: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:22:08.083: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:22:08.083: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-361/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.1.116%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dudp%26host%3D100.96.0.53%26port%3D8081%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 26 11:22:08.594: INFO: Waiting for responses: map[]
    Apr 26 11:22:08.595: INFO: reached 100.96.0.53 after 0/1 tries
    Apr 26 11:22:08.595: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 26 11:22:08.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-361" for this suite. 04/26/24 11:22:08.605
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:22:08.613
Apr 26 11:22:08.613: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename deployment 04/26/24 11:22:08.614
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:22:08.628
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:22:08.635
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132
Apr 26 11:22:08.653: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 26 11:22:13.659: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/26/24 11:22:13.659
Apr 26 11:22:13.659: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 26 11:22:15.666: INFO: Creating deployment "test-rollover-deployment"
Apr 26 11:22:15.677: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 26 11:22:17.695: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 26 11:22:17.706: INFO: Ensure that both replica sets have 1 created replica
Apr 26 11:22:17.715: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 26 11:22:17.728: INFO: Updating deployment test-rollover-deployment
Apr 26 11:22:17.728: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 26 11:22:19.738: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 26 11:22:19.755: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 26 11:22:19.766: INFO: all replica sets need to contain the pod-template-hash label
Apr 26 11:22:19.767: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:22:21.779: INFO: all replica sets need to contain the pod-template-hash label
Apr 26 11:22:21.779: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:22:23.786: INFO: all replica sets need to contain the pod-template-hash label
Apr 26 11:22:23.786: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:22:25.780: INFO: all replica sets need to contain the pod-template-hash label
Apr 26 11:22:25.780: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:22:27.782: INFO: all replica sets need to contain the pod-template-hash label
Apr 26 11:22:27.782: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:22:29.784: INFO: 
Apr 26 11:22:29.784: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 26 11:22:29.797: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-8216  5cb9db64-6cd5-4178-8e7d-446c218ee1a4 25045 2 2024-04-26 11:22:15 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2024-04-26 11:22:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:22:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f9ada8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2024-04-26 11:22:15 +0000 UTC,LastTransitionTime:2024-04-26 11:22:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2024-04-26 11:22:29 +0000 UTC,LastTransitionTime:2024-04-26 11:22:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 26 11:22:29.804: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-8216  4a6a9210-62c9-44ea-83f2-774cbeaaaf37 25038 2 2024-04-26 11:22:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 5cb9db64-6cd5-4178-8e7d-446c218ee1a4 0xc0004b1647 0xc0004b1648}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:22:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5cb9db64-6cd5-4178-8e7d-446c218ee1a4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:22:29 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0004b1718 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 26 11:22:29.804: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 26 11:22:29.804: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-8216  d4bd611e-ed50-4b82-9d38-eee07d368a54 25044 2 2024-04-26 11:22:08 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 5cb9db64-6cd5-4178-8e7d-446c218ee1a4 0xc0002f9e07 0xc0002f9e08}] [] [{e2e.test Update apps/v1 2024-04-26 11:22:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:22:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5cb9db64-6cd5-4178-8e7d-446c218ee1a4\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:22:29 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0004b0ab8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 26 11:22:29.804: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-8216  e7e3d173-b38c-4d28-b2fc-0f130d1a7465 24983 2 2024-04-26 11:22:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 5cb9db64-6cd5-4178-8e7d-446c218ee1a4 0xc0004b0ff7 0xc0004b0ff8}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:22:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5cb9db64-6cd5-4178-8e7d-446c218ee1a4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:22:17 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0004b1398 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 26 11:22:29.809: INFO: Pod "test-rollover-deployment-6d45fd857b-hfdvt" is available:
&Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-hfdvt test-rollover-deployment-6d45fd857b- deployment-8216  e53622a9-14b2-4748-ab13-1cd4adde49d0 24996 0 2024-04-26 11:22:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:358caac6cb4f84830dbd25bdd7eb8addc2d7e40619ebcb1f9d1d5faf60177f66 cni.projectcalico.org/podIP:100.96.1.119/32 cni.projectcalico.org/podIPs:100.96.1.119/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 4a6a9210-62c9-44ea-83f2-774cbeaaaf37 0xc0004b1ec7 0xc0004b1ec8}] [] [{kube-controller-manager Update v1 2024-04-26 11:22:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4a6a9210-62c9-44ea-83f2-774cbeaaaf37\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:22:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:22:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.119\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-84624,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-84624,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:22:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:22:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:22:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:22:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.119,StartTime:2024-04-26 11:22:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:22:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://01972639cbf20d3abf09b8bc9abc02e9bcee1a877e9f60ad20007cb12a9300d7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.119,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 26 11:22:29.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8216" for this suite. 04/26/24 11:22:29.818
{"msg":"PASSED [sig-apps] Deployment deployment should support rollover [Conformance]","completed":88,"skipped":1553,"failed":0}
------------------------------
â€¢ [SLOW TEST] [21.214 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  test/e2e/apps/deployment.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:22:08.613
    Apr 26 11:22:08.613: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename deployment 04/26/24 11:22:08.614
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:22:08.628
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:22:08.635
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support rollover [Conformance]
      test/e2e/apps/deployment.go:132
    Apr 26 11:22:08.653: INFO: Pod name rollover-pod: Found 0 pods out of 1
    Apr 26 11:22:13.659: INFO: Pod name rollover-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/26/24 11:22:13.659
    Apr 26 11:22:13.659: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
    Apr 26 11:22:15.666: INFO: Creating deployment "test-rollover-deployment"
    Apr 26 11:22:15.677: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
    Apr 26 11:22:17.695: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
    Apr 26 11:22:17.706: INFO: Ensure that both replica sets have 1 created replica
    Apr 26 11:22:17.715: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
    Apr 26 11:22:17.728: INFO: Updating deployment test-rollover-deployment
    Apr 26 11:22:17.728: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
    Apr 26 11:22:19.738: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
    Apr 26 11:22:19.755: INFO: Make sure deployment "test-rollover-deployment" is complete
    Apr 26 11:22:19.766: INFO: all replica sets need to contain the pod-template-hash label
    Apr 26 11:22:19.767: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:22:21.779: INFO: all replica sets need to contain the pod-template-hash label
    Apr 26 11:22:21.779: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:22:23.786: INFO: all replica sets need to contain the pod-template-hash label
    Apr 26 11:22:23.786: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:22:25.780: INFO: all replica sets need to contain the pod-template-hash label
    Apr 26 11:22:25.780: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:22:27.782: INFO: all replica sets need to contain the pod-template-hash label
    Apr 26 11:22:27.782: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 22, 19, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 22, 15, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-6d45fd857b\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:22:29.784: INFO: 
    Apr 26 11:22:29.784: INFO: Ensure that both old replica sets have no replicas
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 26 11:22:29.797: INFO: Deployment "test-rollover-deployment":
    &Deployment{ObjectMeta:{test-rollover-deployment  deployment-8216  5cb9db64-6cd5-4178-8e7d-446c218ee1a4 25045 2 2024-04-26 11:22:15 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2024-04-26 11:22:17 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:minReadySeconds":{},"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:22:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003f9ada8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2024-04-26 11:22:15 +0000 UTC,LastTransitionTime:2024-04-26 11:22:15 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-6d45fd857b" has successfully progressed.,LastUpdateTime:2024-04-26 11:22:29 +0000 UTC,LastTransitionTime:2024-04-26 11:22:15 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 26 11:22:29.804: INFO: New ReplicaSet "test-rollover-deployment-6d45fd857b" of Deployment "test-rollover-deployment":
    &ReplicaSet{ObjectMeta:{test-rollover-deployment-6d45fd857b  deployment-8216  4a6a9210-62c9-44ea-83f2-774cbeaaaf37 25038 2 2024-04-26 11:22:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 5cb9db64-6cd5-4178-8e7d-446c218ee1a4 0xc0004b1647 0xc0004b1648}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:22:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5cb9db64-6cd5-4178-8e7d-446c218ee1a4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:22:29 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 6d45fd857b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0004b1718 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 26 11:22:29.804: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
    Apr 26 11:22:29.804: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-8216  d4bd611e-ed50-4b82-9d38-eee07d368a54 25044 2 2024-04-26 11:22:08 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 5cb9db64-6cd5-4178-8e7d-446c218ee1a4 0xc0002f9e07 0xc0002f9e08}] [] [{e2e.test Update apps/v1 2024-04-26 11:22:08 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:22:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5cb9db64-6cd5-4178-8e7d-446c218ee1a4\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:22:29 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0004b0ab8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 26 11:22:29.804: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-59b9df946d  deployment-8216  e7e3d173-b38c-4d28-b2fc-0f130d1a7465 24983 2 2024-04-26 11:22:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 5cb9db64-6cd5-4178-8e7d-446c218ee1a4 0xc0004b0ff7 0xc0004b0ff8}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:22:17 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"5cb9db64-6cd5-4178-8e7d-446c218ee1a4\"}":{}}},"f:spec":{"f:minReadySeconds":{},"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"redis-slave\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:22:17 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 59b9df946d,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:59b9df946d] map[] [] [] []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0004b1398 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 26 11:22:29.809: INFO: Pod "test-rollover-deployment-6d45fd857b-hfdvt" is available:
    &Pod{ObjectMeta:{test-rollover-deployment-6d45fd857b-hfdvt test-rollover-deployment-6d45fd857b- deployment-8216  e53622a9-14b2-4748-ab13-1cd4adde49d0 24996 0 2024-04-26 11:22:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:6d45fd857b] map[cni.projectcalico.org/containerID:358caac6cb4f84830dbd25bdd7eb8addc2d7e40619ebcb1f9d1d5faf60177f66 cni.projectcalico.org/podIP:100.96.1.119/32 cni.projectcalico.org/podIPs:100.96.1.119/32] [{apps/v1 ReplicaSet test-rollover-deployment-6d45fd857b 4a6a9210-62c9-44ea-83f2-774cbeaaaf37 0xc0004b1ec7 0xc0004b1ec8}] [] [{kube-controller-manager Update v1 2024-04-26 11:22:17 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"4a6a9210-62c9-44ea-83f2-774cbeaaaf37\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:22:18 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:22:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.119\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-84624,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-84624,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:22:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:22:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:22:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:22:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.119,StartTime:2024-04-26 11:22:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:22:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://01972639cbf20d3abf09b8bc9abc02e9bcee1a877e9f60ad20007cb12a9300d7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.119,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 26 11:22:29.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8216" for this suite. 04/26/24 11:22:29.818
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:22:29.828
Apr 26 11:22:29.828: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename taint-multiple-pods 04/26/24 11:22:29.829
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:22:29.844
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:22:29.85
[BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/node/taints.go:348
Apr 26 11:22:29.858: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 26 11:23:29.920: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420
Apr 26 11:23:29.924: INFO: Starting informer...
STEP: Starting pods... 04/26/24 11:23:29.924
Apr 26 11:23:29.962: INFO: Pod1 is running on shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp. Tainting Node
Apr 26 11:23:29.978: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-6163" to be "running"
Apr 26 11:23:29.983: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.827754ms
Apr 26 11:23:31.989: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011097316s
Apr 26 11:23:31.989: INFO: Pod "taint-eviction-b1" satisfied condition "running"
Apr 26 11:23:31.989: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-6163" to be "running"
Apr 26 11:23:31.994: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 4.866496ms
Apr 26 11:23:31.994: INFO: Pod "taint-eviction-b2" satisfied condition "running"
Apr 26 11:23:31.994: INFO: Pod2 is running on shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp. Tainting Node
STEP: Trying to apply a taint on the Node 04/26/24 11:23:31.994
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/26/24 11:23:32.015
STEP: Waiting for Pod1 and Pod2 to be deleted 04/26/24 11:23:32.034
Apr 26 11:23:38.309: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr 26 11:23:57.645: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/26/24 11:23:57.665
[AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:23:57.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-6163" for this suite. 04/26/24 11:23:57.693
{"msg":"PASSED [sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]","completed":89,"skipped":1561,"failed":0}
------------------------------
â€¢ [SLOW TEST] [87.872 seconds]
[sig-node] NoExecuteTaintManager Multiple Pods [Serial]
test/e2e/node/framework.go:23
  evicts pods with minTolerationSeconds [Disruptive] [Conformance]
  test/e2e/node/taints.go:420

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:22:29.828
    Apr 26 11:22:29.828: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename taint-multiple-pods 04/26/24 11:22:29.829
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:22:29.844
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:22:29.85
    [BeforeEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/node/taints.go:348
    Apr 26 11:22:29.858: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 26 11:23:29.920: INFO: Waiting for terminating namespaces to be deleted...
    [It] evicts pods with minTolerationSeconds [Disruptive] [Conformance]
      test/e2e/node/taints.go:420
    Apr 26 11:23:29.924: INFO: Starting informer...
    STEP: Starting pods... 04/26/24 11:23:29.924
    Apr 26 11:23:29.962: INFO: Pod1 is running on shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp. Tainting Node
    Apr 26 11:23:29.978: INFO: Waiting up to 5m0s for pod "taint-eviction-b1" in namespace "taint-multiple-pods-6163" to be "running"
    Apr 26 11:23:29.983: INFO: Pod "taint-eviction-b1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.827754ms
    Apr 26 11:23:31.989: INFO: Pod "taint-eviction-b1": Phase="Running", Reason="", readiness=true. Elapsed: 2.011097316s
    Apr 26 11:23:31.989: INFO: Pod "taint-eviction-b1" satisfied condition "running"
    Apr 26 11:23:31.989: INFO: Waiting up to 5m0s for pod "taint-eviction-b2" in namespace "taint-multiple-pods-6163" to be "running"
    Apr 26 11:23:31.994: INFO: Pod "taint-eviction-b2": Phase="Running", Reason="", readiness=true. Elapsed: 4.866496ms
    Apr 26 11:23:31.994: INFO: Pod "taint-eviction-b2" satisfied condition "running"
    Apr 26 11:23:31.994: INFO: Pod2 is running on shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp. Tainting Node
    STEP: Trying to apply a taint on the Node 04/26/24 11:23:31.994
    STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/26/24 11:23:32.015
    STEP: Waiting for Pod1 and Pod2 to be deleted 04/26/24 11:23:32.034
    Apr 26 11:23:38.309: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
    Apr 26 11:23:57.645: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
    STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute 04/26/24 11:23:57.665
    [AfterEach] [sig-node] NoExecuteTaintManager Multiple Pods [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:23:57.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "taint-multiple-pods-6163" for this suite. 04/26/24 11:23:57.693
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:23:57.702
Apr 26 11:23:57.703: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename tables 04/26/24 11:23:57.704
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:23:57.718
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:23:57.724
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/apimachinery/table_conversion.go:49
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  test/e2e/framework/framework.go:187
Apr 26 11:23:57.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-8994" for this suite. 04/26/24 11:23:57.747
{"msg":"PASSED [sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]","completed":90,"skipped":1613,"failed":0}
------------------------------
â€¢ [0.049 seconds]
[sig-api-machinery] Servers with support for Table transformation
test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  test/e2e/apimachinery/table_conversion.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:23:57.702
    Apr 26 11:23:57.703: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename tables 04/26/24 11:23:57.704
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:23:57.718
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:23:57.724
    [BeforeEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/apimachinery/table_conversion.go:49
    [It] should return a 406 for a backend which does not implement metadata [Conformance]
      test/e2e/apimachinery/table_conversion.go:154
    [AfterEach] [sig-api-machinery] Servers with support for Table transformation
      test/e2e/framework/framework.go:187
    Apr 26 11:23:57.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "tables-8994" for this suite. 04/26/24 11:23:57.747
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:23:57.754
Apr 26 11:23:57.754: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 11:23:57.754
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:23:57.772
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:23:57.778
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523
STEP: creating a service nodeport-service with the type=NodePort in namespace services-9657 04/26/24 11:23:57.785
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/26/24 11:23:57.799
STEP: creating service externalsvc in namespace services-9657 04/26/24 11:23:57.799
STEP: creating replication controller externalsvc in namespace services-9657 04/26/24 11:23:57.816
I0426 11:23:57.821389      23 runners.go:193] Created replication controller with name: externalsvc, namespace: services-9657, replica count: 2
I0426 11:24:00.872774      23 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName 04/26/24 11:24:00.877
Apr 26 11:24:00.911: INFO: Creating new exec pod
Apr 26 11:24:00.919: INFO: Waiting up to 5m0s for pod "execpodrw7fl" in namespace "services-9657" to be "running"
Apr 26 11:24:00.926: INFO: Pod "execpodrw7fl": Phase="Pending", Reason="", readiness=false. Elapsed: 6.236802ms
Apr 26 11:24:02.935: INFO: Pod "execpodrw7fl": Phase="Running", Reason="", readiness=true. Elapsed: 2.015752831s
Apr 26 11:24:02.935: INFO: Pod "execpodrw7fl" satisfied condition "running"
Apr 26 11:24:02.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-9657 exec execpodrw7fl -- /bin/sh -x -c nslookup nodeport-service.services-9657.svc.cluster.local'
Apr 26 11:24:03.508: INFO: stderr: "+ nslookup nodeport-service.services-9657.svc.cluster.local\n"
Apr 26 11:24:03.508: INFO: stdout: "Server:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nnodeport-service.services-9657.svc.cluster.local\tcanonical name = externalsvc.services-9657.svc.cluster.local.\nName:\texternalsvc.services-9657.svc.cluster.local\nAddress: 100.66.60.202\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9657, will wait for the garbage collector to delete the pods 04/26/24 11:24:03.508
Apr 26 11:24:03.575: INFO: Deleting ReplicationController externalsvc took: 6.391151ms
Apr 26 11:24:03.676: INFO: Terminating ReplicationController externalsvc pods took: 100.513654ms
Apr 26 11:24:05.490: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 11:24:05.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9657" for this suite. 04/26/24 11:24:05.51
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]","completed":91,"skipped":1658,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.769 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  test/e2e/network/service.go:1523

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:23:57.754
    Apr 26 11:23:57.754: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 11:23:57.754
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:23:57.772
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:23:57.778
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from NodePort to ExternalName [Conformance]
      test/e2e/network/service.go:1523
    STEP: creating a service nodeport-service with the type=NodePort in namespace services-9657 04/26/24 11:23:57.785
    STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service 04/26/24 11:23:57.799
    STEP: creating service externalsvc in namespace services-9657 04/26/24 11:23:57.799
    STEP: creating replication controller externalsvc in namespace services-9657 04/26/24 11:23:57.816
    I0426 11:23:57.821389      23 runners.go:193] Created replication controller with name: externalsvc, namespace: services-9657, replica count: 2
    I0426 11:24:00.872774      23 runners.go:193] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    STEP: changing the NodePort service to type=ExternalName 04/26/24 11:24:00.877
    Apr 26 11:24:00.911: INFO: Creating new exec pod
    Apr 26 11:24:00.919: INFO: Waiting up to 5m0s for pod "execpodrw7fl" in namespace "services-9657" to be "running"
    Apr 26 11:24:00.926: INFO: Pod "execpodrw7fl": Phase="Pending", Reason="", readiness=false. Elapsed: 6.236802ms
    Apr 26 11:24:02.935: INFO: Pod "execpodrw7fl": Phase="Running", Reason="", readiness=true. Elapsed: 2.015752831s
    Apr 26 11:24:02.935: INFO: Pod "execpodrw7fl" satisfied condition "running"
    Apr 26 11:24:02.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-9657 exec execpodrw7fl -- /bin/sh -x -c nslookup nodeport-service.services-9657.svc.cluster.local'
    Apr 26 11:24:03.508: INFO: stderr: "+ nslookup nodeport-service.services-9657.svc.cluster.local\n"
    Apr 26 11:24:03.508: INFO: stdout: "Server:\t\t100.64.0.10\nAddress:\t100.64.0.10#53\n\nnodeport-service.services-9657.svc.cluster.local\tcanonical name = externalsvc.services-9657.svc.cluster.local.\nName:\texternalsvc.services-9657.svc.cluster.local\nAddress: 100.66.60.202\n\n"
    STEP: deleting ReplicationController externalsvc in namespace services-9657, will wait for the garbage collector to delete the pods 04/26/24 11:24:03.508
    Apr 26 11:24:03.575: INFO: Deleting ReplicationController externalsvc took: 6.391151ms
    Apr 26 11:24:03.676: INFO: Terminating ReplicationController externalsvc pods took: 100.513654ms
    Apr 26 11:24:05.490: INFO: Cleaning up the NodePort to ExternalName test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 11:24:05.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9657" for this suite. 04/26/24 11:24:05.51
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:24:05.524
Apr 26 11:24:05.524: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pods 04/26/24 11:24:05.524
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:24:05.542
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:24:05.548
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844
STEP: Create set of pods 04/26/24 11:24:05.554
Apr 26 11:24:05.562: INFO: created test-pod-1
Apr 26 11:24:05.573: INFO: created test-pod-2
Apr 26 11:24:05.584: INFO: created test-pod-3
STEP: waiting for all 3 pods to be running 04/26/24 11:24:05.584
Apr 26 11:24:05.584: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-5418' to be running and ready
Apr 26 11:24:05.602: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 26 11:24:05.602: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 26 11:24:05.602: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
Apr 26 11:24:05.602: INFO: 0 / 3 pods in namespace 'pods-5418' are running and ready (0 seconds elapsed)
Apr 26 11:24:05.602: INFO: expected 0 pod replicas in namespace 'pods-5418', 0 are Running and Ready.
Apr 26 11:24:05.602: INFO: POD         NODE                                                   PHASE    GRACE  CONDITIONS
Apr 26 11:24:05.602: INFO: test-pod-1  shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC  }]
Apr 26 11:24:05.602: INFO: test-pod-2  shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC  }]
Apr 26 11:24:05.602: INFO: test-pod-3  shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC  }]
Apr 26 11:24:05.602: INFO: 
Apr 26 11:24:07.619: INFO: 3 / 3 pods in namespace 'pods-5418' are running and ready (2 seconds elapsed)
Apr 26 11:24:07.619: INFO: expected 0 pod replicas in namespace 'pods-5418', 0 are Running and Ready.
STEP: waiting for all pods to be deleted 04/26/24 11:24:07.637
Apr 26 11:24:07.641: INFO: Pod quantity 3 is different from expected quantity 0
Apr 26 11:24:08.651: INFO: Pod quantity 3 is different from expected quantity 0
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 26 11:24:09.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5418" for this suite. 04/26/24 11:24:09.655
{"msg":"PASSED [sig-node] Pods should delete a collection of pods [Conformance]","completed":92,"skipped":1677,"failed":0}
------------------------------
â€¢ [4.140 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should delete a collection of pods [Conformance]
  test/e2e/common/node/pods.go:844

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:24:05.524
    Apr 26 11:24:05.524: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pods 04/26/24 11:24:05.524
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:24:05.542
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:24:05.548
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should delete a collection of pods [Conformance]
      test/e2e/common/node/pods.go:844
    STEP: Create set of pods 04/26/24 11:24:05.554
    Apr 26 11:24:05.562: INFO: created test-pod-1
    Apr 26 11:24:05.573: INFO: created test-pod-2
    Apr 26 11:24:05.584: INFO: created test-pod-3
    STEP: waiting for all 3 pods to be running 04/26/24 11:24:05.584
    Apr 26 11:24:05.584: INFO: Waiting up to 5m0s for all pods (need at least 3) in namespace 'pods-5418' to be running and ready
    Apr 26 11:24:05.602: INFO: The status of Pod test-pod-1 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 26 11:24:05.602: INFO: The status of Pod test-pod-2 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 26 11:24:05.602: INFO: The status of Pod test-pod-3 is Pending (Ready = false), waiting for it to be either Running (with Ready = true) or Failed
    Apr 26 11:24:05.602: INFO: 0 / 3 pods in namespace 'pods-5418' are running and ready (0 seconds elapsed)
    Apr 26 11:24:05.602: INFO: expected 0 pod replicas in namespace 'pods-5418', 0 are Running and Ready.
    Apr 26 11:24:05.602: INFO: POD         NODE                                                   PHASE    GRACE  CONDITIONS
    Apr 26 11:24:05.602: INFO: test-pod-1  shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC  }]
    Apr 26 11:24:05.602: INFO: test-pod-2  shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp  Pending         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC ContainersNotReady containers with unready status: [token-test]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC  }]
    Apr 26 11:24:05.602: INFO: test-pod-3  shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp  Pending         [{PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2024-04-26 11:24:05 +0000 UTC  }]
    Apr 26 11:24:05.602: INFO: 
    Apr 26 11:24:07.619: INFO: 3 / 3 pods in namespace 'pods-5418' are running and ready (2 seconds elapsed)
    Apr 26 11:24:07.619: INFO: expected 0 pod replicas in namespace 'pods-5418', 0 are Running and Ready.
    STEP: waiting for all pods to be deleted 04/26/24 11:24:07.637
    Apr 26 11:24:07.641: INFO: Pod quantity 3 is different from expected quantity 0
    Apr 26 11:24:08.651: INFO: Pod quantity 3 is different from expected quantity 0
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 26 11:24:09.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-5418" for this suite. 04/26/24 11:24:09.655
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:24:09.664
Apr 26 11:24:09.664: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:24:09.665
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:24:09.684
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:24:09.69
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214
STEP: Creating secret with name s-test-opt-del-69d12f21-efae-406a-a731-063451ce5c1f 04/26/24 11:24:09.709
STEP: Creating secret with name s-test-opt-upd-fc4d1c29-7ecc-4946-9151-639e9ce3cad0 04/26/24 11:24:09.722
STEP: Creating the pod 04/26/24 11:24:09.731
Apr 26 11:24:09.746: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9cb838ed-720a-44a4-a153-db57461dbcf0" in namespace "projected-3651" to be "running and ready"
Apr 26 11:24:09.757: INFO: Pod "pod-projected-secrets-9cb838ed-720a-44a4-a153-db57461dbcf0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.854472ms
Apr 26 11:24:09.757: INFO: The phase of Pod pod-projected-secrets-9cb838ed-720a-44a4-a153-db57461dbcf0 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:24:11.764: INFO: Pod "pod-projected-secrets-9cb838ed-720a-44a4-a153-db57461dbcf0": Phase="Running", Reason="", readiness=true. Elapsed: 2.017946564s
Apr 26 11:24:11.764: INFO: The phase of Pod pod-projected-secrets-9cb838ed-720a-44a4-a153-db57461dbcf0 is Running (Ready = true)
Apr 26 11:24:11.764: INFO: Pod "pod-projected-secrets-9cb838ed-720a-44a4-a153-db57461dbcf0" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-69d12f21-efae-406a-a731-063451ce5c1f 04/26/24 11:24:11.997
STEP: Updating secret s-test-opt-upd-fc4d1c29-7ecc-4946-9151-639e9ce3cad0 04/26/24 11:24:12.001
STEP: Creating secret with name s-test-opt-create-c1afa9c2-9ad0-42b1-a24b-f7c80650d0ea 04/26/24 11:24:12.007
STEP: waiting to observe update in volume 04/26/24 11:24:12.011
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 26 11:24:16.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3651" for this suite. 04/26/24 11:24:16.322
{"msg":"PASSED [sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":93,"skipped":1691,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.663 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:214

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:24:09.664
    Apr 26 11:24:09.664: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:24:09.665
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:24:09.684
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:24:09.69
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:214
    STEP: Creating secret with name s-test-opt-del-69d12f21-efae-406a-a731-063451ce5c1f 04/26/24 11:24:09.709
    STEP: Creating secret with name s-test-opt-upd-fc4d1c29-7ecc-4946-9151-639e9ce3cad0 04/26/24 11:24:09.722
    STEP: Creating the pod 04/26/24 11:24:09.731
    Apr 26 11:24:09.746: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9cb838ed-720a-44a4-a153-db57461dbcf0" in namespace "projected-3651" to be "running and ready"
    Apr 26 11:24:09.757: INFO: Pod "pod-projected-secrets-9cb838ed-720a-44a4-a153-db57461dbcf0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.854472ms
    Apr 26 11:24:09.757: INFO: The phase of Pod pod-projected-secrets-9cb838ed-720a-44a4-a153-db57461dbcf0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:24:11.764: INFO: Pod "pod-projected-secrets-9cb838ed-720a-44a4-a153-db57461dbcf0": Phase="Running", Reason="", readiness=true. Elapsed: 2.017946564s
    Apr 26 11:24:11.764: INFO: The phase of Pod pod-projected-secrets-9cb838ed-720a-44a4-a153-db57461dbcf0 is Running (Ready = true)
    Apr 26 11:24:11.764: INFO: Pod "pod-projected-secrets-9cb838ed-720a-44a4-a153-db57461dbcf0" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-69d12f21-efae-406a-a731-063451ce5c1f 04/26/24 11:24:11.997
    STEP: Updating secret s-test-opt-upd-fc4d1c29-7ecc-4946-9151-639e9ce3cad0 04/26/24 11:24:12.001
    STEP: Creating secret with name s-test-opt-create-c1afa9c2-9ad0-42b1-a24b-f7c80650d0ea 04/26/24 11:24:12.007
    STEP: waiting to observe update in volume 04/26/24 11:24:12.011
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 26 11:24:16.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3651" for this suite. 04/26/24 11:24:16.322
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:24:16.328
Apr 26 11:24:16.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pod-network-test 04/26/24 11:24:16.329
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:24:42.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:24:42.949
[It] should function for intra-pod communication: http [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:82
STEP: Performing setup for networking test in namespace pod-network-test-845 04/26/24 11:24:42.958
STEP: creating a selector 04/26/24 11:24:42.958
STEP: Creating the service pods in kubernetes 04/26/24 11:24:42.958
Apr 26 11:24:42.958: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 26 11:24:43.013: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-845" to be "running and ready"
Apr 26 11:24:43.018: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.66924ms
Apr 26 11:24:43.018: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:24:45.024: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.010812297s
Apr 26 11:24:45.024: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 11:24:47.024: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.011026212s
Apr 26 11:24:47.024: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 11:24:49.024: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.011362276s
Apr 26 11:24:49.025: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 11:24:51.024: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.010732728s
Apr 26 11:24:51.024: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 11:24:53.027: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.013973802s
Apr 26 11:24:53.027: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 11:24:55.025: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.012376946s
Apr 26 11:24:55.026: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 26 11:24:55.026: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 26 11:24:55.031: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-845" to be "running and ready"
Apr 26 11:24:55.037: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.70706ms
Apr 26 11:24:55.037: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 26 11:24:55.037: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 26 11:24:55.043: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-845" to be "running and ready"
Apr 26 11:24:55.047: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.779818ms
Apr 26 11:24:55.048: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 26 11:24:55.048: INFO: Pod "netserver-2" satisfied condition "running and ready"
STEP: Creating test pods 04/26/24 11:24:55.052
Apr 26 11:24:55.065: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-845" to be "running"
Apr 26 11:24:55.072: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.769812ms
Apr 26 11:24:57.079: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014526556s
Apr 26 11:24:57.079: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 26 11:24:57.086: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
Apr 26 11:24:57.086: INFO: Breadth first check of 100.96.2.51 on host 10.250.0.121...
Apr 26 11:24:57.090: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.129:9080/dial?request=hostname&protocol=http&host=100.96.2.51&port=8083&tries=1'] Namespace:pod-network-test-845 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:24:57.090: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:24:57.091: INFO: ExecWithOptions: Clientset creation
Apr 26 11:24:57.091: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-845/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.1.129%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.2.51%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 26 11:24:57.604: INFO: Waiting for responses: map[]
Apr 26 11:24:57.604: INFO: reached 100.96.2.51 after 0/1 tries
Apr 26 11:24:57.604: INFO: Breadth first check of 100.96.1.128 on host 10.250.2.248...
Apr 26 11:24:57.610: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.129:9080/dial?request=hostname&protocol=http&host=100.96.1.128&port=8083&tries=1'] Namespace:pod-network-test-845 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:24:57.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:24:57.610: INFO: ExecWithOptions: Clientset creation
Apr 26 11:24:57.611: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-845/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.1.129%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.1.128%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 26 11:24:58.150: INFO: Waiting for responses: map[]
Apr 26 11:24:58.150: INFO: reached 100.96.1.128 after 0/1 tries
Apr 26 11:24:58.150: INFO: Breadth first check of 100.96.0.54 on host 10.250.1.183...
Apr 26 11:24:58.179: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.129:9080/dial?request=hostname&protocol=http&host=100.96.0.54&port=8083&tries=1'] Namespace:pod-network-test-845 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:24:58.179: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:24:58.180: INFO: ExecWithOptions: Clientset creation
Apr 26 11:24:58.180: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-845/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.1.129%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.0.54%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
Apr 26 11:24:58.617: INFO: Waiting for responses: map[]
Apr 26 11:24:58.617: INFO: reached 100.96.0.54 after 0/1 tries
Apr 26 11:24:58.617: INFO: Going to retry 0 out of 3 pods....
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 26 11:24:58.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-845" for this suite. 04/26/24 11:24:58.626
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]","completed":94,"skipped":1692,"failed":0}
------------------------------
â€¢ [SLOW TEST] [42.305 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for intra-pod communication: http [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:24:16.328
    Apr 26 11:24:16.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pod-network-test 04/26/24 11:24:16.329
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:24:42.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:24:42.949
    [It] should function for intra-pod communication: http [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:82
    STEP: Performing setup for networking test in namespace pod-network-test-845 04/26/24 11:24:42.958
    STEP: creating a selector 04/26/24 11:24:42.958
    STEP: Creating the service pods in kubernetes 04/26/24 11:24:42.958
    Apr 26 11:24:42.958: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 26 11:24:43.013: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-845" to be "running and ready"
    Apr 26 11:24:43.018: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.66924ms
    Apr 26 11:24:43.018: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:24:45.024: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.010812297s
    Apr 26 11:24:45.024: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 11:24:47.024: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.011026212s
    Apr 26 11:24:47.024: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 11:24:49.024: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.011362276s
    Apr 26 11:24:49.025: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 11:24:51.024: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.010732728s
    Apr 26 11:24:51.024: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 11:24:53.027: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.013973802s
    Apr 26 11:24:53.027: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 11:24:55.025: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.012376946s
    Apr 26 11:24:55.026: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 26 11:24:55.026: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 26 11:24:55.031: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-845" to be "running and ready"
    Apr 26 11:24:55.037: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 5.70706ms
    Apr 26 11:24:55.037: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 26 11:24:55.037: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 26 11:24:55.043: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-845" to be "running and ready"
    Apr 26 11:24:55.047: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 4.779818ms
    Apr 26 11:24:55.048: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 26 11:24:55.048: INFO: Pod "netserver-2" satisfied condition "running and ready"
    STEP: Creating test pods 04/26/24 11:24:55.052
    Apr 26 11:24:55.065: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-845" to be "running"
    Apr 26 11:24:55.072: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.769812ms
    Apr 26 11:24:57.079: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014526556s
    Apr 26 11:24:57.079: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 26 11:24:57.086: INFO: Setting MaxTries for pod polling to 39 for networking test based on endpoint count 3
    Apr 26 11:24:57.086: INFO: Breadth first check of 100.96.2.51 on host 10.250.0.121...
    Apr 26 11:24:57.090: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.129:9080/dial?request=hostname&protocol=http&host=100.96.2.51&port=8083&tries=1'] Namespace:pod-network-test-845 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:24:57.090: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:24:57.091: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:24:57.091: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-845/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.1.129%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.2.51%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 26 11:24:57.604: INFO: Waiting for responses: map[]
    Apr 26 11:24:57.604: INFO: reached 100.96.2.51 after 0/1 tries
    Apr 26 11:24:57.604: INFO: Breadth first check of 100.96.1.128 on host 10.250.2.248...
    Apr 26 11:24:57.610: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.129:9080/dial?request=hostname&protocol=http&host=100.96.1.128&port=8083&tries=1'] Namespace:pod-network-test-845 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:24:57.610: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:24:57.610: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:24:57.611: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-845/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.1.129%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.1.128%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 26 11:24:58.150: INFO: Waiting for responses: map[]
    Apr 26 11:24:58.150: INFO: reached 100.96.1.128 after 0/1 tries
    Apr 26 11:24:58.150: INFO: Breadth first check of 100.96.0.54 on host 10.250.1.183...
    Apr 26 11:24:58.179: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.96.1.129:9080/dial?request=hostname&protocol=http&host=100.96.0.54&port=8083&tries=1'] Namespace:pod-network-test-845 PodName:test-container-pod ContainerName:webserver Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:24:58.179: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:24:58.180: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:24:58.180: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-845/pods/test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+%27http%3A%2F%2F100.96.1.129%3A9080%2Fdial%3Frequest%3Dhostname%26protocol%3Dhttp%26host%3D100.96.0.54%26port%3D8083%26tries%3D1%27&container=webserver&container=webserver&stderr=true&stdout=true)
    Apr 26 11:24:58.617: INFO: Waiting for responses: map[]
    Apr 26 11:24:58.617: INFO: reached 100.96.0.54 after 0/1 tries
    Apr 26 11:24:58.617: INFO: Going to retry 0 out of 3 pods....
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 26 11:24:58.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-845" for this suite. 04/26/24 11:24:58.626
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:24:58.634
Apr 26 11:24:58.634: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:24:58.635
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:24:58.65
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:24:58.659
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66
STEP: Creating projection with secret that has name projected-secret-test-d96fe3e2-567b-4c80-818e-cce16bcd77aa 04/26/24 11:24:58.667
STEP: Creating a pod to test consume secrets 04/26/24 11:24:58.673
Apr 26 11:24:58.683: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e" in namespace "projected-3237" to be "Succeeded or Failed"
Apr 26 11:24:58.691: INFO: Pod "pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.983105ms
Apr 26 11:25:00.700: INFO: Pod "pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01636199s
Apr 26 11:25:02.698: INFO: Pod "pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015012738s
STEP: Saw pod success 04/26/24 11:25:02.698
Apr 26 11:25:02.699: INFO: Pod "pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e" satisfied condition "Succeeded or Failed"
Apr 26 11:25:02.703: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e container projected-secret-volume-test: <nil>
STEP: delete the pod 04/26/24 11:25:02.756
Apr 26 11:25:02.767: INFO: Waiting for pod pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e to disappear
Apr 26 11:25:02.772: INFO: Pod pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 26 11:25:02.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3237" for this suite. 04/26/24 11:25:02.782
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":95,"skipped":1702,"failed":0}
------------------------------
â€¢ [4.154 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:24:58.634
    Apr 26 11:24:58.634: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:24:58.635
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:24:58.65
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:24:58.659
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:66
    STEP: Creating projection with secret that has name projected-secret-test-d96fe3e2-567b-4c80-818e-cce16bcd77aa 04/26/24 11:24:58.667
    STEP: Creating a pod to test consume secrets 04/26/24 11:24:58.673
    Apr 26 11:24:58.683: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e" in namespace "projected-3237" to be "Succeeded or Failed"
    Apr 26 11:24:58.691: INFO: Pod "pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.983105ms
    Apr 26 11:25:00.700: INFO: Pod "pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01636199s
    Apr 26 11:25:02.698: INFO: Pod "pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015012738s
    STEP: Saw pod success 04/26/24 11:25:02.698
    Apr 26 11:25:02.699: INFO: Pod "pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e" satisfied condition "Succeeded or Failed"
    Apr 26 11:25:02.703: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 11:25:02.756
    Apr 26 11:25:02.767: INFO: Waiting for pod pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e to disappear
    Apr 26 11:25:02.772: INFO: Pod pod-projected-secrets-1e377233-4677-4d5a-b5b9-48c6e9c36a3e no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 26 11:25:02.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3237" for this suite. 04/26/24 11:25:02.782
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:25:02.79
Apr 26 11:25:02.790: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 11:25:02.79
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:25:02.808
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:25:02.814
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216
STEP: creating service in namespace services-2905 04/26/24 11:25:02.821
STEP: creating service affinity-nodeport-transition in namespace services-2905 04/26/24 11:25:02.821
STEP: creating replication controller affinity-nodeport-transition in namespace services-2905 04/26/24 11:25:02.842
I0426 11:25:02.849935      23 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-2905, replica count: 3
I0426 11:25:05.902406      23 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 26 11:25:05.923: INFO: Creating new exec pod
Apr 26 11:25:05.933: INFO: Waiting up to 5m0s for pod "execpod-affinity8js75" in namespace "services-2905" to be "running"
Apr 26 11:25:05.961: INFO: Pod "execpod-affinity8js75": Phase="Pending", Reason="", readiness=false. Elapsed: 28.183356ms
Apr 26 11:25:07.968: INFO: Pod "execpod-affinity8js75": Phase="Running", Reason="", readiness=true. Elapsed: 2.035188758s
Apr 26 11:25:07.968: INFO: Pod "execpod-affinity8js75" satisfied condition "running"
Apr 26 11:25:08.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-2905 exec execpod-affinity8js75 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
Apr 26 11:25:09.535: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
Apr 26 11:25:09.535: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:25:09.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-2905 exec execpod-affinity8js75 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.66.152.134 80'
Apr 26 11:25:10.041: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.66.152.134 80\nConnection to 100.66.152.134 80 port [tcp/http] succeeded!\n"
Apr 26 11:25:10.041: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:25:10.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-2905 exec execpod-affinity8js75 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.1.183 30395'
Apr 26 11:25:10.494: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.1.183 30395\nConnection to 10.250.1.183 30395 port [tcp/*] succeeded!\n"
Apr 26 11:25:10.494: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:25:10.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-2905 exec execpod-affinity8js75 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.121 30395'
Apr 26 11:25:11.029: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.121 30395\nConnection to 10.250.0.121 30395 port [tcp/*] succeeded!\n"
Apr 26 11:25:11.029: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:25:11.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-2905 exec execpod-affinity8js75 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.121:30395/ ; done'
Apr 26 11:25:11.622: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n"
Apr 26 11:25:11.622: INFO: stdout: "\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-qzvcl\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-qzvcl\naffinity-nodeport-transition-qzvcl"
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-qzvcl
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-qzvcl
Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-qzvcl
Apr 26 11:25:11.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-2905 exec execpod-affinity8js75 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.121:30395/ ; done'
Apr 26 11:25:12.263: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n"
Apr 26 11:25:12.263: INFO: stdout: "\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb"
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
Apr 26 11:25:12.263: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-2905, will wait for the garbage collector to delete the pods 04/26/24 11:25:12.276
Apr 26 11:25:12.338: INFO: Deleting ReplicationController affinity-nodeport-transition took: 7.88952ms
Apr 26 11:25:12.440: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.927095ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 11:25:14.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2905" for this suite. 04/26/24 11:25:14.671
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]","completed":96,"skipped":1719,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.887 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:25:02.79
    Apr 26 11:25:02.790: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 11:25:02.79
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:25:02.808
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:25:02.814
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2216
    STEP: creating service in namespace services-2905 04/26/24 11:25:02.821
    STEP: creating service affinity-nodeport-transition in namespace services-2905 04/26/24 11:25:02.821
    STEP: creating replication controller affinity-nodeport-transition in namespace services-2905 04/26/24 11:25:02.842
    I0426 11:25:02.849935      23 runners.go:193] Created replication controller with name: affinity-nodeport-transition, namespace: services-2905, replica count: 3
    I0426 11:25:05.902406      23 runners.go:193] affinity-nodeport-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 26 11:25:05.923: INFO: Creating new exec pod
    Apr 26 11:25:05.933: INFO: Waiting up to 5m0s for pod "execpod-affinity8js75" in namespace "services-2905" to be "running"
    Apr 26 11:25:05.961: INFO: Pod "execpod-affinity8js75": Phase="Pending", Reason="", readiness=false. Elapsed: 28.183356ms
    Apr 26 11:25:07.968: INFO: Pod "execpod-affinity8js75": Phase="Running", Reason="", readiness=true. Elapsed: 2.035188758s
    Apr 26 11:25:07.968: INFO: Pod "execpod-affinity8js75" satisfied condition "running"
    Apr 26 11:25:08.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-2905 exec execpod-affinity8js75 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport-transition 80'
    Apr 26 11:25:09.535: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport-transition 80\nConnection to affinity-nodeport-transition 80 port [tcp/http] succeeded!\n"
    Apr 26 11:25:09.535: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:25:09.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-2905 exec execpod-affinity8js75 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.66.152.134 80'
    Apr 26 11:25:10.041: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.66.152.134 80\nConnection to 100.66.152.134 80 port [tcp/http] succeeded!\n"
    Apr 26 11:25:10.041: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:25:10.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-2905 exec execpod-affinity8js75 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.1.183 30395'
    Apr 26 11:25:10.494: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.1.183 30395\nConnection to 10.250.1.183 30395 port [tcp/*] succeeded!\n"
    Apr 26 11:25:10.494: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:25:10.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-2905 exec execpod-affinity8js75 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.121 30395'
    Apr 26 11:25:11.029: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.121 30395\nConnection to 10.250.0.121 30395 port [tcp/*] succeeded!\n"
    Apr 26 11:25:11.029: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:25:11.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-2905 exec execpod-affinity8js75 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.121:30395/ ; done'
    Apr 26 11:25:11.622: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n"
    Apr 26 11:25:11.622: INFO: stdout: "\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-qzvcl\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-bv22p\naffinity-nodeport-transition-qzvcl\naffinity-nodeport-transition-qzvcl"
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-qzvcl
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-bv22p
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-qzvcl
    Apr 26 11:25:11.622: INFO: Received response from host: affinity-nodeport-transition-qzvcl
    Apr 26 11:25:11.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-2905 exec execpod-affinity8js75 -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.121:30395/ ; done'
    Apr 26 11:25:12.263: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:30395/\n"
    Apr 26 11:25:12.263: INFO: stdout: "\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb\naffinity-nodeport-transition-s6qsb"
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Received response from host: affinity-nodeport-transition-s6qsb
    Apr 26 11:25:12.263: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport-transition in namespace services-2905, will wait for the garbage collector to delete the pods 04/26/24 11:25:12.276
    Apr 26 11:25:12.338: INFO: Deleting ReplicationController affinity-nodeport-transition took: 7.88952ms
    Apr 26 11:25:12.440: INFO: Terminating ReplicationController affinity-nodeport-transition pods took: 101.927095ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 11:25:14.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2905" for this suite. 04/26/24 11:25:14.671
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:25:14.68
Apr 26 11:25:14.680: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 11:25:14.681
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:25:14.698
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:25:14.704
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124
STEP: Creating secret with name secret-test-1ec0ca54-f63b-4c52-b927-031d693cf732 04/26/24 11:25:14.711
STEP: Creating a pod to test consume secrets 04/26/24 11:25:14.716
Apr 26 11:25:14.726: INFO: Waiting up to 5m0s for pod "pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a" in namespace "secrets-3565" to be "Succeeded or Failed"
Apr 26 11:25:14.731: INFO: Pod "pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.117772ms
Apr 26 11:25:16.742: INFO: Pod "pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0159508s
Apr 26 11:25:18.738: INFO: Pod "pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011827523s
STEP: Saw pod success 04/26/24 11:25:18.738
Apr 26 11:25:18.738: INFO: Pod "pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a" satisfied condition "Succeeded or Failed"
Apr 26 11:25:18.743: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a container secret-volume-test: <nil>
STEP: delete the pod 04/26/24 11:25:18.756
Apr 26 11:25:18.770: INFO: Waiting for pod pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a to disappear
Apr 26 11:25:18.778: INFO: Pod pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 26 11:25:18.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3565" for this suite. 04/26/24 11:25:18.787
{"msg":"PASSED [sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":97,"skipped":1726,"failed":0}
------------------------------
â€¢ [4.114 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:25:14.68
    Apr 26 11:25:14.680: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 11:25:14.681
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:25:14.698
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:25:14.704
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:124
    STEP: Creating secret with name secret-test-1ec0ca54-f63b-4c52-b927-031d693cf732 04/26/24 11:25:14.711
    STEP: Creating a pod to test consume secrets 04/26/24 11:25:14.716
    Apr 26 11:25:14.726: INFO: Waiting up to 5m0s for pod "pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a" in namespace "secrets-3565" to be "Succeeded or Failed"
    Apr 26 11:25:14.731: INFO: Pod "pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a": Phase="Pending", Reason="", readiness=false. Elapsed: 5.117772ms
    Apr 26 11:25:16.742: INFO: Pod "pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0159508s
    Apr 26 11:25:18.738: INFO: Pod "pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011827523s
    STEP: Saw pod success 04/26/24 11:25:18.738
    Apr 26 11:25:18.738: INFO: Pod "pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a" satisfied condition "Succeeded or Failed"
    Apr 26 11:25:18.743: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a container secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 11:25:18.756
    Apr 26 11:25:18.770: INFO: Waiting for pod pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a to disappear
    Apr 26 11:25:18.778: INFO: Pod pod-secrets-c2467bab-b0cd-43eb-a6fd-21589251c57a no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 11:25:18.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-3565" for this suite. 04/26/24 11:25:18.787
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-architecture] Conformance Tests
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
[BeforeEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:25:18.797
Apr 26 11:25:18.798: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename conformance-tests 04/26/24 11:25:18.799
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:25:18.814
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:25:18.82
[It] should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38
STEP: Getting node addresses 04/26/24 11:25:18.827
Apr 26 11:25:18.827: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
[AfterEach] [sig-architecture] Conformance Tests
  test/e2e/framework/framework.go:187
Apr 26 11:25:18.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "conformance-tests-6232" for this suite. 04/26/24 11:25:18.851
{"msg":"PASSED [sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]","completed":98,"skipped":1730,"failed":0}
------------------------------
â€¢ [0.062 seconds]
[sig-architecture] Conformance Tests
test/e2e/architecture/framework.go:23
  should have at least two untainted nodes [Conformance]
  test/e2e/architecture/conformance.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:25:18.797
    Apr 26 11:25:18.798: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename conformance-tests 04/26/24 11:25:18.799
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:25:18.814
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:25:18.82
    [It] should have at least two untainted nodes [Conformance]
      test/e2e/architecture/conformance.go:38
    STEP: Getting node addresses 04/26/24 11:25:18.827
    Apr 26 11:25:18.827: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    [AfterEach] [sig-architecture] Conformance Tests
      test/e2e/framework/framework.go:187
    Apr 26 11:25:18.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "conformance-tests-6232" for this suite. 04/26/24 11:25:18.851
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints
  verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:25:18.865
Apr 26 11:25:18.865: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename sched-preemption 04/26/24 11:25:18.866
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:25:18.88
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:25:18.885
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 26 11:25:18.905: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 26 11:26:18.974: INFO: Waiting for terminating namespaces to be deleted...
[BeforeEach] PriorityClass endpoints
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:26:18.978
Apr 26 11:26:18.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename sched-preemption-path 04/26/24 11:26:18.979
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:26:19.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:26:19.008
[BeforeEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:690
[It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
  test/e2e/scheduling/preemption.go:733
Apr 26 11:26:19.028: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
Apr 26 11:26:19.032: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
[AfterEach] PriorityClass endpoints
  test/e2e/framework/framework.go:187
Apr 26 11:26:19.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-path-4029" for this suite. 04/26/24 11:26:19.058
[AfterEach] PriorityClass endpoints
  test/e2e/scheduling/preemption.go:706
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:26:19.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-5866" for this suite. 04/26/24 11:26:19.076
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]","completed":99,"skipped":1782,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.269 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  PriorityClass endpoints
  test/e2e/scheduling/preemption.go:683
    verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
    test/e2e/scheduling/preemption.go:733

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:25:18.865
    Apr 26 11:25:18.865: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename sched-preemption 04/26/24 11:25:18.866
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:25:18.88
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:25:18.885
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 26 11:25:18.905: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 26 11:26:18.974: INFO: Waiting for terminating namespaces to be deleted...
    [BeforeEach] PriorityClass endpoints
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:26:18.978
    Apr 26 11:26:18.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename sched-preemption-path 04/26/24 11:26:18.979
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:26:19.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:26:19.008
    [BeforeEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:690
    [It] verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]
      test/e2e/scheduling/preemption.go:733
    Apr 26 11:26:19.028: INFO: PriorityClass.scheduling.k8s.io "p1" is invalid: value: Forbidden: may not be changed in an update.
    Apr 26 11:26:19.032: INFO: PriorityClass.scheduling.k8s.io "p2" is invalid: value: Forbidden: may not be changed in an update.
    [AfterEach] PriorityClass endpoints
      test/e2e/framework/framework.go:187
    Apr 26 11:26:19.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-path-4029" for this suite. 04/26/24 11:26:19.058
    [AfterEach] PriorityClass endpoints
      test/e2e/scheduling/preemption.go:706
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:26:19.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-5866" for this suite. 04/26/24 11:26:19.076
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
[sig-node] Probing container
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:26:19.133
Apr 26 11:26:19.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-probe 04/26/24 11:26:19.135
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:26:19.169
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:26:19.178
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148
STEP: Creating pod busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4 in namespace container-probe-8030 04/26/24 11:26:19.185
Apr 26 11:26:19.197: INFO: Waiting up to 5m0s for pod "busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4" in namespace "container-probe-8030" to be "not pending"
Apr 26 11:26:19.203: INFO: Pod "busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.202473ms
Apr 26 11:26:21.209: INFO: Pod "busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4": Phase="Running", Reason="", readiness=true. Elapsed: 2.012606096s
Apr 26 11:26:21.209: INFO: Pod "busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4" satisfied condition "not pending"
Apr 26 11:26:21.209: INFO: Started pod busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4 in namespace container-probe-8030
STEP: checking the pod's current state and verifying that restartCount is present 04/26/24 11:26:21.209
Apr 26 11:26:21.216: INFO: Initial restart count of pod busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4 is 0
STEP: deleting the pod 04/26/24 11:30:22.157
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 26 11:30:22.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8030" for this suite. 04/26/24 11:30:22.189
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]","completed":100,"skipped":1782,"failed":0}
------------------------------
â€¢ [SLOW TEST] [243.062 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:26:19.133
    Apr 26 11:26:19.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-probe 04/26/24 11:26:19.135
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:26:19.169
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:26:19.178
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:148
    STEP: Creating pod busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4 in namespace container-probe-8030 04/26/24 11:26:19.185
    Apr 26 11:26:19.197: INFO: Waiting up to 5m0s for pod "busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4" in namespace "container-probe-8030" to be "not pending"
    Apr 26 11:26:19.203: INFO: Pod "busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.202473ms
    Apr 26 11:26:21.209: INFO: Pod "busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4": Phase="Running", Reason="", readiness=true. Elapsed: 2.012606096s
    Apr 26 11:26:21.209: INFO: Pod "busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4" satisfied condition "not pending"
    Apr 26 11:26:21.209: INFO: Started pod busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4 in namespace container-probe-8030
    STEP: checking the pod's current state and verifying that restartCount is present 04/26/24 11:26:21.209
    Apr 26 11:26:21.216: INFO: Initial restart count of pod busybox-fbde71f9-f43b-4b71-84d4-e41609b9e1b4 is 0
    STEP: deleting the pod 04/26/24 11:30:22.157
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 26 11:30:22.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8030" for this suite. 04/26/24 11:30:22.189
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:30:22.196
Apr 26 11:30:22.196: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 11:30:22.197
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:22.215
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:30:22.221
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 11:30:22.245
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:30:22.379
STEP: Deploying the webhook pod 04/26/24 11:30:22.402
STEP: Wait for the deployment to be ready 04/26/24 11:30:22.471
Apr 26 11:30:22.525: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service 04/26/24 11:30:24.541
STEP: Verifying the service has paired with the endpoint 04/26/24 11:30:24.581
Apr 26 11:30:25.581: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 04/26/24 11:30:25.587
STEP: create a configmap that should be updated by the webhook 04/26/24 11:30:25.711
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:30:25.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8275" for this suite. 04/26/24 11:30:25.892
STEP: Destroying namespace "webhook-8275-markers" for this suite. 04/26/24 11:30:25.898
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]","completed":101,"skipped":1782,"failed":0}
------------------------------
â€¢ [3.746 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  test/e2e/apimachinery/webhook.go:251

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:30:22.196
    Apr 26 11:30:22.196: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 11:30:22.197
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:22.215
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:30:22.221
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 11:30:22.245
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:30:22.379
    STEP: Deploying the webhook pod 04/26/24 11:30:22.402
    STEP: Wait for the deployment to be ready 04/26/24 11:30:22.471
    Apr 26 11:30:22.525: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
    STEP: Deploying the webhook service 04/26/24 11:30:24.541
    STEP: Verifying the service has paired with the endpoint 04/26/24 11:30:24.581
    Apr 26 11:30:25.581: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate configmap [Conformance]
      test/e2e/apimachinery/webhook.go:251
    STEP: Registering the mutating configmap webhook via the AdmissionRegistration API 04/26/24 11:30:25.587
    STEP: create a configmap that should be updated by the webhook 04/26/24 11:30:25.711
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:30:25.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8275" for this suite. 04/26/24 11:30:25.892
    STEP: Destroying namespace "webhook-8275-markers" for this suite. 04/26/24 11:30:25.898
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:30:25.943
Apr 26 11:30:25.943: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 11:30:25.944
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:25.962
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:30:25.969
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96
STEP: Creating a pod to test emptydir 0644 on tmpfs 04/26/24 11:30:25.976
Apr 26 11:30:25.989: INFO: Waiting up to 5m0s for pod "pod-e7e13068-feea-4935-9f6a-48a43e700f95" in namespace "emptydir-46" to be "Succeeded or Failed"
Apr 26 11:30:25.993: INFO: Pod "pod-e7e13068-feea-4935-9f6a-48a43e700f95": Phase="Pending", Reason="", readiness=false. Elapsed: 3.893711ms
Apr 26 11:30:28.000: INFO: Pod "pod-e7e13068-feea-4935-9f6a-48a43e700f95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010753953s
Apr 26 11:30:30.003: INFO: Pod "pod-e7e13068-feea-4935-9f6a-48a43e700f95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013660227s
STEP: Saw pod success 04/26/24 11:30:30.003
Apr 26 11:30:30.003: INFO: Pod "pod-e7e13068-feea-4935-9f6a-48a43e700f95" satisfied condition "Succeeded or Failed"
Apr 26 11:30:30.008: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-e7e13068-feea-4935-9f6a-48a43e700f95 container test-container: <nil>
STEP: delete the pod 04/26/24 11:30:30.028
Apr 26 11:30:30.039: INFO: Waiting for pod pod-e7e13068-feea-4935-9f6a-48a43e700f95 to disappear
Apr 26 11:30:30.043: INFO: Pod pod-e7e13068-feea-4935-9f6a-48a43e700f95 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 11:30:30.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-46" for this suite. 04/26/24 11:30:30.051
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":102,"skipped":1786,"failed":0}
------------------------------
â€¢ [4.114 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:96

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:30:25.943
    Apr 26 11:30:25.943: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 11:30:25.944
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:25.962
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:30:25.969
    [It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:96
    STEP: Creating a pod to test emptydir 0644 on tmpfs 04/26/24 11:30:25.976
    Apr 26 11:30:25.989: INFO: Waiting up to 5m0s for pod "pod-e7e13068-feea-4935-9f6a-48a43e700f95" in namespace "emptydir-46" to be "Succeeded or Failed"
    Apr 26 11:30:25.993: INFO: Pod "pod-e7e13068-feea-4935-9f6a-48a43e700f95": Phase="Pending", Reason="", readiness=false. Elapsed: 3.893711ms
    Apr 26 11:30:28.000: INFO: Pod "pod-e7e13068-feea-4935-9f6a-48a43e700f95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010753953s
    Apr 26 11:30:30.003: INFO: Pod "pod-e7e13068-feea-4935-9f6a-48a43e700f95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013660227s
    STEP: Saw pod success 04/26/24 11:30:30.003
    Apr 26 11:30:30.003: INFO: Pod "pod-e7e13068-feea-4935-9f6a-48a43e700f95" satisfied condition "Succeeded or Failed"
    Apr 26 11:30:30.008: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-e7e13068-feea-4935-9f6a-48a43e700f95 container test-container: <nil>
    STEP: delete the pod 04/26/24 11:30:30.028
    Apr 26 11:30:30.039: INFO: Waiting for pod pod-e7e13068-feea-4935-9f6a-48a43e700f95 to disappear
    Apr 26 11:30:30.043: INFO: Pod pod-e7e13068-feea-4935-9f6a-48a43e700f95 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 11:30:30.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-46" for this suite. 04/26/24 11:30:30.051
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:30:30.061
Apr 26 11:30:30.061: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename resourcequota 04/26/24 11:30:30.062
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:30.076
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:30:30.084
[It] should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933
STEP: Creating a ResourceQuota 04/26/24 11:30:30.092
STEP: Getting a ResourceQuota 04/26/24 11:30:30.098
STEP: Listing all ResourceQuotas with LabelSelector 04/26/24 11:30:30.106
STEP: Patching the ResourceQuota 04/26/24 11:30:30.111
STEP: Deleting a Collection of ResourceQuotas 04/26/24 11:30:30.119
STEP: Verifying the deleted ResourceQuota 04/26/24 11:30:30.126
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 26 11:30:30.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3878" for this suite. 04/26/24 11:30:30.136
{"msg":"PASSED [sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]","completed":103,"skipped":1818,"failed":0}
------------------------------
â€¢ [0.081 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should manage the lifecycle of a ResourceQuota [Conformance]
  test/e2e/apimachinery/resource_quota.go:933

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:30:30.061
    Apr 26 11:30:30.061: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename resourcequota 04/26/24 11:30:30.062
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:30.076
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:30:30.084
    [It] should manage the lifecycle of a ResourceQuota [Conformance]
      test/e2e/apimachinery/resource_quota.go:933
    STEP: Creating a ResourceQuota 04/26/24 11:30:30.092
    STEP: Getting a ResourceQuota 04/26/24 11:30:30.098
    STEP: Listing all ResourceQuotas with LabelSelector 04/26/24 11:30:30.106
    STEP: Patching the ResourceQuota 04/26/24 11:30:30.111
    STEP: Deleting a Collection of ResourceQuotas 04/26/24 11:30:30.119
    STEP: Verifying the deleted ResourceQuota 04/26/24 11:30:30.126
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 26 11:30:30.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-3878" for this suite. 04/26/24 11:30:30.136
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:30:30.144
Apr 26 11:30:30.144: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename runtimeclass 04/26/24 11:30:30.145
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:30.162
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:30:30.168
[It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129
Apr 26 11:30:30.192: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7599 to be scheduled
Apr 26 11:30:30.198: INFO: 1 pods are not scheduled: [runtimeclass-7599/test-runtimeclass-runtimeclass-7599-preconfigured-handler-msx9x(2d662940-a79a-4082-a91a-df2108d74468)]
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 26 11:30:32.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7599" for this suite. 04/26/24 11:30:32.22
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]","completed":104,"skipped":1823,"failed":0}
------------------------------
â€¢ [2.082 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:30:30.144
    Apr 26 11:30:30.144: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename runtimeclass 04/26/24 11:30:30.145
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:30.162
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:30:30.168
    [It] should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:129
    Apr 26 11:30:30.192: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7599 to be scheduled
    Apr 26 11:30:30.198: INFO: 1 pods are not scheduled: [runtimeclass-7599/test-runtimeclass-runtimeclass-7599-preconfigured-handler-msx9x(2d662940-a79a-4082-a91a-df2108d74468)]
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 26 11:30:32.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-7599" for this suite. 04/26/24 11:30:32.22
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:30:32.228
Apr 26 11:30:32.229: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename namespaces 04/26/24 11:30:32.23
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:32.284
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:30:32.292
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242
STEP: Creating a test namespace 04/26/24 11:30:32.298
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:32.338
STEP: Creating a pod in the namespace 04/26/24 11:30:32.346
STEP: Waiting for the pod to have running status 04/26/24 11:30:32.354
Apr 26 11:30:32.354: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-5051" to be "running"
Apr 26 11:30:32.394: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 39.675858ms
Apr 26 11:30:34.401: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.046766695s
Apr 26 11:30:34.401: INFO: Pod "test-pod" satisfied condition "running"
STEP: Deleting the namespace 04/26/24 11:30:34.401
STEP: Waiting for the namespace to be removed. 04/26/24 11:30:34.408
STEP: Recreating the namespace 04/26/24 11:30:45.413
STEP: Verifying there are no pods in the namespace 04/26/24 11:30:45.427
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:30:45.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7315" for this suite. 04/26/24 11:30:45.438
STEP: Destroying namespace "nsdeletetest-5051" for this suite. 04/26/24 11:30:45.444
Apr 26 11:30:45.449: INFO: Namespace nsdeletetest-5051 was already deleted
STEP: Destroying namespace "nsdeletetest-2019" for this suite. 04/26/24 11:30:45.449
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]","completed":105,"skipped":1833,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.230 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  test/e2e/apimachinery/namespace.go:242

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:30:32.228
    Apr 26 11:30:32.229: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename namespaces 04/26/24 11:30:32.23
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:32.284
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:30:32.292
    [It] should ensure that all pods are removed when a namespace is deleted [Conformance]
      test/e2e/apimachinery/namespace.go:242
    STEP: Creating a test namespace 04/26/24 11:30:32.298
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:32.338
    STEP: Creating a pod in the namespace 04/26/24 11:30:32.346
    STEP: Waiting for the pod to have running status 04/26/24 11:30:32.354
    Apr 26 11:30:32.354: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "nsdeletetest-5051" to be "running"
    Apr 26 11:30:32.394: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 39.675858ms
    Apr 26 11:30:34.401: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.046766695s
    Apr 26 11:30:34.401: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Deleting the namespace 04/26/24 11:30:34.401
    STEP: Waiting for the namespace to be removed. 04/26/24 11:30:34.408
    STEP: Recreating the namespace 04/26/24 11:30:45.413
    STEP: Verifying there are no pods in the namespace 04/26/24 11:30:45.427
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:30:45.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-7315" for this suite. 04/26/24 11:30:45.438
    STEP: Destroying namespace "nsdeletetest-5051" for this suite. 04/26/24 11:30:45.444
    Apr 26 11:30:45.449: INFO: Namespace nsdeletetest-5051 was already deleted
    STEP: Destroying namespace "nsdeletetest-2019" for this suite. 04/26/24 11:30:45.449
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:30:45.459
Apr 26 11:30:45.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename statefulset 04/26/24 11:30:45.461
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:45.509
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:30:45.547
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4592 04/26/24 11:30:45.574
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  test/e2e/apps/statefulset.go:315
STEP: Creating a new StatefulSet 04/26/24 11:30:45.581
Apr 26 11:30:45.602: INFO: Found 0 stateful pods, waiting for 3
Apr 26 11:30:55.611: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 26 11:30:55.611: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 26 11:30:55.611: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/26/24 11:30:55.628
Apr 26 11:30:55.648: INFO: Updating stateful set ss2
STEP: Creating a new revision 04/26/24 11:30:55.648
STEP: Not applying an update when the partition is greater than the number of replicas 04/26/24 11:31:05.681
STEP: Performing a canary update 04/26/24 11:31:05.681
Apr 26 11:31:05.703: INFO: Updating stateful set ss2
Apr 26 11:31:05.716: INFO: Waiting for Pod statefulset-4592/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
STEP: Restoring Pods to the correct revision when they are deleted 04/26/24 11:31:15.731
Apr 26 11:31:15.766: INFO: Found 1 stateful pods, waiting for 3
Apr 26 11:31:25.778: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 26 11:31:25.778: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 26 11:31:25.778: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update 04/26/24 11:31:25.789
Apr 26 11:31:25.821: INFO: Updating stateful set ss2
Apr 26 11:31:25.834: INFO: Waiting for Pod statefulset-4592/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
Apr 26 11:31:35.875: INFO: Updating stateful set ss2
Apr 26 11:31:35.892: INFO: Waiting for StatefulSet statefulset-4592/ss2 to complete update
Apr 26 11:31:35.892: INFO: Waiting for Pod statefulset-4592/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 26 11:31:45.946: INFO: Deleting all statefulset in ns statefulset-4592
Apr 26 11:31:45.953: INFO: Scaling statefulset ss2 to 0
Apr 26 11:31:55.978: INFO: Waiting for statefulset status.replicas updated to 0
Apr 26 11:31:55.984: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 26 11:31:56.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4592" for this suite. 04/26/24 11:31:56.007
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]","completed":106,"skipped":1844,"failed":0}
------------------------------
â€¢ [SLOW TEST] [70.555 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    test/e2e/apps/statefulset.go:315

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:30:45.459
    Apr 26 11:30:45.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename statefulset 04/26/24 11:30:45.461
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:30:45.509
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:30:45.547
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4592 04/26/24 11:30:45.574
    [It] should perform canary updates and phased rolling updates of template modifications [Conformance]
      test/e2e/apps/statefulset.go:315
    STEP: Creating a new StatefulSet 04/26/24 11:30:45.581
    Apr 26 11:30:45.602: INFO: Found 0 stateful pods, waiting for 3
    Apr 26 11:30:55.611: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 26 11:30:55.611: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 26 11:30:55.611: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Updating stateful set template: update image from registry.k8s.io/e2e-test-images/httpd:2.4.38-2 to registry.k8s.io/e2e-test-images/httpd:2.4.39-2 04/26/24 11:30:55.628
    Apr 26 11:30:55.648: INFO: Updating stateful set ss2
    STEP: Creating a new revision 04/26/24 11:30:55.648
    STEP: Not applying an update when the partition is greater than the number of replicas 04/26/24 11:31:05.681
    STEP: Performing a canary update 04/26/24 11:31:05.681
    Apr 26 11:31:05.703: INFO: Updating stateful set ss2
    Apr 26 11:31:05.716: INFO: Waiting for Pod statefulset-4592/ss2-2 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    STEP: Restoring Pods to the correct revision when they are deleted 04/26/24 11:31:15.731
    Apr 26 11:31:15.766: INFO: Found 1 stateful pods, waiting for 3
    Apr 26 11:31:25.778: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 26 11:31:25.778: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 26 11:31:25.778: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Performing a phased rolling update 04/26/24 11:31:25.789
    Apr 26 11:31:25.821: INFO: Updating stateful set ss2
    Apr 26 11:31:25.834: INFO: Waiting for Pod statefulset-4592/ss2-1 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    Apr 26 11:31:35.875: INFO: Updating stateful set ss2
    Apr 26 11:31:35.892: INFO: Waiting for StatefulSet statefulset-4592/ss2 to complete update
    Apr 26 11:31:35.892: INFO: Waiting for Pod statefulset-4592/ss2-0 to have revision ss2-5d8c6ff87d update revision ss2-6557876d87
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 26 11:31:45.946: INFO: Deleting all statefulset in ns statefulset-4592
    Apr 26 11:31:45.953: INFO: Scaling statefulset ss2 to 0
    Apr 26 11:31:55.978: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 26 11:31:55.984: INFO: Deleting statefulset ss2
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 26 11:31:56.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4592" for this suite. 04/26/24 11:31:56.007
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:31:56.015
Apr 26 11:31:56.016: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename resourcequota 04/26/24 11:31:56.017
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:31:56.034
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:31:56.041
[It] should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793
STEP: Creating a ResourceQuota with best effort scope 04/26/24 11:31:56.055
STEP: Ensuring ResourceQuota status is calculated 04/26/24 11:31:56.06
STEP: Creating a ResourceQuota with not best effort scope 04/26/24 11:31:58.066
STEP: Ensuring ResourceQuota status is calculated 04/26/24 11:31:58.071
STEP: Creating a best-effort pod 04/26/24 11:32:00.077
STEP: Ensuring resource quota with best effort scope captures the pod usage 04/26/24 11:32:00.092
STEP: Ensuring resource quota with not best effort ignored the pod usage 04/26/24 11:32:02.098
STEP: Deleting the pod 04/26/24 11:32:04.105
STEP: Ensuring resource quota status released the pod usage 04/26/24 11:32:04.118
STEP: Creating a not best-effort pod 04/26/24 11:32:06.14
STEP: Ensuring resource quota with not best effort scope captures the pod usage 04/26/24 11:32:06.183
STEP: Ensuring resource quota with best effort scope ignored the pod usage 04/26/24 11:32:08.189
STEP: Deleting the pod 04/26/24 11:32:10.197
STEP: Ensuring resource quota status released the pod usage 04/26/24 11:32:10.208
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 26 11:32:12.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5160" for this suite. 04/26/24 11:32:12.224
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]","completed":107,"skipped":1849,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.215 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  test/e2e/apimachinery/resource_quota.go:793

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:31:56.015
    Apr 26 11:31:56.016: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename resourcequota 04/26/24 11:31:56.017
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:31:56.034
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:31:56.041
    [It] should verify ResourceQuota with best effort scope. [Conformance]
      test/e2e/apimachinery/resource_quota.go:793
    STEP: Creating a ResourceQuota with best effort scope 04/26/24 11:31:56.055
    STEP: Ensuring ResourceQuota status is calculated 04/26/24 11:31:56.06
    STEP: Creating a ResourceQuota with not best effort scope 04/26/24 11:31:58.066
    STEP: Ensuring ResourceQuota status is calculated 04/26/24 11:31:58.071
    STEP: Creating a best-effort pod 04/26/24 11:32:00.077
    STEP: Ensuring resource quota with best effort scope captures the pod usage 04/26/24 11:32:00.092
    STEP: Ensuring resource quota with not best effort ignored the pod usage 04/26/24 11:32:02.098
    STEP: Deleting the pod 04/26/24 11:32:04.105
    STEP: Ensuring resource quota status released the pod usage 04/26/24 11:32:04.118
    STEP: Creating a not best-effort pod 04/26/24 11:32:06.14
    STEP: Ensuring resource quota with not best effort scope captures the pod usage 04/26/24 11:32:06.183
    STEP: Ensuring resource quota with best effort scope ignored the pod usage 04/26/24 11:32:08.189
    STEP: Deleting the pod 04/26/24 11:32:10.197
    STEP: Ensuring resource quota status released the pod usage 04/26/24 11:32:10.208
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 26 11:32:12.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-5160" for this suite. 04/26/24 11:32:12.224
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:32:12.231
Apr 26 11:32:12.231: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:32:12.232
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:32:12.253
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:32:12.263
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118
STEP: Creating secret with name projected-secret-test-d27fd6d5-4e78-444e-92be-b71dced0b1ca 04/26/24 11:32:12.271
STEP: Creating a pod to test consume secrets 04/26/24 11:32:12.275
Apr 26 11:32:12.308: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93" in namespace "projected-2552" to be "Succeeded or Failed"
Apr 26 11:32:12.315: INFO: Pod "pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93": Phase="Pending", Reason="", readiness=false. Elapsed: 7.351662ms
Apr 26 11:32:14.331: INFO: Pod "pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022999899s
Apr 26 11:32:16.326: INFO: Pod "pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017697871s
STEP: Saw pod success 04/26/24 11:32:16.326
Apr 26 11:32:16.326: INFO: Pod "pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93" satisfied condition "Succeeded or Failed"
Apr 26 11:32:16.331: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93 container secret-volume-test: <nil>
STEP: delete the pod 04/26/24 11:32:16.359
Apr 26 11:32:16.374: INFO: Waiting for pod pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93 to disappear
Apr 26 11:32:16.380: INFO: Pod pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 26 11:32:16.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2552" for this suite. 04/26/24 11:32:16.387
{"msg":"PASSED [sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]","completed":108,"skipped":1865,"failed":0}
------------------------------
â€¢ [4.162 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:118

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:32:12.231
    Apr 26 11:32:12.231: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:32:12.232
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:32:12.253
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:32:12.263
    [It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:118
    STEP: Creating secret with name projected-secret-test-d27fd6d5-4e78-444e-92be-b71dced0b1ca 04/26/24 11:32:12.271
    STEP: Creating a pod to test consume secrets 04/26/24 11:32:12.275
    Apr 26 11:32:12.308: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93" in namespace "projected-2552" to be "Succeeded or Failed"
    Apr 26 11:32:12.315: INFO: Pod "pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93": Phase="Pending", Reason="", readiness=false. Elapsed: 7.351662ms
    Apr 26 11:32:14.331: INFO: Pod "pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022999899s
    Apr 26 11:32:16.326: INFO: Pod "pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017697871s
    STEP: Saw pod success 04/26/24 11:32:16.326
    Apr 26 11:32:16.326: INFO: Pod "pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93" satisfied condition "Succeeded or Failed"
    Apr 26 11:32:16.331: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93 container secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 11:32:16.359
    Apr 26 11:32:16.374: INFO: Waiting for pod pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93 to disappear
    Apr 26 11:32:16.380: INFO: Pod pod-projected-secrets-7313cb18-0e22-4bc4-a802-8e1989365d93 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 26 11:32:16.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2552" for this suite. 04/26/24 11:32:16.387
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:32:16.397
Apr 26 11:32:16.397: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 11:32:16.398
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:32:16.417
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:32:16.424
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86
STEP: Creating a pod to test emptydir volume type on tmpfs 04/26/24 11:32:16.432
Apr 26 11:32:16.442: INFO: Waiting up to 5m0s for pod "pod-61c5df71-5994-48db-a647-235e0906ed5b" in namespace "emptydir-4838" to be "Succeeded or Failed"
Apr 26 11:32:16.447: INFO: Pod "pod-61c5df71-5994-48db-a647-235e0906ed5b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.312942ms
Apr 26 11:32:18.454: INFO: Pod "pod-61c5df71-5994-48db-a647-235e0906ed5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0116011s
Apr 26 11:32:20.454: INFO: Pod "pod-61c5df71-5994-48db-a647-235e0906ed5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012267115s
STEP: Saw pod success 04/26/24 11:32:20.455
Apr 26 11:32:20.455: INFO: Pod "pod-61c5df71-5994-48db-a647-235e0906ed5b" satisfied condition "Succeeded or Failed"
Apr 26 11:32:20.460: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-61c5df71-5994-48db-a647-235e0906ed5b container test-container: <nil>
STEP: delete the pod 04/26/24 11:32:20.475
Apr 26 11:32:20.485: INFO: Waiting for pod pod-61c5df71-5994-48db-a647-235e0906ed5b to disappear
Apr 26 11:32:20.491: INFO: Pod pod-61c5df71-5994-48db-a647-235e0906ed5b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 11:32:20.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4838" for this suite. 04/26/24 11:32:20.5
{"msg":"PASSED [sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]","completed":109,"skipped":1912,"failed":0}
------------------------------
â€¢ [4.109 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:32:16.397
    Apr 26 11:32:16.397: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 11:32:16.398
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:32:16.417
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:32:16.424
    [It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:86
    STEP: Creating a pod to test emptydir volume type on tmpfs 04/26/24 11:32:16.432
    Apr 26 11:32:16.442: INFO: Waiting up to 5m0s for pod "pod-61c5df71-5994-48db-a647-235e0906ed5b" in namespace "emptydir-4838" to be "Succeeded or Failed"
    Apr 26 11:32:16.447: INFO: Pod "pod-61c5df71-5994-48db-a647-235e0906ed5b": Phase="Pending", Reason="", readiness=false. Elapsed: 5.312942ms
    Apr 26 11:32:18.454: INFO: Pod "pod-61c5df71-5994-48db-a647-235e0906ed5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0116011s
    Apr 26 11:32:20.454: INFO: Pod "pod-61c5df71-5994-48db-a647-235e0906ed5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012267115s
    STEP: Saw pod success 04/26/24 11:32:20.455
    Apr 26 11:32:20.455: INFO: Pod "pod-61c5df71-5994-48db-a647-235e0906ed5b" satisfied condition "Succeeded or Failed"
    Apr 26 11:32:20.460: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-61c5df71-5994-48db-a647-235e0906ed5b container test-container: <nil>
    STEP: delete the pod 04/26/24 11:32:20.475
    Apr 26 11:32:20.485: INFO: Waiting for pod pod-61c5df71-5994-48db-a647-235e0906ed5b to disappear
    Apr 26 11:32:20.491: INFO: Pod pod-61c5df71-5994-48db-a647-235e0906ed5b no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 11:32:20.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-4838" for this suite. 04/26/24 11:32:20.5
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:32:20.507
Apr 26 11:32:20.507: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename statefulset 04/26/24 11:32:20.508
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:32:20.526
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:32:20.534
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1810 04/26/24 11:32:20.541
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  test/e2e/apps/statefulset.go:585
STEP: Initializing watcher for selector baz=blah,foo=bar 04/26/24 11:32:20.55
STEP: Creating stateful set ss in namespace statefulset-1810 04/26/24 11:32:20.557
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1810 04/26/24 11:32:20.563
Apr 26 11:32:20.566: INFO: Found 0 stateful pods, waiting for 1
Apr 26 11:32:30.573: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 04/26/24 11:32:30.573
Apr 26 11:32:30.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 26 11:32:31.077: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 26 11:32:31.077: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 26 11:32:31.077: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 26 11:32:31.084: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 26 11:32:41.093: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 26 11:32:41.093: INFO: Waiting for statefulset status.replicas updated to 0
Apr 26 11:32:41.121: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999974s
Apr 26 11:32:42.127: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.9890042s
Apr 26 11:32:43.135: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.981943663s
Apr 26 11:32:44.144: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.974829753s
Apr 26 11:32:45.150: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.966562635s
Apr 26 11:32:46.156: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.960511274s
Apr 26 11:32:47.162: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.953703261s
Apr 26 11:32:48.168: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.947116084s
Apr 26 11:32:49.174: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.941772911s
Apr 26 11:32:50.180: INFO: Verifying statefulset ss doesn't scale past 1 for another 936.308107ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1810 04/26/24 11:32:51.18
Apr 26 11:32:51.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 26 11:32:51.689: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 26 11:32:51.689: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 26 11:32:51.689: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 26 11:32:51.695: INFO: Found 1 stateful pods, waiting for 3
Apr 26 11:33:01.704: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 26 11:33:01.704: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 26 11:33:01.704: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order 04/26/24 11:33:01.704
STEP: Scale down will halt with unhealthy stateful pod 04/26/24 11:33:01.704
Apr 26 11:33:01.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 26 11:33:02.231: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 26 11:33:02.231: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 26 11:33:02.231: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 26 11:33:02.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 26 11:33:02.758: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 26 11:33:02.758: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 26 11:33:02.758: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 26 11:33:02.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 26 11:33:03.297: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 26 11:33:03.297: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 26 11:33:03.297: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 26 11:33:03.297: INFO: Waiting for statefulset status.replicas updated to 0
Apr 26 11:33:03.302: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Apr 26 11:33:13.313: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 26 11:33:13.313: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 26 11:33:13.313: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 26 11:33:13.334: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999789s
Apr 26 11:33:14.343: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99078103s
Apr 26 11:33:15.349: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982103085s
Apr 26 11:33:16.363: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.975915331s
Apr 26 11:33:17.370: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.961467972s
Apr 26 11:33:18.378: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.954064943s
Apr 26 11:33:19.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.946381009s
Apr 26 11:33:20.391: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.94008372s
Apr 26 11:33:21.399: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.933662165s
Apr 26 11:33:22.408: INFO: Verifying statefulset ss doesn't scale past 3 for another 925.678397ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1810 04/26/24 11:33:23.408
Apr 26 11:33:23.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 26 11:33:23.998: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 26 11:33:23.998: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 26 11:33:23.998: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 26 11:33:23.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 26 11:33:24.531: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 26 11:33:24.531: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 26 11:33:24.531: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 26 11:33:24.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 26 11:33:25.042: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 26 11:33:25.042: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 26 11:33:25.042: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 26 11:33:25.042: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order 04/26/24 11:33:35.068
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 26 11:33:35.068: INFO: Deleting all statefulset in ns statefulset-1810
Apr 26 11:33:35.075: INFO: Scaling statefulset ss to 0
Apr 26 11:33:35.092: INFO: Waiting for statefulset status.replicas updated to 0
Apr 26 11:33:35.095: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 26 11:33:35.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1810" for this suite. 04/26/24 11:33:35.12
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]","completed":110,"skipped":1927,"failed":0}
------------------------------
â€¢ [SLOW TEST] [74.618 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    test/e2e/apps/statefulset.go:585

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:32:20.507
    Apr 26 11:32:20.507: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename statefulset 04/26/24 11:32:20.508
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:32:20.526
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:32:20.534
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1810 04/26/24 11:32:20.541
    [It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
      test/e2e/apps/statefulset.go:585
    STEP: Initializing watcher for selector baz=blah,foo=bar 04/26/24 11:32:20.55
    STEP: Creating stateful set ss in namespace statefulset-1810 04/26/24 11:32:20.557
    STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1810 04/26/24 11:32:20.563
    Apr 26 11:32:20.566: INFO: Found 0 stateful pods, waiting for 1
    Apr 26 11:32:30.573: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod 04/26/24 11:32:30.573
    Apr 26 11:32:30.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 26 11:32:31.077: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 26 11:32:31.077: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 26 11:32:31.077: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 26 11:32:31.084: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
    Apr 26 11:32:41.093: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 26 11:32:41.093: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 26 11:32:41.121: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.99999974s
    Apr 26 11:32:42.127: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.9890042s
    Apr 26 11:32:43.135: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.981943663s
    Apr 26 11:32:44.144: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.974829753s
    Apr 26 11:32:45.150: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.966562635s
    Apr 26 11:32:46.156: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.960511274s
    Apr 26 11:32:47.162: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.953703261s
    Apr 26 11:32:48.168: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.947116084s
    Apr 26 11:32:49.174: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.941772911s
    Apr 26 11:32:50.180: INFO: Verifying statefulset ss doesn't scale past 1 for another 936.308107ms
    STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1810 04/26/24 11:32:51.18
    Apr 26 11:32:51.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 26 11:32:51.689: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 26 11:32:51.689: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 26 11:32:51.689: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 26 11:32:51.695: INFO: Found 1 stateful pods, waiting for 3
    Apr 26 11:33:01.704: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 26 11:33:01.704: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
    Apr 26 11:33:01.704: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Verifying that stateful set ss was scaled up in order 04/26/24 11:33:01.704
    STEP: Scale down will halt with unhealthy stateful pod 04/26/24 11:33:01.704
    Apr 26 11:33:01.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 26 11:33:02.231: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 26 11:33:02.231: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 26 11:33:02.231: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 26 11:33:02.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 26 11:33:02.758: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 26 11:33:02.758: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 26 11:33:02.758: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 26 11:33:02.758: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
    Apr 26 11:33:03.297: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
    Apr 26 11:33:03.297: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
    Apr 26 11:33:03.297: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

    Apr 26 11:33:03.297: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 26 11:33:03.302: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
    Apr 26 11:33:13.313: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
    Apr 26 11:33:13.313: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
    Apr 26 11:33:13.313: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
    Apr 26 11:33:13.334: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999789s
    Apr 26 11:33:14.343: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99078103s
    Apr 26 11:33:15.349: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982103085s
    Apr 26 11:33:16.363: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.975915331s
    Apr 26 11:33:17.370: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.961467972s
    Apr 26 11:33:18.378: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.954064943s
    Apr 26 11:33:19.385: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.946381009s
    Apr 26 11:33:20.391: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.94008372s
    Apr 26 11:33:21.399: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.933662165s
    Apr 26 11:33:22.408: INFO: Verifying statefulset ss doesn't scale past 3 for another 925.678397ms
    STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1810 04/26/24 11:33:23.408
    Apr 26 11:33:23.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 26 11:33:23.998: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 26 11:33:23.998: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 26 11:33:23.998: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 26 11:33:23.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 26 11:33:24.531: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 26 11:33:24.531: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 26 11:33:24.531: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 26 11:33:24.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=statefulset-1810 exec ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
    Apr 26 11:33:25.042: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
    Apr 26 11:33:25.042: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
    Apr 26 11:33:25.042: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

    Apr 26 11:33:25.042: INFO: Scaling statefulset ss to 0
    STEP: Verifying that stateful set ss was scaled down in reverse order 04/26/24 11:33:35.068
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 26 11:33:35.068: INFO: Deleting all statefulset in ns statefulset-1810
    Apr 26 11:33:35.075: INFO: Scaling statefulset ss to 0
    Apr 26 11:33:35.092: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 26 11:33:35.095: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 26 11:33:35.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1810" for this suite. 04/26/24 11:33:35.12
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server
  should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:33:35.13
Apr 26 11:33:35.130: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 11:33:35.131
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:33:35.144
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:33:35.151
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should support --unix-socket=/path  [Conformance]
  test/e2e/kubectl/kubectl.go:1810
STEP: Starting the proxy 04/26/24 11:33:35.159
Apr 26 11:33:35.159: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2663 proxy --unix-socket=/tmp/kubectl-proxy-unix3092730994/test'
STEP: retrieving proxy /api/ output 04/26/24 11:33:35.2
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 11:33:35.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2663" for this suite. 04/26/24 11:33:35.211
{"msg":"PASSED [sig-cli] Kubectl client Proxy server should support --unix-socket=/path  [Conformance]","completed":111,"skipped":1944,"failed":0}
------------------------------
â€¢ [0.088 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Proxy server
  test/e2e/kubectl/kubectl.go:1778
    should support --unix-socket=/path  [Conformance]
    test/e2e/kubectl/kubectl.go:1810

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:33:35.13
    Apr 26 11:33:35.130: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 11:33:35.131
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:33:35.144
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:33:35.151
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should support --unix-socket=/path  [Conformance]
      test/e2e/kubectl/kubectl.go:1810
    STEP: Starting the proxy 04/26/24 11:33:35.159
    Apr 26 11:33:35.159: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2663 proxy --unix-socket=/tmp/kubectl-proxy-unix3092730994/test'
    STEP: retrieving proxy /api/ output 04/26/24 11:33:35.2
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 11:33:35.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2663" for this suite. 04/26/24 11:33:35.211
  << End Captured GinkgoWriter Output
------------------------------
[sig-network] Services
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:33:35.218
Apr 26 11:33:35.219: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 11:33:35.22
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:33:35.237
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:33:35.243
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620
STEP: creating a collection of services 04/26/24 11:33:35.252
Apr 26 11:33:35.252: INFO: Creating e2e-svc-a-s229n
Apr 26 11:33:35.263: INFO: Creating e2e-svc-b-ndcw5
Apr 26 11:33:35.277: INFO: Creating e2e-svc-c-rzn6p
STEP: deleting service collection 04/26/24 11:33:35.292
Apr 26 11:33:35.317: INFO: Collection of services has been deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 11:33:35.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2834" for this suite. 04/26/24 11:33:35.325
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should delete a collection of services [Conformance]","completed":112,"skipped":1944,"failed":0}
------------------------------
â€¢ [0.116 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should delete a collection of services [Conformance]
  test/e2e/network/service.go:3620

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:33:35.218
    Apr 26 11:33:35.219: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 11:33:35.22
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:33:35.237
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:33:35.243
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should delete a collection of services [Conformance]
      test/e2e/network/service.go:3620
    STEP: creating a collection of services 04/26/24 11:33:35.252
    Apr 26 11:33:35.252: INFO: Creating e2e-svc-a-s229n
    Apr 26 11:33:35.263: INFO: Creating e2e-svc-b-ndcw5
    Apr 26 11:33:35.277: INFO: Creating e2e-svc-c-rzn6p
    STEP: deleting service collection 04/26/24 11:33:35.292
    Apr 26 11:33:35.317: INFO: Collection of services has been deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 11:33:35.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-2834" for this suite. 04/26/24 11:33:35.325
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Services
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:33:35.335
Apr 26 11:33:35.335: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 11:33:35.336
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:33:35.351
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:33:35.358
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179
STEP: creating service in namespace services-1935 04/26/24 11:33:35.4
STEP: creating service affinity-clusterip-transition in namespace services-1935 04/26/24 11:33:35.4
STEP: creating replication controller affinity-clusterip-transition in namespace services-1935 04/26/24 11:33:35.416
I0426 11:33:35.422064      23 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-1935, replica count: 3
I0426 11:33:38.472843      23 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 26 11:33:38.481: INFO: Creating new exec pod
Apr 26 11:33:38.492: INFO: Waiting up to 5m0s for pod "execpod-affinityhvl6l" in namespace "services-1935" to be "running"
Apr 26 11:33:38.500: INFO: Pod "execpod-affinityhvl6l": Phase="Pending", Reason="", readiness=false. Elapsed: 8.380752ms
Apr 26 11:33:40.506: INFO: Pod "execpod-affinityhvl6l": Phase="Running", Reason="", readiness=true. Elapsed: 2.014084867s
Apr 26 11:33:40.506: INFO: Pod "execpod-affinityhvl6l" satisfied condition "running"
Apr 26 11:33:41.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1935 exec execpod-affinityhvl6l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
Apr 26 11:33:41.972: INFO: stderr: "+ nc -v+  -t -w 2echo affinity-clusterip-transition hostName 80\n\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
Apr 26 11:33:41.972: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:33:41.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1935 exec execpod-affinityhvl6l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.64.21.248 80'
Apr 26 11:33:42.539: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.64.21.248 80\nConnection to 100.64.21.248 80 port [tcp/http] succeeded!\n"
Apr 26 11:33:42.539: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:33:42.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1935 exec execpod-affinityhvl6l -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.64.21.248:80/ ; done'
Apr 26 11:33:43.475: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n"
Apr 26 11:33:43.475: INFO: stdout: "\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-6fb27\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-6fb27\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-k9m8f"
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-6fb27
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-6fb27
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:43.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1935 exec execpod-affinityhvl6l -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.64.21.248:80/ ; done'
Apr 26 11:33:44.049: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n"
Apr 26 11:33:44.049: INFO: stdout: "\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f"
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
Apr 26 11:33:44.049: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-1935, will wait for the garbage collector to delete the pods 04/26/24 11:33:44.065
Apr 26 11:33:44.132: INFO: Deleting ReplicationController affinity-clusterip-transition took: 9.524127ms
Apr 26 11:33:44.232: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.313558ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 11:33:46.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1935" for this suite. 04/26/24 11:33:46.364
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]","completed":113,"skipped":1946,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.034 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2179

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:33:35.335
    Apr 26 11:33:35.335: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 11:33:35.336
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:33:35.351
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:33:35.358
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2179
    STEP: creating service in namespace services-1935 04/26/24 11:33:35.4
    STEP: creating service affinity-clusterip-transition in namespace services-1935 04/26/24 11:33:35.4
    STEP: creating replication controller affinity-clusterip-transition in namespace services-1935 04/26/24 11:33:35.416
    I0426 11:33:35.422064      23 runners.go:193] Created replication controller with name: affinity-clusterip-transition, namespace: services-1935, replica count: 3
    I0426 11:33:38.472843      23 runners.go:193] affinity-clusterip-transition Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 26 11:33:38.481: INFO: Creating new exec pod
    Apr 26 11:33:38.492: INFO: Waiting up to 5m0s for pod "execpod-affinityhvl6l" in namespace "services-1935" to be "running"
    Apr 26 11:33:38.500: INFO: Pod "execpod-affinityhvl6l": Phase="Pending", Reason="", readiness=false. Elapsed: 8.380752ms
    Apr 26 11:33:40.506: INFO: Pod "execpod-affinityhvl6l": Phase="Running", Reason="", readiness=true. Elapsed: 2.014084867s
    Apr 26 11:33:40.506: INFO: Pod "execpod-affinityhvl6l" satisfied condition "running"
    Apr 26 11:33:41.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1935 exec execpod-affinityhvl6l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip-transition 80'
    Apr 26 11:33:41.972: INFO: stderr: "+ nc -v+  -t -w 2echo affinity-clusterip-transition hostName 80\n\nConnection to affinity-clusterip-transition 80 port [tcp/http] succeeded!\n"
    Apr 26 11:33:41.972: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:33:41.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1935 exec execpod-affinityhvl6l -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.64.21.248 80'
    Apr 26 11:33:42.539: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.64.21.248 80\nConnection to 100.64.21.248 80 port [tcp/http] succeeded!\n"
    Apr 26 11:33:42.539: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:33:42.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1935 exec execpod-affinityhvl6l -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.64.21.248:80/ ; done'
    Apr 26 11:33:43.475: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n"
    Apr 26 11:33:43.475: INFO: stdout: "\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-6fb27\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-6fb27\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-d9j66\naffinity-clusterip-transition-k9m8f"
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-6fb27
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-6fb27
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-d9j66
    Apr 26 11:33:43.475: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:43.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1935 exec execpod-affinityhvl6l -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.64.21.248:80/ ; done'
    Apr 26 11:33:44.049: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.64.21.248:80/\n"
    Apr 26 11:33:44.049: INFO: stdout: "\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f\naffinity-clusterip-transition-k9m8f"
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Received response from host: affinity-clusterip-transition-k9m8f
    Apr 26 11:33:44.049: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip-transition in namespace services-1935, will wait for the garbage collector to delete the pods 04/26/24 11:33:44.065
    Apr 26 11:33:44.132: INFO: Deleting ReplicationController affinity-clusterip-transition took: 9.524127ms
    Apr 26 11:33:44.232: INFO: Terminating ReplicationController affinity-clusterip-transition pods took: 100.313558ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 11:33:46.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1935" for this suite. 04/26/24 11:33:46.364
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:33:46.371
Apr 26 11:33:46.371: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:33:46.372
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:33:46.388
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:33:46.395
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77
STEP: Creating projection with secret that has name projected-secret-test-map-24178354-fc62-456b-b472-8298a3e7a6bc 04/26/24 11:33:46.401
STEP: Creating a pod to test consume secrets 04/26/24 11:33:46.406
Apr 26 11:33:46.417: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0" in namespace "projected-7124" to be "Succeeded or Failed"
Apr 26 11:33:46.422: INFO: Pod "pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.189747ms
Apr 26 11:33:48.429: INFO: Pod "pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011111483s
Apr 26 11:33:50.428: INFO: Pod "pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010454967s
STEP: Saw pod success 04/26/24 11:33:50.428
Apr 26 11:33:50.428: INFO: Pod "pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0" satisfied condition "Succeeded or Failed"
Apr 26 11:33:50.434: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/26/24 11:33:50.449
Apr 26 11:33:50.504: INFO: Waiting for pod pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0 to disappear
Apr 26 11:33:50.513: INFO: Pod pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 26 11:33:50.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7124" for this suite. 04/26/24 11:33:50.521
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":114,"skipped":1958,"failed":0}
------------------------------
â€¢ [4.158 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:33:46.371
    Apr 26 11:33:46.371: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:33:46.372
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:33:46.388
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:33:46.395
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:77
    STEP: Creating projection with secret that has name projected-secret-test-map-24178354-fc62-456b-b472-8298a3e7a6bc 04/26/24 11:33:46.401
    STEP: Creating a pod to test consume secrets 04/26/24 11:33:46.406
    Apr 26 11:33:46.417: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0" in namespace "projected-7124" to be "Succeeded or Failed"
    Apr 26 11:33:46.422: INFO: Pod "pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.189747ms
    Apr 26 11:33:48.429: INFO: Pod "pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011111483s
    Apr 26 11:33:50.428: INFO: Pod "pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010454967s
    STEP: Saw pod success 04/26/24 11:33:50.428
    Apr 26 11:33:50.428: INFO: Pod "pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0" satisfied condition "Succeeded or Failed"
    Apr 26 11:33:50.434: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 11:33:50.449
    Apr 26 11:33:50.504: INFO: Waiting for pod pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0 to disappear
    Apr 26 11:33:50.513: INFO: Pod pod-projected-secrets-9273db14-c765-4c89-9235-c5f237c2c3c0 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 26 11:33:50.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7124" for this suite. 04/26/24 11:33:50.521
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:33:50.529
Apr 26 11:33:50.529: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 11:33:50.53
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:33:50.563
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:33:50.58
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73
STEP: Creating configMap with name configmap-test-volume-32a830f8-3ed8-4745-8855-3fdaf2d655e4 04/26/24 11:33:50.591
STEP: Creating a pod to test consume configMaps 04/26/24 11:33:50.628
Apr 26 11:33:50.687: INFO: Waiting up to 5m0s for pod "pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17" in namespace "configmap-3979" to be "Succeeded or Failed"
Apr 26 11:33:50.693: INFO: Pod "pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17": Phase="Pending", Reason="", readiness=false. Elapsed: 6.147355ms
Apr 26 11:33:52.700: INFO: Pod "pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013090552s
Apr 26 11:33:54.700: INFO: Pod "pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013337902s
STEP: Saw pod success 04/26/24 11:33:54.701
Apr 26 11:33:54.701: INFO: Pod "pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17" satisfied condition "Succeeded or Failed"
Apr 26 11:33:54.707: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17 container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:33:54.758
Apr 26 11:33:54.771: INFO: Waiting for pod pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17 to disappear
Apr 26 11:33:54.776: INFO: Pod pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 11:33:54.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3979" for this suite. 04/26/24 11:33:54.786
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":115,"skipped":1959,"failed":0}
------------------------------
â€¢ [4.265 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:33:50.529
    Apr 26 11:33:50.529: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 11:33:50.53
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:33:50.563
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:33:50.58
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:73
    STEP: Creating configMap with name configmap-test-volume-32a830f8-3ed8-4745-8855-3fdaf2d655e4 04/26/24 11:33:50.591
    STEP: Creating a pod to test consume configMaps 04/26/24 11:33:50.628
    Apr 26 11:33:50.687: INFO: Waiting up to 5m0s for pod "pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17" in namespace "configmap-3979" to be "Succeeded or Failed"
    Apr 26 11:33:50.693: INFO: Pod "pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17": Phase="Pending", Reason="", readiness=false. Elapsed: 6.147355ms
    Apr 26 11:33:52.700: INFO: Pod "pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013090552s
    Apr 26 11:33:54.700: INFO: Pod "pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013337902s
    STEP: Saw pod success 04/26/24 11:33:54.701
    Apr 26 11:33:54.701: INFO: Pod "pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17" satisfied condition "Succeeded or Failed"
    Apr 26 11:33:54.707: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17 container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:33:54.758
    Apr 26 11:33:54.771: INFO: Waiting for pod pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17 to disappear
    Apr 26 11:33:54.776: INFO: Pod pod-configmaps-7e137794-88e4-42ab-9119-bd3c379b9f17 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 11:33:54.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3979" for this suite. 04/26/24 11:33:54.786
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:33:54.798
Apr 26 11:33:54.798: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 11:33:54.799
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:33:54.817
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:33:54.824
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194
STEP: creating service in namespace services-9159 04/26/24 11:33:54.831
STEP: creating service affinity-nodeport in namespace services-9159 04/26/24 11:33:54.831
STEP: creating replication controller affinity-nodeport in namespace services-9159 04/26/24 11:33:54.842
I0426 11:33:54.850095      23 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-9159, replica count: 3
I0426 11:33:57.900827      23 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 26 11:33:57.924: INFO: Creating new exec pod
Apr 26 11:33:57.935: INFO: Waiting up to 5m0s for pod "execpod-affinitysb42k" in namespace "services-9159" to be "running"
Apr 26 11:33:57.942: INFO: Pod "execpod-affinitysb42k": Phase="Pending", Reason="", readiness=false. Elapsed: 6.594288ms
Apr 26 11:33:59.948: INFO: Pod "execpod-affinitysb42k": Phase="Running", Reason="", readiness=true. Elapsed: 2.012426464s
Apr 26 11:33:59.948: INFO: Pod "execpod-affinitysb42k" satisfied condition "running"
Apr 26 11:34:00.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-9159 exec execpod-affinitysb42k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
Apr 26 11:34:01.492: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
Apr 26 11:34:01.492: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:34:01.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-9159 exec execpod-affinitysb42k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.70.45.13 80'
Apr 26 11:34:01.936: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.70.45.13 80\nConnection to 100.70.45.13 80 port [tcp/http] succeeded!\n"
Apr 26 11:34:01.936: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:34:01.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-9159 exec execpod-affinitysb42k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.121 32521'
Apr 26 11:34:02.436: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.121 32521\nConnection to 10.250.0.121 32521 port [tcp/*] succeeded!\n"
Apr 26 11:34:02.436: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:34:02.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-9159 exec execpod-affinitysb42k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.2.248 32521'
Apr 26 11:34:02.874: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.2.248 32521\nConnection to 10.250.2.248 32521 port [tcp/*] succeeded!\n"
Apr 26 11:34:02.874: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:34:02.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-9159 exec execpod-affinitysb42k -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.121:32521/ ; done'
Apr 26 11:34:03.408: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n"
Apr 26 11:34:03.408: INFO: stdout: "\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc"
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
Apr 26 11:34:03.408: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-nodeport in namespace services-9159, will wait for the garbage collector to delete the pods 04/26/24 11:34:03.422
Apr 26 11:34:03.487: INFO: Deleting ReplicationController affinity-nodeport took: 9.294849ms
Apr 26 11:34:03.587: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.100857ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 11:34:05.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9159" for this suite. 04/26/24 11:34:05.958
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]","completed":116,"skipped":1988,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.167 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for NodePort service [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:33:54.798
    Apr 26 11:33:54.798: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 11:33:54.799
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:33:54.817
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:33:54.824
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for NodePort service [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2194
    STEP: creating service in namespace services-9159 04/26/24 11:33:54.831
    STEP: creating service affinity-nodeport in namespace services-9159 04/26/24 11:33:54.831
    STEP: creating replication controller affinity-nodeport in namespace services-9159 04/26/24 11:33:54.842
    I0426 11:33:54.850095      23 runners.go:193] Created replication controller with name: affinity-nodeport, namespace: services-9159, replica count: 3
    I0426 11:33:57.900827      23 runners.go:193] affinity-nodeport Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 26 11:33:57.924: INFO: Creating new exec pod
    Apr 26 11:33:57.935: INFO: Waiting up to 5m0s for pod "execpod-affinitysb42k" in namespace "services-9159" to be "running"
    Apr 26 11:33:57.942: INFO: Pod "execpod-affinitysb42k": Phase="Pending", Reason="", readiness=false. Elapsed: 6.594288ms
    Apr 26 11:33:59.948: INFO: Pod "execpod-affinitysb42k": Phase="Running", Reason="", readiness=true. Elapsed: 2.012426464s
    Apr 26 11:33:59.948: INFO: Pod "execpod-affinitysb42k" satisfied condition "running"
    Apr 26 11:34:00.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-9159 exec execpod-affinitysb42k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-nodeport 80'
    Apr 26 11:34:01.492: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-nodeport 80\nConnection to affinity-nodeport 80 port [tcp/http] succeeded!\n"
    Apr 26 11:34:01.492: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:34:01.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-9159 exec execpod-affinitysb42k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.70.45.13 80'
    Apr 26 11:34:01.936: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.70.45.13 80\nConnection to 100.70.45.13 80 port [tcp/http] succeeded!\n"
    Apr 26 11:34:01.936: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:34:01.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-9159 exec execpod-affinitysb42k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.121 32521'
    Apr 26 11:34:02.436: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.121 32521\nConnection to 10.250.0.121 32521 port [tcp/*] succeeded!\n"
    Apr 26 11:34:02.436: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:34:02.436: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-9159 exec execpod-affinitysb42k -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.2.248 32521'
    Apr 26 11:34:02.874: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.2.248 32521\nConnection to 10.250.2.248 32521 port [tcp/*] succeeded!\n"
    Apr 26 11:34:02.874: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:34:02.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-9159 exec execpod-affinitysb42k -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://10.250.0.121:32521/ ; done'
    Apr 26 11:34:03.408: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n+ echo\n+ curl -q -s --connect-timeout 2 http://10.250.0.121:32521/\n"
    Apr 26 11:34:03.408: INFO: stdout: "\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc\naffinity-nodeport-6c2rc"
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Received response from host: affinity-nodeport-6c2rc
    Apr 26 11:34:03.408: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-nodeport in namespace services-9159, will wait for the garbage collector to delete the pods 04/26/24 11:34:03.422
    Apr 26 11:34:03.487: INFO: Deleting ReplicationController affinity-nodeport took: 9.294849ms
    Apr 26 11:34:03.587: INFO: Terminating ReplicationController affinity-nodeport pods took: 100.100857ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 11:34:05.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-9159" for this suite. 04/26/24 11:34:05.958
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:34:05.97
Apr 26 11:34:05.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 11:34:05.971
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:34:05.985
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:34:05.99
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 11:34:06.008
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:34:06.153
STEP: Deploying the webhook pod 04/26/24 11:34:06.165
STEP: Wait for the deployment to be ready 04/26/24 11:34:06.181
Apr 26 11:34:06.214: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 11:34:08.231
STEP: Verifying the service has paired with the endpoint 04/26/24 11:34:08.243
Apr 26 11:34:09.243: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581
STEP: Listing all of the created validation webhooks 04/26/24 11:34:09.306
STEP: Creating a configMap that does not comply to the validation webhook rules 04/26/24 11:34:09.367
STEP: Deleting the collection of validation webhooks 04/26/24 11:34:09.475
STEP: Creating a configMap that does not comply to the validation webhook rules 04/26/24 11:34:09.508
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:34:09.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4577" for this suite. 04/26/24 11:34:09.528
STEP: Destroying namespace "webhook-4577-markers" for this suite. 04/26/24 11:34:09.534
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]","completed":117,"skipped":2050,"failed":0}
------------------------------
â€¢ [3.601 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:581

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:34:05.97
    Apr 26 11:34:05.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 11:34:05.971
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:34:05.985
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:34:05.99
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 11:34:06.008
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:34:06.153
    STEP: Deploying the webhook pod 04/26/24 11:34:06.165
    STEP: Wait for the deployment to be ready 04/26/24 11:34:06.181
    Apr 26 11:34:06.214: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 11:34:08.231
    STEP: Verifying the service has paired with the endpoint 04/26/24 11:34:08.243
    Apr 26 11:34:09.243: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing validating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:581
    STEP: Listing all of the created validation webhooks 04/26/24 11:34:09.306
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/26/24 11:34:09.367
    STEP: Deleting the collection of validation webhooks 04/26/24 11:34:09.475
    STEP: Creating a configMap that does not comply to the validation webhook rules 04/26/24 11:34:09.508
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:34:09.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-4577" for this suite. 04/26/24 11:34:09.528
    STEP: Destroying namespace "webhook-4577-markers" for this suite. 04/26/24 11:34:09.534
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:34:09.571
Apr 26 11:34:09.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename endpointslice 04/26/24 11:34:09.572
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:34:09.593
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:34:09.598
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352
STEP: getting /apis 04/26/24 11:34:09.605
STEP: getting /apis/discovery.k8s.io 04/26/24 11:34:09.612
STEP: getting /apis/discovery.k8s.iov1 04/26/24 11:34:09.618
STEP: creating 04/26/24 11:34:09.622
STEP: getting 04/26/24 11:34:09.639
STEP: listing 04/26/24 11:34:09.643
STEP: watching 04/26/24 11:34:09.648
Apr 26 11:34:09.648: INFO: starting watch
STEP: cluster-wide listing 04/26/24 11:34:09.652
STEP: cluster-wide watching 04/26/24 11:34:09.656
Apr 26 11:34:09.657: INFO: starting watch
STEP: patching 04/26/24 11:34:09.66
STEP: updating 04/26/24 11:34:09.668
Apr 26 11:34:09.678: INFO: waiting for watch events with expected annotations
Apr 26 11:34:09.678: INFO: saw patched and updated annotations
STEP: deleting 04/26/24 11:34:09.678
STEP: deleting a collection 04/26/24 11:34:09.694
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 26 11:34:09.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-2720" for this suite. 04/26/24 11:34:09.715
{"msg":"PASSED [sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]","completed":118,"skipped":2059,"failed":0}
------------------------------
â€¢ [0.149 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should support creating EndpointSlice API operations [Conformance]
  test/e2e/network/endpointslice.go:352

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:34:09.571
    Apr 26 11:34:09.571: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename endpointslice 04/26/24 11:34:09.572
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:34:09.593
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:34:09.598
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should support creating EndpointSlice API operations [Conformance]
      test/e2e/network/endpointslice.go:352
    STEP: getting /apis 04/26/24 11:34:09.605
    STEP: getting /apis/discovery.k8s.io 04/26/24 11:34:09.612
    STEP: getting /apis/discovery.k8s.iov1 04/26/24 11:34:09.618
    STEP: creating 04/26/24 11:34:09.622
    STEP: getting 04/26/24 11:34:09.639
    STEP: listing 04/26/24 11:34:09.643
    STEP: watching 04/26/24 11:34:09.648
    Apr 26 11:34:09.648: INFO: starting watch
    STEP: cluster-wide listing 04/26/24 11:34:09.652
    STEP: cluster-wide watching 04/26/24 11:34:09.656
    Apr 26 11:34:09.657: INFO: starting watch
    STEP: patching 04/26/24 11:34:09.66
    STEP: updating 04/26/24 11:34:09.668
    Apr 26 11:34:09.678: INFO: waiting for watch events with expected annotations
    Apr 26 11:34:09.678: INFO: saw patched and updated annotations
    STEP: deleting 04/26/24 11:34:09.678
    STEP: deleting a collection 04/26/24 11:34:09.694
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 26 11:34:09.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-2720" for this suite. 04/26/24 11:34:09.715
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:34:09.721
Apr 26 11:34:09.722: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename sched-pred 04/26/24 11:34:09.722
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:34:09.753
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:34:09.761
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 26 11:34:09.768: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 26 11:34:09.785: INFO: Waiting for terminating namespaces to be deleted...
Apr 26 11:34:09.789: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw before test
Apr 26 11:34:09.806: INFO: apiserver-proxy-hzh4l from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
Apr 26 11:34:09.806: INFO: 	Container proxy ready: true, restart count 0
Apr 26 11:34:09.806: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 11:34:09.806: INFO: blackbox-exporter-754b59454b-9cprw from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.806: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 26 11:34:09.806: INFO: calico-node-m9nm9 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.807: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 11:34:09.807: INFO: calico-typha-deploy-84df84b854-fv5zl from kube-system started at 2024-04-26 09:50:55 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.807: INFO: 	Container calico-typha ready: true, restart count 0
Apr 26 11:34:09.807: INFO: coredns-86858b4d85-f7j7b from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.807: INFO: 	Container coredns ready: true, restart count 0
Apr 26 11:34:09.807: INFO: csi-driver-node-9wpbg from kube-system started at 2024-04-26 09:50:15 +0000 UTC (3 container statuses recorded)
Apr 26 11:34:09.807: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 11:34:09.807: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 11:34:09.807: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 11:34:09.807: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-z47h4 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
Apr 26 11:34:09.807: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 11:34:09.807: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 11:34:09.807: INFO: metrics-server-56cf547447-db2cf from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.807: INFO: 	Container metrics-server ready: true, restart count 0
Apr 26 11:34:09.807: INFO: node-exporter-mg7sm from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.807: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 11:34:09.807: INFO: node-problem-detector-w7mph from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.807: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 11:34:09.807: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-pkmm6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 11:34:09.807: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 11:34:09.807: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 11:34:09.807: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp before test
Apr 26 11:34:09.817: INFO: apiserver-proxy-hzgtj from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
Apr 26 11:34:09.817: INFO: 	Container proxy ready: true, restart count 0
Apr 26 11:34:09.817: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 11:34:09.817: INFO: calico-node-49gs5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.817: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 11:34:09.817: INFO: csi-driver-node-thmzv from kube-system started at 2024-04-26 09:50:09 +0000 UTC (3 container statuses recorded)
Apr 26 11:34:09.817: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 11:34:09.817: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 11:34:09.817: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 11:34:09.817: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-8h68w from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
Apr 26 11:34:09.817: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 11:34:09.817: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 11:34:09.817: INFO: node-exporter-mzmd5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.817: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 11:34:09.818: INFO: node-problem-detector-x8jsh from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.818: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 11:34:09.818: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-t2fb5 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 11:34:09.818: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 11:34:09.818: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 11:34:09.818: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w before test
Apr 26 11:34:09.837: INFO: apiserver-proxy-8bxw2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
Apr 26 11:34:09.837: INFO: 	Container proxy ready: true, restart count 0
Apr 26 11:34:09.837: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 11:34:09.837: INFO: blackbox-exporter-754b59454b-tqxxm from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.837: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 26 11:34:09.837: INFO: calico-kube-controllers-5bfbd9c84c-ggxxm from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.837: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 26 11:34:09.837: INFO: calico-node-nfp6q from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.837: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 11:34:09.837: INFO: calico-node-vertical-autoscaler-6b85ccc474-scqt5 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.837: INFO: 	Container autoscaler ready: true, restart count 0
Apr 26 11:34:09.837: INFO: calico-typha-deploy-84df84b854-grtfl from kube-system started at 2024-04-26 11:04:13 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.837: INFO: 	Container calico-typha ready: true, restart count 0
Apr 26 11:34:09.837: INFO: calico-typha-horizontal-autoscaler-765f9c86fd-x4mrd from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.837: INFO: 	Container autoscaler ready: true, restart count 0
Apr 26 11:34:09.837: INFO: calico-typha-vertical-autoscaler-8657c6b4fc-d6gnw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.837: INFO: 	Container autoscaler ready: true, restart count 0
Apr 26 11:34:09.837: INFO: coredns-86858b4d85-m4dg4 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.837: INFO: 	Container coredns ready: true, restart count 0
Apr 26 11:34:09.837: INFO: csi-driver-node-f4f5r from kube-system started at 2024-04-26 09:50:05 +0000 UTC (3 container statuses recorded)
Apr 26 11:34:09.837: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 11:34:09.837: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 11:34:09.837: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 11:34:09.837: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-82vtz from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
Apr 26 11:34:09.837: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 11:34:09.838: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 11:34:09.838: INFO: metrics-server-56cf547447-sl4zk from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.838: INFO: 	Container metrics-server ready: true, restart count 0
Apr 26 11:34:09.838: INFO: node-exporter-r2wm2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.838: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 11:34:09.838: INFO: node-problem-detector-8w59w from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.838: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 11:34:09.838: INFO: vpn-shoot-849b6d5c85-z42mw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.838: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 26 11:34:09.838: INFO: sonobuoy from sonobuoy started at 2024-04-26 10:56:56 +0000 UTC (1 container statuses recorded)
Apr 26 11:34:09.838: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 26 11:34:09.838: INFO: sonobuoy-e2e-job-ce2c772167a64049 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 11:34:09.838: INFO: 	Container e2e ready: true, restart count 0
Apr 26 11:34:09.838: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 11:34:09.838: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-6bgn6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 11:34:09.838: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 11:34:09.838: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/26/24 11:34:09.838
Apr 26 11:34:09.848: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9541" to be "running"
Apr 26 11:34:09.872: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 23.866834ms
Apr 26 11:34:11.879: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.030066731s
Apr 26 11:34:11.879: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/26/24 11:34:11.884
STEP: Trying to apply a random label on the found node. 04/26/24 11:34:11.915
STEP: verifying the node has the label kubernetes.io/e2e-f820d80a-a8c4-4125-998b-1d5c9e634255 95 04/26/24 11:34:11.929
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 04/26/24 11:34:11.953
Apr 26 11:34:11.964: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-9541" to be "not pending"
Apr 26 11:34:11.970: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.891465ms
Apr 26 11:34:13.978: INFO: Pod "pod4": Phase="Running", Reason="", readiness=false. Elapsed: 2.013366657s
Apr 26 11:34:13.978: INFO: Pod "pod4" satisfied condition "not pending"
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.250.2.248 on the node which pod4 resides and expect not scheduled 04/26/24 11:34:13.978
Apr 26 11:34:13.986: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-9541" to be "not pending"
Apr 26 11:34:14.018: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.174817ms
Apr 26 11:34:16.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037914772s
Apr 26 11:34:18.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039294734s
Apr 26 11:34:20.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039546025s
Apr 26 11:34:22.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.038316313s
Apr 26 11:34:24.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.038160226s
Apr 26 11:34:26.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.039457722s
Apr 26 11:34:28.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.038540208s
Apr 26 11:34:30.028: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.041916687s
Apr 26 11:34:32.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.040192059s
Apr 26 11:34:34.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.038574822s
Apr 26 11:34:36.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.039532501s
Apr 26 11:34:38.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.038848304s
Apr 26 11:34:40.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.039192316s
Apr 26 11:34:42.030: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.043624162s
Apr 26 11:34:44.054: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.068346807s
Apr 26 11:34:46.030: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.043618601s
Apr 26 11:34:48.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.038125261s
Apr 26 11:34:50.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.038563952s
Apr 26 11:34:52.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.038539005s
Apr 26 11:34:54.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.038567707s
Apr 26 11:34:56.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.039134867s
Apr 26 11:34:58.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.040470271s
Apr 26 11:35:00.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.039163097s
Apr 26 11:35:02.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.039376299s
Apr 26 11:35:04.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.039791186s
Apr 26 11:35:06.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.039612164s
Apr 26 11:35:08.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.039495938s
Apr 26 11:35:10.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.037991796s
Apr 26 11:35:12.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.03937951s
Apr 26 11:35:14.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.038067466s
Apr 26 11:35:16.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.040980526s
Apr 26 11:35:18.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.039789336s
Apr 26 11:35:20.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.039632357s
Apr 26 11:35:22.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.039289222s
Apr 26 11:35:24.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.03807s
Apr 26 11:35:26.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.040452977s
Apr 26 11:35:28.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.040445516s
Apr 26 11:35:30.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.040368036s
Apr 26 11:35:32.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.040180043s
Apr 26 11:35:34.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.038305347s
Apr 26 11:35:36.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.038863441s
Apr 26 11:35:38.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.039921144s
Apr 26 11:35:40.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.038014006s
Apr 26 11:35:42.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.039385481s
Apr 26 11:35:44.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.038087032s
Apr 26 11:35:46.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.038490741s
Apr 26 11:35:48.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.040643313s
Apr 26 11:35:50.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.040621772s
Apr 26 11:35:52.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.040178593s
Apr 26 11:35:54.034: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.048596075s
Apr 26 11:35:56.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.03920216s
Apr 26 11:35:58.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.037652745s
Apr 26 11:36:00.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.038020042s
Apr 26 11:36:02.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.040779362s
Apr 26 11:36:04.032: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.045645689s
Apr 26 11:36:06.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.039008707s
Apr 26 11:36:08.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.038437279s
Apr 26 11:36:10.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.038360284s
Apr 26 11:36:12.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.041500522s
Apr 26 11:36:14.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.038684324s
Apr 26 11:36:16.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.038391826s
Apr 26 11:36:18.052: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.065980028s
Apr 26 11:36:20.023: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.03734277s
Apr 26 11:36:22.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.038726645s
Apr 26 11:36:24.029: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.04277114s
Apr 26 11:36:26.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.038830334s
Apr 26 11:36:28.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.038528162s
Apr 26 11:36:30.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.038174878s
Apr 26 11:36:32.023: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.037595983s
Apr 26 11:36:34.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.038790668s
Apr 26 11:36:36.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.039820071s
Apr 26 11:36:38.023: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.03747071s
Apr 26 11:36:40.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.038606502s
Apr 26 11:36:42.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.0386861s
Apr 26 11:36:44.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.038198943s
Apr 26 11:36:46.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.038520246s
Apr 26 11:36:48.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.039264731s
Apr 26 11:36:50.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.037714068s
Apr 26 11:36:52.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.037970109s
Apr 26 11:36:54.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.038871693s
Apr 26 11:36:56.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.038608896s
Apr 26 11:36:58.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.037735181s
Apr 26 11:37:00.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.039643515s
Apr 26 11:37:02.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.039002423s
Apr 26 11:37:04.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.038609995s
Apr 26 11:37:06.030: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.043969171s
Apr 26 11:37:08.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.039098481s
Apr 26 11:37:10.028: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.042125266s
Apr 26 11:37:12.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.037976134s
Apr 26 11:37:14.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.038734893s
Apr 26 11:37:16.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.037723045s
Apr 26 11:37:18.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.037978499s
Apr 26 11:37:20.023: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.037242319s
Apr 26 11:37:22.028: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.041838782s
Apr 26 11:37:24.029: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.042696726s
Apr 26 11:37:26.046: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.059930914s
Apr 26 11:37:28.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.037684336s
Apr 26 11:37:30.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.038665433s
Apr 26 11:37:32.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.039515981s
Apr 26 11:37:34.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.03800238s
Apr 26 11:37:36.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.040097385s
Apr 26 11:37:38.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.039002921s
Apr 26 11:37:40.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.038204241s
Apr 26 11:37:42.028: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.041829357s
Apr 26 11:37:44.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.040356963s
Apr 26 11:37:46.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.039279395s
Apr 26 11:37:48.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.039371269s
Apr 26 11:37:50.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.03780515s
Apr 26 11:37:52.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.038303936s
Apr 26 11:37:54.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.040639235s
Apr 26 11:37:56.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.040884832s
Apr 26 11:37:58.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.037948532s
Apr 26 11:38:00.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.03831826s
Apr 26 11:38:02.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.040554238s
Apr 26 11:38:04.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.03774649s
Apr 26 11:38:06.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.039921189s
Apr 26 11:38:08.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.041567344s
Apr 26 11:38:10.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.038442264s
Apr 26 11:38:12.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.041126924s
Apr 26 11:38:14.023: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.037195557s
Apr 26 11:38:16.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.038010249s
Apr 26 11:38:18.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.03831095s
Apr 26 11:38:20.044: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.058185577s
Apr 26 11:38:22.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.039066264s
Apr 26 11:38:24.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.038138173s
Apr 26 11:38:26.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.039640829s
Apr 26 11:38:28.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.039851049s
Apr 26 11:38:30.028: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.042484949s
Apr 26 11:38:32.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.039220979s
Apr 26 11:38:34.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.037854353s
Apr 26 11:38:36.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.039225591s
Apr 26 11:38:38.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.038846557s
Apr 26 11:38:40.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.038342035s
Apr 26 11:38:42.028: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.04220415s
Apr 26 11:38:44.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.038201886s
Apr 26 11:38:46.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.039680407s
Apr 26 11:38:48.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.039340141s
Apr 26 11:38:50.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.039121039s
Apr 26 11:38:52.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.039662945s
Apr 26 11:38:54.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.03818035s
Apr 26 11:38:56.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.038028155s
Apr 26 11:38:58.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.038864368s
Apr 26 11:39:00.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.039449377s
Apr 26 11:39:02.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.038418484s
Apr 26 11:39:04.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.03997409s
Apr 26 11:39:06.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.038897427s
Apr 26 11:39:08.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.038011344s
Apr 26 11:39:10.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.040347636s
Apr 26 11:39:12.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.03965832s
Apr 26 11:39:14.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.037755583s
Apr 26 11:39:14.030: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.044050534s
STEP: removing the label kubernetes.io/e2e-f820d80a-a8c4-4125-998b-1d5c9e634255 off the node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp 04/26/24 11:39:14.03
STEP: verifying the node doesn't have the label kubernetes.io/e2e-f820d80a-a8c4-4125-998b-1d5c9e634255 04/26/24 11:39:14.053
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:39:14.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9541" for this suite. 04/26/24 11:39:14.084
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]","completed":119,"skipped":2078,"failed":0}
------------------------------
â€¢ [SLOW TEST] [304.370 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  test/e2e/scheduling/predicates.go:699

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:34:09.721
    Apr 26 11:34:09.722: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename sched-pred 04/26/24 11:34:09.722
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:34:09.753
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:34:09.761
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 26 11:34:09.768: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 26 11:34:09.785: INFO: Waiting for terminating namespaces to be deleted...
    Apr 26 11:34:09.789: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw before test
    Apr 26 11:34:09.806: INFO: apiserver-proxy-hzh4l from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
    Apr 26 11:34:09.806: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 11:34:09.806: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 11:34:09.806: INFO: blackbox-exporter-754b59454b-9cprw from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.806: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Apr 26 11:34:09.806: INFO: calico-node-m9nm9 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.807: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: calico-typha-deploy-84df84b854-fv5zl from kube-system started at 2024-04-26 09:50:55 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.807: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: coredns-86858b4d85-f7j7b from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.807: INFO: 	Container coredns ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: csi-driver-node-9wpbg from kube-system started at 2024-04-26 09:50:15 +0000 UTC (3 container statuses recorded)
    Apr 26 11:34:09.807: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-z47h4 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
    Apr 26 11:34:09.807: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: metrics-server-56cf547447-db2cf from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.807: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: node-exporter-mg7sm from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.807: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: node-problem-detector-w7mph from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.807: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-pkmm6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 11:34:09.807: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 11:34:09.807: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp before test
    Apr 26 11:34:09.817: INFO: apiserver-proxy-hzgtj from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
    Apr 26 11:34:09.817: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 11:34:09.817: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 11:34:09.817: INFO: calico-node-49gs5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.817: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 11:34:09.817: INFO: csi-driver-node-thmzv from kube-system started at 2024-04-26 09:50:09 +0000 UTC (3 container statuses recorded)
    Apr 26 11:34:09.817: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 11:34:09.817: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 11:34:09.817: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 11:34:09.817: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-8h68w from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
    Apr 26 11:34:09.817: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 11:34:09.817: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 11:34:09.817: INFO: node-exporter-mzmd5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.817: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 11:34:09.818: INFO: node-problem-detector-x8jsh from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.818: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 11:34:09.818: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-t2fb5 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 11:34:09.818: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 11:34:09.818: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 11:34:09.818: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w before test
    Apr 26 11:34:09.837: INFO: apiserver-proxy-8bxw2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
    Apr 26 11:34:09.837: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: blackbox-exporter-754b59454b-tqxxm from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.837: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: calico-kube-controllers-5bfbd9c84c-ggxxm from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.837: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: calico-node-nfp6q from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.837: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: calico-node-vertical-autoscaler-6b85ccc474-scqt5 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.837: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: calico-typha-deploy-84df84b854-grtfl from kube-system started at 2024-04-26 11:04:13 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.837: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: calico-typha-horizontal-autoscaler-765f9c86fd-x4mrd from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.837: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: calico-typha-vertical-autoscaler-8657c6b4fc-d6gnw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.837: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: coredns-86858b4d85-m4dg4 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.837: INFO: 	Container coredns ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: csi-driver-node-f4f5r from kube-system started at 2024-04-26 09:50:05 +0000 UTC (3 container statuses recorded)
    Apr 26 11:34:09.837: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 11:34:09.837: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-82vtz from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
    Apr 26 11:34:09.837: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 11:34:09.838: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 11:34:09.838: INFO: metrics-server-56cf547447-sl4zk from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.838: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 26 11:34:09.838: INFO: node-exporter-r2wm2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.838: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 11:34:09.838: INFO: node-problem-detector-8w59w from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.838: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 11:34:09.838: INFO: vpn-shoot-849b6d5c85-z42mw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.838: INFO: 	Container vpn-shoot ready: true, restart count 0
    Apr 26 11:34:09.838: INFO: sonobuoy from sonobuoy started at 2024-04-26 10:56:56 +0000 UTC (1 container statuses recorded)
    Apr 26 11:34:09.838: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 26 11:34:09.838: INFO: sonobuoy-e2e-job-ce2c772167a64049 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 11:34:09.838: INFO: 	Container e2e ready: true, restart count 0
    Apr 26 11:34:09.838: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 11:34:09.838: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-6bgn6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 11:34:09.838: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 11:34:09.838: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
      test/e2e/scheduling/predicates.go:699
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/26/24 11:34:09.838
    Apr 26 11:34:09.848: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9541" to be "running"
    Apr 26 11:34:09.872: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 23.866834ms
    Apr 26 11:34:11.879: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.030066731s
    Apr 26 11:34:11.879: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/26/24 11:34:11.884
    STEP: Trying to apply a random label on the found node. 04/26/24 11:34:11.915
    STEP: verifying the node has the label kubernetes.io/e2e-f820d80a-a8c4-4125-998b-1d5c9e634255 95 04/26/24 11:34:11.929
    STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled 04/26/24 11:34:11.953
    Apr 26 11:34:11.964: INFO: Waiting up to 5m0s for pod "pod4" in namespace "sched-pred-9541" to be "not pending"
    Apr 26 11:34:11.970: INFO: Pod "pod4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.891465ms
    Apr 26 11:34:13.978: INFO: Pod "pod4": Phase="Running", Reason="", readiness=false. Elapsed: 2.013366657s
    Apr 26 11:34:13.978: INFO: Pod "pod4" satisfied condition "not pending"
    STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 10.250.2.248 on the node which pod4 resides and expect not scheduled 04/26/24 11:34:13.978
    Apr 26 11:34:13.986: INFO: Waiting up to 5m0s for pod "pod5" in namespace "sched-pred-9541" to be "not pending"
    Apr 26 11:34:14.018: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.174817ms
    Apr 26 11:34:16.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037914772s
    Apr 26 11:34:18.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.039294734s
    Apr 26 11:34:20.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.039546025s
    Apr 26 11:34:22.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.038316313s
    Apr 26 11:34:24.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.038160226s
    Apr 26 11:34:26.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.039457722s
    Apr 26 11:34:28.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.038540208s
    Apr 26 11:34:30.028: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.041916687s
    Apr 26 11:34:32.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 18.040192059s
    Apr 26 11:34:34.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.038574822s
    Apr 26 11:34:36.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 22.039532501s
    Apr 26 11:34:38.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 24.038848304s
    Apr 26 11:34:40.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 26.039192316s
    Apr 26 11:34:42.030: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 28.043624162s
    Apr 26 11:34:44.054: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 30.068346807s
    Apr 26 11:34:46.030: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 32.043618601s
    Apr 26 11:34:48.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.038125261s
    Apr 26 11:34:50.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.038563952s
    Apr 26 11:34:52.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 38.038539005s
    Apr 26 11:34:54.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 40.038567707s
    Apr 26 11:34:56.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 42.039134867s
    Apr 26 11:34:58.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 44.040470271s
    Apr 26 11:35:00.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 46.039163097s
    Apr 26 11:35:02.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 48.039376299s
    Apr 26 11:35:04.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 50.039791186s
    Apr 26 11:35:06.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 52.039612164s
    Apr 26 11:35:08.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 54.039495938s
    Apr 26 11:35:10.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 56.037991796s
    Apr 26 11:35:12.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 58.03937951s
    Apr 26 11:35:14.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.038067466s
    Apr 26 11:35:16.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.040980526s
    Apr 26 11:35:18.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.039789336s
    Apr 26 11:35:20.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.039632357s
    Apr 26 11:35:22.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.039289222s
    Apr 26 11:35:24.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.03807s
    Apr 26 11:35:26.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.040452977s
    Apr 26 11:35:28.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.040445516s
    Apr 26 11:35:30.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.040368036s
    Apr 26 11:35:32.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.040180043s
    Apr 26 11:35:34.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.038305347s
    Apr 26 11:35:36.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.038863441s
    Apr 26 11:35:38.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.039921144s
    Apr 26 11:35:40.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.038014006s
    Apr 26 11:35:42.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.039385481s
    Apr 26 11:35:44.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.038087032s
    Apr 26 11:35:46.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.038490741s
    Apr 26 11:35:48.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.040643313s
    Apr 26 11:35:50.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.040621772s
    Apr 26 11:35:52.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.040178593s
    Apr 26 11:35:54.034: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.048596075s
    Apr 26 11:35:56.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.03920216s
    Apr 26 11:35:58.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.037652745s
    Apr 26 11:36:00.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.038020042s
    Apr 26 11:36:02.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.040779362s
    Apr 26 11:36:04.032: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.045645689s
    Apr 26 11:36:06.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.039008707s
    Apr 26 11:36:08.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.038437279s
    Apr 26 11:36:10.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.038360284s
    Apr 26 11:36:12.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.041500522s
    Apr 26 11:36:14.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.038684324s
    Apr 26 11:36:16.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m2.038391826s
    Apr 26 11:36:18.052: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m4.065980028s
    Apr 26 11:36:20.023: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m6.03734277s
    Apr 26 11:36:22.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m8.038726645s
    Apr 26 11:36:24.029: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m10.04277114s
    Apr 26 11:36:26.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m12.038830334s
    Apr 26 11:36:28.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m14.038528162s
    Apr 26 11:36:30.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m16.038174878s
    Apr 26 11:36:32.023: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m18.037595983s
    Apr 26 11:36:34.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m20.038790668s
    Apr 26 11:36:36.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m22.039820071s
    Apr 26 11:36:38.023: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m24.03747071s
    Apr 26 11:36:40.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m26.038606502s
    Apr 26 11:36:42.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m28.0386861s
    Apr 26 11:36:44.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m30.038198943s
    Apr 26 11:36:46.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m32.038520246s
    Apr 26 11:36:48.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m34.039264731s
    Apr 26 11:36:50.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m36.037714068s
    Apr 26 11:36:52.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m38.037970109s
    Apr 26 11:36:54.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m40.038871693s
    Apr 26 11:36:56.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m42.038608896s
    Apr 26 11:36:58.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m44.037735181s
    Apr 26 11:37:00.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m46.039643515s
    Apr 26 11:37:02.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m48.039002423s
    Apr 26 11:37:04.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m50.038609995s
    Apr 26 11:37:06.030: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m52.043969171s
    Apr 26 11:37:08.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m54.039098481s
    Apr 26 11:37:10.028: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m56.042125266s
    Apr 26 11:37:12.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 2m58.037976134s
    Apr 26 11:37:14.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m0.038734893s
    Apr 26 11:37:16.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m2.037723045s
    Apr 26 11:37:18.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m4.037978499s
    Apr 26 11:37:20.023: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m6.037242319s
    Apr 26 11:37:22.028: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m8.041838782s
    Apr 26 11:37:24.029: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m10.042696726s
    Apr 26 11:37:26.046: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m12.059930914s
    Apr 26 11:37:28.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m14.037684336s
    Apr 26 11:37:30.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m16.038665433s
    Apr 26 11:37:32.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m18.039515981s
    Apr 26 11:37:34.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m20.03800238s
    Apr 26 11:37:36.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m22.040097385s
    Apr 26 11:37:38.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m24.039002921s
    Apr 26 11:37:40.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m26.038204241s
    Apr 26 11:37:42.028: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m28.041829357s
    Apr 26 11:37:44.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m30.040356963s
    Apr 26 11:37:46.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m32.039279395s
    Apr 26 11:37:48.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m34.039371269s
    Apr 26 11:37:50.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m36.03780515s
    Apr 26 11:37:52.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m38.038303936s
    Apr 26 11:37:54.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m40.040639235s
    Apr 26 11:37:56.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m42.040884832s
    Apr 26 11:37:58.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m44.037948532s
    Apr 26 11:38:00.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m46.03831826s
    Apr 26 11:38:02.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m48.040554238s
    Apr 26 11:38:04.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m50.03774649s
    Apr 26 11:38:06.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m52.039921189s
    Apr 26 11:38:08.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m54.041567344s
    Apr 26 11:38:10.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m56.038442264s
    Apr 26 11:38:12.027: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 3m58.041126924s
    Apr 26 11:38:14.023: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m0.037195557s
    Apr 26 11:38:16.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m2.038010249s
    Apr 26 11:38:18.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m4.03831095s
    Apr 26 11:38:20.044: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m6.058185577s
    Apr 26 11:38:22.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m8.039066264s
    Apr 26 11:38:24.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m10.038138173s
    Apr 26 11:38:26.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m12.039640829s
    Apr 26 11:38:28.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m14.039851049s
    Apr 26 11:38:30.028: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m16.042484949s
    Apr 26 11:38:32.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m18.039220979s
    Apr 26 11:38:34.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m20.037854353s
    Apr 26 11:38:36.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m22.039225591s
    Apr 26 11:38:38.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m24.038846557s
    Apr 26 11:38:40.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m26.038342035s
    Apr 26 11:38:42.028: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m28.04220415s
    Apr 26 11:38:44.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m30.038201886s
    Apr 26 11:38:46.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m32.039680407s
    Apr 26 11:38:48.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m34.039340141s
    Apr 26 11:38:50.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m36.039121039s
    Apr 26 11:38:52.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m38.039662945s
    Apr 26 11:38:54.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m40.03818035s
    Apr 26 11:38:56.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m42.038028155s
    Apr 26 11:38:58.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m44.038864368s
    Apr 26 11:39:00.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m46.039449377s
    Apr 26 11:39:02.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m48.038418484s
    Apr 26 11:39:04.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m50.03997409s
    Apr 26 11:39:06.025: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m52.038897427s
    Apr 26 11:39:08.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m54.038011344s
    Apr 26 11:39:10.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m56.040347636s
    Apr 26 11:39:12.026: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 4m58.03965832s
    Apr 26 11:39:14.024: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.037755583s
    Apr 26 11:39:14.030: INFO: Pod "pod5": Phase="Pending", Reason="", readiness=false. Elapsed: 5m0.044050534s
    STEP: removing the label kubernetes.io/e2e-f820d80a-a8c4-4125-998b-1d5c9e634255 off the node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp 04/26/24 11:39:14.03
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-f820d80a-a8c4-4125-998b-1d5c9e634255 04/26/24 11:39:14.053
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:39:14.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-9541" for this suite. 04/26/24 11:39:14.084
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:39:14.093
Apr 26 11:39:14.093: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:39:14.094
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:14.126
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:14.133
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220
STEP: Creating a pod to test downward API volume plugin 04/26/24 11:39:14.142
Apr 26 11:39:14.161: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4" in namespace "projected-2800" to be "Succeeded or Failed"
Apr 26 11:39:14.168: INFO: Pod "downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.980119ms
Apr 26 11:39:16.173: INFO: Pod "downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011845363s
Apr 26 11:39:18.174: INFO: Pod "downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013108955s
Apr 26 11:39:20.176: INFO: Pod "downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01519053s
STEP: Saw pod success 04/26/24 11:39:20.176
Apr 26 11:39:20.176: INFO: Pod "downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4" satisfied condition "Succeeded or Failed"
Apr 26 11:39:20.181: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4 container client-container: <nil>
STEP: delete the pod 04/26/24 11:39:20.2
Apr 26 11:39:20.212: INFO: Waiting for pod downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4 to disappear
Apr 26 11:39:20.216: INFO: Pod downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 26 11:39:20.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2800" for this suite. 04/26/24 11:39:20.226
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]","completed":120,"skipped":2104,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.140 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:39:14.093
    Apr 26 11:39:14.093: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:39:14.094
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:14.126
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:14.133
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:220
    STEP: Creating a pod to test downward API volume plugin 04/26/24 11:39:14.142
    Apr 26 11:39:14.161: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4" in namespace "projected-2800" to be "Succeeded or Failed"
    Apr 26 11:39:14.168: INFO: Pod "downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.980119ms
    Apr 26 11:39:16.173: INFO: Pod "downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011845363s
    Apr 26 11:39:18.174: INFO: Pod "downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.013108955s
    Apr 26 11:39:20.176: INFO: Pod "downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01519053s
    STEP: Saw pod success 04/26/24 11:39:20.176
    Apr 26 11:39:20.176: INFO: Pod "downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4" satisfied condition "Succeeded or Failed"
    Apr 26 11:39:20.181: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4 container client-container: <nil>
    STEP: delete the pod 04/26/24 11:39:20.2
    Apr 26 11:39:20.212: INFO: Waiting for pod downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4 to disappear
    Apr 26 11:39:20.216: INFO: Pod downwardapi-volume-e08af002-eefe-40dc-9faf-06a21a5448b4 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 26 11:39:20.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2800" for this suite. 04/26/24 11:39:20.226
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Deployment
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:39:20.233
Apr 26 11:39:20.233: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename deployment 04/26/24 11:39:20.234
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:20.254
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:20.261
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160
Apr 26 11:39:20.269: INFO: Creating deployment "webserver-deployment"
Apr 26 11:39:20.276: INFO: Waiting for observed generation 1
Apr 26 11:39:22.298: INFO: Waiting for all required pods to come up
Apr 26 11:39:22.305: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running 04/26/24 11:39:22.305
Apr 26 11:39:22.305: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-t2mx4" in namespace "deployment-9445" to be "running"
Apr 26 11:39:22.305: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-l7gtt" in namespace "deployment-9445" to be "running"
Apr 26 11:39:22.309: INFO: Pod "webserver-deployment-845c8977d9-t2mx4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.43199ms
Apr 26 11:39:22.310: INFO: Pod "webserver-deployment-845c8977d9-l7gtt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.536205ms
Apr 26 11:39:24.323: INFO: Pod "webserver-deployment-845c8977d9-t2mx4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018052866s
Apr 26 11:39:24.323: INFO: Pod "webserver-deployment-845c8977d9-l7gtt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018060641s
Apr 26 11:39:26.318: INFO: Pod "webserver-deployment-845c8977d9-t2mx4": Phase="Running", Reason="", readiness=true. Elapsed: 4.013410816s
Apr 26 11:39:26.319: INFO: Pod "webserver-deployment-845c8977d9-t2mx4" satisfied condition "running"
Apr 26 11:39:26.319: INFO: Pod "webserver-deployment-845c8977d9-l7gtt": Phase="Running", Reason="", readiness=true. Elapsed: 4.013842942s
Apr 26 11:39:26.319: INFO: Pod "webserver-deployment-845c8977d9-l7gtt" satisfied condition "running"
Apr 26 11:39:26.319: INFO: Waiting for deployment "webserver-deployment" to complete
Apr 26 11:39:26.329: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr 26 11:39:26.340: INFO: Updating deployment webserver-deployment
Apr 26 11:39:26.340: INFO: Waiting for observed generation 2
Apr 26 11:39:28.356: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 26 11:39:28.361: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 26 11:39:28.366: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 26 11:39:28.382: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 26 11:39:28.382: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 26 11:39:28.385: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 26 11:39:28.392: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr 26 11:39:28.392: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr 26 11:39:28.402: INFO: Updating deployment webserver-deployment
Apr 26 11:39:28.402: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr 26 11:39:28.414: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 26 11:39:30.427: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 26 11:39:30.439: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-9445  79c792f1-7e96-45ac-8a14-2a009b788b44 30427 3 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:39:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00387a178 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:19,UnavailableReplicas:14,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2024-04-26 11:39:28 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2024-04-26 11:39:30 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,},},ReadyReplicas:19,CollisionCount:nil,},}

Apr 26 11:39:30.444: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-9445  30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 30370 3 2024-04-26 11:39:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 79c792f1-7e96-45ac-8a14-2a009b788b44 0xc001727ba7 0xc001727ba8}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"79c792f1-7e96-45ac-8a14-2a009b788b44\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001727c58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 26 11:39:30.444: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr 26 11:39:30.444: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-9445  8069883b-6620-4e6d-ab11-501ea2128081 30426 3 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 79c792f1-7e96-45ac-8a14-2a009b788b44 0xc001727dd7 0xc001727dd8}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"79c792f1-7e96-45ac-8a14-2a009b788b44\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:39:30 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001727e78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:19,AvailableReplicas:19,Conditions:[]ReplicaSetCondition{},},}
Apr 26 11:39:30.463: INFO: Pod "webserver-deployment-69b7448995-5xrxq" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-5xrxq webserver-deployment-69b7448995- deployment-9445  befd071e-9a1e-4a3f-bf8b-c397703465b1 30386 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:9d6f312daee33b8b3827057315b7aa49c93a6af3e139a65190bfaeed25f93f97 cni.projectcalico.org/podIP:100.96.0.70/32 cni.projectcalico.org/podIPs:100.96.0.70/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387a597 0xc00387a598}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jnw9l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jnw9l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.463: INFO: Pod "webserver-deployment-69b7448995-7sww8" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-7sww8 webserver-deployment-69b7448995- deployment-9445  a54af357-d499-4ac9-b913-5f3b0c7b98f0 30378 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:1b45c0a1f81c175bfb300f0022453c3452f97919504d50bb3455fb34a24f69a3 cni.projectcalico.org/podIP:100.96.1.157/32 cni.projectcalico.org/podIPs:100.96.1.157/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387a7b7 0xc00387a7b8}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g4ccq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g4ccq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.463: INFO: Pod "webserver-deployment-69b7448995-8nzrm" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-8nzrm webserver-deployment-69b7448995- deployment-9445  7154b17c-1df6-495f-82f5-0f52f2282e18 30369 0 2024-04-26 11:39:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2dd814b7fa7ddcbd28b354720e4268d30c8707cb413bda2ec642d06d9c4097e6 cni.projectcalico.org/podIP:100.96.1.155/32 cni.projectcalico.org/podIPs:100.96.1.155/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387a9c7 0xc00387a9c8}] [] [{calico Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.155\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2t8hr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2t8hr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.155,StartTime:2024-04-26 11:39:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.155,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.464: INFO: Pod "webserver-deployment-69b7448995-c5flt" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-c5flt webserver-deployment-69b7448995- deployment-9445  59f32995-cdd8-4828-b5e4-0253c6258014 30387 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:5b311b465f7365d0c551d7b48c6c9ca547a2500f6180d19bb66da14508490dbb cni.projectcalico.org/podIP:100.96.2.68/32 cni.projectcalico.org/podIPs:100.96.2.68/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387ac07 0xc00387ac08}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9btdn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9btdn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.464: INFO: Pod "webserver-deployment-69b7448995-ftksd" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-ftksd webserver-deployment-69b7448995- deployment-9445  85dd00a2-5ac7-4e04-b061-c2267c67bd17 30366 0 2024-04-26 11:39:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d264abb0bb4c58aab1bb49290f7de8f1e42d501fe7eebe4a805c35f3973ac4b1 cni.projectcalico.org/podIP:100.96.2.61/32 cni.projectcalico.org/podIPs:100.96.2.61/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387ae27 0xc00387ae28}] [] [{calico Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.61\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lj2hw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lj2hw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.61,StartTime:2024-04-26 11:39:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.61,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.464: INFO: Pod "webserver-deployment-69b7448995-fv7g8" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-fv7g8 webserver-deployment-69b7448995- deployment-9445  6b7f1151-9d59-4ea6-b498-a8275d2c3a73 30367 0 2024-04-26 11:39:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:5012799dbdeffc52a5b7f6d6ba03f41873204f2fabe19a125e6bc3dd8e94c290 cni.projectcalico.org/podIP:100.96.2.62/32 cni.projectcalico.org/podIPs:100.96.2.62/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387b060 0xc00387b061}] [] [{calico Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.62\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6mphc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6mphc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.62,StartTime:2024-04-26 11:39:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.464: INFO: Pod "webserver-deployment-69b7448995-hnf8q" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-hnf8q webserver-deployment-69b7448995- deployment-9445  8c1456d2-b498-4a59-849a-9c004b2df69a 30374 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:695c0dd6e0db68c8be2fcc0a472f208b232df62c58aa7e0058a9fe9f072eac7c cni.projectcalico.org/podIP:100.96.3.7/32 cni.projectcalico.org/podIPs:100.96.3.7/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387b2b0 0xc00387b2b1}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sm8kt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sm8kt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.464: INFO: Pod "webserver-deployment-69b7448995-jbj2v" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jbj2v webserver-deployment-69b7448995- deployment-9445  81b1b3c3-35a0-40cc-b314-37fe1d0f52a6 30350 0 2024-04-26 11:39:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:473e9dfaf4a6d27eb9e45d62f839657d47952d0856cd965c629b453989359724 cni.projectcalico.org/podIP:100.96.3.6/32 cni.projectcalico.org/podIPs:100.96.3.6/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387b4c7 0xc00387b4c8}] [] [{calico Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.6\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g72bl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g72bl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:100.96.3.6,StartTime:2024-04-26 11:39:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.6,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.465: INFO: Pod "webserver-deployment-69b7448995-jq2vq" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-jq2vq webserver-deployment-69b7448995- deployment-9445  36ee443e-968f-4aa2-a3aa-e2c56afd33df 30381 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:9d442e3f1b79b6fa846e7b2532a5ae1f47aa819c62ed49216bb5e44341c82a99 cni.projectcalico.org/podIP:100.96.1.159/32 cni.projectcalico.org/podIPs:100.96.1.159/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387b700 0xc00387b701}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bkkjf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bkkjf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.465: INFO: Pod "webserver-deployment-69b7448995-k95vx" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-k95vx webserver-deployment-69b7448995- deployment-9445  e06f3208-b81d-48a1-8003-6cbfdd91feab 30292 0 2024-04-26 11:39:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:93253a0b9158aa769ae42b473a5895cddb2cc486148564280a7f9f8643f68fae cni.projectcalico.org/podIP:100.96.0.65/32 cni.projectcalico.org/podIPs:100.96.0.65/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387b917 0xc00387b918}] [] [{calico Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.65\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z95z7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z95z7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.65,StartTime:2024-04-26 11:39:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.65,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.465: INFO: Pod "webserver-deployment-69b7448995-l9rst" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-l9rst webserver-deployment-69b7448995- deployment-9445  be65653a-0639-474b-a7a8-42b8a21658cf 30428 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:df843bae2980bc84526ed915fa7bd968cac844aead9f675d7e27ad7f981b8da2 cni.projectcalico.org/podIP:100.96.0.66/32 cni.projectcalico.org/podIPs:100.96.0.66/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387bb50 0xc00387bb51}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.66\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bbwwv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bbwwv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.66,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.66,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.465: INFO: Pod "webserver-deployment-69b7448995-tkpgk" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-tkpgk webserver-deployment-69b7448995- deployment-9445  e8f65eda-8421-4d70-8647-09f3c10b789b 30383 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:42cc6f0c90fb89dde66b662cd8f4cbb031caa00e896238d40cbfa94b2d538573 cni.projectcalico.org/podIP:100.96.3.8/32 cni.projectcalico.org/podIPs:100.96.3.8/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387bd90 0xc00387bd91}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5j9mk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5j9mk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.465: INFO: Pod "webserver-deployment-69b7448995-tswnx" is not available:
&Pod{ObjectMeta:{webserver-deployment-69b7448995-tswnx webserver-deployment-69b7448995- deployment-9445  9577e9a9-103f-4efa-b607-33f73491d926 30384 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:f68c3064dff30dae1fd2bee91e2b26f6dcd7f473eec52d6aa448d32808739161 cni.projectcalico.org/podIP:100.96.2.65/32 cni.projectcalico.org/podIPs:100.96.2.65/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387bfa7 0xc00387bfa8}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d2w97,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d2w97,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.466: INFO: Pod "webserver-deployment-845c8977d9-2c9hr" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-2c9hr webserver-deployment-845c8977d9- deployment-9445  483e6fff-e8e8-438f-81e3-e5ec5aa75a88 30213 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ea61d39136627944c336eb3eca95f3db9fd188346d411cf456ef3842adfc9d5d cni.projectcalico.org/podIP:100.96.1.154/32 cni.projectcalico.org/podIPs:100.96.1.154/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de01c7 0xc005de01c8}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.154\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lg8nt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lg8nt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.154,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://968ab7d5ea2d6e2c0ac6f3fcbf682d4873f538a9bb94691b6494d3a7d3699529,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.154,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.466: INFO: Pod "webserver-deployment-845c8977d9-7cpbc" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-7cpbc webserver-deployment-845c8977d9- deployment-9445  46123079-86a5-4b70-9553-e9191bb909fc 30415 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:b2525b8812c288d5f9abe8ae25a791ac0b0346ff6360f3f8650fb1ba83c2502b cni.projectcalico.org/podIP:100.96.1.158/32 cni.projectcalico.org/podIPs:100.96.1.158/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de03d7 0xc005de03d8}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.158\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zhsbf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zhsbf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.158,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5f7422dd5411da0fed69dbd5e7377dce6d3895c6c7ba19282af97efe222dd113,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.158,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.466: INFO: Pod "webserver-deployment-845c8977d9-bqwmc" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-bqwmc webserver-deployment-845c8977d9- deployment-9445  707aa385-e983-47e2-a7d4-d508f5e85bc7 30391 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:7bdb582e67462057dd11303dd8669e2bcfd4012bd5f7bea29c480d0b7579efa7 cni.projectcalico.org/podIP:100.96.0.67/32 cni.projectcalico.org/podIPs:100.96.0.67/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de05f7 0xc005de05f8}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.67\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5x2m6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5x2m6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.67,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://be9b56af1b4b7abf39004bd443367150aac68c1f84e28bcfe51fda437e6e7ede,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.67,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.466: INFO: Pod "webserver-deployment-845c8977d9-c2xfx" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-c2xfx webserver-deployment-845c8977d9- deployment-9445  ccabb6eb-50a1-468e-a7ea-b95fed62a15e 30207 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:576e845ff19691776746c50ddcd8de7d3da1c18ea72709e0b0cef999c719cbcb cni.projectcalico.org/podIP:100.96.2.58/32 cni.projectcalico.org/podIPs:100.96.2.58/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de0800 0xc005de0801}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.58\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6z7w8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6z7w8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.58,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a818b72cd6e067662b372777f3851fb45d86e96f934f759ade912b138f8f8a3c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.58,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.466: INFO: Pod "webserver-deployment-845c8977d9-ch865" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ch865 webserver-deployment-845c8977d9- deployment-9445  54249da6-f662-40d8-9c3d-4cba72317bca 30390 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:c438590aebc95fe88426bd089f94d75a8f0a28dc28a0885671a214cf7d1e4b96 cni.projectcalico.org/podIP:100.96.0.68/32 cni.projectcalico.org/podIPs:100.96.0.68/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de0a20 0xc005de0a21}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.68\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kjtpr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kjtpr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.68,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://996eddf84c28d9c76a79477981e1b04732820a4eefee0fa10ce15282eeeade01,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.68,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.466: INFO: Pod "webserver-deployment-845c8977d9-f5wst" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-f5wst webserver-deployment-845c8977d9- deployment-9445  42cfa5cb-2450-4410-af78-ceec1be986c5 30402 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:422e1096ca24eac27a49679999e1eff4acd1222e3a1475becb1b9705a336705d cni.projectcalico.org/podIP:100.96.2.67/32 cni.projectcalico.org/podIPs:100.96.2.67/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de0c30 0xc005de0c31}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.67\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qf9c7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qf9c7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.67,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://4bfde6e71fdda38c35531f244134858246c182416efe5c29d0062f2772cfabdd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.67,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-gjt4c" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-gjt4c webserver-deployment-845c8977d9- deployment-9445  4c373783-833c-4387-9838-7b28f92b0bbe 30399 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:a6296b0df22cb0097f82a368209e24842a72e16695095cc11cee7347f81bfbda cni.projectcalico.org/podIP:100.96.3.9/32 cni.projectcalico.org/podIPs:100.96.3.9/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de0e40 0xc005de0e41}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.9\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xw2l7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xw2l7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:100.96.3.9,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1a2a4b9994badadcf8841c42cec73e188ed1bcd6bd88136ec7fe9569303e44e1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.9,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-hrcr2" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-hrcr2 webserver-deployment-845c8977d9- deployment-9445  8861618e-6d6f-4e40-8c72-147ead76034c 30418 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:828a0d5624b4878e4802962749e5cab3f2284d207d9bd27df1d6a70d63ec014e cni.projectcalico.org/podIP:100.96.1.156/32 cni.projectcalico.org/podIPs:100.96.1.156/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1050 0xc005de1051}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.156\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kvf5b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kvf5b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.156,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://75185e667125ba72973e2d09c99347f19d8c00d4bcc0e228bf49ba40440771e5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.156,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-ht2cw" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-ht2cw webserver-deployment-845c8977d9- deployment-9445  37913cd1-9419-4194-8031-9fea8b2ea87b 30408 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:c2de93745ce88a021fb653ff6116880515c5ba5da407011db490c49316de3caa cni.projectcalico.org/podIP:100.96.2.63/32 cni.projectcalico.org/podIPs:100.96.2.63/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1267 0xc005de1268}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.63\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7dlpx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7dlpx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.63,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f5362b2d833b16e733704cd3135a428366e155bfc58fa581009049d0bafa7dd4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.63,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-jhx74" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-jhx74 webserver-deployment-845c8977d9- deployment-9445  1fc3626c-a4e8-40e3-8e71-079665a49dcf 30405 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:4c92cc4e3708a7a7fd79bd506dfb2f04b3866764934f9cda9324aa91d7ac3d09 cni.projectcalico.org/podIP:100.96.2.64/32 cni.projectcalico.org/podIPs:100.96.2.64/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1470 0xc005de1471}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.64\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jvb85,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jvb85,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.64,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://29875502415dabea8b98fcc700a3a91bccc261474d1e0a01ae6e622be6ae5027,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-l7gtt" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-l7gtt webserver-deployment-845c8977d9- deployment-9445  3d90693d-b56f-4c47-b804-bdb064d08f10 30233 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:c940c816d4dabd6fbc4ad3e0b33c7c0de5c243e38cf9ed1ccc35b0406e0eb228 cni.projectcalico.org/podIP:100.96.3.4/32 cni.projectcalico.org/podIPs:100.96.3.4/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1690 0xc005de1691}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.4\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-49jlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-49jlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:100.96.3.4,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a9d69ddde25e2f7eae2a2bbcb020faca78b613ef201d155f0a7fe018f32aeb13,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.4,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-nlt72" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-nlt72 webserver-deployment-845c8977d9- deployment-9445  bc16f12d-7551-488a-bb89-bdfa5866630f 30204 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:9e3aa3851773feff984be0474cb5f06e57681e378cbe24e1910bef86ac17c7c8 cni.projectcalico.org/podIP:100.96.2.59/32 cni.projectcalico.org/podIPs:100.96.2.59/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de18a0 0xc005de18a1}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.59\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ns9ct,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ns9ct,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.59,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://71061e004379c9462cc1b402538cf746fa4b88eeee5ba5e3ae56acd00d200317,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.59,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-rsgz8" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-rsgz8 webserver-deployment-845c8977d9- deployment-9445  0d92e525-317f-4f3e-b845-27b6bc692c62 30190 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:f95dd8c109c5c49f1f41e61cc5a62481d377816d196b9f850b852a267dc3e696 cni.projectcalico.org/podIP:100.96.0.64/32 cni.projectcalico.org/podIPs:100.96.0.64/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1ab0 0xc005de1ab1}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.64\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rfjkz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rfjkz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.64,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://592f2569b5c771ea11cce5f7de48770eaf755209efb4f923f6b0d365a355bd4f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-t2mx4" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-t2mx4 webserver-deployment-845c8977d9- deployment-9445  6c5d9c6c-b748-4e52-9dd5-cce26f64a08e 30230 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:897726aecb419b6046a6ed51f1ce3f0b14c31d8f7ad2a2f547c584a2d1bb575d cni.projectcalico.org/podIP:100.96.3.5/32 cni.projectcalico.org/podIPs:100.96.3.5/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1cc0 0xc005de1cc1}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.5\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h9w8r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h9w8r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:100.96.3.5,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://77cb0079e633d5cddc8c295cb4665cbadccb26fdf35e90b081b743c7eb45e75d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.5,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.468: INFO: Pod "webserver-deployment-845c8977d9-vr2zs" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-vr2zs webserver-deployment-845c8977d9- deployment-9445  aa7b0993-bdb4-4516-b6d8-b7a20a4e87fc 30425 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:b1f360249acf68d4affb80368d24016c78784e441c92e1491647e349beef7eba cni.projectcalico.org/podIP:100.96.0.69/32 cni.projectcalico.org/podIPs:100.96.0.69/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1ed0 0xc005de1ed1}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.69\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rvcpk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rvcpk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.69,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1476a7669873e5499bd57df21782cde5fbe74ad193c214654139819783552b1f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.69,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.468: INFO: Pod "webserver-deployment-845c8977d9-wz5bc" is not available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-wz5bc webserver-deployment-845c8977d9- deployment-9445  8df8aa06-41e0-4c86-91fb-c97a738964d7 30397 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:9cda84f3b2d0171622c39f252f5b40a64c895eb536b82521d8f7be5d61820e61 cni.projectcalico.org/podIP:100.96.3.10/32 cni.projectcalico.org/podIPs:100.96.3.10/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005faa0f0 0xc005faa0f1}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6fhjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6fhjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.468: INFO: Pod "webserver-deployment-845c8977d9-x767h" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-x767h webserver-deployment-845c8977d9- deployment-9445  9e48c73d-6cc9-450a-a6ff-9eff9979aecd 30422 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:20c34d7b3de91bcde1a1b6915ccde6192cdfb83308900d45f6adce2296adc37b cni.projectcalico.org/podIP:100.96.0.71/32 cni.projectcalico.org/podIPs:100.96.0.71/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005faa2e7 0xc005faa2e8}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.71\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hxdh2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hxdh2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.71,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f2bee6ebc56fd4696b5fae063257171cab1989a9137960de7af63c689c719ac2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.71,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.468: INFO: Pod "webserver-deployment-845c8977d9-xf78h" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-xf78h webserver-deployment-845c8977d9- deployment-9445  b1a85bbd-d3b7-438d-a9b2-e2ad051e49ff 30193 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:30aae6844e59576ed890e65853fd1f0234a2a55186c5bb89b0e135be9d97f944 cni.projectcalico.org/podIP:100.96.0.62/32 cni.projectcalico.org/podIPs:100.96.0.62/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005faa500 0xc005faa501}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.62\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wwm69,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wwm69,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.62,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://113514cf58cd8c2814cfeb45a5421c8988ad3c851880ecb04b242f32952c847a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.468: INFO: Pod "webserver-deployment-845c8977d9-zlfp7" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zlfp7 webserver-deployment-845c8977d9- deployment-9445  c6fccedf-52bb-493b-bd72-5c95e2fd28de 30412 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:48b32bfcee9e7b56fb130b57139223ed82c660b43461db17520c1d7774e4bb30 cni.projectcalico.org/podIP:100.96.2.66/32 cni.projectcalico.org/podIPs:100.96.2.66/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005faa710 0xc005faa711}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.66\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2tm8f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2tm8f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.66,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://fc4cfe447eb8dd545a5789ae813f3956eb1135ab981d273e83df2fcbb81e0674,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.66,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:39:30.468: INFO: Pod "webserver-deployment-845c8977d9-zpf28" is available:
&Pod{ObjectMeta:{webserver-deployment-845c8977d9-zpf28 webserver-deployment-845c8977d9- deployment-9445  c0fa2a51-fd4c-43cb-870a-edf4bd204597 30210 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:64c90a61b5a0e09374bac090eb5373ec5661d5061d7649eb8d83f7bbcf147b93 cni.projectcalico.org/podIP:100.96.1.153/32 cni.projectcalico.org/podIPs:100.96.1.153/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005faa930 0xc005faa931}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.153\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6l66h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6l66h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.153,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://14da3a8619fa5340c19ea9233dd828a80cd18710ffc0a356b589eb1f906222d7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.153,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 26 11:39:30.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9445" for this suite. 04/26/24 11:39:30.479
{"msg":"PASSED [sig-apps] Deployment deployment should support proportional scaling [Conformance]","completed":121,"skipped":2106,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.255 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  test/e2e/apps/deployment.go:160

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:39:20.233
    Apr 26 11:39:20.233: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename deployment 04/26/24 11:39:20.234
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:20.254
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:20.261
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should support proportional scaling [Conformance]
      test/e2e/apps/deployment.go:160
    Apr 26 11:39:20.269: INFO: Creating deployment "webserver-deployment"
    Apr 26 11:39:20.276: INFO: Waiting for observed generation 1
    Apr 26 11:39:22.298: INFO: Waiting for all required pods to come up
    Apr 26 11:39:22.305: INFO: Pod name httpd: Found 10 pods out of 10
    STEP: ensuring each pod is running 04/26/24 11:39:22.305
    Apr 26 11:39:22.305: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-t2mx4" in namespace "deployment-9445" to be "running"
    Apr 26 11:39:22.305: INFO: Waiting up to 5m0s for pod "webserver-deployment-845c8977d9-l7gtt" in namespace "deployment-9445" to be "running"
    Apr 26 11:39:22.309: INFO: Pod "webserver-deployment-845c8977d9-t2mx4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.43199ms
    Apr 26 11:39:22.310: INFO: Pod "webserver-deployment-845c8977d9-l7gtt": Phase="Pending", Reason="", readiness=false. Elapsed: 4.536205ms
    Apr 26 11:39:24.323: INFO: Pod "webserver-deployment-845c8977d9-t2mx4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018052866s
    Apr 26 11:39:24.323: INFO: Pod "webserver-deployment-845c8977d9-l7gtt": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018060641s
    Apr 26 11:39:26.318: INFO: Pod "webserver-deployment-845c8977d9-t2mx4": Phase="Running", Reason="", readiness=true. Elapsed: 4.013410816s
    Apr 26 11:39:26.319: INFO: Pod "webserver-deployment-845c8977d9-t2mx4" satisfied condition "running"
    Apr 26 11:39:26.319: INFO: Pod "webserver-deployment-845c8977d9-l7gtt": Phase="Running", Reason="", readiness=true. Elapsed: 4.013842942s
    Apr 26 11:39:26.319: INFO: Pod "webserver-deployment-845c8977d9-l7gtt" satisfied condition "running"
    Apr 26 11:39:26.319: INFO: Waiting for deployment "webserver-deployment" to complete
    Apr 26 11:39:26.329: INFO: Updating deployment "webserver-deployment" with a non-existent image
    Apr 26 11:39:26.340: INFO: Updating deployment webserver-deployment
    Apr 26 11:39:26.340: INFO: Waiting for observed generation 2
    Apr 26 11:39:28.356: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
    Apr 26 11:39:28.361: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
    Apr 26 11:39:28.366: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Apr 26 11:39:28.382: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
    Apr 26 11:39:28.382: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
    Apr 26 11:39:28.385: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
    Apr 26 11:39:28.392: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
    Apr 26 11:39:28.392: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
    Apr 26 11:39:28.402: INFO: Updating deployment webserver-deployment
    Apr 26 11:39:28.402: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
    Apr 26 11:39:28.414: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
    Apr 26 11:39:30.427: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 26 11:39:30.439: INFO: Deployment "webserver-deployment":
    &Deployment{ObjectMeta:{webserver-deployment  deployment-9445  79c792f1-7e96-45ac-8a14-2a009b788b44 30427 3 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:39:30 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00387a178 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:19,UnavailableReplicas:14,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2024-04-26 11:39:28 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-69b7448995" is progressing.,LastUpdateTime:2024-04-26 11:39:30 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,},},ReadyReplicas:19,CollisionCount:nil,},}

    Apr 26 11:39:30.444: INFO: New ReplicaSet "webserver-deployment-69b7448995" of Deployment "webserver-deployment":
    &ReplicaSet{ObjectMeta:{webserver-deployment-69b7448995  deployment-9445  30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 30370 3 2024-04-26 11:39:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 79c792f1-7e96-45ac-8a14-2a009b788b44 0xc001727ba7 0xc001727ba8}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"79c792f1-7e96-45ac-8a14-2a009b788b44\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 69b7448995,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[] [] [] []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001727c58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 26 11:39:30.444: INFO: All old ReplicaSets of Deployment "webserver-deployment":
    Apr 26 11:39:30.444: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-845c8977d9  deployment-9445  8069883b-6620-4e6d-ab11-501ea2128081 30426 3 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 79c792f1-7e96-45ac-8a14-2a009b788b44 0xc001727dd7 0xc001727dd8}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"79c792f1-7e96-45ac-8a14-2a009b788b44\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:39:30 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc001727e78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:19,AvailableReplicas:19,Conditions:[]ReplicaSetCondition{},},}
    Apr 26 11:39:30.463: INFO: Pod "webserver-deployment-69b7448995-5xrxq" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-5xrxq webserver-deployment-69b7448995- deployment-9445  befd071e-9a1e-4a3f-bf8b-c397703465b1 30386 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:9d6f312daee33b8b3827057315b7aa49c93a6af3e139a65190bfaeed25f93f97 cni.projectcalico.org/podIP:100.96.0.70/32 cni.projectcalico.org/podIPs:100.96.0.70/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387a597 0xc00387a598}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jnw9l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jnw9l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.463: INFO: Pod "webserver-deployment-69b7448995-7sww8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-7sww8 webserver-deployment-69b7448995- deployment-9445  a54af357-d499-4ac9-b913-5f3b0c7b98f0 30378 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:1b45c0a1f81c175bfb300f0022453c3452f97919504d50bb3455fb34a24f69a3 cni.projectcalico.org/podIP:100.96.1.157/32 cni.projectcalico.org/podIPs:100.96.1.157/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387a7b7 0xc00387a7b8}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g4ccq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g4ccq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.463: INFO: Pod "webserver-deployment-69b7448995-8nzrm" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-8nzrm webserver-deployment-69b7448995- deployment-9445  7154b17c-1df6-495f-82f5-0f52f2282e18 30369 0 2024-04-26 11:39:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:2dd814b7fa7ddcbd28b354720e4268d30c8707cb413bda2ec642d06d9c4097e6 cni.projectcalico.org/podIP:100.96.1.155/32 cni.projectcalico.org/podIPs:100.96.1.155/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387a9c7 0xc00387a9c8}] [] [{calico Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.155\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2t8hr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2t8hr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.155,StartTime:2024-04-26 11:39:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.155,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.464: INFO: Pod "webserver-deployment-69b7448995-c5flt" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-c5flt webserver-deployment-69b7448995- deployment-9445  59f32995-cdd8-4828-b5e4-0253c6258014 30387 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:5b311b465f7365d0c551d7b48c6c9ca547a2500f6180d19bb66da14508490dbb cni.projectcalico.org/podIP:100.96.2.68/32 cni.projectcalico.org/podIPs:100.96.2.68/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387ac07 0xc00387ac08}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-9btdn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-9btdn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.464: INFO: Pod "webserver-deployment-69b7448995-ftksd" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-ftksd webserver-deployment-69b7448995- deployment-9445  85dd00a2-5ac7-4e04-b061-c2267c67bd17 30366 0 2024-04-26 11:39:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:d264abb0bb4c58aab1bb49290f7de8f1e42d501fe7eebe4a805c35f3973ac4b1 cni.projectcalico.org/podIP:100.96.2.61/32 cni.projectcalico.org/podIPs:100.96.2.61/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387ae27 0xc00387ae28}] [] [{calico Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.61\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lj2hw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lj2hw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.61,StartTime:2024-04-26 11:39:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.61,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.464: INFO: Pod "webserver-deployment-69b7448995-fv7g8" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-fv7g8 webserver-deployment-69b7448995- deployment-9445  6b7f1151-9d59-4ea6-b498-a8275d2c3a73 30367 0 2024-04-26 11:39:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:5012799dbdeffc52a5b7f6d6ba03f41873204f2fabe19a125e6bc3dd8e94c290 cni.projectcalico.org/podIP:100.96.2.62/32 cni.projectcalico.org/podIPs:100.96.2.62/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387b060 0xc00387b061}] [] [{calico Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.62\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6mphc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6mphc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.62,StartTime:2024-04-26 11:39:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.464: INFO: Pod "webserver-deployment-69b7448995-hnf8q" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-hnf8q webserver-deployment-69b7448995- deployment-9445  8c1456d2-b498-4a59-849a-9c004b2df69a 30374 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:695c0dd6e0db68c8be2fcc0a472f208b232df62c58aa7e0058a9fe9f072eac7c cni.projectcalico.org/podIP:100.96.3.7/32 cni.projectcalico.org/podIPs:100.96.3.7/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387b2b0 0xc00387b2b1}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-sm8kt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-sm8kt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.464: INFO: Pod "webserver-deployment-69b7448995-jbj2v" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jbj2v webserver-deployment-69b7448995- deployment-9445  81b1b3c3-35a0-40cc-b314-37fe1d0f52a6 30350 0 2024-04-26 11:39:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:473e9dfaf4a6d27eb9e45d62f839657d47952d0856cd965c629b453989359724 cni.projectcalico.org/podIP:100.96.3.6/32 cni.projectcalico.org/podIPs:100.96.3.6/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387b4c7 0xc00387b4c8}] [] [{calico Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.6\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-g72bl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-g72bl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:100.96.3.6,StartTime:2024-04-26 11:39:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.6,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.465: INFO: Pod "webserver-deployment-69b7448995-jq2vq" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-jq2vq webserver-deployment-69b7448995- deployment-9445  36ee443e-968f-4aa2-a3aa-e2c56afd33df 30381 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:9d442e3f1b79b6fa846e7b2532a5ae1f47aa819c62ed49216bb5e44341c82a99 cni.projectcalico.org/podIP:100.96.1.159/32 cni.projectcalico.org/podIPs:100.96.1.159/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387b700 0xc00387b701}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bkkjf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bkkjf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.465: INFO: Pod "webserver-deployment-69b7448995-k95vx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-k95vx webserver-deployment-69b7448995- deployment-9445  e06f3208-b81d-48a1-8003-6cbfdd91feab 30292 0 2024-04-26 11:39:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:93253a0b9158aa769ae42b473a5895cddb2cc486148564280a7f9f8643f68fae cni.projectcalico.org/podIP:100.96.0.65/32 cni.projectcalico.org/podIPs:100.96.0.65/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387b917 0xc00387b918}] [] [{calico Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:26 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.65\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-z95z7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-z95z7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.65,StartTime:2024-04-26 11:39:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.65,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.465: INFO: Pod "webserver-deployment-69b7448995-l9rst" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-l9rst webserver-deployment-69b7448995- deployment-9445  be65653a-0639-474b-a7a8-42b8a21658cf 30428 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:df843bae2980bc84526ed915fa7bd968cac844aead9f675d7e27ad7f981b8da2 cni.projectcalico.org/podIP:100.96.0.66/32 cni.projectcalico.org/podIPs:100.96.0.66/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387bb50 0xc00387bb51}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.66\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-bbwwv,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-bbwwv,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.66,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.66,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.465: INFO: Pod "webserver-deployment-69b7448995-tkpgk" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-tkpgk webserver-deployment-69b7448995- deployment-9445  e8f65eda-8421-4d70-8647-09f3c10b789b 30383 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:42cc6f0c90fb89dde66b662cd8f4cbb031caa00e896238d40cbfa94b2d538573 cni.projectcalico.org/podIP:100.96.3.8/32 cni.projectcalico.org/podIPs:100.96.3.8/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387bd90 0xc00387bd91}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5j9mk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5j9mk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.465: INFO: Pod "webserver-deployment-69b7448995-tswnx" is not available:
    &Pod{ObjectMeta:{webserver-deployment-69b7448995-tswnx webserver-deployment-69b7448995- deployment-9445  9577e9a9-103f-4efa-b607-33f73491d926 30384 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:69b7448995] map[cni.projectcalico.org/containerID:f68c3064dff30dae1fd2bee91e2b26f6dcd7f473eec52d6aa448d32808739161 cni.projectcalico.org/podIP:100.96.2.65/32 cni.projectcalico.org/podIPs:100.96.2.65/32] [{apps/v1 ReplicaSet webserver-deployment-69b7448995 30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b 0xc00387bfa7 0xc00387bfa8}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"30100bb4-f0a9-4d4d-8040-4cadb0c0ee1b\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-d2w97,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-d2w97,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.466: INFO: Pod "webserver-deployment-845c8977d9-2c9hr" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-2c9hr webserver-deployment-845c8977d9- deployment-9445  483e6fff-e8e8-438f-81e3-e5ec5aa75a88 30213 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:ea61d39136627944c336eb3eca95f3db9fd188346d411cf456ef3842adfc9d5d cni.projectcalico.org/podIP:100.96.1.154/32 cni.projectcalico.org/podIPs:100.96.1.154/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de01c7 0xc005de01c8}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.154\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-lg8nt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-lg8nt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.154,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://968ab7d5ea2d6e2c0ac6f3fcbf682d4873f538a9bb94691b6494d3a7d3699529,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.154,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.466: INFO: Pod "webserver-deployment-845c8977d9-7cpbc" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-7cpbc webserver-deployment-845c8977d9- deployment-9445  46123079-86a5-4b70-9553-e9191bb909fc 30415 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:b2525b8812c288d5f9abe8ae25a791ac0b0346ff6360f3f8650fb1ba83c2502b cni.projectcalico.org/podIP:100.96.1.158/32 cni.projectcalico.org/podIPs:100.96.1.158/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de03d7 0xc005de03d8}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.158\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-zhsbf,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-zhsbf,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.158,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://5f7422dd5411da0fed69dbd5e7377dce6d3895c6c7ba19282af97efe222dd113,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.158,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.466: INFO: Pod "webserver-deployment-845c8977d9-bqwmc" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-bqwmc webserver-deployment-845c8977d9- deployment-9445  707aa385-e983-47e2-a7d4-d508f5e85bc7 30391 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:7bdb582e67462057dd11303dd8669e2bcfd4012bd5f7bea29c480d0b7579efa7 cni.projectcalico.org/podIP:100.96.0.67/32 cni.projectcalico.org/podIPs:100.96.0.67/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de05f7 0xc005de05f8}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.67\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5x2m6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5x2m6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.67,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://be9b56af1b4b7abf39004bd443367150aac68c1f84e28bcfe51fda437e6e7ede,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.67,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.466: INFO: Pod "webserver-deployment-845c8977d9-c2xfx" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-c2xfx webserver-deployment-845c8977d9- deployment-9445  ccabb6eb-50a1-468e-a7ea-b95fed62a15e 30207 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:576e845ff19691776746c50ddcd8de7d3da1c18ea72709e0b0cef999c719cbcb cni.projectcalico.org/podIP:100.96.2.58/32 cni.projectcalico.org/podIPs:100.96.2.58/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de0800 0xc005de0801}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.58\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6z7w8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6z7w8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.58,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a818b72cd6e067662b372777f3851fb45d86e96f934f759ade912b138f8f8a3c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.58,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.466: INFO: Pod "webserver-deployment-845c8977d9-ch865" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ch865 webserver-deployment-845c8977d9- deployment-9445  54249da6-f662-40d8-9c3d-4cba72317bca 30390 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:c438590aebc95fe88426bd089f94d75a8f0a28dc28a0885671a214cf7d1e4b96 cni.projectcalico.org/podIP:100.96.0.68/32 cni.projectcalico.org/podIPs:100.96.0.68/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de0a20 0xc005de0a21}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.68\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kjtpr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kjtpr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.68,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://996eddf84c28d9c76a79477981e1b04732820a4eefee0fa10ce15282eeeade01,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.68,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.466: INFO: Pod "webserver-deployment-845c8977d9-f5wst" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-f5wst webserver-deployment-845c8977d9- deployment-9445  42cfa5cb-2450-4410-af78-ceec1be986c5 30402 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:422e1096ca24eac27a49679999e1eff4acd1222e3a1475becb1b9705a336705d cni.projectcalico.org/podIP:100.96.2.67/32 cni.projectcalico.org/podIPs:100.96.2.67/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de0c30 0xc005de0c31}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.67\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-qf9c7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-qf9c7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.67,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://4bfde6e71fdda38c35531f244134858246c182416efe5c29d0062f2772cfabdd,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.67,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-gjt4c" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-gjt4c webserver-deployment-845c8977d9- deployment-9445  4c373783-833c-4387-9838-7b28f92b0bbe 30399 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:a6296b0df22cb0097f82a368209e24842a72e16695095cc11cee7347f81bfbda cni.projectcalico.org/podIP:100.96.3.9/32 cni.projectcalico.org/podIPs:100.96.3.9/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de0e40 0xc005de0e41}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.9\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-xw2l7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-xw2l7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:100.96.3.9,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1a2a4b9994badadcf8841c42cec73e188ed1bcd6bd88136ec7fe9569303e44e1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.9,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-hrcr2" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-hrcr2 webserver-deployment-845c8977d9- deployment-9445  8861618e-6d6f-4e40-8c72-147ead76034c 30418 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:828a0d5624b4878e4802962749e5cab3f2284d207d9bd27df1d6a70d63ec014e cni.projectcalico.org/podIP:100.96.1.156/32 cni.projectcalico.org/podIPs:100.96.1.156/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1050 0xc005de1051}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.156\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-kvf5b,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-kvf5b,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.156,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://75185e667125ba72973e2d09c99347f19d8c00d4bcc0e228bf49ba40440771e5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.156,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-ht2cw" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-ht2cw webserver-deployment-845c8977d9- deployment-9445  37913cd1-9419-4194-8031-9fea8b2ea87b 30408 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:c2de93745ce88a021fb653ff6116880515c5ba5da407011db490c49316de3caa cni.projectcalico.org/podIP:100.96.2.63/32 cni.projectcalico.org/podIPs:100.96.2.63/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1267 0xc005de1268}] [] [{calico Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.63\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-7dlpx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-7dlpx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.63,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f5362b2d833b16e733704cd3135a428366e155bfc58fa581009049d0bafa7dd4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.63,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-jhx74" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-jhx74 webserver-deployment-845c8977d9- deployment-9445  1fc3626c-a4e8-40e3-8e71-079665a49dcf 30405 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:4c92cc4e3708a7a7fd79bd506dfb2f04b3866764934f9cda9324aa91d7ac3d09 cni.projectcalico.org/podIP:100.96.2.64/32 cni.projectcalico.org/podIPs:100.96.2.64/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1470 0xc005de1471}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.64\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-jvb85,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-jvb85,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.64,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://29875502415dabea8b98fcc700a3a91bccc261474d1e0a01ae6e622be6ae5027,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-l7gtt" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-l7gtt webserver-deployment-845c8977d9- deployment-9445  3d90693d-b56f-4c47-b804-bdb064d08f10 30233 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:c940c816d4dabd6fbc4ad3e0b33c7c0de5c243e38cf9ed1ccc35b0406e0eb228 cni.projectcalico.org/podIP:100.96.3.4/32 cni.projectcalico.org/podIPs:100.96.3.4/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1690 0xc005de1691}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.4\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-49jlw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-49jlw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:100.96.3.4,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://a9d69ddde25e2f7eae2a2bbcb020faca78b613ef201d155f0a7fe018f32aeb13,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.4,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-nlt72" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-nlt72 webserver-deployment-845c8977d9- deployment-9445  bc16f12d-7551-488a-bb89-bdfa5866630f 30204 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:9e3aa3851773feff984be0474cb5f06e57681e378cbe24e1910bef86ac17c7c8 cni.projectcalico.org/podIP:100.96.2.59/32 cni.projectcalico.org/podIPs:100.96.2.59/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de18a0 0xc005de18a1}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.59\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-ns9ct,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-ns9ct,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.59,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://71061e004379c9462cc1b402538cf746fa4b88eeee5ba5e3ae56acd00d200317,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.59,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-rsgz8" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-rsgz8 webserver-deployment-845c8977d9- deployment-9445  0d92e525-317f-4f3e-b845-27b6bc692c62 30190 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:f95dd8c109c5c49f1f41e61cc5a62481d377816d196b9f850b852a267dc3e696 cni.projectcalico.org/podIP:100.96.0.64/32 cni.projectcalico.org/podIPs:100.96.0.64/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1ab0 0xc005de1ab1}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.64\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rfjkz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rfjkz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.64,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://592f2569b5c771ea11cce5f7de48770eaf755209efb4f923f6b0d365a355bd4f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.467: INFO: Pod "webserver-deployment-845c8977d9-t2mx4" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-t2mx4 webserver-deployment-845c8977d9- deployment-9445  6c5d9c6c-b748-4e52-9dd5-cce26f64a08e 30230 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:897726aecb419b6046a6ed51f1ce3f0b14c31d8f7ad2a2f547c584a2d1bb575d cni.projectcalico.org/podIP:100.96.3.5/32 cni.projectcalico.org/podIPs:100.96.3.5/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1cc0 0xc005de1cc1}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:24 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.5\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-h9w8r,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-h9w8r,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:100.96.3.5,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://77cb0079e633d5cddc8c295cb4665cbadccb26fdf35e90b081b743c7eb45e75d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.3.5,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.468: INFO: Pod "webserver-deployment-845c8977d9-vr2zs" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-vr2zs webserver-deployment-845c8977d9- deployment-9445  aa7b0993-bdb4-4516-b6d8-b7a20a4e87fc 30425 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:b1f360249acf68d4affb80368d24016c78784e441c92e1491647e349beef7eba cni.projectcalico.org/podIP:100.96.0.69/32 cni.projectcalico.org/podIPs:100.96.0.69/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005de1ed0 0xc005de1ed1}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.69\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-rvcpk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-rvcpk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.69,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://1476a7669873e5499bd57df21782cde5fbe74ad193c214654139819783552b1f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.69,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.468: INFO: Pod "webserver-deployment-845c8977d9-wz5bc" is not available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-wz5bc webserver-deployment-845c8977d9- deployment-9445  8df8aa06-41e0-4c86-91fb-c97a738964d7 30397 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:9cda84f3b2d0171622c39f252f5b40a64c895eb536b82521d8f7be5d61820e61 cni.projectcalico.org/podIP:100.96.3.10/32 cni.projectcalico.org/podIPs:100.96.3.10/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005faa0f0 0xc005faa0f1}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status} {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6fhjt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6fhjt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.152,PodIP:,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.468: INFO: Pod "webserver-deployment-845c8977d9-x767h" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-x767h webserver-deployment-845c8977d9- deployment-9445  9e48c73d-6cc9-450a-a6ff-9eff9979aecd 30422 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:20c34d7b3de91bcde1a1b6915ccde6192cdfb83308900d45f6adce2296adc37b cni.projectcalico.org/podIP:100.96.0.71/32 cni.projectcalico.org/podIPs:100.96.0.71/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005faa2e7 0xc005faa2e8}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:30 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.71\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-hxdh2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-hxdh2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.71,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://f2bee6ebc56fd4696b5fae063257171cab1989a9137960de7af63c689c719ac2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.71,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.468: INFO: Pod "webserver-deployment-845c8977d9-xf78h" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-xf78h webserver-deployment-845c8977d9- deployment-9445  b1a85bbd-d3b7-438d-a9b2-e2ad051e49ff 30193 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:30aae6844e59576ed890e65853fd1f0234a2a55186c5bb89b0e135be9d97f944 cni.projectcalico.org/podIP:100.96.0.62/32 cni.projectcalico.org/podIPs:100.96.0.62/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005faa500 0xc005faa501}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.62\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wwm69,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wwm69,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.1.183,PodIP:100.96.0.62,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://113514cf58cd8c2814cfeb45a5421c8988ad3c851880ecb04b242f32952c847a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.0.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.468: INFO: Pod "webserver-deployment-845c8977d9-zlfp7" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zlfp7 webserver-deployment-845c8977d9- deployment-9445  c6fccedf-52bb-493b-bd72-5c95e2fd28de 30412 0 2024-04-26 11:39:28 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:48b32bfcee9e7b56fb130b57139223ed82c660b43461db17520c1d7774e4bb30 cni.projectcalico.org/podIP:100.96.2.66/32 cni.projectcalico.org/podIPs:100.96.2.66/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005faa710 0xc005faa711}] [] [{kube-controller-manager Update v1 2024-04-26 11:39:28 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:39:29 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.66\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-2tm8f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-2tm8f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:28 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.121,PodIP:100.96.2.66,StartTime:2024-04-26 11:39:28 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:29 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://fc4cfe447eb8dd545a5789ae813f3956eb1135ab981d273e83df2fcbb81e0674,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.2.66,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:39:30.468: INFO: Pod "webserver-deployment-845c8977d9-zpf28" is available:
    &Pod{ObjectMeta:{webserver-deployment-845c8977d9-zpf28 webserver-deployment-845c8977d9- deployment-9445  c0fa2a51-fd4c-43cb-870a-edf4bd204597 30210 0 2024-04-26 11:39:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:64c90a61b5a0e09374bac090eb5373ec5661d5061d7649eb8d83f7bbcf147b93 cni.projectcalico.org/podIP:100.96.1.153/32 cni.projectcalico.org/podIPs:100.96.1.153/32] [{apps/v1 ReplicaSet webserver-deployment-845c8977d9 8069883b-6620-4e6d-ab11-501ea2128081 0xc005faa930 0xc005faa931}] [] [{calico Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:39:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8069883b-6620-4e6d-ab11-501ea2128081\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:39:21 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.153\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-6l66h,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-6l66h,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:21 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:39:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.153,StartTime:2024-04-26 11:39:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:39:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://14da3a8619fa5340c19ea9233dd828a80cd18710ffc0a356b589eb1f906222d7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.153,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 26 11:39:30.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-9445" for this suite. 04/26/24 11:39:30.479
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:39:30.491
Apr 26 11:39:30.491: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:39:30.492
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:30.526
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:30.532
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55
STEP: Creating projection with secret that has name projected-secret-test-4d221753-a78d-4eb9-a10b-b73092c91434 04/26/24 11:39:30.539
STEP: Creating a pod to test consume secrets 04/26/24 11:39:30.546
Apr 26 11:39:30.583: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d" in namespace "projected-1405" to be "Succeeded or Failed"
Apr 26 11:39:30.594: INFO: Pod "pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.960848ms
Apr 26 11:39:32.606: INFO: Pod "pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022496259s
Apr 26 11:39:34.606: INFO: Pod "pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022409224s
STEP: Saw pod success 04/26/24 11:39:34.606
Apr 26 11:39:34.606: INFO: Pod "pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d" satisfied condition "Succeeded or Failed"
Apr 26 11:39:34.613: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d container projected-secret-volume-test: <nil>
STEP: delete the pod 04/26/24 11:39:34.666
Apr 26 11:39:34.679: INFO: Waiting for pod pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d to disappear
Apr 26 11:39:34.684: INFO: Pod pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 26 11:39:34.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1405" for this suite. 04/26/24 11:39:34.693
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":122,"skipped":2108,"failed":0}
------------------------------
â€¢ [4.210 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:39:30.491
    Apr 26 11:39:30.491: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:39:30.492
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:30.526
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:30.532
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:55
    STEP: Creating projection with secret that has name projected-secret-test-4d221753-a78d-4eb9-a10b-b73092c91434 04/26/24 11:39:30.539
    STEP: Creating a pod to test consume secrets 04/26/24 11:39:30.546
    Apr 26 11:39:30.583: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d" in namespace "projected-1405" to be "Succeeded or Failed"
    Apr 26 11:39:30.594: INFO: Pod "pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d": Phase="Pending", Reason="", readiness=false. Elapsed: 10.960848ms
    Apr 26 11:39:32.606: INFO: Pod "pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022496259s
    Apr 26 11:39:34.606: INFO: Pod "pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022409224s
    STEP: Saw pod success 04/26/24 11:39:34.606
    Apr 26 11:39:34.606: INFO: Pod "pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d" satisfied condition "Succeeded or Failed"
    Apr 26 11:39:34.613: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 11:39:34.666
    Apr 26 11:39:34.679: INFO: Waiting for pod pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d to disappear
    Apr 26 11:39:34.684: INFO: Pod pod-projected-secrets-1a34fae6-44b5-47d9-9fa6-cf5c0814cd7d no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 26 11:39:34.684: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1405" for this suite. 04/26/24 11:39:34.693
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:39:34.701
Apr 26 11:39:34.701: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 11:39:34.702
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:34.721
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:34.727
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 11:39:34.753
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:39:34.983
STEP: Deploying the webhook pod 04/26/24 11:39:34.992
STEP: Wait for the deployment to be ready 04/26/24 11:39:35.004
Apr 26 11:39:35.017: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 11:39:37.032
STEP: Verifying the service has paired with the endpoint 04/26/24 11:39:37.051
Apr 26 11:39:38.052: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263
STEP: Registering the mutating pod webhook via the AdmissionRegistration API 04/26/24 11:39:38.061
STEP: create a pod that should be updated by the webhook 04/26/24 11:39:38.186
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:39:38.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6395" for this suite. 04/26/24 11:39:38.383
STEP: Destroying namespace "webhook-6395-markers" for this suite. 04/26/24 11:39:38.4
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]","completed":123,"skipped":2115,"failed":0}
------------------------------
â€¢ [3.966 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  test/e2e/apimachinery/webhook.go:263

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:39:34.701
    Apr 26 11:39:34.701: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 11:39:34.702
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:34.721
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:34.727
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 11:39:34.753
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:39:34.983
    STEP: Deploying the webhook pod 04/26/24 11:39:34.992
    STEP: Wait for the deployment to be ready 04/26/24 11:39:35.004
    Apr 26 11:39:35.017: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 11:39:37.032
    STEP: Verifying the service has paired with the endpoint 04/26/24 11:39:37.051
    Apr 26 11:39:38.052: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate pod and apply defaults after mutation [Conformance]
      test/e2e/apimachinery/webhook.go:263
    STEP: Registering the mutating pod webhook via the AdmissionRegistration API 04/26/24 11:39:38.061
    STEP: create a pod that should be updated by the webhook 04/26/24 11:39:38.186
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:39:38.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-6395" for this suite. 04/26/24 11:39:38.383
    STEP: Destroying namespace "webhook-6395-markers" for this suite. 04/26/24 11:39:38.4
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:39:38.667
Apr 26 11:39:38.667: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 11:39:38.669
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:38.686
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:38.703
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206
STEP: Creating a pod to test emptydir 0666 on node default medium 04/26/24 11:39:38.716
Apr 26 11:39:38.730: INFO: Waiting up to 5m0s for pod "pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f" in namespace "emptydir-885" to be "Succeeded or Failed"
Apr 26 11:39:38.735: INFO: Pod "pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.671048ms
Apr 26 11:39:40.740: INFO: Pod "pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010149795s
Apr 26 11:39:42.742: INFO: Pod "pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012008207s
STEP: Saw pod success 04/26/24 11:39:42.742
Apr 26 11:39:42.742: INFO: Pod "pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f" satisfied condition "Succeeded or Failed"
Apr 26 11:39:42.747: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f container test-container: <nil>
STEP: delete the pod 04/26/24 11:39:42.762
Apr 26 11:39:42.775: INFO: Waiting for pod pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f to disappear
Apr 26 11:39:42.779: INFO: Pod pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 11:39:42.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-885" for this suite. 04/26/24 11:39:42.792
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":124,"skipped":2119,"failed":0}
------------------------------
â€¢ [4.131 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:39:38.667
    Apr 26 11:39:38.667: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 11:39:38.669
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:38.686
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:38.703
    [It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:206
    STEP: Creating a pod to test emptydir 0666 on node default medium 04/26/24 11:39:38.716
    Apr 26 11:39:38.730: INFO: Waiting up to 5m0s for pod "pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f" in namespace "emptydir-885" to be "Succeeded or Failed"
    Apr 26 11:39:38.735: INFO: Pod "pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.671048ms
    Apr 26 11:39:40.740: INFO: Pod "pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010149795s
    Apr 26 11:39:42.742: INFO: Pod "pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012008207s
    STEP: Saw pod success 04/26/24 11:39:42.742
    Apr 26 11:39:42.742: INFO: Pod "pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f" satisfied condition "Succeeded or Failed"
    Apr 26 11:39:42.747: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f container test-container: <nil>
    STEP: delete the pod 04/26/24 11:39:42.762
    Apr 26 11:39:42.775: INFO: Waiting for pod pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f to disappear
    Apr 26 11:39:42.779: INFO: Pod pod-4c03a754-04c0-4a74-af62-9bfcbcf5729f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 11:39:42.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-885" for this suite. 04/26/24 11:39:42.792
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version
  should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:39:42.799
Apr 26 11:39:42.799: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 11:39:42.8
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:42.818
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:42.825
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check is all data is printed  [Conformance]
  test/e2e/kubectl/kubectl.go:1683
Apr 26 11:39:42.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-5975 version'
Apr 26 11:39:42.988: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
Apr 26 11:39:42.988: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.16\", GitCommit:\"c5f43560a4f98f2af3743a59299fb79f07924373\", GitTreeState:\"clean\", BuildDate:\"2023-11-15T22:39:12Z\", GoVersion:\"go1.20.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.16\", GitCommit:\"c5f43560a4f98f2af3743a59299fb79f07924373\", GitTreeState:\"clean\", BuildDate:\"2023-11-15T22:28:05Z\", GoVersion:\"go1.20.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 11:39:42.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5975" for this suite. 04/26/24 11:39:43
{"msg":"PASSED [sig-cli] Kubectl client Kubectl version should check is all data is printed  [Conformance]","completed":125,"skipped":2136,"failed":0}
------------------------------
â€¢ [0.207 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl version
  test/e2e/kubectl/kubectl.go:1677
    should check is all data is printed  [Conformance]
    test/e2e/kubectl/kubectl.go:1683

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:39:42.799
    Apr 26 11:39:42.799: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 11:39:42.8
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:42.818
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:42.825
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check is all data is printed  [Conformance]
      test/e2e/kubectl/kubectl.go:1683
    Apr 26 11:39:42.831: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-5975 version'
    Apr 26 11:39:42.988: INFO: stderr: "WARNING: This version information is deprecated and will be replaced with the output from kubectl version --short.  Use --output=yaml|json to get the full version.\n"
    Apr 26 11:39:42.988: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.16\", GitCommit:\"c5f43560a4f98f2af3743a59299fb79f07924373\", GitTreeState:\"clean\", BuildDate:\"2023-11-15T22:39:12Z\", GoVersion:\"go1.20.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nKustomize Version: v4.5.7\nServer Version: version.Info{Major:\"1\", Minor:\"25\", GitVersion:\"v1.25.16\", GitCommit:\"c5f43560a4f98f2af3743a59299fb79f07924373\", GitTreeState:\"clean\", BuildDate:\"2023-11-15T22:28:05Z\", GoVersion:\"go1.20.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 11:39:42.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5975" for this suite. 04/26/24 11:39:43
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:39:43.007
Apr 26 11:39:43.007: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename var-expansion 04/26/24 11:39:43.008
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:43.024
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:43.029
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72
STEP: Creating a pod to test substitution in container's command 04/26/24 11:39:43.034
Apr 26 11:39:43.049: INFO: Waiting up to 5m0s for pod "var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97" in namespace "var-expansion-2646" to be "Succeeded or Failed"
Apr 26 11:39:43.055: INFO: Pod "var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97": Phase="Pending", Reason="", readiness=false. Elapsed: 5.559209ms
Apr 26 11:39:45.063: INFO: Pod "var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013906967s
Apr 26 11:39:47.061: INFO: Pod "var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012201992s
STEP: Saw pod success 04/26/24 11:39:47.061
Apr 26 11:39:47.061: INFO: Pod "var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97" satisfied condition "Succeeded or Failed"
Apr 26 11:39:47.067: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97 container dapi-container: <nil>
STEP: delete the pod 04/26/24 11:39:47.081
Apr 26 11:39:47.094: INFO: Waiting for pod var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97 to disappear
Apr 26 11:39:47.102: INFO: Pod var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 26 11:39:47.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2646" for this suite. 04/26/24 11:39:47.113
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]","completed":126,"skipped":2150,"failed":0}
------------------------------
â€¢ [4.113 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:39:43.007
    Apr 26 11:39:43.007: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename var-expansion 04/26/24 11:39:43.008
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:43.024
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:43.029
    [It] should allow substituting values in a container's command [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:72
    STEP: Creating a pod to test substitution in container's command 04/26/24 11:39:43.034
    Apr 26 11:39:43.049: INFO: Waiting up to 5m0s for pod "var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97" in namespace "var-expansion-2646" to be "Succeeded or Failed"
    Apr 26 11:39:43.055: INFO: Pod "var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97": Phase="Pending", Reason="", readiness=false. Elapsed: 5.559209ms
    Apr 26 11:39:45.063: INFO: Pod "var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013906967s
    Apr 26 11:39:47.061: INFO: Pod "var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012201992s
    STEP: Saw pod success 04/26/24 11:39:47.061
    Apr 26 11:39:47.061: INFO: Pod "var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97" satisfied condition "Succeeded or Failed"
    Apr 26 11:39:47.067: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97 container dapi-container: <nil>
    STEP: delete the pod 04/26/24 11:39:47.081
    Apr 26 11:39:47.094: INFO: Waiting for pod var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97 to disappear
    Apr 26 11:39:47.102: INFO: Pod var-expansion-20d03497-0cdc-4dff-8ad6-fe30cc30af97 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 26 11:39:47.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2646" for this suite. 04/26/24 11:39:47.113
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:39:47.121
Apr 26 11:39:47.121: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename namespaces 04/26/24 11:39:47.122
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:47.14
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:47.146
[It] should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298
STEP: Read namespace status 04/26/24 11:39:47.152
Apr 26 11:39:47.156: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
STEP: Patch namespace status 04/26/24 11:39:47.156
Apr 26 11:39:47.162: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
STEP: Update namespace status 04/26/24 11:39:47.162
Apr 26 11:39:47.172: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:39:47.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8964" for this suite. 04/26/24 11:39:47.18
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]","completed":127,"skipped":2197,"failed":0}
------------------------------
â€¢ [0.064 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should apply changes to a namespace status [Conformance]
  test/e2e/apimachinery/namespace.go:298

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:39:47.121
    Apr 26 11:39:47.121: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename namespaces 04/26/24 11:39:47.122
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:47.14
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:47.146
    [It] should apply changes to a namespace status [Conformance]
      test/e2e/apimachinery/namespace.go:298
    STEP: Read namespace status 04/26/24 11:39:47.152
    Apr 26 11:39:47.156: INFO: Status: v1.NamespaceStatus{Phase:"Active", Conditions:[]v1.NamespaceCondition(nil)}
    STEP: Patch namespace status 04/26/24 11:39:47.156
    Apr 26 11:39:47.162: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusPatch", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Patched by an e2e test"}
    STEP: Update namespace status 04/26/24 11:39:47.162
    Apr 26 11:39:47.172: INFO: Status.Condition: v1.NamespaceCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Updated by an e2e test"}
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:39:47.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-8964" for this suite. 04/26/24 11:39:47.18
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:39:47.185
Apr 26 11:39:47.186: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename sched-preemption 04/26/24 11:39:47.186
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:47.2
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:47.207
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 26 11:39:47.230: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 26 11:40:47.315: INFO: Waiting for terminating namespaces to be deleted...
[It] validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218
STEP: Create pods that use 4/5 of node resources. 04/26/24 11:40:47.321
Apr 26 11:40:47.361: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 26 11:40:47.378: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 26 11:40:47.413: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 26 11:40:47.427: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Apr 26 11:40:47.473: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Apr 26 11:40:47.484: INFO: Created pod: pod2-1-sched-preemption-medium-priority
Apr 26 11:40:47.523: INFO: Created pod: pod3-0-sched-preemption-medium-priority
Apr 26 11:40:47.534: INFO: Created pod: pod3-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 04/26/24 11:40:47.534
Apr 26 11:40:47.534: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-1203" to be "running"
Apr 26 11:40:47.539: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.764179ms
Apr 26 11:40:49.549: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014727098s
Apr 26 11:40:51.547: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012717965s
Apr 26 11:40:53.545: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011023779s
Apr 26 11:40:55.546: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011464307s
Apr 26 11:40:57.555: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020319097s
Apr 26 11:40:59.547: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.012330893s
Apr 26 11:40:59.547: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Apr 26 11:40:59.547: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
Apr 26 11:40:59.554: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 7.343743ms
Apr 26 11:40:59.554: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 26 11:40:59.554: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
Apr 26 11:40:59.560: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.143429ms
Apr 26 11:40:59.560: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 26 11:40:59.560: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
Apr 26 11:40:59.567: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.344955ms
Apr 26 11:40:59.567: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 26 11:40:59.567: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
Apr 26 11:40:59.572: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.116188ms
Apr 26 11:40:59.572: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 26 11:40:59.572: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
Apr 26 11:40:59.584: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.369471ms
Apr 26 11:40:59.584: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 26 11:40:59.584: INFO: Waiting up to 5m0s for pod "pod3-0-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
Apr 26 11:40:59.591: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 7.257082ms
Apr 26 11:40:59.592: INFO: Pod "pod3-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 26 11:40:59.592: INFO: Waiting up to 5m0s for pod "pod3-1-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
Apr 26 11:40:59.597: INFO: Pod "pod3-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.041508ms
Apr 26 11:40:59.597: INFO: Pod "pod3-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a critical pod that use same resources as that of a lower priority pod 04/26/24 11:40:59.597
Apr 26 11:40:59.617: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
Apr 26 11:40:59.621: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.231172ms
Apr 26 11:41:01.650: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033184672s
Apr 26 11:41:03.629: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01172897s
Apr 26 11:41:05.629: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.012300467s
Apr 26 11:41:05.629: INFO: Pod "critical-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:41:05.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-1203" for this suite. 04/26/24 11:41:05.713
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]","completed":128,"skipped":2202,"failed":0}
------------------------------
â€¢ [SLOW TEST] [78.616 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates lower priority pod preemption by critical pod [Conformance]
  test/e2e/scheduling/preemption.go:218

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:39:47.185
    Apr 26 11:39:47.186: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename sched-preemption 04/26/24 11:39:47.186
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:39:47.2
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:39:47.207
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 26 11:39:47.230: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 26 11:40:47.315: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates lower priority pod preemption by critical pod [Conformance]
      test/e2e/scheduling/preemption.go:218
    STEP: Create pods that use 4/5 of node resources. 04/26/24 11:40:47.321
    Apr 26 11:40:47.361: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Apr 26 11:40:47.378: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Apr 26 11:40:47.413: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Apr 26 11:40:47.427: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Apr 26 11:40:47.473: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Apr 26 11:40:47.484: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    Apr 26 11:40:47.523: INFO: Created pod: pod3-0-sched-preemption-medium-priority
    Apr 26 11:40:47.534: INFO: Created pod: pod3-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 04/26/24 11:40:47.534
    Apr 26 11:40:47.534: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-1203" to be "running"
    Apr 26 11:40:47.539: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.764179ms
    Apr 26 11:40:49.549: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014727098s
    Apr 26 11:40:51.547: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012717965s
    Apr 26 11:40:53.545: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011023779s
    Apr 26 11:40:55.546: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011464307s
    Apr 26 11:40:57.555: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 10.020319097s
    Apr 26 11:40:59.547: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.012330893s
    Apr 26 11:40:59.547: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Apr 26 11:40:59.547: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
    Apr 26 11:40:59.554: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 7.343743ms
    Apr 26 11:40:59.554: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 26 11:40:59.554: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
    Apr 26 11:40:59.560: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.143429ms
    Apr 26 11:40:59.560: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 26 11:40:59.560: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
    Apr 26 11:40:59.567: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 6.344955ms
    Apr 26 11:40:59.567: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 26 11:40:59.567: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
    Apr 26 11:40:59.572: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.116188ms
    Apr 26 11:40:59.572: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 26 11:40:59.572: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
    Apr 26 11:40:59.584: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 12.369471ms
    Apr 26 11:40:59.584: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 26 11:40:59.584: INFO: Waiting up to 5m0s for pod "pod3-0-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
    Apr 26 11:40:59.591: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 7.257082ms
    Apr 26 11:40:59.592: INFO: Pod "pod3-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 26 11:40:59.592: INFO: Waiting up to 5m0s for pod "pod3-1-sched-preemption-medium-priority" in namespace "sched-preemption-1203" to be "running"
    Apr 26 11:40:59.597: INFO: Pod "pod3-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.041508ms
    Apr 26 11:40:59.597: INFO: Pod "pod3-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a critical pod that use same resources as that of a lower priority pod 04/26/24 11:40:59.597
    Apr 26 11:40:59.617: INFO: Waiting up to 2m0s for pod "critical-pod" in namespace "kube-system" to be "running"
    Apr 26 11:40:59.621: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.231172ms
    Apr 26 11:41:01.650: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033184672s
    Apr 26 11:41:03.629: INFO: Pod "critical-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01172897s
    Apr 26 11:41:05.629: INFO: Pod "critical-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.012300467s
    Apr 26 11:41:05.629: INFO: Pod "critical-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:41:05.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-1203" for this suite. 04/26/24 11:41:05.713
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-apps] Deployment
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:41:05.803
Apr 26 11:41:05.803: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename deployment 04/26/24 11:41:05.804
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:05.823
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:05.831
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479
STEP: creating a Deployment 04/26/24 11:41:05.843
Apr 26 11:41:05.843: INFO: Creating simple deployment test-deployment-kk2ps
Apr 26 11:41:05.859: INFO: deployment "test-deployment-kk2ps" doesn't have the required revision set
STEP: Getting /status 04/26/24 11:41:07.881
Apr 26 11:41:07.887: INFO: Deployment test-deployment-kk2ps has Conditions: [{Available True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-kk2ps-777898ffcc" has successfully progressed.}]
STEP: updating Deployment Status 04/26/24 11:41:07.887
Apr 26 11:41:07.898: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 41, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 41, 7, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 41, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 41, 5, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-kk2ps-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Deployment status to be updated 04/26/24 11:41:07.898
Apr 26 11:41:07.904: INFO: Observed &Deployment event: ADDED
Apr 26 11:41:07.904: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-kk2ps-777898ffcc"}
Apr 26 11:41:07.904: INFO: Observed &Deployment event: MODIFIED
Apr 26 11:41:07.904: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-kk2ps-777898ffcc"}
Apr 26 11:41:07.904: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 26 11:41:07.905: INFO: Observed &Deployment event: MODIFIED
Apr 26 11:41:07.905: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 26 11:41:07.905: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-kk2ps-777898ffcc" is progressing.}
Apr 26 11:41:07.905: INFO: Observed &Deployment event: MODIFIED
Apr 26 11:41:07.906: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 26 11:41:07.906: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-kk2ps-777898ffcc" has successfully progressed.}
Apr 26 11:41:07.906: INFO: Observed &Deployment event: MODIFIED
Apr 26 11:41:07.906: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 26 11:41:07.907: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-kk2ps-777898ffcc" has successfully progressed.}
Apr 26 11:41:07.907: INFO: Found Deployment test-deployment-kk2ps in namespace deployment-7654 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 26 11:41:07.907: INFO: Deployment test-deployment-kk2ps has an updated status
STEP: patching the Statefulset Status 04/26/24 11:41:07.907
Apr 26 11:41:07.907: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 26 11:41:07.916: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Deployment status to be patched 04/26/24 11:41:07.916
Apr 26 11:41:07.922: INFO: Observed &Deployment event: ADDED
Apr 26 11:41:07.922: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-kk2ps-777898ffcc"}
Apr 26 11:41:07.922: INFO: Observed &Deployment event: MODIFIED
Apr 26 11:41:07.922: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-kk2ps-777898ffcc"}
Apr 26 11:41:07.922: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 26 11:41:07.922: INFO: Observed &Deployment event: MODIFIED
Apr 26 11:41:07.922: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
Apr 26 11:41:07.922: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-kk2ps-777898ffcc" is progressing.}
Apr 26 11:41:07.922: INFO: Observed &Deployment event: MODIFIED
Apr 26 11:41:07.923: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 26 11:41:07.923: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-kk2ps-777898ffcc" has successfully progressed.}
Apr 26 11:41:07.923: INFO: Observed &Deployment event: MODIFIED
Apr 26 11:41:07.923: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
Apr 26 11:41:07.923: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-kk2ps-777898ffcc" has successfully progressed.}
Apr 26 11:41:07.923: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 26 11:41:07.923: INFO: Observed &Deployment event: MODIFIED
Apr 26 11:41:07.923: INFO: Found deployment test-deployment-kk2ps in namespace deployment-7654 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
Apr 26 11:41:07.923: INFO: Deployment test-deployment-kk2ps has a patched status
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 26 11:41:07.929: INFO: Deployment "test-deployment-kk2ps":
&Deployment{ObjectMeta:{test-deployment-kk2ps  deployment-7654  b9f03116-22b7-459d-a0a4-5937ac8c542d 31111 1 2024-04-26 11:41:05 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2024-04-26 11:41:05 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2024-04-26 11:41:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2024-04-26 11:41:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00394ff68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-kk2ps-777898ffcc",LastUpdateTime:2024-04-26 11:41:07 +0000 UTC,LastTransitionTime:2024-04-26 11:41:07 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 26 11:41:07.936: INFO: New ReplicaSet "test-deployment-kk2ps-777898ffcc" of Deployment "test-deployment-kk2ps":
&ReplicaSet{ObjectMeta:{test-deployment-kk2ps-777898ffcc  deployment-7654  c706fa5a-dee2-4c7e-b36d-9c95a2a20a32 31106 1 2024-04-26 11:41:05 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-kk2ps b9f03116-22b7-459d-a0a4-5937ac8c542d 0xc0060363f0 0xc0060363f1}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:41:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b9f03116-22b7-459d-a0a4-5937ac8c542d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:41:07 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006036498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 26 11:41:07.940: INFO: Pod "test-deployment-kk2ps-777898ffcc-t9mrc" is available:
&Pod{ObjectMeta:{test-deployment-kk2ps-777898ffcc-t9mrc test-deployment-kk2ps-777898ffcc- deployment-7654  a61ee42d-bed7-4149-8f81-0dd31fffb084 31105 0 2024-04-26 11:41:05 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:0825d5b32f4f6642d459061c02c950b71c86f86676e6464480d771b6f500607e cni.projectcalico.org/podIP:100.96.1.166/32 cni.projectcalico.org/podIPs:100.96.1.166/32] [{apps/v1 ReplicaSet test-deployment-kk2ps-777898ffcc c706fa5a-dee2-4c7e-b36d-9c95a2a20a32 0xc006036810 0xc006036811}] [] [{kube-controller-manager Update v1 2024-04-26 11:41:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c706fa5a-dee2-4c7e-b36d-9c95a2a20a32\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:41:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:41:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.166\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cpxvd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cpxvd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:41:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:41:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:41:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:41:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.166,StartTime:2024-04-26 11:41:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:41:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://4148f601c75b4aa6e1a76b6006c7311d988a0da64549810074403b8637b9d4b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.166,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 26 11:41:07.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7654" for this suite. 04/26/24 11:41:07.952
{"msg":"PASSED [sig-apps] Deployment should validate Deployment Status endpoints [Conformance]","completed":129,"skipped":2206,"failed":0}
------------------------------
â€¢ [2.157 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should validate Deployment Status endpoints [Conformance]
  test/e2e/apps/deployment.go:479

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:41:05.803
    Apr 26 11:41:05.803: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename deployment 04/26/24 11:41:05.804
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:05.823
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:05.831
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should validate Deployment Status endpoints [Conformance]
      test/e2e/apps/deployment.go:479
    STEP: creating a Deployment 04/26/24 11:41:05.843
    Apr 26 11:41:05.843: INFO: Creating simple deployment test-deployment-kk2ps
    Apr 26 11:41:05.859: INFO: deployment "test-deployment-kk2ps" doesn't have the required revision set
    STEP: Getting /status 04/26/24 11:41:07.881
    Apr 26 11:41:07.887: INFO: Deployment test-deployment-kk2ps has Conditions: [{Available True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.} {Progressing True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-kk2ps-777898ffcc" has successfully progressed.}]
    STEP: updating Deployment Status 04/26/24 11:41:07.887
    Apr 26 11:41:07.898: INFO: updatedStatus.Conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 41, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 41, 7, 0, time.Local), Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 41, 7, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 41, 5, 0, time.Local), Reason:"NewReplicaSetAvailable", Message:"ReplicaSet \"test-deployment-kk2ps-777898ffcc\" has successfully progressed."}, v1.DeploymentCondition{Type:"StatusUpdate", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Deployment status to be updated 04/26/24 11:41:07.898
    Apr 26 11:41:07.904: INFO: Observed &Deployment event: ADDED
    Apr 26 11:41:07.904: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-kk2ps-777898ffcc"}
    Apr 26 11:41:07.904: INFO: Observed &Deployment event: MODIFIED
    Apr 26 11:41:07.904: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-kk2ps-777898ffcc"}
    Apr 26 11:41:07.904: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 26 11:41:07.905: INFO: Observed &Deployment event: MODIFIED
    Apr 26 11:41:07.905: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 26 11:41:07.905: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-kk2ps-777898ffcc" is progressing.}
    Apr 26 11:41:07.905: INFO: Observed &Deployment event: MODIFIED
    Apr 26 11:41:07.906: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 26 11:41:07.906: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-kk2ps-777898ffcc" has successfully progressed.}
    Apr 26 11:41:07.906: INFO: Observed &Deployment event: MODIFIED
    Apr 26 11:41:07.906: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 26 11:41:07.907: INFO: Observed Deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-kk2ps-777898ffcc" has successfully progressed.}
    Apr 26 11:41:07.907: INFO: Found Deployment test-deployment-kk2ps in namespace deployment-7654 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 26 11:41:07.907: INFO: Deployment test-deployment-kk2ps has an updated status
    STEP: patching the Statefulset Status 04/26/24 11:41:07.907
    Apr 26 11:41:07.907: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 26 11:41:07.916: INFO: Patched status conditions: []v1.DeploymentCondition{v1.DeploymentCondition{Type:"StatusPatched", Status:"True", LastUpdateTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Deployment status to be patched 04/26/24 11:41:07.916
    Apr 26 11:41:07.922: INFO: Observed &Deployment event: ADDED
    Apr 26 11:41:07.922: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-kk2ps-777898ffcc"}
    Apr 26 11:41:07.922: INFO: Observed &Deployment event: MODIFIED
    Apr 26 11:41:07.922: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetCreated Created new replica set "test-deployment-kk2ps-777898ffcc"}
    Apr 26 11:41:07.922: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 26 11:41:07.922: INFO: Observed &Deployment event: MODIFIED
    Apr 26 11:41:07.922: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available False 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC MinimumReplicasUnavailable Deployment does not have minimum availability.}
    Apr 26 11:41:07.922: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:05 +0000 UTC 2024-04-26 11:41:05 +0000 UTC ReplicaSetUpdated ReplicaSet "test-deployment-kk2ps-777898ffcc" is progressing.}
    Apr 26 11:41:07.922: INFO: Observed &Deployment event: MODIFIED
    Apr 26 11:41:07.923: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 26 11:41:07.923: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-kk2ps-777898ffcc" has successfully progressed.}
    Apr 26 11:41:07.923: INFO: Observed &Deployment event: MODIFIED
    Apr 26 11:41:07.923: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Available True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:07 +0000 UTC MinimumReplicasAvailable Deployment has minimum availability.}
    Apr 26 11:41:07.923: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {Progressing True 2024-04-26 11:41:07 +0000 UTC 2024-04-26 11:41:05 +0000 UTC NewReplicaSetAvailable ReplicaSet "test-deployment-kk2ps-777898ffcc" has successfully progressed.}
    Apr 26 11:41:07.923: INFO: Observed deployment test-deployment-kk2ps in namespace deployment-7654 with annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 26 11:41:07.923: INFO: Observed &Deployment event: MODIFIED
    Apr 26 11:41:07.923: INFO: Found deployment test-deployment-kk2ps in namespace deployment-7654 with labels: map[e2e:testing name:httpd] annotations: map[deployment.kubernetes.io/revision:1] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC 0001-01-01 00:00:00 +0000 UTC  }
    Apr 26 11:41:07.923: INFO: Deployment test-deployment-kk2ps has a patched status
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 26 11:41:07.929: INFO: Deployment "test-deployment-kk2ps":
    &Deployment{ObjectMeta:{test-deployment-kk2ps  deployment-7654  b9f03116-22b7-459d-a0a4-5937ac8c542d 31111 1 2024-04-26 11:41:05 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2024-04-26 11:41:05 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {e2e.test Update apps/v1 2024-04-26 11:41:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"StatusPatched\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:status":{},"f:type":{}}}}} status} {kube-controller-manager Update apps/v1 2024-04-26 11:41:07 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc00394ff68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:StatusPatched,Status:True,Reason:,Message:,LastUpdateTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:0001-01-01 00:00:00 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:FoundNewReplicaSet,Message:Found new replica set "test-deployment-kk2ps-777898ffcc",LastUpdateTime:2024-04-26 11:41:07 +0000 UTC,LastTransitionTime:2024-04-26 11:41:07 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 26 11:41:07.936: INFO: New ReplicaSet "test-deployment-kk2ps-777898ffcc" of Deployment "test-deployment-kk2ps":
    &ReplicaSet{ObjectMeta:{test-deployment-kk2ps-777898ffcc  deployment-7654  c706fa5a-dee2-4c7e-b36d-9c95a2a20a32 31106 1 2024-04-26 11:41:05 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-deployment-kk2ps b9f03116-22b7-459d-a0a4-5937ac8c542d 0xc0060363f0 0xc0060363f1}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:41:05 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b9f03116-22b7-459d-a0a4-5937ac8c542d\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:41:07 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{e2e: testing,name: httpd,pod-template-hash: 777898ffcc,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006036498 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 26 11:41:07.940: INFO: Pod "test-deployment-kk2ps-777898ffcc-t9mrc" is available:
    &Pod{ObjectMeta:{test-deployment-kk2ps-777898ffcc-t9mrc test-deployment-kk2ps-777898ffcc- deployment-7654  a61ee42d-bed7-4149-8f81-0dd31fffb084 31105 0 2024-04-26 11:41:05 +0000 UTC <nil> <nil> map[e2e:testing name:httpd pod-template-hash:777898ffcc] map[cni.projectcalico.org/containerID:0825d5b32f4f6642d459061c02c950b71c86f86676e6464480d771b6f500607e cni.projectcalico.org/podIP:100.96.1.166/32 cni.projectcalico.org/podIPs:100.96.1.166/32] [{apps/v1 ReplicaSet test-deployment-kk2ps-777898ffcc c706fa5a-dee2-4c7e-b36d-9c95a2a20a32 0xc006036810 0xc006036811}] [] [{kube-controller-manager Update v1 2024-04-26 11:41:05 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:e2e":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c706fa5a-dee2-4c7e-b36d-9c95a2a20a32\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:41:06 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:41:07 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.166\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-cpxvd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-cpxvd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:41:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:41:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:41:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:41:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.166,StartTime:2024-04-26 11:41:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:41:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://4148f601c75b4aa6e1a76b6006c7311d988a0da64549810074403b8637b9d4b7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.166,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 26 11:41:07.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7654" for this suite. 04/26/24 11:41:07.952
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Secrets
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:41:07.961
Apr 26 11:41:07.961: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 11:41:07.962
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:07.978
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:07.985
[It] should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139
STEP: Creating projection with secret that has name secret-emptykey-test-d4d55b60-1f75-40bb-ac92-1a1dd82ca2dd 04/26/24 11:41:07.992
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 26 11:41:07.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4704" for this suite. 04/26/24 11:41:08.007
{"msg":"PASSED [sig-node] Secrets should fail to create secret due to empty secret key [Conformance]","completed":130,"skipped":2210,"failed":0}
------------------------------
â€¢ [0.053 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should fail to create secret due to empty secret key [Conformance]
  test/e2e/common/node/secrets.go:139

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:41:07.961
    Apr 26 11:41:07.961: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 11:41:07.962
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:07.978
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:07.985
    [It] should fail to create secret due to empty secret key [Conformance]
      test/e2e/common/node/secrets.go:139
    STEP: Creating projection with secret that has name secret-emptykey-test-d4d55b60-1f75-40bb-ac92-1a1dd82ca2dd 04/26/24 11:41:07.992
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 11:41:07.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-4704" for this suite. 04/26/24 11:41:08.007
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
[BeforeEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:41:08.018
Apr 26 11:41:08.018: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:41:08.019
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:08.035
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:08.042
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43
STEP: Creating configMap with name configmap-projected-all-test-volume-97723962-b331-41d6-83c5-ce43ba5d2ad4 04/26/24 11:41:08.05
STEP: Creating secret with name secret-projected-all-test-volume-3349f4e2-b689-4368-8e4f-002fafc70951 04/26/24 11:41:08.055
STEP: Creating a pod to test Check all projections for projected volume plugin 04/26/24 11:41:08.061
Apr 26 11:41:08.072: INFO: Waiting up to 5m0s for pod "projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e" in namespace "projected-2804" to be "Succeeded or Failed"
Apr 26 11:41:08.079: INFO: Pod "projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.694521ms
Apr 26 11:41:10.092: INFO: Pod "projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019700506s
Apr 26 11:41:12.090: INFO: Pod "projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018301888s
STEP: Saw pod success 04/26/24 11:41:12.091
Apr 26 11:41:12.091: INFO: Pod "projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e" satisfied condition "Succeeded or Failed"
Apr 26 11:41:12.096: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e container projected-all-volume-test: <nil>
STEP: delete the pod 04/26/24 11:41:12.117
Apr 26 11:41:12.130: INFO: Waiting for pod projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e to disappear
Apr 26 11:41:12.134: INFO: Pod projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e no longer exists
[AfterEach] [sig-storage] Projected combined
  test/e2e/framework/framework.go:187
Apr 26 11:41:12.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2804" for this suite. 04/26/24 11:41:12.146
{"msg":"PASSED [sig-storage] Projected combined should project all components that make up the projection API [Projection][NodeConformance] [Conformance]","completed":131,"skipped":2242,"failed":0}
------------------------------
â€¢ [4.134 seconds]
[sig-storage] Projected combined
test/e2e/common/storage/framework.go:23
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  test/e2e/common/storage/projected_combined.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:41:08.018
    Apr 26 11:41:08.018: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:41:08.019
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:08.035
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:08.042
    [It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
      test/e2e/common/storage/projected_combined.go:43
    STEP: Creating configMap with name configmap-projected-all-test-volume-97723962-b331-41d6-83c5-ce43ba5d2ad4 04/26/24 11:41:08.05
    STEP: Creating secret with name secret-projected-all-test-volume-3349f4e2-b689-4368-8e4f-002fafc70951 04/26/24 11:41:08.055
    STEP: Creating a pod to test Check all projections for projected volume plugin 04/26/24 11:41:08.061
    Apr 26 11:41:08.072: INFO: Waiting up to 5m0s for pod "projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e" in namespace "projected-2804" to be "Succeeded or Failed"
    Apr 26 11:41:08.079: INFO: Pod "projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.694521ms
    Apr 26 11:41:10.092: INFO: Pod "projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019700506s
    Apr 26 11:41:12.090: INFO: Pod "projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018301888s
    STEP: Saw pod success 04/26/24 11:41:12.091
    Apr 26 11:41:12.091: INFO: Pod "projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e" satisfied condition "Succeeded or Failed"
    Apr 26 11:41:12.096: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e container projected-all-volume-test: <nil>
    STEP: delete the pod 04/26/24 11:41:12.117
    Apr 26 11:41:12.130: INFO: Waiting for pod projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e to disappear
    Apr 26 11:41:12.134: INFO: Pod projected-volume-1d5a4aea-d35e-4365-9b63-21e4183cfe1e no longer exists
    [AfterEach] [sig-storage] Projected combined
      test/e2e/framework/framework.go:187
    Apr 26 11:41:12.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-2804" for this suite. 04/26/24 11:41:12.146
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:41:12.162
Apr 26 11:41:12.162: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename init-container 04/26/24 11:41:12.162
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:12.186
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:12.194
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457
STEP: creating the pod 04/26/24 11:41:12.201
Apr 26 11:41:12.201: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 26 11:41:16.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8623" for this suite. 04/26/24 11:41:16.59
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]","completed":132,"skipped":2312,"failed":0}
------------------------------
â€¢ [4.435 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:457

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:41:12.162
    Apr 26 11:41:12.162: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename init-container 04/26/24 11:41:12.162
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:12.186
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:12.194
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:457
    STEP: creating the pod 04/26/24 11:41:12.201
    Apr 26 11:41:12.201: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 26 11:41:16.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-8623" for this suite. 04/26/24 11:41:16.59
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:41:16.597
Apr 26 11:41:16.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename watch 04/26/24 11:41:16.598
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:16.613
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:16.62
[It] should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142
STEP: creating a new configmap 04/26/24 11:41:16.628
STEP: modifying the configmap once 04/26/24 11:41:16.633
STEP: modifying the configmap a second time 04/26/24 11:41:16.649
STEP: deleting the configmap 04/26/24 11:41:16.66
STEP: creating a watch on configmaps from the resource version returned by the first update 04/26/24 11:41:16.667
STEP: Expecting to observe notifications for all changes to the configmap after the first update 04/26/24 11:41:16.67
Apr 26 11:41:16.671: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4646  db54aabf-e21e-4e05-8ef9-a7cee3d205a1 31240 0 2024-04-26 11:41:16 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-04-26 11:41:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 11:41:16.671: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4646  db54aabf-e21e-4e05-8ef9-a7cee3d205a1 31241 0 2024-04-26 11:41:16 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-04-26 11:41:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 26 11:41:16.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4646" for this suite. 04/26/24 11:41:16.684
{"msg":"PASSED [sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]","completed":133,"skipped":2315,"failed":0}
------------------------------
â€¢ [0.095 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  test/e2e/apimachinery/watch.go:142

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:41:16.597
    Apr 26 11:41:16.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename watch 04/26/24 11:41:16.598
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:16.613
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:16.62
    [It] should be able to start watching from a specific resource version [Conformance]
      test/e2e/apimachinery/watch.go:142
    STEP: creating a new configmap 04/26/24 11:41:16.628
    STEP: modifying the configmap once 04/26/24 11:41:16.633
    STEP: modifying the configmap a second time 04/26/24 11:41:16.649
    STEP: deleting the configmap 04/26/24 11:41:16.66
    STEP: creating a watch on configmaps from the resource version returned by the first update 04/26/24 11:41:16.667
    STEP: Expecting to observe notifications for all changes to the configmap after the first update 04/26/24 11:41:16.67
    Apr 26 11:41:16.671: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4646  db54aabf-e21e-4e05-8ef9-a7cee3d205a1 31240 0 2024-04-26 11:41:16 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-04-26 11:41:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 11:41:16.671: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4646  db54aabf-e21e-4e05-8ef9-a7cee3d205a1 31241 0 2024-04-26 11:41:16 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] [] [{e2e.test Update v1 2024-04-26 11:41:16 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 26 11:41:16.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-4646" for this suite. 04/26/24 11:41:16.684
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods Extended Pods Set QOS Class
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
[BeforeEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:41:16.693
Apr 26 11:41:16.693: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pods 04/26/24 11:41:16.695
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:16.712
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:16.719
[BeforeEach] Pods Set QOS Class
  test/e2e/node/pods.go:152
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  test/e2e/node/pods.go:161
STEP: creating the pod 04/26/24 11:41:16.727
STEP: submitting the pod to kubernetes 04/26/24 11:41:16.727
STEP: verifying QOS class is set on the pod 04/26/24 11:41:16.74
[AfterEach] [sig-node] Pods Extended
  test/e2e/framework/framework.go:187
Apr 26 11:41:16.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4727" for this suite. 04/26/24 11:41:16.792
{"msg":"PASSED [sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]","completed":134,"skipped":2317,"failed":0}
------------------------------
â€¢ [0.145 seconds]
[sig-node] Pods Extended
test/e2e/node/framework.go:23
  Pods Set QOS Class
  test/e2e/node/pods.go:150
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    test/e2e/node/pods.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:41:16.693
    Apr 26 11:41:16.693: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pods 04/26/24 11:41:16.695
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:16.712
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:16.719
    [BeforeEach] Pods Set QOS Class
      test/e2e/node/pods.go:152
    [It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
      test/e2e/node/pods.go:161
    STEP: creating the pod 04/26/24 11:41:16.727
    STEP: submitting the pod to kubernetes 04/26/24 11:41:16.727
    STEP: verifying QOS class is set on the pod 04/26/24 11:41:16.74
    [AfterEach] [sig-node] Pods Extended
      test/e2e/framework/framework.go:187
    Apr 26 11:41:16.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-4727" for this suite. 04/26/24 11:41:16.792
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:41:16.84
Apr 26 11:41:16.840: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:41:16.842
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:16.867
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:16.874
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123
STEP: Creating projection with configMap that has name projected-configmap-test-upd-65ec69ff-0723-471f-aea1-e6124635d1fb 04/26/24 11:41:16.941
STEP: Creating the pod 04/26/24 11:41:16.947
Apr 26 11:41:16.961: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-89034377-b256-4334-a04d-7912cf049097" in namespace "projected-9610" to be "running and ready"
Apr 26 11:41:16.970: INFO: Pod "pod-projected-configmaps-89034377-b256-4334-a04d-7912cf049097": Phase="Pending", Reason="", readiness=false. Elapsed: 9.109769ms
Apr 26 11:41:16.970: INFO: The phase of Pod pod-projected-configmaps-89034377-b256-4334-a04d-7912cf049097 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:41:18.975: INFO: Pod "pod-projected-configmaps-89034377-b256-4334-a04d-7912cf049097": Phase="Running", Reason="", readiness=true. Elapsed: 2.01461862s
Apr 26 11:41:18.975: INFO: The phase of Pod pod-projected-configmaps-89034377-b256-4334-a04d-7912cf049097 is Running (Ready = true)
Apr 26 11:41:18.975: INFO: Pod "pod-projected-configmaps-89034377-b256-4334-a04d-7912cf049097" satisfied condition "running and ready"
STEP: Updating configmap projected-configmap-test-upd-65ec69ff-0723-471f-aea1-e6124635d1fb 04/26/24 11:41:19.032
STEP: waiting to observe update in volume 04/26/24 11:41:19.037
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 26 11:41:21.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9610" for this suite. 04/26/24 11:41:21.155
{"msg":"PASSED [sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]","completed":135,"skipped":2324,"failed":0}
------------------------------
â€¢ [4.321 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:41:16.84
    Apr 26 11:41:16.840: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:41:16.842
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:16.867
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:16.874
    [It] updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:123
    STEP: Creating projection with configMap that has name projected-configmap-test-upd-65ec69ff-0723-471f-aea1-e6124635d1fb 04/26/24 11:41:16.941
    STEP: Creating the pod 04/26/24 11:41:16.947
    Apr 26 11:41:16.961: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-89034377-b256-4334-a04d-7912cf049097" in namespace "projected-9610" to be "running and ready"
    Apr 26 11:41:16.970: INFO: Pod "pod-projected-configmaps-89034377-b256-4334-a04d-7912cf049097": Phase="Pending", Reason="", readiness=false. Elapsed: 9.109769ms
    Apr 26 11:41:16.970: INFO: The phase of Pod pod-projected-configmaps-89034377-b256-4334-a04d-7912cf049097 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:41:18.975: INFO: Pod "pod-projected-configmaps-89034377-b256-4334-a04d-7912cf049097": Phase="Running", Reason="", readiness=true. Elapsed: 2.01461862s
    Apr 26 11:41:18.975: INFO: The phase of Pod pod-projected-configmaps-89034377-b256-4334-a04d-7912cf049097 is Running (Ready = true)
    Apr 26 11:41:18.975: INFO: Pod "pod-projected-configmaps-89034377-b256-4334-a04d-7912cf049097" satisfied condition "running and ready"
    STEP: Updating configmap projected-configmap-test-upd-65ec69ff-0723-471f-aea1-e6124635d1fb 04/26/24 11:41:19.032
    STEP: waiting to observe update in volume 04/26/24 11:41:19.037
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 26 11:41:21.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9610" for this suite. 04/26/24 11:41:21.155
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:41:21.176
Apr 26 11:41:21.176: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename resourcequota 04/26/24 11:41:21.177
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:21.193
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:21.201
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65
STEP: Counting existing ResourceQuota 04/26/24 11:41:21.207
STEP: Creating a ResourceQuota 04/26/24 11:41:26.214
STEP: Ensuring resource quota status is calculated 04/26/24 11:41:26.22
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 26 11:41:28.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7880" for this suite. 04/26/24 11:41:28.236
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]","completed":136,"skipped":2390,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.065 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  test/e2e/apimachinery/resource_quota.go:65

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:41:21.176
    Apr 26 11:41:21.176: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename resourcequota 04/26/24 11:41:21.177
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:21.193
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:21.201
    [It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
      test/e2e/apimachinery/resource_quota.go:65
    STEP: Counting existing ResourceQuota 04/26/24 11:41:21.207
    STEP: Creating a ResourceQuota 04/26/24 11:41:26.214
    STEP: Ensuring resource quota status is calculated 04/26/24 11:41:26.22
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 26 11:41:28.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-7880" for this suite. 04/26/24 11:41:28.236
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPreemption [Serial]
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:41:28.241
Apr 26 11:41:28.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename sched-preemption 04/26/24 11:41:28.242
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:28.271
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:28.277
[BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:92
Apr 26 11:41:28.340: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 26 11:42:28.419: INFO: Waiting for terminating namespaces to be deleted...
[It] validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125
STEP: Create pods that use 4/5 of node resources. 04/26/24 11:42:28.423
Apr 26 11:42:28.492: INFO: Created pod: pod0-0-sched-preemption-low-priority
Apr 26 11:42:28.502: INFO: Created pod: pod0-1-sched-preemption-medium-priority
Apr 26 11:42:28.545: INFO: Created pod: pod1-0-sched-preemption-medium-priority
Apr 26 11:42:28.555: INFO: Created pod: pod1-1-sched-preemption-medium-priority
Apr 26 11:42:28.580: INFO: Created pod: pod2-0-sched-preemption-medium-priority
Apr 26 11:42:28.594: INFO: Created pod: pod2-1-sched-preemption-medium-priority
Apr 26 11:42:28.616: INFO: Created pod: pod3-0-sched-preemption-medium-priority
Apr 26 11:42:28.628: INFO: Created pod: pod3-1-sched-preemption-medium-priority
STEP: Wait for pods to be scheduled. 04/26/24 11:42:28.628
Apr 26 11:42:28.628: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-1392" to be "running"
Apr 26 11:42:28.637: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 9.033246ms
Apr 26 11:42:30.645: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.017130743s
Apr 26 11:42:30.645: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
Apr 26 11:42:30.645: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
Apr 26 11:42:30.650: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.555436ms
Apr 26 11:42:30.650: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 26 11:42:30.650: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
Apr 26 11:42:30.654: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.563579ms
Apr 26 11:42:30.654: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 26 11:42:30.654: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
Apr 26 11:42:30.659: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.00675ms
Apr 26 11:42:30.659: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 26 11:42:30.659: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
Apr 26 11:42:30.663: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.303334ms
Apr 26 11:42:30.663: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 26 11:42:30.663: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
Apr 26 11:42:30.667: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.743076ms
Apr 26 11:42:30.667: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
Apr 26 11:42:30.667: INFO: Waiting up to 5m0s for pod "pod3-0-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
Apr 26 11:42:30.672: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.767272ms
Apr 26 11:42:30.672: INFO: Pod "pod3-0-sched-preemption-medium-priority" satisfied condition "running"
Apr 26 11:42:30.672: INFO: Waiting up to 5m0s for pod "pod3-1-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
Apr 26 11:42:30.677: INFO: Pod "pod3-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.430742ms
Apr 26 11:42:30.677: INFO: Pod "pod3-1-sched-preemption-medium-priority" satisfied condition "running"
STEP: Run a high priority pod that has same requirements as that of lower priority pod 04/26/24 11:42:30.677
Apr 26 11:42:30.688: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-1392" to be "running"
Apr 26 11:42:30.694: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.787451ms
Apr 26 11:42:32.701: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012620904s
Apr 26 11:42:34.700: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011361218s
Apr 26 11:42:36.704: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.015462972s
Apr 26 11:42:36.704: INFO: Pod "preemptor-pod" satisfied condition "running"
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:42:36.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-preemption-1392" for this suite. 04/26/24 11:42:36.758
[AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
  test/e2e/scheduling/preemption.go:80
{"msg":"PASSED [sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]","completed":137,"skipped":2400,"failed":0}
------------------------------
â€¢ [SLOW TEST] [68.642 seconds]
[sig-scheduling] SchedulerPreemption [Serial]
test/e2e/scheduling/framework.go:40
  validates basic preemption works [Conformance]
  test/e2e/scheduling/preemption.go:125

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:41:28.241
    Apr 26 11:41:28.241: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename sched-preemption 04/26/24 11:41:28.242
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:41:28.271
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:41:28.277
    [BeforeEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:92
    Apr 26 11:41:28.340: INFO: Waiting up to 1m0s for all nodes to be ready
    Apr 26 11:42:28.419: INFO: Waiting for terminating namespaces to be deleted...
    [It] validates basic preemption works [Conformance]
      test/e2e/scheduling/preemption.go:125
    STEP: Create pods that use 4/5 of node resources. 04/26/24 11:42:28.423
    Apr 26 11:42:28.492: INFO: Created pod: pod0-0-sched-preemption-low-priority
    Apr 26 11:42:28.502: INFO: Created pod: pod0-1-sched-preemption-medium-priority
    Apr 26 11:42:28.545: INFO: Created pod: pod1-0-sched-preemption-medium-priority
    Apr 26 11:42:28.555: INFO: Created pod: pod1-1-sched-preemption-medium-priority
    Apr 26 11:42:28.580: INFO: Created pod: pod2-0-sched-preemption-medium-priority
    Apr 26 11:42:28.594: INFO: Created pod: pod2-1-sched-preemption-medium-priority
    Apr 26 11:42:28.616: INFO: Created pod: pod3-0-sched-preemption-medium-priority
    Apr 26 11:42:28.628: INFO: Created pod: pod3-1-sched-preemption-medium-priority
    STEP: Wait for pods to be scheduled. 04/26/24 11:42:28.628
    Apr 26 11:42:28.628: INFO: Waiting up to 5m0s for pod "pod0-0-sched-preemption-low-priority" in namespace "sched-preemption-1392" to be "running"
    Apr 26 11:42:28.637: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Pending", Reason="", readiness=false. Elapsed: 9.033246ms
    Apr 26 11:42:30.645: INFO: Pod "pod0-0-sched-preemption-low-priority": Phase="Running", Reason="", readiness=true. Elapsed: 2.017130743s
    Apr 26 11:42:30.645: INFO: Pod "pod0-0-sched-preemption-low-priority" satisfied condition "running"
    Apr 26 11:42:30.645: INFO: Waiting up to 5m0s for pod "pod0-1-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
    Apr 26 11:42:30.650: INFO: Pod "pod0-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.555436ms
    Apr 26 11:42:30.650: INFO: Pod "pod0-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 26 11:42:30.650: INFO: Waiting up to 5m0s for pod "pod1-0-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
    Apr 26 11:42:30.654: INFO: Pod "pod1-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.563579ms
    Apr 26 11:42:30.654: INFO: Pod "pod1-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 26 11:42:30.654: INFO: Waiting up to 5m0s for pod "pod1-1-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
    Apr 26 11:42:30.659: INFO: Pod "pod1-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 5.00675ms
    Apr 26 11:42:30.659: INFO: Pod "pod1-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 26 11:42:30.659: INFO: Waiting up to 5m0s for pod "pod2-0-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
    Apr 26 11:42:30.663: INFO: Pod "pod2-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.303334ms
    Apr 26 11:42:30.663: INFO: Pod "pod2-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 26 11:42:30.663: INFO: Waiting up to 5m0s for pod "pod2-1-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
    Apr 26 11:42:30.667: INFO: Pod "pod2-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 3.743076ms
    Apr 26 11:42:30.667: INFO: Pod "pod2-1-sched-preemption-medium-priority" satisfied condition "running"
    Apr 26 11:42:30.667: INFO: Waiting up to 5m0s for pod "pod3-0-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
    Apr 26 11:42:30.672: INFO: Pod "pod3-0-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.767272ms
    Apr 26 11:42:30.672: INFO: Pod "pod3-0-sched-preemption-medium-priority" satisfied condition "running"
    Apr 26 11:42:30.672: INFO: Waiting up to 5m0s for pod "pod3-1-sched-preemption-medium-priority" in namespace "sched-preemption-1392" to be "running"
    Apr 26 11:42:30.677: INFO: Pod "pod3-1-sched-preemption-medium-priority": Phase="Running", Reason="", readiness=true. Elapsed: 4.430742ms
    Apr 26 11:42:30.677: INFO: Pod "pod3-1-sched-preemption-medium-priority" satisfied condition "running"
    STEP: Run a high priority pod that has same requirements as that of lower priority pod 04/26/24 11:42:30.677
    Apr 26 11:42:30.688: INFO: Waiting up to 2m0s for pod "preemptor-pod" in namespace "sched-preemption-1392" to be "running"
    Apr 26 11:42:30.694: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.787451ms
    Apr 26 11:42:32.701: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012620904s
    Apr 26 11:42:34.700: INFO: Pod "preemptor-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011361218s
    Apr 26 11:42:36.704: INFO: Pod "preemptor-pod": Phase="Running", Reason="", readiness=true. Elapsed: 6.015462972s
    Apr 26 11:42:36.704: INFO: Pod "preemptor-pod" satisfied condition "running"
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:42:36.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-preemption-1392" for this suite. 04/26/24 11:42:36.758
    [AfterEach] [sig-scheduling] SchedulerPreemption [Serial]
      test/e2e/scheduling/preemption.go:80
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:42:36.885
Apr 26 11:42:36.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename job 04/26/24 11:42:36.885
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:42:36.902
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:42:36.909
[It] should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335
STEP: Creating a job 04/26/24 11:42:36.915
STEP: Ensuring active pods == parallelism 04/26/24 11:42:36.922
STEP: Orphaning one of the Job's Pods 04/26/24 11:42:38.928
Apr 26 11:42:39.453: INFO: Successfully updated pod "adopt-release-249hh"
STEP: Checking that the Job readopts the Pod 04/26/24 11:42:39.453
Apr 26 11:42:39.453: INFO: Waiting up to 15m0s for pod "adopt-release-249hh" in namespace "job-516" to be "adopted"
Apr 26 11:42:39.495: INFO: Pod "adopt-release-249hh": Phase="Running", Reason="", readiness=true. Elapsed: 41.85712ms
Apr 26 11:42:41.503: INFO: Pod "adopt-release-249hh": Phase="Running", Reason="", readiness=true. Elapsed: 2.049957755s
Apr 26 11:42:41.503: INFO: Pod "adopt-release-249hh" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod 04/26/24 11:42:41.504
Apr 26 11:42:42.020: INFO: Successfully updated pod "adopt-release-249hh"
STEP: Checking that the Job releases the Pod 04/26/24 11:42:42.02
Apr 26 11:42:42.020: INFO: Waiting up to 15m0s for pod "adopt-release-249hh" in namespace "job-516" to be "released"
Apr 26 11:42:42.024: INFO: Pod "adopt-release-249hh": Phase="Running", Reason="", readiness=true. Elapsed: 3.955844ms
Apr 26 11:42:44.030: INFO: Pod "adopt-release-249hh": Phase="Running", Reason="", readiness=true. Elapsed: 2.009675453s
Apr 26 11:42:44.030: INFO: Pod "adopt-release-249hh" satisfied condition "released"
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 26 11:42:44.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-516" for this suite. 04/26/24 11:42:44.04
{"msg":"PASSED [sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]","completed":138,"skipped":2426,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.160 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  test/e2e/apps/job.go:335

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:42:36.885
    Apr 26 11:42:36.885: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename job 04/26/24 11:42:36.885
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:42:36.902
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:42:36.909
    [It] should adopt matching orphans and release non-matching pods [Conformance]
      test/e2e/apps/job.go:335
    STEP: Creating a job 04/26/24 11:42:36.915
    STEP: Ensuring active pods == parallelism 04/26/24 11:42:36.922
    STEP: Orphaning one of the Job's Pods 04/26/24 11:42:38.928
    Apr 26 11:42:39.453: INFO: Successfully updated pod "adopt-release-249hh"
    STEP: Checking that the Job readopts the Pod 04/26/24 11:42:39.453
    Apr 26 11:42:39.453: INFO: Waiting up to 15m0s for pod "adopt-release-249hh" in namespace "job-516" to be "adopted"
    Apr 26 11:42:39.495: INFO: Pod "adopt-release-249hh": Phase="Running", Reason="", readiness=true. Elapsed: 41.85712ms
    Apr 26 11:42:41.503: INFO: Pod "adopt-release-249hh": Phase="Running", Reason="", readiness=true. Elapsed: 2.049957755s
    Apr 26 11:42:41.503: INFO: Pod "adopt-release-249hh" satisfied condition "adopted"
    STEP: Removing the labels from the Job's Pod 04/26/24 11:42:41.504
    Apr 26 11:42:42.020: INFO: Successfully updated pod "adopt-release-249hh"
    STEP: Checking that the Job releases the Pod 04/26/24 11:42:42.02
    Apr 26 11:42:42.020: INFO: Waiting up to 15m0s for pod "adopt-release-249hh" in namespace "job-516" to be "released"
    Apr 26 11:42:42.024: INFO: Pod "adopt-release-249hh": Phase="Running", Reason="", readiness=true. Elapsed: 3.955844ms
    Apr 26 11:42:44.030: INFO: Pod "adopt-release-249hh": Phase="Running", Reason="", readiness=true. Elapsed: 2.009675453s
    Apr 26 11:42:44.030: INFO: Pod "adopt-release-249hh" satisfied condition "released"
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 26 11:42:44.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-516" for this suite. 04/26/24 11:42:44.04
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:42:44.047
Apr 26 11:42:44.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename endpointslice 04/26/24 11:42:44.048
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:42:44.064
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:42:44.071
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204
STEP: referencing a single matching pod 04/26/24 11:42:49.154
STEP: referencing matching pods with named port 04/26/24 11:42:54.165
STEP: creating empty Endpoints and EndpointSlices for no matching Pods 04/26/24 11:42:59.176
STEP: recreating EndpointSlices after they've been deleted 04/26/24 11:43:04.187
Apr 26 11:43:04.215: INFO: EndpointSlice for Service endpointslice-6019/example-named-port not found
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 26 11:43:14.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-6019" for this suite. 04/26/24 11:43:14.238
{"msg":"PASSED [sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]","completed":139,"skipped":2438,"failed":0}
------------------------------
â€¢ [SLOW TEST] [30.198 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
  test/e2e/network/endpointslice.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:42:44.047
    Apr 26 11:42:44.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename endpointslice 04/26/24 11:42:44.048
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:42:44.064
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:42:44.071
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]
      test/e2e/network/endpointslice.go:204
    STEP: referencing a single matching pod 04/26/24 11:42:49.154
    STEP: referencing matching pods with named port 04/26/24 11:42:54.165
    STEP: creating empty Endpoints and EndpointSlices for no matching Pods 04/26/24 11:42:59.176
    STEP: recreating EndpointSlices after they've been deleted 04/26/24 11:43:04.187
    Apr 26 11:43:04.215: INFO: EndpointSlice for Service endpointslice-6019/example-named-port not found
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 26 11:43:14.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-6019" for this suite. 04/26/24 11:43:14.238
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:43:14.251
Apr 26 11:43:14.251: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename replicaset 04/26/24 11:43:14.252
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:43:14.268
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:43:14.275
[It] should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176
STEP: Create a Replicaset 04/26/24 11:43:14.288
STEP: Verify that the required pods have come up. 04/26/24 11:43:14.293
Apr 26 11:43:14.296: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 26 11:43:19.303: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/26/24 11:43:19.303
STEP: Getting /status 04/26/24 11:43:19.303
Apr 26 11:43:19.307: INFO: Replicaset test-rs has Conditions: []
STEP: updating the Replicaset Status 04/26/24 11:43:19.307
Apr 26 11:43:19.316: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the ReplicaSet status to be updated 04/26/24 11:43:19.316
Apr 26 11:43:19.319: INFO: Observed &ReplicaSet event: ADDED
Apr 26 11:43:19.319: INFO: Observed &ReplicaSet event: MODIFIED
Apr 26 11:43:19.319: INFO: Observed &ReplicaSet event: MODIFIED
Apr 26 11:43:19.319: INFO: Observed &ReplicaSet event: MODIFIED
Apr 26 11:43:19.320: INFO: Found replicaset test-rs in namespace replicaset-5455 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 26 11:43:19.320: INFO: Replicaset test-rs has an updated status
STEP: patching the Replicaset Status 04/26/24 11:43:19.32
Apr 26 11:43:19.320: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 26 11:43:19.327: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Replicaset status to be patched 04/26/24 11:43:19.327
Apr 26 11:43:19.330: INFO: Observed &ReplicaSet event: ADDED
Apr 26 11:43:19.330: INFO: Observed &ReplicaSet event: MODIFIED
Apr 26 11:43:19.330: INFO: Observed &ReplicaSet event: MODIFIED
Apr 26 11:43:19.330: INFO: Observed &ReplicaSet event: MODIFIED
Apr 26 11:43:19.330: INFO: Observed replicaset test-rs in namespace replicaset-5455 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 26 11:43:19.330: INFO: Observed &ReplicaSet event: MODIFIED
Apr 26 11:43:19.330: INFO: Found replicaset test-rs in namespace replicaset-5455 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
Apr 26 11:43:19.330: INFO: Replicaset test-rs has a patched status
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 26 11:43:19.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5455" for this suite. 04/26/24 11:43:19.346
{"msg":"PASSED [sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]","completed":140,"skipped":2514,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.105 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should validate Replicaset Status endpoints [Conformance]
  test/e2e/apps/replica_set.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:43:14.251
    Apr 26 11:43:14.251: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename replicaset 04/26/24 11:43:14.252
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:43:14.268
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:43:14.275
    [It] should validate Replicaset Status endpoints [Conformance]
      test/e2e/apps/replica_set.go:176
    STEP: Create a Replicaset 04/26/24 11:43:14.288
    STEP: Verify that the required pods have come up. 04/26/24 11:43:14.293
    Apr 26 11:43:14.296: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 26 11:43:19.303: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/26/24 11:43:19.303
    STEP: Getting /status 04/26/24 11:43:19.303
    Apr 26 11:43:19.307: INFO: Replicaset test-rs has Conditions: []
    STEP: updating the Replicaset Status 04/26/24 11:43:19.307
    Apr 26 11:43:19.316: INFO: updatedStatus.Conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the ReplicaSet status to be updated 04/26/24 11:43:19.316
    Apr 26 11:43:19.319: INFO: Observed &ReplicaSet event: ADDED
    Apr 26 11:43:19.319: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 26 11:43:19.319: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 26 11:43:19.319: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 26 11:43:19.320: INFO: Found replicaset test-rs in namespace replicaset-5455 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 26 11:43:19.320: INFO: Replicaset test-rs has an updated status
    STEP: patching the Replicaset Status 04/26/24 11:43:19.32
    Apr 26 11:43:19.320: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 26 11:43:19.327: INFO: Patched status conditions: []v1.ReplicaSetCondition{v1.ReplicaSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Replicaset status to be patched 04/26/24 11:43:19.327
    Apr 26 11:43:19.330: INFO: Observed &ReplicaSet event: ADDED
    Apr 26 11:43:19.330: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 26 11:43:19.330: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 26 11:43:19.330: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 26 11:43:19.330: INFO: Observed replicaset test-rs in namespace replicaset-5455 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 26 11:43:19.330: INFO: Observed &ReplicaSet event: MODIFIED
    Apr 26 11:43:19.330: INFO: Found replicaset test-rs in namespace replicaset-5455 with labels: map[name:sample-pod pod:httpd] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    Apr 26 11:43:19.330: INFO: Replicaset test-rs has a patched status
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 26 11:43:19.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-5455" for this suite. 04/26/24 11:43:19.346
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:43:19.358
Apr 26 11:43:19.358: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename crd-webhook 04/26/24 11:43:19.36
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:43:19.373
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:43:19.38
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 04/26/24 11:43:19.389
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/26/24 11:43:19.706
STEP: Deploying the custom resource conversion webhook pod 04/26/24 11:43:19.715
STEP: Wait for the deployment to be ready 04/26/24 11:43:19.729
Apr 26 11:43:19.739: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 11:43:21.757
STEP: Verifying the service has paired with the endpoint 04/26/24 11:43:21.77
Apr 26 11:43:22.771: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184
Apr 26 11:43:22.779: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Creating a v1 custom resource 04/26/24 11:43:25.61
STEP: Create a v2 custom resource 04/26/24 11:43:25.63
STEP: List CRs in v1 04/26/24 11:43:25.716
STEP: List CRs in v2 04/26/24 11:43:25.771
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:43:26.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7679" for this suite. 04/26/24 11:43:26.321
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]","completed":141,"skipped":2518,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.016 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:184

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:43:19.358
    Apr 26 11:43:19.358: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename crd-webhook 04/26/24 11:43:19.36
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:43:19.373
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:43:19.38
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 04/26/24 11:43:19.389
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/26/24 11:43:19.706
    STEP: Deploying the custom resource conversion webhook pod 04/26/24 11:43:19.715
    STEP: Wait for the deployment to be ready 04/26/24 11:43:19.729
    Apr 26 11:43:19.739: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 11:43:21.757
    STEP: Verifying the service has paired with the endpoint 04/26/24 11:43:21.77
    Apr 26 11:43:22.771: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert a non homogeneous list of CRs [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:184
    Apr 26 11:43:22.779: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Creating a v1 custom resource 04/26/24 11:43:25.61
    STEP: Create a v2 custom resource 04/26/24 11:43:25.63
    STEP: List CRs in v1 04/26/24 11:43:25.716
    STEP: List CRs in v2 04/26/24 11:43:25.771
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:43:26.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-7679" for this suite. 04/26/24 11:43:26.321
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:43:26.376
Apr 26 11:43:26.377: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename replication-controller 04/26/24 11:43:26.378
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:43:26.428
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:43:26.435
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91
STEP: Given a Pod with a 'name' label pod-adoption is created 04/26/24 11:43:26.442
Apr 26 11:43:26.455: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-7252" to be "running and ready"
Apr 26 11:43:26.471: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 15.223992ms
Apr 26 11:43:26.471: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:43:28.493: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.037963929s
Apr 26 11:43:28.494: INFO: The phase of Pod pod-adoption is Running (Ready = true)
Apr 26 11:43:28.494: INFO: Pod "pod-adoption" satisfied condition "running and ready"
STEP: When a replication controller with a matching selector is created 04/26/24 11:43:28.5
STEP: Then the orphan pod is adopted 04/26/24 11:43:28.518
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 26 11:43:29.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7252" for this suite. 04/26/24 11:43:29.567
{"msg":"PASSED [sig-apps] ReplicationController should adopt matching pods on creation [Conformance]","completed":142,"skipped":2531,"failed":0}
------------------------------
â€¢ [3.198 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  test/e2e/apps/rc.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:43:26.376
    Apr 26 11:43:26.377: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename replication-controller 04/26/24 11:43:26.378
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:43:26.428
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:43:26.435
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should adopt matching pods on creation [Conformance]
      test/e2e/apps/rc.go:91
    STEP: Given a Pod with a 'name' label pod-adoption is created 04/26/24 11:43:26.442
    Apr 26 11:43:26.455: INFO: Waiting up to 5m0s for pod "pod-adoption" in namespace "replication-controller-7252" to be "running and ready"
    Apr 26 11:43:26.471: INFO: Pod "pod-adoption": Phase="Pending", Reason="", readiness=false. Elapsed: 15.223992ms
    Apr 26 11:43:26.471: INFO: The phase of Pod pod-adoption is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:43:28.493: INFO: Pod "pod-adoption": Phase="Running", Reason="", readiness=true. Elapsed: 2.037963929s
    Apr 26 11:43:28.494: INFO: The phase of Pod pod-adoption is Running (Ready = true)
    Apr 26 11:43:28.494: INFO: Pod "pod-adoption" satisfied condition "running and ready"
    STEP: When a replication controller with a matching selector is created 04/26/24 11:43:28.5
    STEP: Then the orphan pod is adopted 04/26/24 11:43:28.518
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 26 11:43:29.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-7252" for this suite. 04/26/24 11:43:29.567
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] KubeletManagedEtcHosts
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
[BeforeEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:43:29.578
Apr 26 11:43:29.578: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 04/26/24 11:43:29.579
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:43:29.594
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:43:29.6
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63
STEP: Setting up the test 04/26/24 11:43:29.607
STEP: Creating hostNetwork=false pod 04/26/24 11:43:29.607
Apr 26 11:43:29.639: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-6032" to be "running and ready"
Apr 26 11:43:29.649: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.946349ms
Apr 26 11:43:29.649: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:43:31.656: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.016040683s
Apr 26 11:43:31.656: INFO: The phase of Pod test-pod is Running (Ready = true)
Apr 26 11:43:31.656: INFO: Pod "test-pod" satisfied condition "running and ready"
STEP: Creating hostNetwork=true pod 04/26/24 11:43:31.665
Apr 26 11:43:31.673: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-6032" to be "running and ready"
Apr 26 11:43:31.682: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.608899ms
Apr 26 11:43:31.682: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:43:33.689: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015935902s
Apr 26 11:43:33.689: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
Apr 26 11:43:33.689: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
STEP: Running the test 04/26/24 11:43:33.694
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 04/26/24 11:43:33.694
Apr 26 11:43:33.694: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:43:33.694: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:43:33.695: INFO: ExecWithOptions: Clientset creation
Apr 26 11:43:33.695: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 26 11:43:34.167: INFO: Exec stderr: ""
Apr 26 11:43:34.167: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:43:34.167: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:43:34.167: INFO: ExecWithOptions: Clientset creation
Apr 26 11:43:34.168: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 26 11:43:34.603: INFO: Exec stderr: ""
Apr 26 11:43:34.603: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:43:34.603: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:43:34.604: INFO: ExecWithOptions: Clientset creation
Apr 26 11:43:34.604: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 26 11:43:35.004: INFO: Exec stderr: ""
Apr 26 11:43:35.004: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:43:35.004: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:43:35.005: INFO: ExecWithOptions: Clientset creation
Apr 26 11:43:35.005: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 26 11:43:35.475: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 04/26/24 11:43:35.475
Apr 26 11:43:35.475: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:43:35.475: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:43:35.476: INFO: ExecWithOptions: Clientset creation
Apr 26 11:43:35.476: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Apr 26 11:43:35.913: INFO: Exec stderr: ""
Apr 26 11:43:35.913: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:43:35.913: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:43:35.914: INFO: ExecWithOptions: Clientset creation
Apr 26 11:43:35.914: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
Apr 26 11:43:36.350: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 04/26/24 11:43:36.35
Apr 26 11:43:36.350: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:43:36.350: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:43:36.351: INFO: ExecWithOptions: Clientset creation
Apr 26 11:43:36.351: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 26 11:43:36.868: INFO: Exec stderr: ""
Apr 26 11:43:36.868: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:43:36.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:43:36.868: INFO: ExecWithOptions: Clientset creation
Apr 26 11:43:36.869: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
Apr 26 11:43:37.317: INFO: Exec stderr: ""
Apr 26 11:43:37.317: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:43:37.317: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:43:37.317: INFO: ExecWithOptions: Clientset creation
Apr 26 11:43:37.317: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 26 11:43:37.609: INFO: Exec stderr: ""
Apr 26 11:43:37.609: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:43:37.609: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:43:37.609: INFO: ExecWithOptions: Clientset creation
Apr 26 11:43:37.609: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
Apr 26 11:43:38.050: INFO: Exec stderr: ""
[AfterEach] [sig-node] KubeletManagedEtcHosts
  test/e2e/framework/framework.go:187
Apr 26 11:43:38.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-6032" for this suite. 04/26/24 11:43:38.061
{"msg":"PASSED [sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]","completed":143,"skipped":2578,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.489 seconds]
[sig-node] KubeletManagedEtcHosts
test/e2e/common/node/framework.go:23
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet_etc_hosts.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:43:29.578
    Apr 26 11:43:29.578: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts 04/26/24 11:43:29.579
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:43:29.594
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:43:29.6
    [It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet_etc_hosts.go:63
    STEP: Setting up the test 04/26/24 11:43:29.607
    STEP: Creating hostNetwork=false pod 04/26/24 11:43:29.607
    Apr 26 11:43:29.639: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "e2e-kubelet-etc-hosts-6032" to be "running and ready"
    Apr 26 11:43:29.649: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.946349ms
    Apr 26 11:43:29.649: INFO: The phase of Pod test-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:43:31.656: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.016040683s
    Apr 26 11:43:31.656: INFO: The phase of Pod test-pod is Running (Ready = true)
    Apr 26 11:43:31.656: INFO: Pod "test-pod" satisfied condition "running and ready"
    STEP: Creating hostNetwork=true pod 04/26/24 11:43:31.665
    Apr 26 11:43:31.673: INFO: Waiting up to 5m0s for pod "test-host-network-pod" in namespace "e2e-kubelet-etc-hosts-6032" to be "running and ready"
    Apr 26 11:43:31.682: INFO: Pod "test-host-network-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 8.608899ms
    Apr 26 11:43:31.682: INFO: The phase of Pod test-host-network-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:43:33.689: INFO: Pod "test-host-network-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.015935902s
    Apr 26 11:43:33.689: INFO: The phase of Pod test-host-network-pod is Running (Ready = true)
    Apr 26 11:43:33.689: INFO: Pod "test-host-network-pod" satisfied condition "running and ready"
    STEP: Running the test 04/26/24 11:43:33.694
    STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false 04/26/24 11:43:33.694
    Apr 26 11:43:33.694: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:43:33.694: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:43:33.695: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:43:33.695: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 26 11:43:34.167: INFO: Exec stderr: ""
    Apr 26 11:43:34.167: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:43:34.167: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:43:34.167: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:43:34.168: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 26 11:43:34.603: INFO: Exec stderr: ""
    Apr 26 11:43:34.603: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:43:34.603: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:43:34.604: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:43:34.604: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 26 11:43:35.004: INFO: Exec stderr: ""
    Apr 26 11:43:35.004: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:43:35.004: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:43:35.005: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:43:35.005: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 26 11:43:35.475: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount 04/26/24 11:43:35.475
    Apr 26 11:43:35.475: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:43:35.475: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:43:35.476: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:43:35.476: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Apr 26 11:43:35.913: INFO: Exec stderr: ""
    Apr 26 11:43:35.913: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:43:35.913: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:43:35.914: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:43:35.914: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-3&container=busybox-3&stderr=true&stdout=true)
    Apr 26 11:43:36.350: INFO: Exec stderr: ""
    STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true 04/26/24 11:43:36.35
    Apr 26 11:43:36.350: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:43:36.350: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:43:36.351: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:43:36.351: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 26 11:43:36.868: INFO: Exec stderr: ""
    Apr 26 11:43:36.868: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:43:36.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:43:36.868: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:43:36.869: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-1&container=busybox-1&stderr=true&stdout=true)
    Apr 26 11:43:37.317: INFO: Exec stderr: ""
    Apr 26 11:43:37.317: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:43:37.317: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:43:37.317: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:43:37.317: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 26 11:43:37.609: INFO: Exec stderr: ""
    Apr 26 11:43:37.609: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-6032 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:43:37.609: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:43:37.609: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:43:37.609: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/e2e-kubelet-etc-hosts-6032/pods/test-host-network-pod/exec?command=cat&command=%2Fetc%2Fhosts-original&container=busybox-2&container=busybox-2&stderr=true&stdout=true)
    Apr 26 11:43:38.050: INFO: Exec stderr: ""
    [AfterEach] [sig-node] KubeletManagedEtcHosts
      test/e2e/framework/framework.go:187
    Apr 26 11:43:38.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "e2e-kubelet-etc-hosts-6032" for this suite. 04/26/24 11:43:38.061
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:43:38.071
Apr 26 11:43:38.071: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 11:43:38.072
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:43:38.092
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:43:38.098
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7369 04/26/24 11:43:38.111
STEP: changing the ExternalName service to type=NodePort 04/26/24 11:43:38.126
STEP: creating replication controller externalname-service in namespace services-7369 04/26/24 11:43:38.224
I0426 11:43:38.231372      23 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7369, replica count: 2
I0426 11:43:41.282616      23 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 26 11:43:41.282: INFO: Creating new exec pod
Apr 26 11:43:41.295: INFO: Waiting up to 5m0s for pod "execpodmstwl" in namespace "services-7369" to be "running"
Apr 26 11:43:41.305: INFO: Pod "execpodmstwl": Phase="Pending", Reason="", readiness=false. Elapsed: 10.590329ms
Apr 26 11:43:43.311: INFO: Pod "execpodmstwl": Phase="Running", Reason="", readiness=true. Elapsed: 2.016189737s
Apr 26 11:43:43.311: INFO: Pod "execpodmstwl" satisfied condition "running"
Apr 26 11:43:44.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-7369 exec execpodmstwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 26 11:43:44.752: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 26 11:43:44.752: INFO: stdout: "externalname-service-nz45d"
Apr 26 11:43:44.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-7369 exec execpodmstwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.69.166.109 80'
Apr 26 11:43:45.084: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.69.166.109 80\nConnection to 100.69.166.109 80 port [tcp/http] succeeded!\n"
Apr 26 11:43:45.084: INFO: stdout: "externalname-service-nz45d"
Apr 26 11:43:45.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-7369 exec execpodmstwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.152 32565'
Apr 26 11:43:45.595: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.152 32565\nConnection to 10.250.0.152 32565 port [tcp/*] succeeded!\n"
Apr 26 11:43:45.595: INFO: stdout: "externalname-service-nz45d"
Apr 26 11:43:45.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-7369 exec execpodmstwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.2.248 32565'
Apr 26 11:43:46.042: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.2.248 32565\nConnection to 10.250.2.248 32565 port [tcp/*] succeeded!\n"
Apr 26 11:43:46.042: INFO: stdout: "externalname-service-9gcmw"
Apr 26 11:43:46.042: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 11:43:46.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7369" for this suite. 04/26/24 11:43:46.128
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]","completed":144,"skipped":2603,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.063 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  test/e2e/network/service.go:1443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:43:38.071
    Apr 26 11:43:38.071: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 11:43:38.072
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:43:38.092
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:43:38.098
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to NodePort [Conformance]
      test/e2e/network/service.go:1443
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-7369 04/26/24 11:43:38.111
    STEP: changing the ExternalName service to type=NodePort 04/26/24 11:43:38.126
    STEP: creating replication controller externalname-service in namespace services-7369 04/26/24 11:43:38.224
    I0426 11:43:38.231372      23 runners.go:193] Created replication controller with name: externalname-service, namespace: services-7369, replica count: 2
    I0426 11:43:41.282616      23 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 26 11:43:41.282: INFO: Creating new exec pod
    Apr 26 11:43:41.295: INFO: Waiting up to 5m0s for pod "execpodmstwl" in namespace "services-7369" to be "running"
    Apr 26 11:43:41.305: INFO: Pod "execpodmstwl": Phase="Pending", Reason="", readiness=false. Elapsed: 10.590329ms
    Apr 26 11:43:43.311: INFO: Pod "execpodmstwl": Phase="Running", Reason="", readiness=true. Elapsed: 2.016189737s
    Apr 26 11:43:43.311: INFO: Pod "execpodmstwl" satisfied condition "running"
    Apr 26 11:43:44.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-7369 exec execpodmstwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 26 11:43:44.752: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 26 11:43:44.752: INFO: stdout: "externalname-service-nz45d"
    Apr 26 11:43:44.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-7369 exec execpodmstwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.69.166.109 80'
    Apr 26 11:43:45.084: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.69.166.109 80\nConnection to 100.69.166.109 80 port [tcp/http] succeeded!\n"
    Apr 26 11:43:45.084: INFO: stdout: "externalname-service-nz45d"
    Apr 26 11:43:45.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-7369 exec execpodmstwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.152 32565'
    Apr 26 11:43:45.595: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.152 32565\nConnection to 10.250.0.152 32565 port [tcp/*] succeeded!\n"
    Apr 26 11:43:45.595: INFO: stdout: "externalname-service-nz45d"
    Apr 26 11:43:45.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-7369 exec execpodmstwl -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.2.248 32565'
    Apr 26 11:43:46.042: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.2.248 32565\nConnection to 10.250.2.248 32565 port [tcp/*] succeeded!\n"
    Apr 26 11:43:46.042: INFO: stdout: "externalname-service-9gcmw"
    Apr 26 11:43:46.042: INFO: Cleaning up the ExternalName to NodePort test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 11:43:46.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7369" for this suite. 04/26/24 11:43:46.128
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:43:46.134
Apr 26 11:43:46.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename dns 04/26/24 11:43:46.135
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:43:46.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:43:46.155
[It] should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290
STEP: Creating a test headless service 04/26/24 11:43:46.162
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7629.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7629.svc.cluster.local;sleep 1; done
 04/26/24 11:43:46.169
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7629.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7629.svc.cluster.local;sleep 1; done
 04/26/24 11:43:46.17
STEP: creating a pod to probe DNS 04/26/24 11:43:46.17
STEP: submitting the pod to kubernetes 04/26/24 11:43:46.17
Apr 26 11:43:46.207: INFO: Waiting up to 15m0s for pod "dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2" in namespace "dns-7629" to be "running"
Apr 26 11:43:46.213: INFO: Pod "dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.129905ms
Apr 26 11:43:48.219: INFO: Pod "dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2": Phase="Running", Reason="", readiness=true. Elapsed: 2.011619147s
Apr 26 11:43:48.219: INFO: Pod "dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2" satisfied condition "running"
STEP: retrieving the pod 04/26/24 11:43:48.219
STEP: looking for the results for each expected name from probers 04/26/24 11:43:48.224
Apr 26 11:43:48.330: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:48.380: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:48.400: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:48.409: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:48.424: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:48.475: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:48.484: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:48.484: INFO: Lookups using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7629.svc.cluster.local]

Apr 26 11:43:53.494: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:53.538: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:53.568: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:53.584: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:53.604: INFO: Lookups using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local]

Apr 26 11:43:58.495: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:58.544: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:58.574: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:58.583: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:43:58.606: INFO: Lookups using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local]

Apr 26 11:44:03.496: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:44:03.546: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:44:03.577: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:44:03.588: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:44:03.609: INFO: Lookups using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local]

Apr 26 11:44:08.494: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:44:08.543: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:44:08.568: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:44:08.576: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:44:08.592: INFO: Lookups using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local]

Apr 26 11:44:13.494: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:44:13.548: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:44:13.610: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:44:13.620: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
Apr 26 11:44:13.641: INFO: Lookups using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local]

Apr 26 11:44:18.606: INFO: DNS probes using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 succeeded

STEP: deleting the pod 04/26/24 11:44:18.606
STEP: deleting the test headless service 04/26/24 11:44:18.647
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 26 11:44:18.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7629" for this suite. 04/26/24 11:44:18.705
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Subdomain [Conformance]","completed":145,"skipped":2607,"failed":0}
------------------------------
â€¢ [SLOW TEST] [32.587 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  test/e2e/network/dns.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:43:46.134
    Apr 26 11:43:46.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename dns 04/26/24 11:43:46.135
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:43:46.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:43:46.155
    [It] should provide DNS for pods for Subdomain [Conformance]
      test/e2e/network/dns.go:290
    STEP: Creating a test headless service 04/26/24 11:43:46.162
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7629.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7629.svc.cluster.local;sleep 1; done
     04/26/24 11:43:46.169
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7629.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7629.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7629.svc.cluster.local;sleep 1; done
     04/26/24 11:43:46.17
    STEP: creating a pod to probe DNS 04/26/24 11:43:46.17
    STEP: submitting the pod to kubernetes 04/26/24 11:43:46.17
    Apr 26 11:43:46.207: INFO: Waiting up to 15m0s for pod "dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2" in namespace "dns-7629" to be "running"
    Apr 26 11:43:46.213: INFO: Pod "dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2": Phase="Pending", Reason="", readiness=false. Elapsed: 5.129905ms
    Apr 26 11:43:48.219: INFO: Pod "dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2": Phase="Running", Reason="", readiness=true. Elapsed: 2.011619147s
    Apr 26 11:43:48.219: INFO: Pod "dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2" satisfied condition "running"
    STEP: retrieving the pod 04/26/24 11:43:48.219
    STEP: looking for the results for each expected name from probers 04/26/24 11:43:48.224
    Apr 26 11:43:48.330: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:48.380: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:48.400: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:48.409: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:48.424: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:48.475: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:48.484: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:48.484: INFO: Lookups using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7629.svc.cluster.local]

    Apr 26 11:43:53.494: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:53.538: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:53.568: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:53.584: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:53.604: INFO: Lookups using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local]

    Apr 26 11:43:58.495: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:58.544: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:58.574: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:58.583: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:43:58.606: INFO: Lookups using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local]

    Apr 26 11:44:03.496: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:44:03.546: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:44:03.577: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:44:03.588: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:44:03.609: INFO: Lookups using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local]

    Apr 26 11:44:08.494: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:44:08.543: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:44:08.568: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:44:08.576: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:44:08.592: INFO: Lookups using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local]

    Apr 26 11:44:13.494: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:44:13.548: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:44:13.610: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:44:13.620: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local from pod dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2: the server could not find the requested resource (get pods dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2)
    Apr 26 11:44:13.641: INFO: Lookups using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7629.svc.cluster.local]

    Apr 26 11:44:18.606: INFO: DNS probes using dns-7629/dns-test-e96f7e96-fd9a-4f63-9633-1f4e0406b1e2 succeeded

    STEP: deleting the pod 04/26/24 11:44:18.606
    STEP: deleting the test headless service 04/26/24 11:44:18.647
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 26 11:44:18.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7629" for this suite. 04/26/24 11:44:18.705
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:44:18.724
Apr 26 11:44:18.724: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename resourcequota 04/26/24 11:44:18.725
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:44:18.748
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:44:18.757
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438
STEP: Counting existing ResourceQuota 04/26/24 11:44:18.765
STEP: Creating a ResourceQuota 04/26/24 11:44:23.773
STEP: Ensuring resource quota status is calculated 04/26/24 11:44:23.779
STEP: Creating a ReplicaSet 04/26/24 11:44:25.787
STEP: Ensuring resource quota status captures replicaset creation 04/26/24 11:44:25.798
STEP: Deleting a ReplicaSet 04/26/24 11:44:27.809
STEP: Ensuring resource quota status released usage 04/26/24 11:44:27.815
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 26 11:44:29.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8271" for this suite. 04/26/24 11:44:29.835
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]","completed":146,"skipped":2638,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.118 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  test/e2e/apimachinery/resource_quota.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:44:18.724
    Apr 26 11:44:18.724: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename resourcequota 04/26/24 11:44:18.725
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:44:18.748
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:44:18.757
    [It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
      test/e2e/apimachinery/resource_quota.go:438
    STEP: Counting existing ResourceQuota 04/26/24 11:44:18.765
    STEP: Creating a ResourceQuota 04/26/24 11:44:23.773
    STEP: Ensuring resource quota status is calculated 04/26/24 11:44:23.779
    STEP: Creating a ReplicaSet 04/26/24 11:44:25.787
    STEP: Ensuring resource quota status captures replicaset creation 04/26/24 11:44:25.798
    STEP: Deleting a ReplicaSet 04/26/24 11:44:27.809
    STEP: Ensuring resource quota status released usage 04/26/24 11:44:27.815
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 26 11:44:29.824: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8271" for this suite. 04/26/24 11:44:29.835
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:44:29.845
Apr 26 11:44:29.845: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-probe 04/26/24 11:44:29.846
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:44:29.863
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:44:29.87
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 26 11:45:29.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6264" for this suite. 04/26/24 11:45:29.91
{"msg":"PASSED [sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]","completed":147,"skipped":2657,"failed":0}
------------------------------
â€¢ [SLOW TEST] [60.071 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:44:29.845
    Apr 26 11:44:29.845: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-probe 04/26/24 11:44:29.846
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:44:29.863
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:44:29.87
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:104
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 26 11:45:29.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-6264" for this suite. 04/26/24 11:45:29.91
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases
  should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:45:29.917
Apr 26 11:45:29.917: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubelet-test 04/26/24 11:45:29.918
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:45:29.932
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:45:29.938
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should write entries to /etc/hosts [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:148
STEP: Waiting for pod completion 04/26/24 11:45:29.954
Apr 26 11:45:29.954: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesfa918c7b-f0fc-40c6-8cc7-437623663140" in namespace "kubelet-test-8421" to be "completed"
Apr 26 11:45:29.961: INFO: Pod "agnhost-host-aliasesfa918c7b-f0fc-40c6-8cc7-437623663140": Phase="Pending", Reason="", readiness=false. Elapsed: 7.01347ms
Apr 26 11:45:31.968: INFO: Pod "agnhost-host-aliasesfa918c7b-f0fc-40c6-8cc7-437623663140": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014380056s
Apr 26 11:45:33.968: INFO: Pod "agnhost-host-aliasesfa918c7b-f0fc-40c6-8cc7-437623663140": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01435358s
Apr 26 11:45:33.968: INFO: Pod "agnhost-host-aliasesfa918c7b-f0fc-40c6-8cc7-437623663140" satisfied condition "completed"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 26 11:45:33.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8421" for this suite. 04/26/24 11:45:34.001
{"msg":"PASSED [sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]","completed":148,"skipped":2661,"failed":0}
------------------------------
â€¢ [4.091 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling an agnhost Pod with hostAliases
  test/e2e/common/node/kubelet.go:140
    should write entries to /etc/hosts [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:148

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:45:29.917
    Apr 26 11:45:29.917: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubelet-test 04/26/24 11:45:29.918
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:45:29.932
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:45:29.938
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should write entries to /etc/hosts [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:148
    STEP: Waiting for pod completion 04/26/24 11:45:29.954
    Apr 26 11:45:29.954: INFO: Waiting up to 3m0s for pod "agnhost-host-aliasesfa918c7b-f0fc-40c6-8cc7-437623663140" in namespace "kubelet-test-8421" to be "completed"
    Apr 26 11:45:29.961: INFO: Pod "agnhost-host-aliasesfa918c7b-f0fc-40c6-8cc7-437623663140": Phase="Pending", Reason="", readiness=false. Elapsed: 7.01347ms
    Apr 26 11:45:31.968: INFO: Pod "agnhost-host-aliasesfa918c7b-f0fc-40c6-8cc7-437623663140": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014380056s
    Apr 26 11:45:33.968: INFO: Pod "agnhost-host-aliasesfa918c7b-f0fc-40c6-8cc7-437623663140": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01435358s
    Apr 26 11:45:33.968: INFO: Pod "agnhost-host-aliasesfa918c7b-f0fc-40c6-8cc7-437623663140" satisfied condition "completed"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 26 11:45:33.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-8421" for this suite. 04/26/24 11:45:34.001
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:45:34.012
Apr 26 11:45:34.012: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 11:45:34.013
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:45:34.026
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:45:34.032
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88
STEP: Creating configMap with name configmap-test-volume-map-fdbd1fe9-6c57-4e4d-9c96-5ec073f6d27c 04/26/24 11:45:34.038
STEP: Creating a pod to test consume configMaps 04/26/24 11:45:34.043
Apr 26 11:45:34.055: INFO: Waiting up to 5m0s for pod "pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26" in namespace "configmap-9655" to be "Succeeded or Failed"
Apr 26 11:45:34.062: INFO: Pod "pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26": Phase="Pending", Reason="", readiness=false. Elapsed: 7.0499ms
Apr 26 11:45:36.069: INFO: Pod "pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26": Phase="Running", Reason="", readiness=false. Elapsed: 2.014086289s
Apr 26 11:45:38.069: INFO: Pod "pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013685291s
STEP: Saw pod success 04/26/24 11:45:38.069
Apr 26 11:45:38.069: INFO: Pod "pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26" satisfied condition "Succeeded or Failed"
Apr 26 11:45:38.075: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26 container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:45:38.088
Apr 26 11:45:38.102: INFO: Waiting for pod pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26 to disappear
Apr 26 11:45:38.110: INFO: Pod pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 11:45:38.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9655" for this suite. 04/26/24 11:45:38.117
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":149,"skipped":2716,"failed":0}
------------------------------
â€¢ [4.111 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:45:34.012
    Apr 26 11:45:34.012: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 11:45:34.013
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:45:34.026
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:45:34.032
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:88
    STEP: Creating configMap with name configmap-test-volume-map-fdbd1fe9-6c57-4e4d-9c96-5ec073f6d27c 04/26/24 11:45:34.038
    STEP: Creating a pod to test consume configMaps 04/26/24 11:45:34.043
    Apr 26 11:45:34.055: INFO: Waiting up to 5m0s for pod "pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26" in namespace "configmap-9655" to be "Succeeded or Failed"
    Apr 26 11:45:34.062: INFO: Pod "pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26": Phase="Pending", Reason="", readiness=false. Elapsed: 7.0499ms
    Apr 26 11:45:36.069: INFO: Pod "pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26": Phase="Running", Reason="", readiness=false. Elapsed: 2.014086289s
    Apr 26 11:45:38.069: INFO: Pod "pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013685291s
    STEP: Saw pod success 04/26/24 11:45:38.069
    Apr 26 11:45:38.069: INFO: Pod "pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26" satisfied condition "Succeeded or Failed"
    Apr 26 11:45:38.075: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26 container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:45:38.088
    Apr 26 11:45:38.102: INFO: Waiting for pod pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26 to disappear
    Apr 26 11:45:38.110: INFO: Pod pod-configmaps-aa0cc288-79ef-4c28-bf44-91b363098d26 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 11:45:38.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9655" for this suite. 04/26/24 11:45:38.117
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:45:38.127
Apr 26 11:45:38.127: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename dns 04/26/24 11:45:38.128
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:45:38.143
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:45:38.149
[It] should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137
STEP: Creating a test headless service 04/26/24 11:45:38.156
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2363.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2363.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2363.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2363.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 2.120.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.120.2_udp@PTR;check="$$(dig +tcp +noall +answer +search 2.120.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.120.2_tcp@PTR;sleep 1; done
 04/26/24 11:45:38.179
STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2363.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2363.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2363.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2363.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 2.120.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.120.2_udp@PTR;check="$$(dig +tcp +noall +answer +search 2.120.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.120.2_tcp@PTR;sleep 1; done
 04/26/24 11:45:38.179
STEP: creating a pod to probe DNS 04/26/24 11:45:38.179
STEP: submitting the pod to kubernetes 04/26/24 11:45:38.179
Apr 26 11:45:38.198: INFO: Waiting up to 15m0s for pod "dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3" in namespace "dns-2363" to be "running"
Apr 26 11:45:38.203: INFO: Pod "dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.955957ms
Apr 26 11:45:40.208: INFO: Pod "dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3": Phase="Running", Reason="", readiness=true. Elapsed: 2.010158s
Apr 26 11:45:40.208: INFO: Pod "dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3" satisfied condition "running"
STEP: retrieving the pod 04/26/24 11:45:40.208
STEP: looking for the results for each expected name from probers 04/26/24 11:45:40.213
Apr 26 11:45:40.352: INFO: Unable to read wheezy_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:40.399: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:40.408: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:40.417: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:40.467: INFO: Unable to read jessie_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:40.477: INFO: Unable to read jessie_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:40.486: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:40.496: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:40.534: INFO: Lookups using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 failed for: [wheezy_udp@dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_udp@dns-test-service.dns-2363.svc.cluster.local jessie_tcp@dns-test-service.dns-2363.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local]

Apr 26 11:45:45.562: INFO: Unable to read wheezy_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:45.593: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:45.603: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:45.651: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:45.691: INFO: Unable to read jessie_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:45.700: INFO: Unable to read jessie_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:45.710: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:45.718: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:45.808: INFO: Lookups using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 failed for: [wheezy_udp@dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_udp@dns-test-service.dns-2363.svc.cluster.local jessie_tcp@dns-test-service.dns-2363.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local]

Apr 26 11:45:50.578: INFO: Unable to read wheezy_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:50.628: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:50.639: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:50.650: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:50.697: INFO: Unable to read jessie_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:50.708: INFO: Unable to read jessie_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:50.716: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:50.725: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:50.763: INFO: Lookups using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 failed for: [wheezy_udp@dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_udp@dns-test-service.dns-2363.svc.cluster.local jessie_tcp@dns-test-service.dns-2363.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local]

Apr 26 11:45:55.543: INFO: Unable to read wheezy_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:55.590: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:55.598: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:55.609: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:55.659: INFO: Unable to read jessie_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:55.668: INFO: Unable to read jessie_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:55.678: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:55.687: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:45:55.728: INFO: Lookups using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 failed for: [wheezy_udp@dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_udp@dns-test-service.dns-2363.svc.cluster.local jessie_tcp@dns-test-service.dns-2363.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local]

Apr 26 11:46:00.550: INFO: Unable to read wheezy_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:00.598: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:00.606: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:00.615: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:00.654: INFO: Unable to read jessie_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:00.662: INFO: Unable to read jessie_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:00.671: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:00.681: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:00.716: INFO: Lookups using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 failed for: [wheezy_udp@dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_udp@dns-test-service.dns-2363.svc.cluster.local jessie_tcp@dns-test-service.dns-2363.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local]

Apr 26 11:46:05.545: INFO: Unable to read wheezy_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:05.590: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:05.600: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:05.609: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:05.657: INFO: Unable to read jessie_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:05.666: INFO: Unable to read jessie_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:05.674: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:05.682: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
Apr 26 11:46:05.720: INFO: Lookups using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 failed for: [wheezy_udp@dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_udp@dns-test-service.dns-2363.svc.cluster.local jessie_tcp@dns-test-service.dns-2363.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local]

Apr 26 11:46:10.729: INFO: DNS probes using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 succeeded

STEP: deleting the pod 04/26/24 11:46:10.729
STEP: deleting the test service 04/26/24 11:46:10.747
STEP: deleting the test headless service 04/26/24 11:46:10.765
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 26 11:46:10.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2363" for this suite. 04/26/24 11:46:10.78
{"msg":"PASSED [sig-network] DNS should provide DNS for services  [Conformance]","completed":150,"skipped":2748,"failed":0}
------------------------------
â€¢ [SLOW TEST] [32.660 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for services  [Conformance]
  test/e2e/network/dns.go:137

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:45:38.127
    Apr 26 11:45:38.127: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename dns 04/26/24 11:45:38.128
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:45:38.143
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:45:38.149
    [It] should provide DNS for services  [Conformance]
      test/e2e/network/dns.go:137
    STEP: Creating a test headless service 04/26/24 11:45:38.156
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2363.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2363.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2363.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2363.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 2.120.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.120.2_udp@PTR;check="$$(dig +tcp +noall +answer +search 2.120.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.120.2_tcp@PTR;sleep 1; done
     04/26/24 11:45:38.179
    STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2363.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2363.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2363.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2363.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2363.svc.cluster.local;check="$$(dig +notcp +noall +answer +search 2.120.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.120.2_udp@PTR;check="$$(dig +tcp +noall +answer +search 2.120.69.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.69.120.2_tcp@PTR;sleep 1; done
     04/26/24 11:45:38.179
    STEP: creating a pod to probe DNS 04/26/24 11:45:38.179
    STEP: submitting the pod to kubernetes 04/26/24 11:45:38.179
    Apr 26 11:45:38.198: INFO: Waiting up to 15m0s for pod "dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3" in namespace "dns-2363" to be "running"
    Apr 26 11:45:38.203: INFO: Pod "dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.955957ms
    Apr 26 11:45:40.208: INFO: Pod "dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3": Phase="Running", Reason="", readiness=true. Elapsed: 2.010158s
    Apr 26 11:45:40.208: INFO: Pod "dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3" satisfied condition "running"
    STEP: retrieving the pod 04/26/24 11:45:40.208
    STEP: looking for the results for each expected name from probers 04/26/24 11:45:40.213
    Apr 26 11:45:40.352: INFO: Unable to read wheezy_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:40.399: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:40.408: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:40.417: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:40.467: INFO: Unable to read jessie_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:40.477: INFO: Unable to read jessie_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:40.486: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:40.496: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:40.534: INFO: Lookups using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 failed for: [wheezy_udp@dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_udp@dns-test-service.dns-2363.svc.cluster.local jessie_tcp@dns-test-service.dns-2363.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local]

    Apr 26 11:45:45.562: INFO: Unable to read wheezy_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:45.593: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:45.603: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:45.651: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:45.691: INFO: Unable to read jessie_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:45.700: INFO: Unable to read jessie_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:45.710: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:45.718: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:45.808: INFO: Lookups using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 failed for: [wheezy_udp@dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_udp@dns-test-service.dns-2363.svc.cluster.local jessie_tcp@dns-test-service.dns-2363.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local]

    Apr 26 11:45:50.578: INFO: Unable to read wheezy_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:50.628: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:50.639: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:50.650: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:50.697: INFO: Unable to read jessie_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:50.708: INFO: Unable to read jessie_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:50.716: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:50.725: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:50.763: INFO: Lookups using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 failed for: [wheezy_udp@dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_udp@dns-test-service.dns-2363.svc.cluster.local jessie_tcp@dns-test-service.dns-2363.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local]

    Apr 26 11:45:55.543: INFO: Unable to read wheezy_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:55.590: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:55.598: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:55.609: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:55.659: INFO: Unable to read jessie_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:55.668: INFO: Unable to read jessie_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:55.678: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:55.687: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:45:55.728: INFO: Lookups using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 failed for: [wheezy_udp@dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_udp@dns-test-service.dns-2363.svc.cluster.local jessie_tcp@dns-test-service.dns-2363.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local]

    Apr 26 11:46:00.550: INFO: Unable to read wheezy_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:00.598: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:00.606: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:00.615: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:00.654: INFO: Unable to read jessie_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:00.662: INFO: Unable to read jessie_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:00.671: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:00.681: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:00.716: INFO: Lookups using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 failed for: [wheezy_udp@dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_udp@dns-test-service.dns-2363.svc.cluster.local jessie_tcp@dns-test-service.dns-2363.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local]

    Apr 26 11:46:05.545: INFO: Unable to read wheezy_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:05.590: INFO: Unable to read wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:05.600: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:05.609: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:05.657: INFO: Unable to read jessie_udp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:05.666: INFO: Unable to read jessie_tcp@dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:05.674: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:05.682: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local from pod dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3: the server could not find the requested resource (get pods dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3)
    Apr 26 11:46:05.720: INFO: Lookups using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 failed for: [wheezy_udp@dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@dns-test-service.dns-2363.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_udp@dns-test-service.dns-2363.svc.cluster.local jessie_tcp@dns-test-service.dns-2363.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2363.svc.cluster.local]

    Apr 26 11:46:10.729: INFO: DNS probes using dns-2363/dns-test-6b60cce4-f395-495e-9b36-ee0119a68cc3 succeeded

    STEP: deleting the pod 04/26/24 11:46:10.729
    STEP: deleting the test service 04/26/24 11:46:10.747
    STEP: deleting the test headless service 04/26/24 11:46:10.765
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 26 11:46:10.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-2363" for this suite. 04/26/24 11:46:10.78
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:46:10.788
Apr 26 11:46:10.788: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 11:46:10.789
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:10.807
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:10.815
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174
STEP: Creating configMap with name configmap-test-upd-699c49dd-5aa6-4e06-b025-3d9b72de9a4c 04/26/24 11:46:10.835
STEP: Creating the pod 04/26/24 11:46:10.842
Apr 26 11:46:10.855: INFO: Waiting up to 5m0s for pod "pod-configmaps-9023c78c-243d-405b-9571-ea77a86183cf" in namespace "configmap-3962" to be "running"
Apr 26 11:46:10.859: INFO: Pod "pod-configmaps-9023c78c-243d-405b-9571-ea77a86183cf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.351414ms
Apr 26 11:46:12.866: INFO: Pod "pod-configmaps-9023c78c-243d-405b-9571-ea77a86183cf": Phase="Running", Reason="", readiness=false. Elapsed: 2.011096351s
Apr 26 11:46:12.866: INFO: Pod "pod-configmaps-9023c78c-243d-405b-9571-ea77a86183cf" satisfied condition "running"
STEP: Waiting for pod with text data 04/26/24 11:46:12.866
STEP: Waiting for pod with binary data 04/26/24 11:46:12.923
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 11:46:13.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3962" for this suite. 04/26/24 11:46:13.03
{"msg":"PASSED [sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]","completed":151,"skipped":2760,"failed":0}
------------------------------
â€¢ [2.255 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  binary data should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:174

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:46:10.788
    Apr 26 11:46:10.788: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 11:46:10.789
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:10.807
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:10.815
    [It] binary data should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:174
    STEP: Creating configMap with name configmap-test-upd-699c49dd-5aa6-4e06-b025-3d9b72de9a4c 04/26/24 11:46:10.835
    STEP: Creating the pod 04/26/24 11:46:10.842
    Apr 26 11:46:10.855: INFO: Waiting up to 5m0s for pod "pod-configmaps-9023c78c-243d-405b-9571-ea77a86183cf" in namespace "configmap-3962" to be "running"
    Apr 26 11:46:10.859: INFO: Pod "pod-configmaps-9023c78c-243d-405b-9571-ea77a86183cf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.351414ms
    Apr 26 11:46:12.866: INFO: Pod "pod-configmaps-9023c78c-243d-405b-9571-ea77a86183cf": Phase="Running", Reason="", readiness=false. Elapsed: 2.011096351s
    Apr 26 11:46:12.866: INFO: Pod "pod-configmaps-9023c78c-243d-405b-9571-ea77a86183cf" satisfied condition "running"
    STEP: Waiting for pod with text data 04/26/24 11:46:12.866
    STEP: Waiting for pod with binary data 04/26/24 11:46:12.923
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 11:46:13.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-3962" for this suite. 04/26/24 11:46:13.03
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:46:13.044
Apr 26 11:46:13.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename daemonsets 04/26/24 11:46:13.046
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:13.063
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:13.071
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165
STEP: Creating simple DaemonSet "daemon-set" 04/26/24 11:46:13.121
STEP: Check that daemon pods launch on every node of the cluster. 04/26/24 11:46:13.127
Apr 26 11:46:13.143: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:46:13.143: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
Apr 26 11:46:14.161: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 26 11:46:14.161: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
Apr 26 11:46:15.222: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Apr 26 11:46:15.222: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
STEP: Stop a daemon pod, check that the daemon pod is revived. 04/26/24 11:46:15.234
Apr 26 11:46:15.284: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 26 11:46:15.284: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp is running 0 daemon pod, expected 1
Apr 26 11:46:16.303: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 26 11:46:16.303: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp is running 0 daemon pod, expected 1
Apr 26 11:46:17.297: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
Apr 26 11:46:17.298: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp is running 0 daemon pod, expected 1
Apr 26 11:46:18.305: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Apr 26 11:46:18.305: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/26/24 11:46:18.314
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6067, will wait for the garbage collector to delete the pods 04/26/24 11:46:18.314
Apr 26 11:46:18.375: INFO: Deleting DaemonSet.extensions daemon-set took: 6.771731ms
Apr 26 11:46:18.476: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.074877ms
Apr 26 11:46:20.883: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:46:20.883: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 26 11:46:20.888: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33097"},"items":null}

Apr 26 11:46:20.893: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33097"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:46:20.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6067" for this suite. 04/26/24 11:46:20.942
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]","completed":152,"skipped":2762,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.903 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  test/e2e/apps/daemon_set.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:46:13.044
    Apr 26 11:46:13.045: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename daemonsets 04/26/24 11:46:13.046
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:13.063
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:13.071
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop simple daemon [Conformance]
      test/e2e/apps/daemon_set.go:165
    STEP: Creating simple DaemonSet "daemon-set" 04/26/24 11:46:13.121
    STEP: Check that daemon pods launch on every node of the cluster. 04/26/24 11:46:13.127
    Apr 26 11:46:13.143: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:46:13.143: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
    Apr 26 11:46:14.161: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 26 11:46:14.161: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
    Apr 26 11:46:15.222: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Apr 26 11:46:15.222: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    STEP: Stop a daemon pod, check that the daemon pod is revived. 04/26/24 11:46:15.234
    Apr 26 11:46:15.284: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 26 11:46:15.284: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp is running 0 daemon pod, expected 1
    Apr 26 11:46:16.303: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 26 11:46:16.303: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp is running 0 daemon pod, expected 1
    Apr 26 11:46:17.297: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 3
    Apr 26 11:46:17.298: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp is running 0 daemon pod, expected 1
    Apr 26 11:46:18.305: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Apr 26 11:46:18.305: INFO: Number of running nodes: 4, number of available pods: 4 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/26/24 11:46:18.314
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6067, will wait for the garbage collector to delete the pods 04/26/24 11:46:18.314
    Apr 26 11:46:18.375: INFO: Deleting DaemonSet.extensions daemon-set took: 6.771731ms
    Apr 26 11:46:18.476: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.074877ms
    Apr 26 11:46:20.883: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:46:20.883: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 26 11:46:20.888: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"33097"},"items":null}

    Apr 26 11:46:20.893: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"33097"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:46:20.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-6067" for this suite. 04/26/24 11:46:20.942
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:46:20.958
Apr 26 11:46:20.958: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 11:46:20.959
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:20.974
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:20.981
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89
STEP: Creating a pod to test downward api env vars 04/26/24 11:46:20.987
Apr 26 11:46:20.997: INFO: Waiting up to 5m0s for pod "downward-api-04077b6a-542f-4168-b656-f5cbb53d8723" in namespace "downward-api-2964" to be "Succeeded or Failed"
Apr 26 11:46:21.001: INFO: Pod "downward-api-04077b6a-542f-4168-b656-f5cbb53d8723": Phase="Pending", Reason="", readiness=false. Elapsed: 4.517417ms
Apr 26 11:46:23.008: INFO: Pod "downward-api-04077b6a-542f-4168-b656-f5cbb53d8723": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011332011s
Apr 26 11:46:25.008: INFO: Pod "downward-api-04077b6a-542f-4168-b656-f5cbb53d8723": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011789429s
STEP: Saw pod success 04/26/24 11:46:25.009
Apr 26 11:46:25.009: INFO: Pod "downward-api-04077b6a-542f-4168-b656-f5cbb53d8723" satisfied condition "Succeeded or Failed"
Apr 26 11:46:25.014: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downward-api-04077b6a-542f-4168-b656-f5cbb53d8723 container dapi-container: <nil>
STEP: delete the pod 04/26/24 11:46:25.029
Apr 26 11:46:25.067: INFO: Waiting for pod downward-api-04077b6a-542f-4168-b656-f5cbb53d8723 to disappear
Apr 26 11:46:25.079: INFO: Pod downward-api-04077b6a-542f-4168-b656-f5cbb53d8723 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 26 11:46:25.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2964" for this suite. 04/26/24 11:46:25.093
{"msg":"PASSED [sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]","completed":153,"skipped":2805,"failed":0}
------------------------------
â€¢ [4.150 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide host IP as an env var [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:89

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:46:20.958
    Apr 26 11:46:20.958: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 11:46:20.959
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:20.974
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:20.981
    [It] should provide host IP as an env var [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:89
    STEP: Creating a pod to test downward api env vars 04/26/24 11:46:20.987
    Apr 26 11:46:20.997: INFO: Waiting up to 5m0s for pod "downward-api-04077b6a-542f-4168-b656-f5cbb53d8723" in namespace "downward-api-2964" to be "Succeeded or Failed"
    Apr 26 11:46:21.001: INFO: Pod "downward-api-04077b6a-542f-4168-b656-f5cbb53d8723": Phase="Pending", Reason="", readiness=false. Elapsed: 4.517417ms
    Apr 26 11:46:23.008: INFO: Pod "downward-api-04077b6a-542f-4168-b656-f5cbb53d8723": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011332011s
    Apr 26 11:46:25.008: INFO: Pod "downward-api-04077b6a-542f-4168-b656-f5cbb53d8723": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011789429s
    STEP: Saw pod success 04/26/24 11:46:25.009
    Apr 26 11:46:25.009: INFO: Pod "downward-api-04077b6a-542f-4168-b656-f5cbb53d8723" satisfied condition "Succeeded or Failed"
    Apr 26 11:46:25.014: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downward-api-04077b6a-542f-4168-b656-f5cbb53d8723 container dapi-container: <nil>
    STEP: delete the pod 04/26/24 11:46:25.029
    Apr 26 11:46:25.067: INFO: Waiting for pod downward-api-04077b6a-542f-4168-b656-f5cbb53d8723 to disappear
    Apr 26 11:46:25.079: INFO: Pod downward-api-04077b6a-542f-4168-b656-f5cbb53d8723 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 26 11:46:25.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2964" for this suite. 04/26/24 11:46:25.093
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:46:25.113
Apr 26 11:46:25.113: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename statefulset 04/26/24 11:46:25.114
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:25.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:25.157
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-7589 04/26/24 11:46:25.164
[It] should validate Statefulset Status endpoints [Conformance]
  test/e2e/apps/statefulset.go:975
STEP: Creating statefulset ss in namespace statefulset-7589 04/26/24 11:46:25.177
Apr 26 11:46:25.238: INFO: Found 0 stateful pods, waiting for 1
Apr 26 11:46:35.245: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Patch Statefulset to include a label 04/26/24 11:46:35.255
STEP: Getting /status 04/26/24 11:46:35.264
Apr 26 11:46:35.274: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
STEP: updating the StatefulSet Status 04/26/24 11:46:35.274
Apr 26 11:46:35.285: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the statefulset status to be updated 04/26/24 11:46:35.285
Apr 26 11:46:35.289: INFO: Observed &StatefulSet event: ADDED
Apr 26 11:46:35.289: INFO: Found Statefulset ss in namespace statefulset-7589 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 26 11:46:35.289: INFO: Statefulset ss has an updated status
STEP: patching the Statefulset Status 04/26/24 11:46:35.289
Apr 26 11:46:35.290: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
Apr 26 11:46:35.297: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
STEP: watching for the Statefulset status to be patched 04/26/24 11:46:35.298
Apr 26 11:46:35.303: INFO: Observed &StatefulSet event: ADDED
Apr 26 11:46:35.303: INFO: Observed Statefulset ss in namespace statefulset-7589 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
Apr 26 11:46:35.303: INFO: Observed &StatefulSet event: MODIFIED
Apr 26 11:46:35.303: INFO: Found Statefulset ss in namespace statefulset-7589 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 26 11:46:35.303: INFO: Deleting all statefulset in ns statefulset-7589
Apr 26 11:46:35.307: INFO: Scaling statefulset ss to 0
Apr 26 11:46:45.331: INFO: Waiting for statefulset status.replicas updated to 0
Apr 26 11:46:45.335: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 26 11:46:45.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7589" for this suite. 04/26/24 11:46:45.363
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]","completed":154,"skipped":2822,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.257 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should validate Statefulset Status endpoints [Conformance]
    test/e2e/apps/statefulset.go:975

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:46:25.113
    Apr 26 11:46:25.113: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename statefulset 04/26/24 11:46:25.114
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:25.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:25.157
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-7589 04/26/24 11:46:25.164
    [It] should validate Statefulset Status endpoints [Conformance]
      test/e2e/apps/statefulset.go:975
    STEP: Creating statefulset ss in namespace statefulset-7589 04/26/24 11:46:25.177
    Apr 26 11:46:25.238: INFO: Found 0 stateful pods, waiting for 1
    Apr 26 11:46:35.245: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Patch Statefulset to include a label 04/26/24 11:46:35.255
    STEP: Getting /status 04/26/24 11:46:35.264
    Apr 26 11:46:35.274: INFO: StatefulSet ss has Conditions: []v1.StatefulSetCondition(nil)
    STEP: updating the StatefulSet Status 04/26/24 11:46:35.274
    Apr 26 11:46:35.285: INFO: updatedStatus.Conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the statefulset status to be updated 04/26/24 11:46:35.285
    Apr 26 11:46:35.289: INFO: Observed &StatefulSet event: ADDED
    Apr 26 11:46:35.289: INFO: Found Statefulset ss in namespace statefulset-7589 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 26 11:46:35.289: INFO: Statefulset ss has an updated status
    STEP: patching the Statefulset Status 04/26/24 11:46:35.289
    Apr 26 11:46:35.290: INFO: Patch payload: {"status":{"conditions":[{"type":"StatusPatched","status":"True"}]}}
    Apr 26 11:46:35.297: INFO: Patched status conditions: []v1.StatefulSetCondition{v1.StatefulSetCondition{Type:"StatusPatched", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"", Message:""}}
    STEP: watching for the Statefulset status to be patched 04/26/24 11:46:35.298
    Apr 26 11:46:35.303: INFO: Observed &StatefulSet event: ADDED
    Apr 26 11:46:35.303: INFO: Observed Statefulset ss in namespace statefulset-7589 with annotations: map[] & Conditions: {StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}
    Apr 26 11:46:35.303: INFO: Observed &StatefulSet event: MODIFIED
    Apr 26 11:46:35.303: INFO: Found Statefulset ss in namespace statefulset-7589 with labels: map[e2e:testing] annotations: map[] & Conditions: {StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 26 11:46:35.303: INFO: Deleting all statefulset in ns statefulset-7589
    Apr 26 11:46:35.307: INFO: Scaling statefulset ss to 0
    Apr 26 11:46:45.331: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 26 11:46:45.335: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 26 11:46:45.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-7589" for this suite. 04/26/24 11:46:45.363
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:46:45.373
Apr 26 11:46:45.373: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 11:46:45.374
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:45.388
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:45.394
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136
STEP: Creating a pod to test emptydir 0666 on tmpfs 04/26/24 11:46:45.4
Apr 26 11:46:45.413: INFO: Waiting up to 5m0s for pod "pod-706f8e8d-ad38-4724-92f3-d4640be0689d" in namespace "emptydir-1566" to be "Succeeded or Failed"
Apr 26 11:46:45.420: INFO: Pod "pod-706f8e8d-ad38-4724-92f3-d4640be0689d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.883693ms
Apr 26 11:46:47.432: INFO: Pod "pod-706f8e8d-ad38-4724-92f3-d4640be0689d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018452316s
Apr 26 11:46:49.428: INFO: Pod "pod-706f8e8d-ad38-4724-92f3-d4640be0689d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014555908s
STEP: Saw pod success 04/26/24 11:46:49.428
Apr 26 11:46:49.428: INFO: Pod "pod-706f8e8d-ad38-4724-92f3-d4640be0689d" satisfied condition "Succeeded or Failed"
Apr 26 11:46:49.433: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-706f8e8d-ad38-4724-92f3-d4640be0689d container test-container: <nil>
STEP: delete the pod 04/26/24 11:46:49.445
Apr 26 11:46:49.465: INFO: Waiting for pod pod-706f8e8d-ad38-4724-92f3-d4640be0689d to disappear
Apr 26 11:46:49.489: INFO: Pod pod-706f8e8d-ad38-4724-92f3-d4640be0689d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 11:46:49.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1566" for this suite. 04/26/24 11:46:49.499
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":155,"skipped":2840,"failed":0}
------------------------------
â€¢ [4.132 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:136

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:46:45.373
    Apr 26 11:46:45.373: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 11:46:45.374
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:45.388
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:45.394
    [It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:136
    STEP: Creating a pod to test emptydir 0666 on tmpfs 04/26/24 11:46:45.4
    Apr 26 11:46:45.413: INFO: Waiting up to 5m0s for pod "pod-706f8e8d-ad38-4724-92f3-d4640be0689d" in namespace "emptydir-1566" to be "Succeeded or Failed"
    Apr 26 11:46:45.420: INFO: Pod "pod-706f8e8d-ad38-4724-92f3-d4640be0689d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.883693ms
    Apr 26 11:46:47.432: INFO: Pod "pod-706f8e8d-ad38-4724-92f3-d4640be0689d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018452316s
    Apr 26 11:46:49.428: INFO: Pod "pod-706f8e8d-ad38-4724-92f3-d4640be0689d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014555908s
    STEP: Saw pod success 04/26/24 11:46:49.428
    Apr 26 11:46:49.428: INFO: Pod "pod-706f8e8d-ad38-4724-92f3-d4640be0689d" satisfied condition "Succeeded or Failed"
    Apr 26 11:46:49.433: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-706f8e8d-ad38-4724-92f3-d4640be0689d container test-container: <nil>
    STEP: delete the pod 04/26/24 11:46:49.445
    Apr 26 11:46:49.465: INFO: Waiting for pod pod-706f8e8d-ad38-4724-92f3-d4640be0689d to disappear
    Apr 26 11:46:49.489: INFO: Pod pod-706f8e8d-ad38-4724-92f3-d4640be0689d no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 11:46:49.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1566" for this suite. 04/26/24 11:46:49.499
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:46:49.505
Apr 26 11:46:49.506: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 11:46:49.506
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:49.575
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:49.583
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422
STEP: Creating configMap with name configmap-test-volume-79df78ca-29d6-4494-a286-2ce6e652b905 04/26/24 11:46:49.589
STEP: Creating a pod to test consume configMaps 04/26/24 11:46:49.594
Apr 26 11:46:49.617: INFO: Waiting up to 5m0s for pod "pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468" in namespace "configmap-9256" to be "Succeeded or Failed"
Apr 26 11:46:49.622: INFO: Pod "pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468": Phase="Pending", Reason="", readiness=false. Elapsed: 5.259088ms
Apr 26 11:46:51.630: INFO: Pod "pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012703865s
Apr 26 11:46:53.630: INFO: Pod "pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012763143s
STEP: Saw pod success 04/26/24 11:46:53.63
Apr 26 11:46:53.630: INFO: Pod "pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468" satisfied condition "Succeeded or Failed"
Apr 26 11:46:53.635: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468 container configmap-volume-test: <nil>
STEP: delete the pod 04/26/24 11:46:53.686
Apr 26 11:46:53.700: INFO: Waiting for pod pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468 to disappear
Apr 26 11:46:53.704: INFO: Pod pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 11:46:53.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9256" for this suite. 04/26/24 11:46:53.713
{"msg":"PASSED [sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]","completed":156,"skipped":2860,"failed":0}
------------------------------
â€¢ [4.213 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:422

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:46:49.505
    Apr 26 11:46:49.506: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 11:46:49.506
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:49.575
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:49.583
    [It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:422
    STEP: Creating configMap with name configmap-test-volume-79df78ca-29d6-4494-a286-2ce6e652b905 04/26/24 11:46:49.589
    STEP: Creating a pod to test consume configMaps 04/26/24 11:46:49.594
    Apr 26 11:46:49.617: INFO: Waiting up to 5m0s for pod "pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468" in namespace "configmap-9256" to be "Succeeded or Failed"
    Apr 26 11:46:49.622: INFO: Pod "pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468": Phase="Pending", Reason="", readiness=false. Elapsed: 5.259088ms
    Apr 26 11:46:51.630: INFO: Pod "pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012703865s
    Apr 26 11:46:53.630: INFO: Pod "pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012763143s
    STEP: Saw pod success 04/26/24 11:46:53.63
    Apr 26 11:46:53.630: INFO: Pod "pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468" satisfied condition "Succeeded or Failed"
    Apr 26 11:46:53.635: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468 container configmap-volume-test: <nil>
    STEP: delete the pod 04/26/24 11:46:53.686
    Apr 26 11:46:53.700: INFO: Waiting for pod pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468 to disappear
    Apr 26 11:46:53.704: INFO: Pod pod-configmaps-3f13c3e5-eb09-4e6c-a2b0-d3b11b13e468 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 11:46:53.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-9256" for this suite. 04/26/24 11:46:53.713
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:46:53.719
Apr 26 11:46:53.719: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-probe 04/26/24 11:46:53.721
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:53.752
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:53.758
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180
STEP: Creating pod liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8 in namespace container-probe-8046 04/26/24 11:46:53.765
Apr 26 11:46:53.778: INFO: Waiting up to 5m0s for pod "liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8" in namespace "container-probe-8046" to be "not pending"
Apr 26 11:46:53.784: INFO: Pod "liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.430583ms
Apr 26 11:46:55.793: INFO: Pod "liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.015342343s
Apr 26 11:46:55.793: INFO: Pod "liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8" satisfied condition "not pending"
Apr 26 11:46:55.793: INFO: Started pod liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8 in namespace container-probe-8046
STEP: checking the pod's current state and verifying that restartCount is present 04/26/24 11:46:55.793
Apr 26 11:46:55.798: INFO: Initial restart count of pod liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8 is 0
STEP: deleting the pod 04/26/24 11:50:56.773
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 26 11:50:56.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8046" for this suite. 04/26/24 11:50:56.8
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]","completed":157,"skipped":2870,"failed":0}
------------------------------
â€¢ [SLOW TEST] [243.087 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:180

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:46:53.719
    Apr 26 11:46:53.719: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-probe 04/26/24 11:46:53.721
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:46:53.752
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:46:53.758
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:180
    STEP: Creating pod liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8 in namespace container-probe-8046 04/26/24 11:46:53.765
    Apr 26 11:46:53.778: INFO: Waiting up to 5m0s for pod "liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8" in namespace "container-probe-8046" to be "not pending"
    Apr 26 11:46:53.784: INFO: Pod "liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.430583ms
    Apr 26 11:46:55.793: INFO: Pod "liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8": Phase="Running", Reason="", readiness=true. Elapsed: 2.015342343s
    Apr 26 11:46:55.793: INFO: Pod "liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8" satisfied condition "not pending"
    Apr 26 11:46:55.793: INFO: Started pod liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8 in namespace container-probe-8046
    STEP: checking the pod's current state and verifying that restartCount is present 04/26/24 11:46:55.793
    Apr 26 11:46:55.798: INFO: Initial restart count of pod liveness-4a6332fb-6dba-47a8-8a1c-b18cd193d2e8 is 0
    STEP: deleting the pod 04/26/24 11:50:56.773
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 26 11:50:56.788: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-8046" for this suite. 04/26/24 11:50:56.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:50:56.809
Apr 26 11:50:56.809: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 11:50:56.809
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:50:56.824
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:50:56.83
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126
STEP: Creating a pod to test emptydir 0644 on tmpfs 04/26/24 11:50:56.837
Apr 26 11:50:56.876: INFO: Waiting up to 5m0s for pod "pod-0a76075e-a1b5-4001-b4de-e3f19010803f" in namespace "emptydir-5487" to be "Succeeded or Failed"
Apr 26 11:50:56.887: INFO: Pod "pod-0a76075e-a1b5-4001-b4de-e3f19010803f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.736031ms
Apr 26 11:50:58.892: INFO: Pod "pod-0a76075e-a1b5-4001-b4de-e3f19010803f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016472468s
Apr 26 11:51:00.895: INFO: Pod "pod-0a76075e-a1b5-4001-b4de-e3f19010803f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018695102s
STEP: Saw pod success 04/26/24 11:51:00.895
Apr 26 11:51:00.895: INFO: Pod "pod-0a76075e-a1b5-4001-b4de-e3f19010803f" satisfied condition "Succeeded or Failed"
Apr 26 11:51:00.900: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-0a76075e-a1b5-4001-b4de-e3f19010803f container test-container: <nil>
STEP: delete the pod 04/26/24 11:51:00.932
Apr 26 11:51:00.965: INFO: Waiting for pod pod-0a76075e-a1b5-4001-b4de-e3f19010803f to disappear
Apr 26 11:51:00.969: INFO: Pod pod-0a76075e-a1b5-4001-b4de-e3f19010803f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 11:51:00.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5487" for this suite. 04/26/24 11:51:00.982
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":158,"skipped":2940,"failed":0}
------------------------------
â€¢ [4.183 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:126

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:50:56.809
    Apr 26 11:50:56.809: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 11:50:56.809
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:50:56.824
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:50:56.83
    [It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:126
    STEP: Creating a pod to test emptydir 0644 on tmpfs 04/26/24 11:50:56.837
    Apr 26 11:50:56.876: INFO: Waiting up to 5m0s for pod "pod-0a76075e-a1b5-4001-b4de-e3f19010803f" in namespace "emptydir-5487" to be "Succeeded or Failed"
    Apr 26 11:50:56.887: INFO: Pod "pod-0a76075e-a1b5-4001-b4de-e3f19010803f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.736031ms
    Apr 26 11:50:58.892: INFO: Pod "pod-0a76075e-a1b5-4001-b4de-e3f19010803f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016472468s
    Apr 26 11:51:00.895: INFO: Pod "pod-0a76075e-a1b5-4001-b4de-e3f19010803f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018695102s
    STEP: Saw pod success 04/26/24 11:51:00.895
    Apr 26 11:51:00.895: INFO: Pod "pod-0a76075e-a1b5-4001-b4de-e3f19010803f" satisfied condition "Succeeded or Failed"
    Apr 26 11:51:00.900: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-0a76075e-a1b5-4001-b4de-e3f19010803f container test-container: <nil>
    STEP: delete the pod 04/26/24 11:51:00.932
    Apr 26 11:51:00.965: INFO: Waiting for pod pod-0a76075e-a1b5-4001-b4de-e3f19010803f to disappear
    Apr 26 11:51:00.969: INFO: Pod pod-0a76075e-a1b5-4001-b4de-e3f19010803f no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 11:51:00.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5487" for this suite. 04/26/24 11:51:00.982
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:51:00.993
Apr 26 11:51:00.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 11:51:00.994
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:01.019
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:01.028
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should scale a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:350
STEP: creating a replication controller 04/26/24 11:51:01.036
Apr 26 11:51:01.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 create -f -'
Apr 26 11:51:01.668: INFO: stderr: ""
Apr 26 11:51:01.668: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/26/24 11:51:01.668
Apr 26 11:51:01.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 26 11:51:01.752: INFO: stderr: ""
Apr 26 11:51:01.752: INFO: stdout: "update-demo-nautilus-jdz9l update-demo-nautilus-x6fdp "
Apr 26 11:51:01.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 26 11:51:01.820: INFO: stderr: ""
Apr 26 11:51:01.820: INFO: stdout: ""
Apr 26 11:51:01.820: INFO: update-demo-nautilus-jdz9l is created but not running
Apr 26 11:51:06.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 26 11:51:06.884: INFO: stderr: ""
Apr 26 11:51:06.884: INFO: stdout: "update-demo-nautilus-jdz9l update-demo-nautilus-x6fdp "
Apr 26 11:51:06.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 26 11:51:06.944: INFO: stderr: ""
Apr 26 11:51:06.944: INFO: stdout: "true"
Apr 26 11:51:06.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 26 11:51:07.002: INFO: stderr: ""
Apr 26 11:51:07.002: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 26 11:51:07.002: INFO: validating pod update-demo-nautilus-jdz9l
Apr 26 11:51:07.109: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 26 11:51:07.109: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 26 11:51:07.109: INFO: update-demo-nautilus-jdz9l is verified up and running
Apr 26 11:51:07.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-x6fdp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 26 11:51:07.176: INFO: stderr: ""
Apr 26 11:51:07.176: INFO: stdout: "true"
Apr 26 11:51:07.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-x6fdp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 26 11:51:07.245: INFO: stderr: ""
Apr 26 11:51:07.245: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 26 11:51:07.245: INFO: validating pod update-demo-nautilus-x6fdp
Apr 26 11:51:07.356: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 26 11:51:07.356: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 26 11:51:07.356: INFO: update-demo-nautilus-x6fdp is verified up and running
STEP: scaling down the replication controller 04/26/24 11:51:07.356
Apr 26 11:51:07.357: INFO: scanned /root for discovery docs: <nil>
Apr 26 11:51:07.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
Apr 26 11:51:08.447: INFO: stderr: ""
Apr 26 11:51:08.447: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/26/24 11:51:08.447
Apr 26 11:51:08.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 26 11:51:08.517: INFO: stderr: ""
Apr 26 11:51:08.517: INFO: stdout: "update-demo-nautilus-jdz9l update-demo-nautilus-x6fdp "
STEP: Replicas for name=update-demo: expected=1 actual=2 04/26/24 11:51:08.517
Apr 26 11:51:13.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 26 11:51:13.578: INFO: stderr: ""
Apr 26 11:51:13.578: INFO: stdout: "update-demo-nautilus-jdz9l "
Apr 26 11:51:13.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 26 11:51:13.651: INFO: stderr: ""
Apr 26 11:51:13.651: INFO: stdout: "true"
Apr 26 11:51:13.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 26 11:51:13.710: INFO: stderr: ""
Apr 26 11:51:13.710: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 26 11:51:13.710: INFO: validating pod update-demo-nautilus-jdz9l
Apr 26 11:51:13.726: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 26 11:51:13.726: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 26 11:51:13.726: INFO: update-demo-nautilus-jdz9l is verified up and running
STEP: scaling up the replication controller 04/26/24 11:51:13.726
Apr 26 11:51:13.727: INFO: scanned /root for discovery docs: <nil>
Apr 26 11:51:13.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
Apr 26 11:51:14.814: INFO: stderr: ""
Apr 26 11:51:14.814: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/26/24 11:51:14.814
Apr 26 11:51:14.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 26 11:51:14.882: INFO: stderr: ""
Apr 26 11:51:14.882: INFO: stdout: "update-demo-nautilus-jdz9l update-demo-nautilus-tj86w "
Apr 26 11:51:14.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 26 11:51:14.953: INFO: stderr: ""
Apr 26 11:51:14.953: INFO: stdout: "true"
Apr 26 11:51:14.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 26 11:51:15.022: INFO: stderr: ""
Apr 26 11:51:15.022: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 26 11:51:15.022: INFO: validating pod update-demo-nautilus-jdz9l
Apr 26 11:51:15.032: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 26 11:51:15.032: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 26 11:51:15.032: INFO: update-demo-nautilus-jdz9l is verified up and running
Apr 26 11:51:15.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-tj86w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 26 11:51:15.087: INFO: stderr: ""
Apr 26 11:51:15.087: INFO: stdout: "true"
Apr 26 11:51:15.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-tj86w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 26 11:51:15.154: INFO: stderr: ""
Apr 26 11:51:15.155: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 26 11:51:15.155: INFO: validating pod update-demo-nautilus-tj86w
Apr 26 11:51:15.265: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 26 11:51:15.265: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 26 11:51:15.265: INFO: update-demo-nautilus-tj86w is verified up and running
STEP: using delete to clean up resources 04/26/24 11:51:15.265
Apr 26 11:51:15.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 delete --grace-period=0 --force -f -'
Apr 26 11:51:15.351: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 26 11:51:15.351: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 26 11:51:15.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get rc,svc -l name=update-demo --no-headers'
Apr 26 11:51:15.422: INFO: stderr: "No resources found in kubectl-7384 namespace.\n"
Apr 26 11:51:15.422: INFO: stdout: ""
Apr 26 11:51:15.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 26 11:51:15.502: INFO: stderr: ""
Apr 26 11:51:15.502: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 11:51:15.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7384" for this suite. 04/26/24 11:51:15.515
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should scale a replication controller  [Conformance]","completed":159,"skipped":2974,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.531 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should scale a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:350

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:51:00.993
    Apr 26 11:51:00.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 11:51:00.994
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:01.019
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:01.028
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should scale a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:350
    STEP: creating a replication controller 04/26/24 11:51:01.036
    Apr 26 11:51:01.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 create -f -'
    Apr 26 11:51:01.668: INFO: stderr: ""
    Apr 26 11:51:01.668: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/26/24 11:51:01.668
    Apr 26 11:51:01.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 26 11:51:01.752: INFO: stderr: ""
    Apr 26 11:51:01.752: INFO: stdout: "update-demo-nautilus-jdz9l update-demo-nautilus-x6fdp "
    Apr 26 11:51:01.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 26 11:51:01.820: INFO: stderr: ""
    Apr 26 11:51:01.820: INFO: stdout: ""
    Apr 26 11:51:01.820: INFO: update-demo-nautilus-jdz9l is created but not running
    Apr 26 11:51:06.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 26 11:51:06.884: INFO: stderr: ""
    Apr 26 11:51:06.884: INFO: stdout: "update-demo-nautilus-jdz9l update-demo-nautilus-x6fdp "
    Apr 26 11:51:06.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 26 11:51:06.944: INFO: stderr: ""
    Apr 26 11:51:06.944: INFO: stdout: "true"
    Apr 26 11:51:06.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 26 11:51:07.002: INFO: stderr: ""
    Apr 26 11:51:07.002: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 26 11:51:07.002: INFO: validating pod update-demo-nautilus-jdz9l
    Apr 26 11:51:07.109: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 26 11:51:07.109: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 26 11:51:07.109: INFO: update-demo-nautilus-jdz9l is verified up and running
    Apr 26 11:51:07.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-x6fdp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 26 11:51:07.176: INFO: stderr: ""
    Apr 26 11:51:07.176: INFO: stdout: "true"
    Apr 26 11:51:07.176: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-x6fdp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 26 11:51:07.245: INFO: stderr: ""
    Apr 26 11:51:07.245: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 26 11:51:07.245: INFO: validating pod update-demo-nautilus-x6fdp
    Apr 26 11:51:07.356: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 26 11:51:07.356: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 26 11:51:07.356: INFO: update-demo-nautilus-x6fdp is verified up and running
    STEP: scaling down the replication controller 04/26/24 11:51:07.356
    Apr 26 11:51:07.357: INFO: scanned /root for discovery docs: <nil>
    Apr 26 11:51:07.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 scale rc update-demo-nautilus --replicas=1 --timeout=5m'
    Apr 26 11:51:08.447: INFO: stderr: ""
    Apr 26 11:51:08.447: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/26/24 11:51:08.447
    Apr 26 11:51:08.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 26 11:51:08.517: INFO: stderr: ""
    Apr 26 11:51:08.517: INFO: stdout: "update-demo-nautilus-jdz9l update-demo-nautilus-x6fdp "
    STEP: Replicas for name=update-demo: expected=1 actual=2 04/26/24 11:51:08.517
    Apr 26 11:51:13.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 26 11:51:13.578: INFO: stderr: ""
    Apr 26 11:51:13.578: INFO: stdout: "update-demo-nautilus-jdz9l "
    Apr 26 11:51:13.578: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 26 11:51:13.651: INFO: stderr: ""
    Apr 26 11:51:13.651: INFO: stdout: "true"
    Apr 26 11:51:13.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 26 11:51:13.710: INFO: stderr: ""
    Apr 26 11:51:13.710: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 26 11:51:13.710: INFO: validating pod update-demo-nautilus-jdz9l
    Apr 26 11:51:13.726: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 26 11:51:13.726: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 26 11:51:13.726: INFO: update-demo-nautilus-jdz9l is verified up and running
    STEP: scaling up the replication controller 04/26/24 11:51:13.726
    Apr 26 11:51:13.727: INFO: scanned /root for discovery docs: <nil>
    Apr 26 11:51:13.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 scale rc update-demo-nautilus --replicas=2 --timeout=5m'
    Apr 26 11:51:14.814: INFO: stderr: ""
    Apr 26 11:51:14.814: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/26/24 11:51:14.814
    Apr 26 11:51:14.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 26 11:51:14.882: INFO: stderr: ""
    Apr 26 11:51:14.882: INFO: stdout: "update-demo-nautilus-jdz9l update-demo-nautilus-tj86w "
    Apr 26 11:51:14.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 26 11:51:14.953: INFO: stderr: ""
    Apr 26 11:51:14.953: INFO: stdout: "true"
    Apr 26 11:51:14.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-jdz9l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 26 11:51:15.022: INFO: stderr: ""
    Apr 26 11:51:15.022: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 26 11:51:15.022: INFO: validating pod update-demo-nautilus-jdz9l
    Apr 26 11:51:15.032: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 26 11:51:15.032: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 26 11:51:15.032: INFO: update-demo-nautilus-jdz9l is verified up and running
    Apr 26 11:51:15.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-tj86w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 26 11:51:15.087: INFO: stderr: ""
    Apr 26 11:51:15.087: INFO: stdout: "true"
    Apr 26 11:51:15.088: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods update-demo-nautilus-tj86w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 26 11:51:15.154: INFO: stderr: ""
    Apr 26 11:51:15.155: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 26 11:51:15.155: INFO: validating pod update-demo-nautilus-tj86w
    Apr 26 11:51:15.265: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 26 11:51:15.265: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 26 11:51:15.265: INFO: update-demo-nautilus-tj86w is verified up and running
    STEP: using delete to clean up resources 04/26/24 11:51:15.265
    Apr 26 11:51:15.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 delete --grace-period=0 --force -f -'
    Apr 26 11:51:15.351: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 26 11:51:15.351: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Apr 26 11:51:15.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get rc,svc -l name=update-demo --no-headers'
    Apr 26 11:51:15.422: INFO: stderr: "No resources found in kubectl-7384 namespace.\n"
    Apr 26 11:51:15.422: INFO: stdout: ""
    Apr 26 11:51:15.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7384 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 26 11:51:15.502: INFO: stderr: ""
    Apr 26 11:51:15.502: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 11:51:15.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7384" for this suite. 04/26/24 11:51:15.515
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:51:15.524
Apr 26 11:51:15.524: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 11:51:15.525
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:15.543
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:15.55
[It] works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 04/26/24 11:51:15.556
Apr 26 11:51:15.557: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:51:17.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:51:27.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6181" for this suite. 04/26/24 11:51:27.228
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]","completed":160,"skipped":2990,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.711 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:275

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:51:15.524
    Apr 26 11:51:15.524: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 11:51:15.525
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:15.543
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:15.55
    [It] works for multiple CRDs of different groups [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:275
    STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation 04/26/24 11:51:15.556
    Apr 26 11:51:15.557: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:51:17.841: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:51:27.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-6181" for this suite. 04/26/24 11:51:27.228
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-instrumentation] Events
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:51:27.236
Apr 26 11:51:27.236: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename events 04/26/24 11:51:27.237
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:27.255
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:27.261
[It] should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57
STEP: creating a test event 04/26/24 11:51:27.268
STEP: listing all events in all namespaces 04/26/24 11:51:27.274
STEP: patching the test event 04/26/24 11:51:27.293
STEP: fetching the test event 04/26/24 11:51:27.301
STEP: updating the test event 04/26/24 11:51:27.306
STEP: getting the test event 04/26/24 11:51:27.318
STEP: deleting the test event 04/26/24 11:51:27.324
STEP: listing all events in all namespaces 04/26/24 11:51:27.335
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Apr 26 11:51:27.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-5813" for this suite. 04/26/24 11:51:27.36
{"msg":"PASSED [sig-instrumentation] Events should manage the lifecycle of an event [Conformance]","completed":161,"skipped":2998,"failed":0}
------------------------------
â€¢ [0.129 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should manage the lifecycle of an event [Conformance]
  test/e2e/instrumentation/core_events.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:51:27.236
    Apr 26 11:51:27.236: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename events 04/26/24 11:51:27.237
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:27.255
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:27.261
    [It] should manage the lifecycle of an event [Conformance]
      test/e2e/instrumentation/core_events.go:57
    STEP: creating a test event 04/26/24 11:51:27.268
    STEP: listing all events in all namespaces 04/26/24 11:51:27.274
    STEP: patching the test event 04/26/24 11:51:27.293
    STEP: fetching the test event 04/26/24 11:51:27.301
    STEP: updating the test event 04/26/24 11:51:27.306
    STEP: getting the test event 04/26/24 11:51:27.318
    STEP: deleting the test event 04/26/24 11:51:27.324
    STEP: listing all events in all namespaces 04/26/24 11:51:27.335
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Apr 26 11:51:27.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-5813" for this suite. 04/26/24 11:51:27.36
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:51:27.367
Apr 26 11:51:27.367: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 11:51:27.368
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:27.384
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:27.391
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852
STEP: creating service multi-endpoint-test in namespace services-999 04/26/24 11:51:27.399
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-999 to expose endpoints map[] 04/26/24 11:51:27.41
Apr 26 11:51:27.417: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
Apr 26 11:51:28.431: INFO: successfully validated that service multi-endpoint-test in namespace services-999 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-999 04/26/24 11:51:28.432
Apr 26 11:51:28.444: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-999" to be "running and ready"
Apr 26 11:51:28.449: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.992338ms
Apr 26 11:51:28.449: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:51:30.455: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.010773536s
Apr 26 11:51:30.455: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 26 11:51:30.455: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-999 to expose endpoints map[pod1:[100]] 04/26/24 11:51:30.46
Apr 26 11:51:30.476: INFO: successfully validated that service multi-endpoint-test in namespace services-999 exposes endpoints map[pod1:[100]]
STEP: Creating pod pod2 in namespace services-999 04/26/24 11:51:30.476
Apr 26 11:51:30.483: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-999" to be "running and ready"
Apr 26 11:51:30.495: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.809457ms
Apr 26 11:51:30.495: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:51:32.501: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.017058007s
Apr 26 11:51:32.501: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 26 11:51:32.501: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-999 to expose endpoints map[pod1:[100] pod2:[101]] 04/26/24 11:51:32.505
Apr 26 11:51:32.528: INFO: successfully validated that service multi-endpoint-test in namespace services-999 exposes endpoints map[pod1:[100] pod2:[101]]
STEP: Checking if the Service forwards traffic to pods 04/26/24 11:51:32.528
Apr 26 11:51:32.529: INFO: Creating new exec pod
Apr 26 11:51:32.537: INFO: Waiting up to 5m0s for pod "execpodw6zmx" in namespace "services-999" to be "running"
Apr 26 11:51:32.546: INFO: Pod "execpodw6zmx": Phase="Pending", Reason="", readiness=false. Elapsed: 8.352521ms
Apr 26 11:51:34.555: INFO: Pod "execpodw6zmx": Phase="Running", Reason="", readiness=true. Elapsed: 2.017307284s
Apr 26 11:51:34.555: INFO: Pod "execpodw6zmx" satisfied condition "running"
Apr 26 11:51:35.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-999 exec execpodw6zmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
Apr 26 11:51:36.045: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
Apr 26 11:51:36.045: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:51:36.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-999 exec execpodw6zmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.69.135.41 80'
Apr 26 11:51:36.414: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.69.135.41 80\nConnection to 100.69.135.41 80 port [tcp/http] succeeded!\n"
Apr 26 11:51:36.414: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:51:36.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-999 exec execpodw6zmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
Apr 26 11:51:36.937: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
Apr 26 11:51:36.938: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:51:36.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-999 exec execpodw6zmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.69.135.41 81'
Apr 26 11:51:37.456: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.69.135.41 81\nConnection to 100.69.135.41 81 port [tcp/*] succeeded!\n"
Apr 26 11:51:37.456: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-999 04/26/24 11:51:37.456
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-999 to expose endpoints map[pod2:[101]] 04/26/24 11:51:37.487
Apr 26 11:51:37.526: INFO: successfully validated that service multi-endpoint-test in namespace services-999 exposes endpoints map[pod2:[101]]
STEP: Deleting pod pod2 in namespace services-999 04/26/24 11:51:37.526
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-999 to expose endpoints map[] 04/26/24 11:51:37.545
Apr 26 11:51:37.560: INFO: successfully validated that service multi-endpoint-test in namespace services-999 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 11:51:37.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-999" for this suite. 04/26/24 11:51:37.58
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve multiport endpoints from pods  [Conformance]","completed":162,"skipped":3011,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.226 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  test/e2e/network/service.go:852

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:51:27.367
    Apr 26 11:51:27.367: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 11:51:27.368
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:27.384
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:27.391
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve multiport endpoints from pods  [Conformance]
      test/e2e/network/service.go:852
    STEP: creating service multi-endpoint-test in namespace services-999 04/26/24 11:51:27.399
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-999 to expose endpoints map[] 04/26/24 11:51:27.41
    Apr 26 11:51:27.417: INFO: Failed go get Endpoints object: endpoints "multi-endpoint-test" not found
    Apr 26 11:51:28.431: INFO: successfully validated that service multi-endpoint-test in namespace services-999 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-999 04/26/24 11:51:28.432
    Apr 26 11:51:28.444: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-999" to be "running and ready"
    Apr 26 11:51:28.449: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.992338ms
    Apr 26 11:51:28.449: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:51:30.455: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.010773536s
    Apr 26 11:51:30.455: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 26 11:51:30.455: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-999 to expose endpoints map[pod1:[100]] 04/26/24 11:51:30.46
    Apr 26 11:51:30.476: INFO: successfully validated that service multi-endpoint-test in namespace services-999 exposes endpoints map[pod1:[100]]
    STEP: Creating pod pod2 in namespace services-999 04/26/24 11:51:30.476
    Apr 26 11:51:30.483: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-999" to be "running and ready"
    Apr 26 11:51:30.495: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.809457ms
    Apr 26 11:51:30.495: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:51:32.501: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.017058007s
    Apr 26 11:51:32.501: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 26 11:51:32.501: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-999 to expose endpoints map[pod1:[100] pod2:[101]] 04/26/24 11:51:32.505
    Apr 26 11:51:32.528: INFO: successfully validated that service multi-endpoint-test in namespace services-999 exposes endpoints map[pod1:[100] pod2:[101]]
    STEP: Checking if the Service forwards traffic to pods 04/26/24 11:51:32.528
    Apr 26 11:51:32.529: INFO: Creating new exec pod
    Apr 26 11:51:32.537: INFO: Waiting up to 5m0s for pod "execpodw6zmx" in namespace "services-999" to be "running"
    Apr 26 11:51:32.546: INFO: Pod "execpodw6zmx": Phase="Pending", Reason="", readiness=false. Elapsed: 8.352521ms
    Apr 26 11:51:34.555: INFO: Pod "execpodw6zmx": Phase="Running", Reason="", readiness=true. Elapsed: 2.017307284s
    Apr 26 11:51:34.555: INFO: Pod "execpodw6zmx" satisfied condition "running"
    Apr 26 11:51:35.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-999 exec execpodw6zmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 80'
    Apr 26 11:51:36.045: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 80\nConnection to multi-endpoint-test 80 port [tcp/http] succeeded!\n"
    Apr 26 11:51:36.045: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:51:36.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-999 exec execpodw6zmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.69.135.41 80'
    Apr 26 11:51:36.414: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.69.135.41 80\nConnection to 100.69.135.41 80 port [tcp/http] succeeded!\n"
    Apr 26 11:51:36.414: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:51:36.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-999 exec execpodw6zmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 multi-endpoint-test 81'
    Apr 26 11:51:36.937: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 multi-endpoint-test 81\nConnection to multi-endpoint-test 81 port [tcp/*] succeeded!\n"
    Apr 26 11:51:36.938: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:51:36.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-999 exec execpodw6zmx -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.69.135.41 81'
    Apr 26 11:51:37.456: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.69.135.41 81\nConnection to 100.69.135.41 81 port [tcp/*] succeeded!\n"
    Apr 26 11:51:37.456: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-999 04/26/24 11:51:37.456
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-999 to expose endpoints map[pod2:[101]] 04/26/24 11:51:37.487
    Apr 26 11:51:37.526: INFO: successfully validated that service multi-endpoint-test in namespace services-999 exposes endpoints map[pod2:[101]]
    STEP: Deleting pod pod2 in namespace services-999 04/26/24 11:51:37.526
    STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-999 to expose endpoints map[] 04/26/24 11:51:37.545
    Apr 26 11:51:37.560: INFO: successfully validated that service multi-endpoint-test in namespace services-999 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 11:51:37.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-999" for this suite. 04/26/24 11:51:37.58
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:51:37.598
Apr 26 11:51:37.598: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 11:51:37.599
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:37.614
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:37.62
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166
STEP: Creating a pod to test emptydir 0644 on node default medium 04/26/24 11:51:37.626
Apr 26 11:51:37.638: INFO: Waiting up to 5m0s for pod "pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e" in namespace "emptydir-8511" to be "Succeeded or Failed"
Apr 26 11:51:37.643: INFO: Pod "pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.726017ms
Apr 26 11:51:39.653: INFO: Pod "pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014708689s
Apr 26 11:51:41.652: INFO: Pod "pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014036079s
STEP: Saw pod success 04/26/24 11:51:41.652
Apr 26 11:51:41.652: INFO: Pod "pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e" satisfied condition "Succeeded or Failed"
Apr 26 11:51:41.658: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e container test-container: <nil>
STEP: delete the pod 04/26/24 11:51:41.672
Apr 26 11:51:41.686: INFO: Waiting for pod pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e to disappear
Apr 26 11:51:41.690: INFO: Pod pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 11:51:41.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8511" for this suite. 04/26/24 11:51:41.7
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":163,"skipped":3065,"failed":0}
------------------------------
â€¢ [4.112 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:166

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:51:37.598
    Apr 26 11:51:37.598: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 11:51:37.599
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:37.614
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:37.62
    [It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:166
    STEP: Creating a pod to test emptydir 0644 on node default medium 04/26/24 11:51:37.626
    Apr 26 11:51:37.638: INFO: Waiting up to 5m0s for pod "pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e" in namespace "emptydir-8511" to be "Succeeded or Failed"
    Apr 26 11:51:37.643: INFO: Pod "pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.726017ms
    Apr 26 11:51:39.653: INFO: Pod "pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014708689s
    Apr 26 11:51:41.652: INFO: Pod "pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014036079s
    STEP: Saw pod success 04/26/24 11:51:41.652
    Apr 26 11:51:41.652: INFO: Pod "pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e" satisfied condition "Succeeded or Failed"
    Apr 26 11:51:41.658: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e container test-container: <nil>
    STEP: delete the pod 04/26/24 11:51:41.672
    Apr 26 11:51:41.686: INFO: Waiting for pod pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e to disappear
    Apr 26 11:51:41.690: INFO: Pod pod-d29eeb4a-98b6-4bbd-a049-007dcc5eae0e no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 11:51:41.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-8511" for this suite. 04/26/24 11:51:41.7
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-node] Pods
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:51:41.711
Apr 26 11:51:41.711: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pods 04/26/24 11:51:41.712
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:41.731
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:41.739
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443
Apr 26 11:51:41.760: INFO: Waiting up to 5m0s for pod "server-envvars-1e925b3f-5bb6-4a2d-afd8-07e6a6a6bc46" in namespace "pods-7555" to be "running and ready"
Apr 26 11:51:41.764: INFO: Pod "server-envvars-1e925b3f-5bb6-4a2d-afd8-07e6a6a6bc46": Phase="Pending", Reason="", readiness=false. Elapsed: 3.561172ms
Apr 26 11:51:41.764: INFO: The phase of Pod server-envvars-1e925b3f-5bb6-4a2d-afd8-07e6a6a6bc46 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:51:43.770: INFO: Pod "server-envvars-1e925b3f-5bb6-4a2d-afd8-07e6a6a6bc46": Phase="Running", Reason="", readiness=true. Elapsed: 2.009958998s
Apr 26 11:51:43.770: INFO: The phase of Pod server-envvars-1e925b3f-5bb6-4a2d-afd8-07e6a6a6bc46 is Running (Ready = true)
Apr 26 11:51:43.770: INFO: Pod "server-envvars-1e925b3f-5bb6-4a2d-afd8-07e6a6a6bc46" satisfied condition "running and ready"
Apr 26 11:51:43.799: INFO: Waiting up to 5m0s for pod "client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903" in namespace "pods-7555" to be "Succeeded or Failed"
Apr 26 11:51:43.807: INFO: Pod "client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903": Phase="Pending", Reason="", readiness=false. Elapsed: 8.42081ms
Apr 26 11:51:45.815: INFO: Pod "client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016271812s
Apr 26 11:51:47.813: INFO: Pod "client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0146491s
STEP: Saw pod success 04/26/24 11:51:47.813
Apr 26 11:51:47.813: INFO: Pod "client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903" satisfied condition "Succeeded or Failed"
Apr 26 11:51:47.820: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903 container env3cont: <nil>
STEP: delete the pod 04/26/24 11:51:47.838
Apr 26 11:51:47.851: INFO: Waiting for pod client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903 to disappear
Apr 26 11:51:47.881: INFO: Pod client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903 no longer exists
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 26 11:51:47.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7555" for this suite. 04/26/24 11:51:47.933
{"msg":"PASSED [sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]","completed":164,"skipped":3069,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.246 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should contain environment variables for services [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:443

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:51:41.711
    Apr 26 11:51:41.711: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pods 04/26/24 11:51:41.712
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:41.731
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:41.739
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should contain environment variables for services [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:443
    Apr 26 11:51:41.760: INFO: Waiting up to 5m0s for pod "server-envvars-1e925b3f-5bb6-4a2d-afd8-07e6a6a6bc46" in namespace "pods-7555" to be "running and ready"
    Apr 26 11:51:41.764: INFO: Pod "server-envvars-1e925b3f-5bb6-4a2d-afd8-07e6a6a6bc46": Phase="Pending", Reason="", readiness=false. Elapsed: 3.561172ms
    Apr 26 11:51:41.764: INFO: The phase of Pod server-envvars-1e925b3f-5bb6-4a2d-afd8-07e6a6a6bc46 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:51:43.770: INFO: Pod "server-envvars-1e925b3f-5bb6-4a2d-afd8-07e6a6a6bc46": Phase="Running", Reason="", readiness=true. Elapsed: 2.009958998s
    Apr 26 11:51:43.770: INFO: The phase of Pod server-envvars-1e925b3f-5bb6-4a2d-afd8-07e6a6a6bc46 is Running (Ready = true)
    Apr 26 11:51:43.770: INFO: Pod "server-envvars-1e925b3f-5bb6-4a2d-afd8-07e6a6a6bc46" satisfied condition "running and ready"
    Apr 26 11:51:43.799: INFO: Waiting up to 5m0s for pod "client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903" in namespace "pods-7555" to be "Succeeded or Failed"
    Apr 26 11:51:43.807: INFO: Pod "client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903": Phase="Pending", Reason="", readiness=false. Elapsed: 8.42081ms
    Apr 26 11:51:45.815: INFO: Pod "client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016271812s
    Apr 26 11:51:47.813: INFO: Pod "client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.0146491s
    STEP: Saw pod success 04/26/24 11:51:47.813
    Apr 26 11:51:47.813: INFO: Pod "client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903" satisfied condition "Succeeded or Failed"
    Apr 26 11:51:47.820: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903 container env3cont: <nil>
    STEP: delete the pod 04/26/24 11:51:47.838
    Apr 26 11:51:47.851: INFO: Waiting for pod client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903 to disappear
    Apr 26 11:51:47.881: INFO: Pod client-envvars-6919973f-d8f8-408c-b34b-9fafa5f50903 no longer exists
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 26 11:51:47.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-7555" for this suite. 04/26/24 11:51:47.933
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Pods
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:51:47.958
Apr 26 11:51:47.958: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pods 04/26/24 11:51:47.96
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:47.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:48.005
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082
STEP: Create a pod 04/26/24 11:51:48.012
Apr 26 11:51:48.023: INFO: Waiting up to 5m0s for pod "pod-vqnnc" in namespace "pods-3398" to be "running"
Apr 26 11:51:48.028: INFO: Pod "pod-vqnnc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.630043ms
Apr 26 11:51:50.037: INFO: Pod "pod-vqnnc": Phase="Running", Reason="", readiness=true. Elapsed: 2.013810215s
Apr 26 11:51:50.037: INFO: Pod "pod-vqnnc" satisfied condition "running"
STEP: patching /status 04/26/24 11:51:50.037
Apr 26 11:51:50.046: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 26 11:51:50.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3398" for this suite. 04/26/24 11:51:50.055
{"msg":"PASSED [sig-node] Pods should patch a pod status [Conformance]","completed":165,"skipped":3071,"failed":0}
------------------------------
â€¢ [2.102 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should patch a pod status [Conformance]
  test/e2e/common/node/pods.go:1082

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:51:47.958
    Apr 26 11:51:47.958: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pods 04/26/24 11:51:47.96
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:47.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:48.005
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should patch a pod status [Conformance]
      test/e2e/common/node/pods.go:1082
    STEP: Create a pod 04/26/24 11:51:48.012
    Apr 26 11:51:48.023: INFO: Waiting up to 5m0s for pod "pod-vqnnc" in namespace "pods-3398" to be "running"
    Apr 26 11:51:48.028: INFO: Pod "pod-vqnnc": Phase="Pending", Reason="", readiness=false. Elapsed: 5.630043ms
    Apr 26 11:51:50.037: INFO: Pod "pod-vqnnc": Phase="Running", Reason="", readiness=true. Elapsed: 2.013810215s
    Apr 26 11:51:50.037: INFO: Pod "pod-vqnnc" satisfied condition "running"
    STEP: patching /status 04/26/24 11:51:50.037
    Apr 26 11:51:50.046: INFO: Status Message: "Patched by e2e test" and Reason: "E2E"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 26 11:51:50.046: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3398" for this suite. 04/26/24 11:51:50.055
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:51:50.064
Apr 26 11:51:50.064: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubelet-test 04/26/24 11:51:50.065
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:50.082
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:50.089
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should be possible to delete [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:135
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 26 11:51:50.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8435" for this suite. 04/26/24 11:51:50.126
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]","completed":166,"skipped":3095,"failed":0}
------------------------------
â€¢ [0.071 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should be possible to delete [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:135

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:51:50.064
    Apr 26 11:51:50.064: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubelet-test 04/26/24 11:51:50.065
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:50.082
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:50.089
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should be possible to delete [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:135
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 26 11:51:50.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-8435" for this suite. 04/26/24 11:51:50.126
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command that always fails in a pod
  should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:51:50.136
Apr 26 11:51:50.136: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubelet-test 04/26/24 11:51:50.137
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:50.153
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:50.159
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[BeforeEach] when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:85
[It] should have an terminated reason [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:110
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 26 11:51:54.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6387" for this suite. 04/26/24 11:51:54.213
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]","completed":167,"skipped":3108,"failed":0}
------------------------------
â€¢ [4.084 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command that always fails in a pod
  test/e2e/common/node/kubelet.go:82
    should have an terminated reason [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:110

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:51:50.136
    Apr 26 11:51:50.136: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubelet-test 04/26/24 11:51:50.137
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:50.153
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:50.159
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [BeforeEach] when scheduling a busybox command that always fails in a pod
      test/e2e/common/node/kubelet.go:85
    [It] should have an terminated reason [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:110
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 26 11:51:54.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-6387" for this suite. 04/26/24 11:51:54.213
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:51:54.227
Apr 26 11:51:54.227: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 11:51:54.228
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:54.252
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:54.259
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 11:51:54.277
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:51:54.806
STEP: Deploying the webhook pod 04/26/24 11:51:54.822
STEP: Wait for the deployment to be ready 04/26/24 11:51:54.847
Apr 26 11:51:54.857: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 11:51:56.878
STEP: Verifying the service has paired with the endpoint 04/26/24 11:51:56.895
Apr 26 11:51:57.895: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380
STEP: Setting timeout (1s) shorter than webhook latency (5s) 04/26/24 11:51:57.902
STEP: Registering slow webhook via the AdmissionRegistration API 04/26/24 11:51:57.902
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 04/26/24 11:51:58.031
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 04/26/24 11:51:59.044
STEP: Registering slow webhook via the AdmissionRegistration API 04/26/24 11:51:59.044
STEP: Having no error when timeout is longer than webhook latency 04/26/24 11:52:00.08
STEP: Registering slow webhook via the AdmissionRegistration API 04/26/24 11:52:00.08
STEP: Having no error when timeout is empty (defaulted to 10s in v1) 04/26/24 11:52:05.261
STEP: Registering slow webhook via the AdmissionRegistration API 04/26/24 11:52:05.261
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:52:10.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-293" for this suite. 04/26/24 11:52:10.328
STEP: Destroying namespace "webhook-293-markers" for this suite. 04/26/24 11:52:10.333
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]","completed":168,"skipped":3126,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.163 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  test/e2e/apimachinery/webhook.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:51:54.227
    Apr 26 11:51:54.227: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 11:51:54.228
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:51:54.252
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:51:54.259
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 11:51:54.277
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:51:54.806
    STEP: Deploying the webhook pod 04/26/24 11:51:54.822
    STEP: Wait for the deployment to be ready 04/26/24 11:51:54.847
    Apr 26 11:51:54.857: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 11:51:56.878
    STEP: Verifying the service has paired with the endpoint 04/26/24 11:51:56.895
    Apr 26 11:51:57.895: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should honor timeout [Conformance]
      test/e2e/apimachinery/webhook.go:380
    STEP: Setting timeout (1s) shorter than webhook latency (5s) 04/26/24 11:51:57.902
    STEP: Registering slow webhook via the AdmissionRegistration API 04/26/24 11:51:57.902
    STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s) 04/26/24 11:51:58.031
    STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore 04/26/24 11:51:59.044
    STEP: Registering slow webhook via the AdmissionRegistration API 04/26/24 11:51:59.044
    STEP: Having no error when timeout is longer than webhook latency 04/26/24 11:52:00.08
    STEP: Registering slow webhook via the AdmissionRegistration API 04/26/24 11:52:00.08
    STEP: Having no error when timeout is empty (defaulted to 10s in v1) 04/26/24 11:52:05.261
    STEP: Registering slow webhook via the AdmissionRegistration API 04/26/24 11:52:05.261
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:52:10.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-293" for this suite. 04/26/24 11:52:10.328
    STEP: Destroying namespace "webhook-293-markers" for this suite. 04/26/24 11:52:10.333
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:52:10.393
Apr 26 11:52:10.393: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 11:52:10.394
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:10.412
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:10.416
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6502 04/26/24 11:52:10.422
STEP: changing the ExternalName service to type=ClusterIP 04/26/24 11:52:10.429
STEP: creating replication controller externalname-service in namespace services-6502 04/26/24 11:52:10.443
I0426 11:52:10.448488      23 runners.go:193] Created replication controller with name: externalname-service, namespace: services-6502, replica count: 2
I0426 11:52:13.500092      23 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 26 11:52:13.500: INFO: Creating new exec pod
Apr 26 11:52:13.511: INFO: Waiting up to 5m0s for pod "execpodhbr4r" in namespace "services-6502" to be "running"
Apr 26 11:52:13.518: INFO: Pod "execpodhbr4r": Phase="Pending", Reason="", readiness=false. Elapsed: 6.847389ms
Apr 26 11:52:15.525: INFO: Pod "execpodhbr4r": Phase="Running", Reason="", readiness=true. Elapsed: 2.013878325s
Apr 26 11:52:15.525: INFO: Pod "execpodhbr4r" satisfied condition "running"
Apr 26 11:52:16.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-6502 exec execpodhbr4r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
Apr 26 11:52:17.041: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 26 11:52:17.041: INFO: stdout: "externalname-service-dt6sg"
Apr 26 11:52:17.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-6502 exec execpodhbr4r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.158.140 80'
Apr 26 11:52:17.621: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.158.140 80\nConnection to 100.65.158.140 80 port [tcp/http] succeeded!\n"
Apr 26 11:52:17.621: INFO: stdout: "externalname-service-dt6sg"
Apr 26 11:52:17.621: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 11:52:17.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6502" for this suite. 04/26/24 11:52:17.706
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]","completed":169,"skipped":3139,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.345 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  test/e2e/network/service.go:1404

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:52:10.393
    Apr 26 11:52:10.393: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 11:52:10.394
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:10.412
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:10.416
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to change the type from ExternalName to ClusterIP [Conformance]
      test/e2e/network/service.go:1404
    STEP: creating a service externalname-service with the type=ExternalName in namespace services-6502 04/26/24 11:52:10.422
    STEP: changing the ExternalName service to type=ClusterIP 04/26/24 11:52:10.429
    STEP: creating replication controller externalname-service in namespace services-6502 04/26/24 11:52:10.443
    I0426 11:52:10.448488      23 runners.go:193] Created replication controller with name: externalname-service, namespace: services-6502, replica count: 2
    I0426 11:52:13.500092      23 runners.go:193] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 26 11:52:13.500: INFO: Creating new exec pod
    Apr 26 11:52:13.511: INFO: Waiting up to 5m0s for pod "execpodhbr4r" in namespace "services-6502" to be "running"
    Apr 26 11:52:13.518: INFO: Pod "execpodhbr4r": Phase="Pending", Reason="", readiness=false. Elapsed: 6.847389ms
    Apr 26 11:52:15.525: INFO: Pod "execpodhbr4r": Phase="Running", Reason="", readiness=true. Elapsed: 2.013878325s
    Apr 26 11:52:15.525: INFO: Pod "execpodhbr4r" satisfied condition "running"
    Apr 26 11:52:16.526: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-6502 exec execpodhbr4r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 externalname-service 80'
    Apr 26 11:52:17.041: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
    Apr 26 11:52:17.041: INFO: stdout: "externalname-service-dt6sg"
    Apr 26 11:52:17.041: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-6502 exec execpodhbr4r -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.65.158.140 80'
    Apr 26 11:52:17.621: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.65.158.140 80\nConnection to 100.65.158.140 80 port [tcp/http] succeeded!\n"
    Apr 26 11:52:17.621: INFO: stdout: "externalname-service-dt6sg"
    Apr 26 11:52:17.621: INFO: Cleaning up the ExternalName to ClusterIP test service
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 11:52:17.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6502" for this suite. 04/26/24 11:52:17.706
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo
  should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:52:17.738
Apr 26 11:52:17.738: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 11:52:17.739
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:17.754
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:17.761
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Update Demo
  test/e2e/kubectl/kubectl.go:324
[It] should create and stop a replication controller  [Conformance]
  test/e2e/kubectl/kubectl.go:337
STEP: creating a replication controller 04/26/24 11:52:17.769
Apr 26 11:52:17.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 create -f -'
Apr 26 11:52:18.134: INFO: stderr: ""
Apr 26 11:52:18.134: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up. 04/26/24 11:52:18.134
Apr 26 11:52:18.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 26 11:52:18.202: INFO: stderr: ""
Apr 26 11:52:18.202: INFO: stdout: "update-demo-nautilus-r7fc2 update-demo-nautilus-tqvzt "
Apr 26 11:52:18.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods update-demo-nautilus-r7fc2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 26 11:52:18.255: INFO: stderr: ""
Apr 26 11:52:18.255: INFO: stdout: ""
Apr 26 11:52:18.255: INFO: update-demo-nautilus-r7fc2 is created but not running
Apr 26 11:52:23.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
Apr 26 11:52:23.333: INFO: stderr: ""
Apr 26 11:52:23.333: INFO: stdout: "update-demo-nautilus-r7fc2 update-demo-nautilus-tqvzt "
Apr 26 11:52:23.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods update-demo-nautilus-r7fc2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 26 11:52:23.388: INFO: stderr: ""
Apr 26 11:52:23.388: INFO: stdout: "true"
Apr 26 11:52:23.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods update-demo-nautilus-r7fc2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 26 11:52:23.458: INFO: stderr: ""
Apr 26 11:52:23.458: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 26 11:52:23.458: INFO: validating pod update-demo-nautilus-r7fc2
Apr 26 11:52:23.566: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 26 11:52:23.566: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 26 11:52:23.566: INFO: update-demo-nautilus-r7fc2 is verified up and running
Apr 26 11:52:23.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods update-demo-nautilus-tqvzt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
Apr 26 11:52:23.631: INFO: stderr: ""
Apr 26 11:52:23.631: INFO: stdout: "true"
Apr 26 11:52:23.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods update-demo-nautilus-tqvzt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
Apr 26 11:52:23.696: INFO: stderr: ""
Apr 26 11:52:23.696: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
Apr 26 11:52:23.696: INFO: validating pod update-demo-nautilus-tqvzt
Apr 26 11:52:23.834: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 26 11:52:23.834: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 26 11:52:23.834: INFO: update-demo-nautilus-tqvzt is verified up and running
STEP: using delete to clean up resources 04/26/24 11:52:23.834
Apr 26 11:52:23.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 delete --grace-period=0 --force -f -'
Apr 26 11:52:23.892: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 26 11:52:23.892: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 26 11:52:23.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get rc,svc -l name=update-demo --no-headers'
Apr 26 11:52:23.957: INFO: stderr: "No resources found in kubectl-2884 namespace.\n"
Apr 26 11:52:23.957: INFO: stdout: ""
Apr 26 11:52:23.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 26 11:52:24.029: INFO: stderr: ""
Apr 26 11:52:24.029: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 11:52:24.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2884" for this suite. 04/26/24 11:52:24.038
{"msg":"PASSED [sig-cli] Kubectl client Update Demo should create and stop a replication controller  [Conformance]","completed":170,"skipped":3148,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.304 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Update Demo
  test/e2e/kubectl/kubectl.go:322
    should create and stop a replication controller  [Conformance]
    test/e2e/kubectl/kubectl.go:337

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:52:17.738
    Apr 26 11:52:17.738: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 11:52:17.739
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:17.754
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:17.761
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Update Demo
      test/e2e/kubectl/kubectl.go:324
    [It] should create and stop a replication controller  [Conformance]
      test/e2e/kubectl/kubectl.go:337
    STEP: creating a replication controller 04/26/24 11:52:17.769
    Apr 26 11:52:17.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 create -f -'
    Apr 26 11:52:18.134: INFO: stderr: ""
    Apr 26 11:52:18.134: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
    STEP: waiting for all containers in name=update-demo pods to come up. 04/26/24 11:52:18.134
    Apr 26 11:52:18.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 26 11:52:18.202: INFO: stderr: ""
    Apr 26 11:52:18.202: INFO: stdout: "update-demo-nautilus-r7fc2 update-demo-nautilus-tqvzt "
    Apr 26 11:52:18.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods update-demo-nautilus-r7fc2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 26 11:52:18.255: INFO: stderr: ""
    Apr 26 11:52:18.255: INFO: stdout: ""
    Apr 26 11:52:18.255: INFO: update-demo-nautilus-r7fc2 is created but not running
    Apr 26 11:52:23.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo'
    Apr 26 11:52:23.333: INFO: stderr: ""
    Apr 26 11:52:23.333: INFO: stdout: "update-demo-nautilus-r7fc2 update-demo-nautilus-tqvzt "
    Apr 26 11:52:23.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods update-demo-nautilus-r7fc2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 26 11:52:23.388: INFO: stderr: ""
    Apr 26 11:52:23.388: INFO: stdout: "true"
    Apr 26 11:52:23.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods update-demo-nautilus-r7fc2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 26 11:52:23.458: INFO: stderr: ""
    Apr 26 11:52:23.458: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 26 11:52:23.458: INFO: validating pod update-demo-nautilus-r7fc2
    Apr 26 11:52:23.566: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 26 11:52:23.566: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 26 11:52:23.566: INFO: update-demo-nautilus-r7fc2 is verified up and running
    Apr 26 11:52:23.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods update-demo-nautilus-tqvzt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}}'
    Apr 26 11:52:23.631: INFO: stderr: ""
    Apr 26 11:52:23.631: INFO: stdout: "true"
    Apr 26 11:52:23.631: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods update-demo-nautilus-tqvzt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}}'
    Apr 26 11:52:23.696: INFO: stderr: ""
    Apr 26 11:52:23.696: INFO: stdout: "registry.k8s.io/e2e-test-images/nautilus:1.5"
    Apr 26 11:52:23.696: INFO: validating pod update-demo-nautilus-tqvzt
    Apr 26 11:52:23.834: INFO: got data: {
      "image": "nautilus.jpg"
    }

    Apr 26 11:52:23.834: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
    Apr 26 11:52:23.834: INFO: update-demo-nautilus-tqvzt is verified up and running
    STEP: using delete to clean up resources 04/26/24 11:52:23.834
    Apr 26 11:52:23.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 delete --grace-period=0 --force -f -'
    Apr 26 11:52:23.892: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 26 11:52:23.892: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
    Apr 26 11:52:23.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get rc,svc -l name=update-demo --no-headers'
    Apr 26 11:52:23.957: INFO: stderr: "No resources found in kubectl-2884 namespace.\n"
    Apr 26 11:52:23.957: INFO: stdout: ""
    Apr 26 11:52:23.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2884 get pods -l name=update-demo -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 26 11:52:24.029: INFO: stderr: ""
    Apr 26 11:52:24.029: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 11:52:24.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2884" for this suite. 04/26/24 11:52:24.038
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] ReplicaSet
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:52:24.043
Apr 26 11:52:24.044: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename replicaset 04/26/24 11:52:24.045
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:24.059
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:24.066
[It] Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143
STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 04/26/24 11:52:24.075
Apr 26 11:52:24.090: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 26 11:52:29.096: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/26/24 11:52:29.096
STEP: getting scale subresource 04/26/24 11:52:29.097
STEP: updating a scale subresource 04/26/24 11:52:29.102
STEP: verifying the replicaset Spec.Replicas was modified 04/26/24 11:52:29.108
STEP: Patch a scale subresource 04/26/24 11:52:29.112
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 26 11:52:29.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1077" for this suite. 04/26/24 11:52:29.152
{"msg":"PASSED [sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]","completed":171,"skipped":3148,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.119 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replicaset should have a working scale subresource [Conformance]
  test/e2e/apps/replica_set.go:143

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:52:24.043
    Apr 26 11:52:24.044: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename replicaset 04/26/24 11:52:24.045
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:24.059
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:24.066
    [It] Replicaset should have a working scale subresource [Conformance]
      test/e2e/apps/replica_set.go:143
    STEP: Creating replica set "test-rs" that asks for more than the allowed pod quota 04/26/24 11:52:24.075
    Apr 26 11:52:24.090: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 26 11:52:29.096: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/26/24 11:52:29.096
    STEP: getting scale subresource 04/26/24 11:52:29.097
    STEP: updating a scale subresource 04/26/24 11:52:29.102
    STEP: verifying the replicaset Spec.Replicas was modified 04/26/24 11:52:29.108
    STEP: Patch a scale subresource 04/26/24 11:52:29.112
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 26 11:52:29.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-1077" for this suite. 04/26/24 11:52:29.152
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl server-side dry-run
  should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:52:29.164
Apr 26 11:52:29.164: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 11:52:29.164
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:29.18
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:29.186
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl can dry-run update Pods [Conformance]
  test/e2e/kubectl/kubectl.go:960
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/26/24 11:52:29.192
Apr 26 11:52:29.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9962 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 26 11:52:29.279: INFO: stderr: ""
Apr 26 11:52:29.279: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: replace the image in the pod with server-side dry-run 04/26/24 11:52:29.279
Apr 26 11:52:29.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9962 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
Apr 26 11:52:29.687: INFO: stderr: ""
Apr 26 11:52:29.687: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/26/24 11:52:29.687
Apr 26 11:52:29.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9962 delete pods e2e-test-httpd-pod'
Apr 26 11:52:31.797: INFO: stderr: ""
Apr 26 11:52:31.797: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 11:52:31.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9962" for this suite. 04/26/24 11:52:31.812
{"msg":"PASSED [sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]","completed":172,"skipped":3161,"failed":0}
------------------------------
â€¢ [2.661 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl server-side dry-run
  test/e2e/kubectl/kubectl.go:954
    should check if kubectl can dry-run update Pods [Conformance]
    test/e2e/kubectl/kubectl.go:960

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:52:29.164
    Apr 26 11:52:29.164: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 11:52:29.164
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:29.18
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:29.186
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl can dry-run update Pods [Conformance]
      test/e2e/kubectl/kubectl.go:960
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/26/24 11:52:29.192
    Apr 26 11:52:29.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9962 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Apr 26 11:52:29.279: INFO: stderr: ""
    Apr 26 11:52:29.279: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: replace the image in the pod with server-side dry-run 04/26/24 11:52:29.279
    Apr 26 11:52:29.280: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9962 patch pod e2e-test-httpd-pod -p {"spec":{"containers":[{"name": "e2e-test-httpd-pod","image": "registry.k8s.io/e2e-test-images/busybox:1.29-2"}]}} --dry-run=server'
    Apr 26 11:52:29.687: INFO: stderr: ""
    Apr 26 11:52:29.687: INFO: stdout: "pod/e2e-test-httpd-pod patched\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/26/24 11:52:29.687
    Apr 26 11:52:29.693: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9962 delete pods e2e-test-httpd-pod'
    Apr 26 11:52:31.797: INFO: stderr: ""
    Apr 26 11:52:31.797: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 11:52:31.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9962" for this suite. 04/26/24 11:52:31.812
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial]
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:52:31.827
Apr 26 11:52:31.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename namespaces 04/26/24 11:52:31.828
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:31.849
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:31.859
[It] should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267
STEP: creating a Namespace 04/26/24 11:52:31.868
STEP: patching the Namespace 04/26/24 11:52:31.887
STEP: get the Namespace and ensuring it has the label 04/26/24 11:52:31.895
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:52:31.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7033" for this suite. 04/26/24 11:52:31.908
STEP: Destroying namespace "nspatchtest-862b5acd-11a5-490c-a052-05717d6d31c9-7273" for this suite. 04/26/24 11:52:31.913
{"msg":"PASSED [sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]","completed":173,"skipped":3197,"failed":0}
------------------------------
â€¢ [0.093 seconds]
[sig-api-machinery] Namespaces [Serial]
test/e2e/apimachinery/framework.go:23
  should patch a Namespace [Conformance]
  test/e2e/apimachinery/namespace.go:267

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:52:31.827
    Apr 26 11:52:31.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename namespaces 04/26/24 11:52:31.828
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:31.849
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:31.859
    [It] should patch a Namespace [Conformance]
      test/e2e/apimachinery/namespace.go:267
    STEP: creating a Namespace 04/26/24 11:52:31.868
    STEP: patching the Namespace 04/26/24 11:52:31.887
    STEP: get the Namespace and ensuring it has the label 04/26/24 11:52:31.895
    [AfterEach] [sig-api-machinery] Namespaces [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:52:31.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "namespaces-7033" for this suite. 04/26/24 11:52:31.908
    STEP: Destroying namespace "nspatchtest-862b5acd-11a5-490c-a052-05717d6d31c9-7273" for this suite. 04/26/24 11:52:31.913
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:52:31.921
Apr 26 11:52:31.921: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename runtimeclass 04/26/24 11:52:31.923
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:31.942
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:31.95
[It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156
STEP: Deleting RuntimeClass runtimeclass-1402-delete-me 04/26/24 11:52:31.965
STEP: Waiting for the RuntimeClass to disappear 04/26/24 11:52:31.971
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 26 11:52:31.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1402" for this suite. 04/26/24 11:52:31.995
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]","completed":174,"skipped":3223,"failed":0}
------------------------------
â€¢ [0.081 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:156

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:52:31.921
    Apr 26 11:52:31.921: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename runtimeclass 04/26/24 11:52:31.923
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:31.942
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:31.95
    [It] should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:156
    STEP: Deleting RuntimeClass runtimeclass-1402-delete-me 04/26/24 11:52:31.965
    STEP: Waiting for the RuntimeClass to disappear 04/26/24 11:52:31.971
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 26 11:52:31.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1402" for this suite. 04/26/24 11:52:31.995
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-scheduling] LimitRange
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
[BeforeEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:52:32.003
Apr 26 11:52:32.004: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename limitrange 04/26/24 11:52:32.004
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:32.02
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:32.028
[It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57
STEP: Creating a LimitRange 04/26/24 11:52:32.037
STEP: Setting up watch 04/26/24 11:52:32.037
STEP: Submitting a LimitRange 04/26/24 11:52:32.144
STEP: Verifying LimitRange creation was observed 04/26/24 11:52:32.155
STEP: Fetching the LimitRange to ensure it has proper values 04/26/24 11:52:32.155
Apr 26 11:52:32.160: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 26 11:52:32.160: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with no resource requirements 04/26/24 11:52:32.16
STEP: Ensuring Pod has resource requirements applied from LimitRange 04/26/24 11:52:32.175
Apr 26 11:52:32.181: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
Apr 26 11:52:32.181: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Creating a Pod with partial resource requirements 04/26/24 11:52:32.181
STEP: Ensuring Pod has merged resource requirements applied from LimitRange 04/26/24 11:52:32.191
Apr 26 11:52:32.196: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
Apr 26 11:52:32.196: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
STEP: Failing to create a Pod with less than min resources 04/26/24 11:52:32.196
STEP: Failing to create a Pod with more than max resources 04/26/24 11:52:32.203
STEP: Updating a LimitRange 04/26/24 11:52:32.211
STEP: Verifying LimitRange updating is effective 04/26/24 11:52:32.218
STEP: Creating a Pod with less than former min resources 04/26/24 11:52:34.226
STEP: Failing to create a Pod with more than max resources 04/26/24 11:52:34.236
STEP: Deleting a LimitRange 04/26/24 11:52:34.245
STEP: Verifying the LimitRange was deleted 04/26/24 11:52:34.25
Apr 26 11:52:39.256: INFO: limitRange is already deleted
STEP: Creating a Pod with more than former max resources 04/26/24 11:52:39.256
[AfterEach] [sig-scheduling] LimitRange
  test/e2e/framework/framework.go:187
Apr 26 11:52:39.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "limitrange-5464" for this suite. 04/26/24 11:52:39.28
{"msg":"PASSED [sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]","completed":175,"skipped":3226,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.283 seconds]
[sig-scheduling] LimitRange
test/e2e/scheduling/framework.go:40
  should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
  test/e2e/scheduling/limit_range.go:57

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:52:32.003
    Apr 26 11:52:32.004: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename limitrange 04/26/24 11:52:32.004
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:32.02
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:32.028
    [It] should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]
      test/e2e/scheduling/limit_range.go:57
    STEP: Creating a LimitRange 04/26/24 11:52:32.037
    STEP: Setting up watch 04/26/24 11:52:32.037
    STEP: Submitting a LimitRange 04/26/24 11:52:32.144
    STEP: Verifying LimitRange creation was observed 04/26/24 11:52:32.155
    STEP: Fetching the LimitRange to ensure it has proper values 04/26/24 11:52:32.155
    Apr 26 11:52:32.160: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Apr 26 11:52:32.160: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with no resource requirements 04/26/24 11:52:32.16
    STEP: Ensuring Pod has resource requirements applied from LimitRange 04/26/24 11:52:32.175
    Apr 26 11:52:32.181: INFO: Verifying requests: expected map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}] with actual map[cpu:{{100 -3} {<nil>} 100m DecimalSI} ephemeral-storage:{{214748364800 0} {<nil>}  BinarySI} memory:{{209715200 0} {<nil>}  BinarySI}]
    Apr 26 11:52:32.181: INFO: Verifying limits: expected map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{500 -3} {<nil>} 500m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Creating a Pod with partial resource requirements 04/26/24 11:52:32.181
    STEP: Ensuring Pod has merged resource requirements applied from LimitRange 04/26/24 11:52:32.191
    Apr 26 11:52:32.196: INFO: Verifying requests: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{161061273600 0} {<nil>} 150Gi BinarySI} memory:{{157286400 0} {<nil>} 150Mi BinarySI}]
    Apr 26 11:52:32.196: INFO: Verifying limits: expected map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}] with actual map[cpu:{{300 -3} {<nil>} 300m DecimalSI} ephemeral-storage:{{536870912000 0} {<nil>} 500Gi BinarySI} memory:{{524288000 0} {<nil>} 500Mi BinarySI}]
    STEP: Failing to create a Pod with less than min resources 04/26/24 11:52:32.196
    STEP: Failing to create a Pod with more than max resources 04/26/24 11:52:32.203
    STEP: Updating a LimitRange 04/26/24 11:52:32.211
    STEP: Verifying LimitRange updating is effective 04/26/24 11:52:32.218
    STEP: Creating a Pod with less than former min resources 04/26/24 11:52:34.226
    STEP: Failing to create a Pod with more than max resources 04/26/24 11:52:34.236
    STEP: Deleting a LimitRange 04/26/24 11:52:34.245
    STEP: Verifying the LimitRange was deleted 04/26/24 11:52:34.25
    Apr 26 11:52:39.256: INFO: limitRange is already deleted
    STEP: Creating a Pod with more than former max resources 04/26/24 11:52:39.256
    [AfterEach] [sig-scheduling] LimitRange
      test/e2e/framework/framework.go:187
    Apr 26 11:52:39.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "limitrange-5464" for this suite. 04/26/24 11:52:39.28
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:52:39.289
Apr 26 11:52:39.289: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename replicaset 04/26/24 11:52:39.29
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:39.307
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:39.313
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131
STEP: Given a Pod with a 'name' label pod-adoption-release is created 04/26/24 11:52:39.321
Apr 26 11:52:39.331: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-4702" to be "running and ready"
Apr 26 11:52:39.339: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 7.103131ms
Apr 26 11:52:39.339: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:52:41.345: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.013878618s
Apr 26 11:52:41.345: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
Apr 26 11:52:41.345: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
STEP: When a replicaset with a matching selector is created 04/26/24 11:52:41.35
STEP: Then the orphan pod is adopted 04/26/24 11:52:41.359
STEP: When the matched label of one of its pods change 04/26/24 11:52:42.371
Apr 26 11:52:42.377: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released 04/26/24 11:52:42.394
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 26 11:52:42.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4702" for this suite. 04/26/24 11:52:42.414
{"msg":"PASSED [sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]","completed":176,"skipped":3233,"failed":0}
------------------------------
â€¢ [3.135 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  test/e2e/apps/replica_set.go:131

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:52:39.289
    Apr 26 11:52:39.289: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename replicaset 04/26/24 11:52:39.29
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:39.307
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:39.313
    [It] should adopt matching pods on creation and release no longer matching pods [Conformance]
      test/e2e/apps/replica_set.go:131
    STEP: Given a Pod with a 'name' label pod-adoption-release is created 04/26/24 11:52:39.321
    Apr 26 11:52:39.331: INFO: Waiting up to 5m0s for pod "pod-adoption-release" in namespace "replicaset-4702" to be "running and ready"
    Apr 26 11:52:39.339: INFO: Pod "pod-adoption-release": Phase="Pending", Reason="", readiness=false. Elapsed: 7.103131ms
    Apr 26 11:52:39.339: INFO: The phase of Pod pod-adoption-release is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:52:41.345: INFO: Pod "pod-adoption-release": Phase="Running", Reason="", readiness=true. Elapsed: 2.013878618s
    Apr 26 11:52:41.345: INFO: The phase of Pod pod-adoption-release is Running (Ready = true)
    Apr 26 11:52:41.345: INFO: Pod "pod-adoption-release" satisfied condition "running and ready"
    STEP: When a replicaset with a matching selector is created 04/26/24 11:52:41.35
    STEP: Then the orphan pod is adopted 04/26/24 11:52:41.359
    STEP: When the matched label of one of its pods change 04/26/24 11:52:42.371
    Apr 26 11:52:42.377: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
    STEP: Then the pod is released 04/26/24 11:52:42.394
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 26 11:52:42.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4702" for this suite. 04/26/24 11:52:42.414
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
[BeforeEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:52:42.424
Apr 26 11:52:42.425: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename replicaset 04/26/24 11:52:42.425
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:42.44
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:42.445
[It] Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154
Apr 26 11:52:42.469: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 26 11:52:47.479: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/26/24 11:52:47.479
STEP: Scaling up "test-rs" replicaset  04/26/24 11:52:47.479
Apr 26 11:52:47.491: INFO: Updating replica set "test-rs"
STEP: patching the ReplicaSet 04/26/24 11:52:47.491
W0426 11:52:47.501913      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 26 11:52:47.507: INFO: observed ReplicaSet test-rs in namespace replicaset-4073 with ReadyReplicas 1, AvailableReplicas 1
Apr 26 11:52:47.516: INFO: observed ReplicaSet test-rs in namespace replicaset-4073 with ReadyReplicas 1, AvailableReplicas 1
Apr 26 11:52:47.535: INFO: observed ReplicaSet test-rs in namespace replicaset-4073 with ReadyReplicas 1, AvailableReplicas 1
Apr 26 11:52:47.545: INFO: observed ReplicaSet test-rs in namespace replicaset-4073 with ReadyReplicas 1, AvailableReplicas 1
Apr 26 11:52:48.797: INFO: observed ReplicaSet test-rs in namespace replicaset-4073 with ReadyReplicas 2, AvailableReplicas 2
Apr 26 11:52:49.172: INFO: observed Replicaset test-rs in namespace replicaset-4073 with ReadyReplicas 3 found true
[AfterEach] [sig-apps] ReplicaSet
  test/e2e/framework/framework.go:187
Apr 26 11:52:49.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4073" for this suite. 04/26/24 11:52:49.182
{"msg":"PASSED [sig-apps] ReplicaSet Replace and Patch tests [Conformance]","completed":177,"skipped":3250,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.764 seconds]
[sig-apps] ReplicaSet
test/e2e/apps/framework.go:23
  Replace and Patch tests [Conformance]
  test/e2e/apps/replica_set.go:154

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:52:42.424
    Apr 26 11:52:42.425: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename replicaset 04/26/24 11:52:42.425
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:42.44
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:42.445
    [It] Replace and Patch tests [Conformance]
      test/e2e/apps/replica_set.go:154
    Apr 26 11:52:42.469: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 26 11:52:47.479: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/26/24 11:52:47.479
    STEP: Scaling up "test-rs" replicaset  04/26/24 11:52:47.479
    Apr 26 11:52:47.491: INFO: Updating replica set "test-rs"
    STEP: patching the ReplicaSet 04/26/24 11:52:47.491
    W0426 11:52:47.501913      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 26 11:52:47.507: INFO: observed ReplicaSet test-rs in namespace replicaset-4073 with ReadyReplicas 1, AvailableReplicas 1
    Apr 26 11:52:47.516: INFO: observed ReplicaSet test-rs in namespace replicaset-4073 with ReadyReplicas 1, AvailableReplicas 1
    Apr 26 11:52:47.535: INFO: observed ReplicaSet test-rs in namespace replicaset-4073 with ReadyReplicas 1, AvailableReplicas 1
    Apr 26 11:52:47.545: INFO: observed ReplicaSet test-rs in namespace replicaset-4073 with ReadyReplicas 1, AvailableReplicas 1
    Apr 26 11:52:48.797: INFO: observed ReplicaSet test-rs in namespace replicaset-4073 with ReadyReplicas 2, AvailableReplicas 2
    Apr 26 11:52:49.172: INFO: observed Replicaset test-rs in namespace replicaset-4073 with ReadyReplicas 3 found true
    [AfterEach] [sig-apps] ReplicaSet
      test/e2e/framework/framework.go:187
    Apr 26 11:52:49.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replicaset-4073" for this suite. 04/26/24 11:52:49.182
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:52:49.193
Apr 26 11:52:49.193: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-lifecycle-hook 04/26/24 11:52:49.194
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:49.212
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:49.22
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/26/24 11:52:49.24
Apr 26 11:52:49.251: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9978" to be "running and ready"
Apr 26 11:52:49.258: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.994185ms
Apr 26 11:52:49.258: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:52:51.266: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.014473645s
Apr 26 11:52:51.266: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 26 11:52:51.266: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:114
STEP: create the pod with lifecycle hook 04/26/24 11:52:51.272
Apr 26 11:52:51.281: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-9978" to be "running and ready"
Apr 26 11:52:51.288: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 7.343341ms
Apr 26 11:52:51.288: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:52:53.295: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.014292159s
Apr 26 11:52:53.295: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
Apr 26 11:52:53.295: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 04/26/24 11:52:53.3
Apr 26 11:52:53.311: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 26 11:52:53.316: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 26 11:52:55.316: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 26 11:52:55.323: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 26 11:52:57.316: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 26 11:52:57.322: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook 04/26/24 11:52:57.322
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 26 11:52:57.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9978" for this suite. 04/26/24 11:52:57.346
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]","completed":178,"skipped":3288,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.160 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:114

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:52:49.193
    Apr 26 11:52:49.193: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/26/24 11:52:49.194
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:49.212
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:49.22
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/26/24 11:52:49.24
    Apr 26 11:52:49.251: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-9978" to be "running and ready"
    Apr 26 11:52:49.258: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 6.994185ms
    Apr 26 11:52:49.258: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:52:51.266: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.014473645s
    Apr 26 11:52:51.266: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 26 11:52:51.266: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:114
    STEP: create the pod with lifecycle hook 04/26/24 11:52:51.272
    Apr 26 11:52:51.281: INFO: Waiting up to 5m0s for pod "pod-with-prestop-exec-hook" in namespace "container-lifecycle-hook-9978" to be "running and ready"
    Apr 26 11:52:51.288: INFO: Pod "pod-with-prestop-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 7.343341ms
    Apr 26 11:52:51.288: INFO: The phase of Pod pod-with-prestop-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:52:53.295: INFO: Pod "pod-with-prestop-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.014292159s
    Apr 26 11:52:53.295: INFO: The phase of Pod pod-with-prestop-exec-hook is Running (Ready = true)
    Apr 26 11:52:53.295: INFO: Pod "pod-with-prestop-exec-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 04/26/24 11:52:53.3
    Apr 26 11:52:53.311: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 26 11:52:53.316: INFO: Pod pod-with-prestop-exec-hook still exists
    Apr 26 11:52:55.316: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 26 11:52:55.323: INFO: Pod pod-with-prestop-exec-hook still exists
    Apr 26 11:52:57.316: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
    Apr 26 11:52:57.322: INFO: Pod pod-with-prestop-exec-hook no longer exists
    STEP: check prestop hook 04/26/24 11:52:57.322
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 26 11:52:57.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-9978" for this suite. 04/26/24 11:52:57.346
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Lease
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[BeforeEach] [sig-node] Lease
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:52:57.355
Apr 26 11:52:57.355: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename lease-test 04/26/24 11:52:57.356
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:57.371
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:57.379
[It] lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72
[AfterEach] [sig-node] Lease
  test/e2e/framework/framework.go:187
Apr 26 11:52:57.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "lease-test-7260" for this suite. 04/26/24 11:52:57.49
{"msg":"PASSED [sig-node] Lease lease API should be available [Conformance]","completed":179,"skipped":3310,"failed":0}
------------------------------
â€¢ [0.141 seconds]
[sig-node] Lease
test/e2e/common/node/framework.go:23
  lease API should be available [Conformance]
  test/e2e/common/node/lease.go:72

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Lease
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:52:57.355
    Apr 26 11:52:57.355: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename lease-test 04/26/24 11:52:57.356
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:57.371
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:57.379
    [It] lease API should be available [Conformance]
      test/e2e/common/node/lease.go:72
    [AfterEach] [sig-node] Lease
      test/e2e/framework/framework.go:187
    Apr 26 11:52:57.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "lease-test-7260" for this suite. 04/26/24 11:52:57.49
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:52:57.497
Apr 26 11:52:57.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename subpath 04/26/24 11:52:57.498
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:57.513
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:57.519
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/26/24 11:52:57.526
[It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
  test/e2e/storage/subpath.go:80
STEP: Creating pod pod-subpath-test-configmap-p5vs 04/26/24 11:52:57.541
STEP: Creating a pod to test atomic-volume-subpath 04/26/24 11:52:57.541
Apr 26 11:52:57.552: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-p5vs" in namespace "subpath-3771" to be "Succeeded or Failed"
Apr 26 11:52:57.557: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Pending", Reason="", readiness=false. Elapsed: 5.142141ms
Apr 26 11:52:59.567: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 2.014958935s
Apr 26 11:53:01.570: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 4.018343846s
Apr 26 11:53:03.564: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 6.011643729s
Apr 26 11:53:05.563: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 8.01151529s
Apr 26 11:53:07.566: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 10.014372669s
Apr 26 11:53:09.563: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 12.011452516s
Apr 26 11:53:11.562: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 14.010568778s
Apr 26 11:53:13.563: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 16.011330716s
Apr 26 11:53:15.570: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 18.017858432s
Apr 26 11:53:17.563: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 20.011221377s
Apr 26 11:53:19.564: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=false. Elapsed: 22.01230544s
Apr 26 11:53:21.566: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.014054133s
STEP: Saw pod success 04/26/24 11:53:21.566
Apr 26 11:53:21.566: INFO: Pod "pod-subpath-test-configmap-p5vs" satisfied condition "Succeeded or Failed"
Apr 26 11:53:21.573: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-subpath-test-configmap-p5vs container test-container-subpath-configmap-p5vs: <nil>
STEP: delete the pod 04/26/24 11:53:21.59
Apr 26 11:53:21.608: INFO: Waiting for pod pod-subpath-test-configmap-p5vs to disappear
Apr 26 11:53:21.614: INFO: Pod pod-subpath-test-configmap-p5vs no longer exists
STEP: Deleting pod pod-subpath-test-configmap-p5vs 04/26/24 11:53:21.614
Apr 26 11:53:21.614: INFO: Deleting pod "pod-subpath-test-configmap-p5vs" in namespace "subpath-3771"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 26 11:53:21.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3771" for this suite. 04/26/24 11:53:21.629
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]","completed":180,"skipped":3337,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.140 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with configmap pod with mountPath of existing file [Conformance]
    test/e2e/storage/subpath.go:80

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:52:57.497
    Apr 26 11:52:57.497: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename subpath 04/26/24 11:52:57.498
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:52:57.513
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:52:57.519
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/26/24 11:52:57.526
    [It] should support subpaths with configmap pod with mountPath of existing file [Conformance]
      test/e2e/storage/subpath.go:80
    STEP: Creating pod pod-subpath-test-configmap-p5vs 04/26/24 11:52:57.541
    STEP: Creating a pod to test atomic-volume-subpath 04/26/24 11:52:57.541
    Apr 26 11:52:57.552: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-p5vs" in namespace "subpath-3771" to be "Succeeded or Failed"
    Apr 26 11:52:57.557: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Pending", Reason="", readiness=false. Elapsed: 5.142141ms
    Apr 26 11:52:59.567: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 2.014958935s
    Apr 26 11:53:01.570: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 4.018343846s
    Apr 26 11:53:03.564: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 6.011643729s
    Apr 26 11:53:05.563: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 8.01151529s
    Apr 26 11:53:07.566: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 10.014372669s
    Apr 26 11:53:09.563: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 12.011452516s
    Apr 26 11:53:11.562: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 14.010568778s
    Apr 26 11:53:13.563: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 16.011330716s
    Apr 26 11:53:15.570: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 18.017858432s
    Apr 26 11:53:17.563: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=true. Elapsed: 20.011221377s
    Apr 26 11:53:19.564: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Running", Reason="", readiness=false. Elapsed: 22.01230544s
    Apr 26 11:53:21.566: INFO: Pod "pod-subpath-test-configmap-p5vs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.014054133s
    STEP: Saw pod success 04/26/24 11:53:21.566
    Apr 26 11:53:21.566: INFO: Pod "pod-subpath-test-configmap-p5vs" satisfied condition "Succeeded or Failed"
    Apr 26 11:53:21.573: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-subpath-test-configmap-p5vs container test-container-subpath-configmap-p5vs: <nil>
    STEP: delete the pod 04/26/24 11:53:21.59
    Apr 26 11:53:21.608: INFO: Waiting for pod pod-subpath-test-configmap-p5vs to disappear
    Apr 26 11:53:21.614: INFO: Pod pod-subpath-test-configmap-p5vs no longer exists
    STEP: Deleting pod pod-subpath-test-configmap-p5vs 04/26/24 11:53:21.614
    Apr 26 11:53:21.614: INFO: Deleting pod "pod-subpath-test-configmap-p5vs" in namespace "subpath-3771"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 26 11:53:21.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-3771" for this suite. 04/26/24 11:53:21.629
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-node] Containers
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:53:21.639
Apr 26 11:53:21.640: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename containers 04/26/24 11:53:21.641
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:21.658
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:21.664
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38
Apr 26 11:53:21.680: INFO: Waiting up to 5m0s for pod "client-containers-0f98b54f-e670-4e42-b846-3278df1855c4" in namespace "containers-6644" to be "running"
Apr 26 11:53:21.702: INFO: Pod "client-containers-0f98b54f-e670-4e42-b846-3278df1855c4": Phase="Pending", Reason="", readiness=false. Elapsed: 22.276868ms
Apr 26 11:53:23.710: INFO: Pod "client-containers-0f98b54f-e670-4e42-b846-3278df1855c4": Phase="Running", Reason="", readiness=true. Elapsed: 2.03008829s
Apr 26 11:53:23.710: INFO: Pod "client-containers-0f98b54f-e670-4e42-b846-3278df1855c4" satisfied condition "running"
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 26 11:53:23.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6644" for this suite. 04/26/24 11:53:23.737
{"msg":"PASSED [sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]","completed":181,"skipped":3340,"failed":0}
------------------------------
â€¢ [2.104 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:38

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:53:21.639
    Apr 26 11:53:21.640: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename containers 04/26/24 11:53:21.641
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:21.658
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:21.664
    [It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:38
    Apr 26 11:53:21.680: INFO: Waiting up to 5m0s for pod "client-containers-0f98b54f-e670-4e42-b846-3278df1855c4" in namespace "containers-6644" to be "running"
    Apr 26 11:53:21.702: INFO: Pod "client-containers-0f98b54f-e670-4e42-b846-3278df1855c4": Phase="Pending", Reason="", readiness=false. Elapsed: 22.276868ms
    Apr 26 11:53:23.710: INFO: Pod "client-containers-0f98b54f-e670-4e42-b846-3278df1855c4": Phase="Running", Reason="", readiness=true. Elapsed: 2.03008829s
    Apr 26 11:53:23.710: INFO: Pod "client-containers-0f98b54f-e670-4e42-b846-3278df1855c4" satisfied condition "running"
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 26 11:53:23.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-6644" for this suite. 04/26/24 11:53:23.737
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] server version
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
[BeforeEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:53:23.749
Apr 26 11:53:23.749: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename server-version 04/26/24 11:53:23.75
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:23.765
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:23.772
[It] should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39
STEP: Request ServerVersion 04/26/24 11:53:23.779
STEP: Confirm major version 04/26/24 11:53:23.783
Apr 26 11:53:23.783: INFO: Major version: 1
STEP: Confirm minor version 04/26/24 11:53:23.783
Apr 26 11:53:23.783: INFO: cleanMinorVersion: 25
Apr 26 11:53:23.783: INFO: Minor version: 25
[AfterEach] [sig-api-machinery] server version
  test/e2e/framework/framework.go:187
Apr 26 11:53:23.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "server-version-2300" for this suite. 04/26/24 11:53:23.794
{"msg":"PASSED [sig-api-machinery] server version should find the server version [Conformance]","completed":182,"skipped":3369,"failed":0}
------------------------------
â€¢ [0.053 seconds]
[sig-api-machinery] server version
test/e2e/apimachinery/framework.go:23
  should find the server version [Conformance]
  test/e2e/apimachinery/server_version.go:39

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:53:23.749
    Apr 26 11:53:23.749: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename server-version 04/26/24 11:53:23.75
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:23.765
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:23.772
    [It] should find the server version [Conformance]
      test/e2e/apimachinery/server_version.go:39
    STEP: Request ServerVersion 04/26/24 11:53:23.779
    STEP: Confirm major version 04/26/24 11:53:23.783
    Apr 26 11:53:23.783: INFO: Major version: 1
    STEP: Confirm minor version 04/26/24 11:53:23.783
    Apr 26 11:53:23.783: INFO: cleanMinorVersion: 25
    Apr 26 11:53:23.783: INFO: Minor version: 25
    [AfterEach] [sig-api-machinery] server version
      test/e2e/framework/framework.go:187
    Apr 26 11:53:23.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "server-version-2300" for this suite. 04/26/24 11:53:23.794
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:53:23.804
Apr 26 11:53:23.804: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename watch 04/26/24 11:53:23.805
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:23.855
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:23.864
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60
STEP: creating a watch on configmaps with label A 04/26/24 11:53:23.872
STEP: creating a watch on configmaps with label B 04/26/24 11:53:23.876
STEP: creating a watch on configmaps with label A or B 04/26/24 11:53:23.879
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 04/26/24 11:53:23.883
Apr 26 11:53:23.889: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35501 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 11:53:23.889: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35501 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A and ensuring the correct watchers observe the notification 04/26/24 11:53:23.89
Apr 26 11:53:23.904: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35502 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 11:53:23.904: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35502 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification 04/26/24 11:53:23.904
Apr 26 11:53:23.932: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35504 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 11:53:23.933: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35504 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap A and ensuring the correct watchers observe the notification 04/26/24 11:53:23.933
Apr 26 11:53:23.942: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35505 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 11:53:23.942: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35505 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 04/26/24 11:53:23.942
Apr 26 11:53:23.952: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2254  45db1d2e-435e-4de7-8796-d30d21ae15f4 35506 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 11:53:23.952: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2254  45db1d2e-435e-4de7-8796-d30d21ae15f4 35506 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: deleting configmap B and ensuring the correct watchers observe the notification 04/26/24 11:53:33.953
Apr 26 11:53:33.974: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2254  45db1d2e-435e-4de7-8796-d30d21ae15f4 35565 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 11:53:33.974: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2254  45db1d2e-435e-4de7-8796-d30d21ae15f4 35565 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 26 11:53:43.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2254" for this suite. 04/26/24 11:53:43.992
{"msg":"PASSED [sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]","completed":183,"skipped":3416,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.199 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  test/e2e/apimachinery/watch.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:53:23.804
    Apr 26 11:53:23.804: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename watch 04/26/24 11:53:23.805
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:23.855
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:23.864
    [It] should observe add, update, and delete watch notifications on configmaps [Conformance]
      test/e2e/apimachinery/watch.go:60
    STEP: creating a watch on configmaps with label A 04/26/24 11:53:23.872
    STEP: creating a watch on configmaps with label B 04/26/24 11:53:23.876
    STEP: creating a watch on configmaps with label A or B 04/26/24 11:53:23.879
    STEP: creating a configmap with label A and ensuring the correct watchers observe the notification 04/26/24 11:53:23.883
    Apr 26 11:53:23.889: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35501 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 11:53:23.889: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35501 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A and ensuring the correct watchers observe the notification 04/26/24 11:53:23.89
    Apr 26 11:53:23.904: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35502 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 11:53:23.904: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35502 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying configmap A again and ensuring the correct watchers observe the notification 04/26/24 11:53:23.904
    Apr 26 11:53:23.932: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35504 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 11:53:23.933: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35504 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap A and ensuring the correct watchers observe the notification 04/26/24 11:53:23.933
    Apr 26 11:53:23.942: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35505 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 11:53:23.942: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2254  6b9f65c1-79ea-486e-af6e-51ff550199b7 35505 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: creating a configmap with label B and ensuring the correct watchers observe the notification 04/26/24 11:53:23.942
    Apr 26 11:53:23.952: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2254  45db1d2e-435e-4de7-8796-d30d21ae15f4 35506 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 11:53:23.952: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2254  45db1d2e-435e-4de7-8796-d30d21ae15f4 35506 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: deleting configmap B and ensuring the correct watchers observe the notification 04/26/24 11:53:33.953
    Apr 26 11:53:33.974: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2254  45db1d2e-435e-4de7-8796-d30d21ae15f4 35565 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 11:53:33.974: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2254  45db1d2e-435e-4de7-8796-d30d21ae15f4 35565 0 2024-04-26 11:53:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] [] [{e2e.test Update v1 2024-04-26 11:53:23 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 26 11:53:43.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-2254" for this suite. 04/26/24 11:53:43.992
  << End Captured GinkgoWriter Output
------------------------------
[sig-storage] ConfigMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:53:44.003
Apr 26 11:53:44.003: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 11:53:44.004
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:44.018
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:44.023
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239
STEP: Creating configMap with name cm-test-opt-del-71f35f2c-f605-47e7-a504-cd95920319ed 04/26/24 11:53:44.04
STEP: Creating configMap with name cm-test-opt-upd-78e640ac-4b52-4291-b1ab-164815a1ae83 04/26/24 11:53:44.045
STEP: Creating the pod 04/26/24 11:53:44.049
Apr 26 11:53:44.059: INFO: Waiting up to 5m0s for pod "pod-configmaps-6dfc6804-5114-4b8d-ad3e-4c227e62a655" in namespace "configmap-1575" to be "running and ready"
Apr 26 11:53:44.064: INFO: Pod "pod-configmaps-6dfc6804-5114-4b8d-ad3e-4c227e62a655": Phase="Pending", Reason="", readiness=false. Elapsed: 4.673382ms
Apr 26 11:53:44.064: INFO: The phase of Pod pod-configmaps-6dfc6804-5114-4b8d-ad3e-4c227e62a655 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:53:46.072: INFO: Pod "pod-configmaps-6dfc6804-5114-4b8d-ad3e-4c227e62a655": Phase="Running", Reason="", readiness=true. Elapsed: 2.012631454s
Apr 26 11:53:46.072: INFO: The phase of Pod pod-configmaps-6dfc6804-5114-4b8d-ad3e-4c227e62a655 is Running (Ready = true)
Apr 26 11:53:46.072: INFO: Pod "pod-configmaps-6dfc6804-5114-4b8d-ad3e-4c227e62a655" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-71f35f2c-f605-47e7-a504-cd95920319ed 04/26/24 11:53:46.276
STEP: Updating configmap cm-test-opt-upd-78e640ac-4b52-4291-b1ab-164815a1ae83 04/26/24 11:53:46.283
STEP: Creating configMap with name cm-test-opt-create-5faffa87-aa46-4f2d-b960-f63b14f3793c 04/26/24 11:53:46.289
STEP: waiting to observe update in volume 04/26/24 11:53:46.295
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 11:53:50.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1575" for this suite. 04/26/24 11:53:50.588
{"msg":"PASSED [sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":184,"skipped":3416,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.591 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:239

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:53:44.003
    Apr 26 11:53:44.003: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 11:53:44.004
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:44.018
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:44.023
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:239
    STEP: Creating configMap with name cm-test-opt-del-71f35f2c-f605-47e7-a504-cd95920319ed 04/26/24 11:53:44.04
    STEP: Creating configMap with name cm-test-opt-upd-78e640ac-4b52-4291-b1ab-164815a1ae83 04/26/24 11:53:44.045
    STEP: Creating the pod 04/26/24 11:53:44.049
    Apr 26 11:53:44.059: INFO: Waiting up to 5m0s for pod "pod-configmaps-6dfc6804-5114-4b8d-ad3e-4c227e62a655" in namespace "configmap-1575" to be "running and ready"
    Apr 26 11:53:44.064: INFO: Pod "pod-configmaps-6dfc6804-5114-4b8d-ad3e-4c227e62a655": Phase="Pending", Reason="", readiness=false. Elapsed: 4.673382ms
    Apr 26 11:53:44.064: INFO: The phase of Pod pod-configmaps-6dfc6804-5114-4b8d-ad3e-4c227e62a655 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:53:46.072: INFO: Pod "pod-configmaps-6dfc6804-5114-4b8d-ad3e-4c227e62a655": Phase="Running", Reason="", readiness=true. Elapsed: 2.012631454s
    Apr 26 11:53:46.072: INFO: The phase of Pod pod-configmaps-6dfc6804-5114-4b8d-ad3e-4c227e62a655 is Running (Ready = true)
    Apr 26 11:53:46.072: INFO: Pod "pod-configmaps-6dfc6804-5114-4b8d-ad3e-4c227e62a655" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-71f35f2c-f605-47e7-a504-cd95920319ed 04/26/24 11:53:46.276
    STEP: Updating configmap cm-test-opt-upd-78e640ac-4b52-4291-b1ab-164815a1ae83 04/26/24 11:53:46.283
    STEP: Creating configMap with name cm-test-opt-create-5faffa87-aa46-4f2d-b960-f63b14f3793c 04/26/24 11:53:46.289
    STEP: waiting to observe update in volume 04/26/24 11:53:46.295
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 11:53:50.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1575" for this suite. 04/26/24 11:53:50.588
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:53:50.597
Apr 26 11:53:50.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 11:53:50.598
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:50.616
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:50.624
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260
STEP: Creating a pod to test downward API volume plugin 04/26/24 11:53:50.63
Apr 26 11:53:50.645: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95" in namespace "downward-api-3564" to be "Succeeded or Failed"
Apr 26 11:53:50.651: INFO: Pod "downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95": Phase="Pending", Reason="", readiness=false. Elapsed: 6.591661ms
Apr 26 11:53:52.658: INFO: Pod "downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01311529s
Apr 26 11:53:54.660: INFO: Pod "downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015265726s
STEP: Saw pod success 04/26/24 11:53:54.66
Apr 26 11:53:54.660: INFO: Pod "downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95" satisfied condition "Succeeded or Failed"
Apr 26 11:53:54.665: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95 container client-container: <nil>
STEP: delete the pod 04/26/24 11:53:54.72
Apr 26 11:53:54.743: INFO: Waiting for pod downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95 to disappear
Apr 26 11:53:54.755: INFO: Pod downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 26 11:53:54.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3564" for this suite. 04/26/24 11:53:54.766
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]","completed":185,"skipped":3458,"failed":0}
------------------------------
â€¢ [4.175 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:260

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:53:50.597
    Apr 26 11:53:50.597: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 11:53:50.598
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:50.616
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:50.624
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:260
    STEP: Creating a pod to test downward API volume plugin 04/26/24 11:53:50.63
    Apr 26 11:53:50.645: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95" in namespace "downward-api-3564" to be "Succeeded or Failed"
    Apr 26 11:53:50.651: INFO: Pod "downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95": Phase="Pending", Reason="", readiness=false. Elapsed: 6.591661ms
    Apr 26 11:53:52.658: INFO: Pod "downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01311529s
    Apr 26 11:53:54.660: INFO: Pod "downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015265726s
    STEP: Saw pod success 04/26/24 11:53:54.66
    Apr 26 11:53:54.660: INFO: Pod "downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95" satisfied condition "Succeeded or Failed"
    Apr 26 11:53:54.665: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95 container client-container: <nil>
    STEP: delete the pod 04/26/24 11:53:54.72
    Apr 26 11:53:54.743: INFO: Waiting for pod downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95 to disappear
    Apr 26 11:53:54.755: INFO: Pod downwardapi-volume-a12be07d-90e9-49c5-ae00-adfee20afc95 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 26 11:53:54.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-3564" for this suite. 04/26/24 11:53:54.766
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] DisruptionController
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:53:54.773
Apr 26 11:53:54.773: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename disruption 04/26/24 11:53:54.774
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:54.79
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:54.797
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107
STEP: creating the pdb 04/26/24 11:53:54.804
STEP: Waiting for the pdb to be processed 04/26/24 11:53:54.81
STEP: updating the pdb 04/26/24 11:53:56.821
STEP: Waiting for the pdb to be processed 04/26/24 11:53:56.835
STEP: patching the pdb 04/26/24 11:53:56.843
STEP: Waiting for the pdb to be processed 04/26/24 11:53:56.856
STEP: Waiting for the pdb to be deleted 04/26/24 11:53:56.865
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 26 11:53:56.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2636" for this suite. 04/26/24 11:53:56.877
{"msg":"PASSED [sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]","completed":186,"skipped":3458,"failed":0}
------------------------------
â€¢ [2.111 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should create a PodDisruptionBudget [Conformance]
  test/e2e/apps/disruption.go:107

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:53:54.773
    Apr 26 11:53:54.773: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename disruption 04/26/24 11:53:54.774
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:54.79
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:54.797
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should create a PodDisruptionBudget [Conformance]
      test/e2e/apps/disruption.go:107
    STEP: creating the pdb 04/26/24 11:53:54.804
    STEP: Waiting for the pdb to be processed 04/26/24 11:53:54.81
    STEP: updating the pdb 04/26/24 11:53:56.821
    STEP: Waiting for the pdb to be processed 04/26/24 11:53:56.835
    STEP: patching the pdb 04/26/24 11:53:56.843
    STEP: Waiting for the pdb to be processed 04/26/24 11:53:56.856
    STEP: Waiting for the pdb to be deleted 04/26/24 11:53:56.865
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 26 11:53:56.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2636" for this suite. 04/26/24 11:53:56.877
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Deployment
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:53:56.884
Apr 26 11:53:56.884: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename deployment 04/26/24 11:53:56.885
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:56.902
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:56.908
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185
STEP: creating a Deployment 04/26/24 11:53:56.921
STEP: waiting for Deployment to be created 04/26/24 11:53:56.928
STEP: waiting for all Replicas to be Ready 04/26/24 11:53:56.932
Apr 26 11:53:56.937: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 26 11:53:56.937: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 26 11:53:56.939: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 26 11:53:56.939: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 26 11:53:56.948: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 26 11:53:56.948: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 26 11:53:56.977: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 26 11:53:56.977: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
Apr 26 11:53:57.974: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 26 11:53:57.974: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment-static:true]
Apr 26 11:53:58.057: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2 and labels map[test-deployment-static:true]
STEP: patching the Deployment 04/26/24 11:53:58.057
W0426 11:53:58.087187      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 26 11:53:58.104: INFO: observed event type ADDED
STEP: waiting for Replicas to scale 04/26/24 11:53:58.104
Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
Apr 26 11:53:58.131: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:53:58.131: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:53:58.131: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:53:58.131: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:53:58.131: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:53:58.131: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:53:58.173: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:53:58.173: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:53:58.188: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
Apr 26 11:53:58.188: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
Apr 26 11:53:58.193: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
Apr 26 11:53:58.193: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
Apr 26 11:53:59.802: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:53:59.802: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:53:59.821: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
STEP: listing Deployments 04/26/24 11:53:59.821
Apr 26 11:53:59.827: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
STEP: updating the Deployment 04/26/24 11:53:59.827
Apr 26 11:53:59.847: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
STEP: fetching the DeploymentStatus 04/26/24 11:53:59.847
Apr 26 11:53:59.878: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 26 11:53:59.880: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 26 11:53:59.880: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 26 11:53:59.896: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 26 11:53:59.908: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
Apr 26 11:54:01.035: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 26 11:54:01.143: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
Apr 26 11:54:01.177: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 26 11:54:01.180: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
Apr 26 11:54:02.029: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
STEP: patching the DeploymentStatus 04/26/24 11:54:02.047
STEP: fetching the DeploymentStatus 04/26/24 11:54:02.057
Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 3
Apr 26 11:54:02.067: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:54:02.067: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
Apr 26 11:54:02.067: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 3
STEP: deleting the Deployment 04/26/24 11:54:02.067
Apr 26 11:54:02.080: INFO: observed event type MODIFIED
Apr 26 11:54:02.080: INFO: observed event type MODIFIED
Apr 26 11:54:02.080: INFO: observed event type MODIFIED
Apr 26 11:54:02.081: INFO: observed event type MODIFIED
Apr 26 11:54:02.081: INFO: observed event type MODIFIED
Apr 26 11:54:02.081: INFO: observed event type MODIFIED
Apr 26 11:54:02.081: INFO: observed event type MODIFIED
Apr 26 11:54:02.081: INFO: observed event type MODIFIED
Apr 26 11:54:02.081: INFO: observed event type MODIFIED
Apr 26 11:54:02.082: INFO: observed event type MODIFIED
Apr 26 11:54:02.082: INFO: observed event type MODIFIED
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 26 11:54:02.087: INFO: Log out all the ReplicaSets if there is no deployment created
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 26 11:54:02.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8520" for this suite. 04/26/24 11:54:02.105
{"msg":"PASSED [sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]","completed":187,"skipped":3460,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.226 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  should run the lifecycle of a Deployment [Conformance]
  test/e2e/apps/deployment.go:185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:53:56.884
    Apr 26 11:53:56.884: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename deployment 04/26/24 11:53:56.885
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:53:56.902
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:53:56.908
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] should run the lifecycle of a Deployment [Conformance]
      test/e2e/apps/deployment.go:185
    STEP: creating a Deployment 04/26/24 11:53:56.921
    STEP: waiting for Deployment to be created 04/26/24 11:53:56.928
    STEP: waiting for all Replicas to be Ready 04/26/24 11:53:56.932
    Apr 26 11:53:56.937: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 26 11:53:56.937: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 26 11:53:56.939: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 26 11:53:56.939: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 26 11:53:56.948: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 26 11:53:56.948: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 26 11:53:56.977: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 26 11:53:56.977: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0 and labels map[test-deployment-static:true]
    Apr 26 11:53:57.974: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Apr 26 11:53:57.974: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment-static:true]
    Apr 26 11:53:58.057: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2 and labels map[test-deployment-static:true]
    STEP: patching the Deployment 04/26/24 11:53:58.057
    W0426 11:53:58.087187      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 26 11:53:58.104: INFO: observed event type ADDED
    STEP: waiting for Replicas to scale 04/26/24 11:53:58.104
    Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
    Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
    Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
    Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
    Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
    Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
    Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
    Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 0
    Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    Apr 26 11:53:58.130: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    Apr 26 11:53:58.131: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:53:58.131: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:53:58.131: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:53:58.131: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:53:58.131: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:53:58.131: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:53:58.173: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:53:58.173: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:53:58.188: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    Apr 26 11:53:58.188: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    Apr 26 11:53:58.193: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    Apr 26 11:53:58.193: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    Apr 26 11:53:59.802: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:53:59.802: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:53:59.821: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    STEP: listing Deployments 04/26/24 11:53:59.821
    Apr 26 11:53:59.827: INFO: Found test-deployment with labels: map[test-deployment:patched test-deployment-static:true]
    STEP: updating the Deployment 04/26/24 11:53:59.827
    Apr 26 11:53:59.847: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    STEP: fetching the DeploymentStatus 04/26/24 11:53:59.847
    Apr 26 11:53:59.878: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 26 11:53:59.880: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 26 11:53:59.880: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 26 11:53:59.896: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 26 11:53:59.908: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 26 11:54:01.035: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 26 11:54:01.143: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 26 11:54:01.177: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 26 11:54:01.180: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2 and labels map[test-deployment:updated test-deployment-static:true]
    Apr 26 11:54:02.029: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 3 and labels map[test-deployment:updated test-deployment-static:true]
    STEP: patching the DeploymentStatus 04/26/24 11:54:02.047
    STEP: fetching the DeploymentStatus 04/26/24 11:54:02.057
    Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 1
    Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:54:02.066: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 3
    Apr 26 11:54:02.067: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:54:02.067: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 2
    Apr 26 11:54:02.067: INFO: observed Deployment test-deployment in namespace deployment-8520 with ReadyReplicas 3
    STEP: deleting the Deployment 04/26/24 11:54:02.067
    Apr 26 11:54:02.080: INFO: observed event type MODIFIED
    Apr 26 11:54:02.080: INFO: observed event type MODIFIED
    Apr 26 11:54:02.080: INFO: observed event type MODIFIED
    Apr 26 11:54:02.081: INFO: observed event type MODIFIED
    Apr 26 11:54:02.081: INFO: observed event type MODIFIED
    Apr 26 11:54:02.081: INFO: observed event type MODIFIED
    Apr 26 11:54:02.081: INFO: observed event type MODIFIED
    Apr 26 11:54:02.081: INFO: observed event type MODIFIED
    Apr 26 11:54:02.081: INFO: observed event type MODIFIED
    Apr 26 11:54:02.082: INFO: observed event type MODIFIED
    Apr 26 11:54:02.082: INFO: observed event type MODIFIED
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 26 11:54:02.087: INFO: Log out all the ReplicaSets if there is no deployment created
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 26 11:54:02.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-8520" for this suite. 04/26/24 11:54:02.105
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:54:02.111
Apr 26 11:54:02.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:54:02.113
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:02.128
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:02.136
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45
STEP: Creating projection with secret that has name projected-secret-test-13b70d87-2954-40da-a7f5-76ce84276e40 04/26/24 11:54:02.142
STEP: Creating a pod to test consume secrets 04/26/24 11:54:02.148
Apr 26 11:54:02.160: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0" in namespace "projected-3791" to be "Succeeded or Failed"
Apr 26 11:54:02.166: INFO: Pod "pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016853ms
Apr 26 11:54:04.173: INFO: Pod "pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0": Phase="Running", Reason="", readiness=false. Elapsed: 2.012939808s
Apr 26 11:54:06.175: INFO: Pod "pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015100028s
STEP: Saw pod success 04/26/24 11:54:06.175
Apr 26 11:54:06.176: INFO: Pod "pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0" satisfied condition "Succeeded or Failed"
Apr 26 11:54:06.181: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/26/24 11:54:06.232
Apr 26 11:54:06.293: INFO: Waiting for pod pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0 to disappear
Apr 26 11:54:06.308: INFO: Pod pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 26 11:54:06.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3791" for this suite. 04/26/24 11:54:06.318
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]","completed":188,"skipped":3463,"failed":0}
------------------------------
â€¢ [4.213 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:54:02.111
    Apr 26 11:54:02.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:54:02.113
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:02.128
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:02.136
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:45
    STEP: Creating projection with secret that has name projected-secret-test-13b70d87-2954-40da-a7f5-76ce84276e40 04/26/24 11:54:02.142
    STEP: Creating a pod to test consume secrets 04/26/24 11:54:02.148
    Apr 26 11:54:02.160: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0" in namespace "projected-3791" to be "Succeeded or Failed"
    Apr 26 11:54:02.166: INFO: Pod "pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016853ms
    Apr 26 11:54:04.173: INFO: Pod "pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0": Phase="Running", Reason="", readiness=false. Elapsed: 2.012939808s
    Apr 26 11:54:06.175: INFO: Pod "pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015100028s
    STEP: Saw pod success 04/26/24 11:54:06.175
    Apr 26 11:54:06.176: INFO: Pod "pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0" satisfied condition "Succeeded or Failed"
    Apr 26 11:54:06.181: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 11:54:06.232
    Apr 26 11:54:06.293: INFO: Waiting for pod pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0 to disappear
    Apr 26 11:54:06.308: INFO: Pod pod-projected-secrets-84ff4bee-3fdd-4e73-9451-4f8af24345b0 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 26 11:54:06.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3791" for this suite. 04/26/24 11:54:06.318
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:54:06.328
Apr 26 11:54:06.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:54:06.329
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:06.353
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:06.359
[It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73
STEP: Creating configMap with name projected-configmap-test-volume-16cbb6c7-7648-4070-ad6b-44e57ddb458b 04/26/24 11:54:06.368
STEP: Creating a pod to test consume configMaps 04/26/24 11:54:06.373
Apr 26 11:54:06.386: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914" in namespace "projected-6164" to be "Succeeded or Failed"
Apr 26 11:54:06.395: INFO: Pod "pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914": Phase="Pending", Reason="", readiness=false. Elapsed: 8.94489ms
Apr 26 11:54:08.402: INFO: Pod "pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016484093s
Apr 26 11:54:10.404: INFO: Pod "pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017935145s
STEP: Saw pod success 04/26/24 11:54:10.404
Apr 26 11:54:10.404: INFO: Pod "pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914" satisfied condition "Succeeded or Failed"
Apr 26 11:54:10.409: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914 container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:54:10.479
Apr 26 11:54:10.490: INFO: Waiting for pod pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914 to disappear
Apr 26 11:54:10.499: INFO: Pod pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 26 11:54:10.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6164" for this suite. 04/26/24 11:54:10.508
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]","completed":189,"skipped":3466,"failed":0}
------------------------------
â€¢ [4.186 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:73

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:54:06.328
    Apr 26 11:54:06.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:54:06.329
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:06.353
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:06.359
    [It] should be consumable from pods in volume as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:73
    STEP: Creating configMap with name projected-configmap-test-volume-16cbb6c7-7648-4070-ad6b-44e57ddb458b 04/26/24 11:54:06.368
    STEP: Creating a pod to test consume configMaps 04/26/24 11:54:06.373
    Apr 26 11:54:06.386: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914" in namespace "projected-6164" to be "Succeeded or Failed"
    Apr 26 11:54:06.395: INFO: Pod "pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914": Phase="Pending", Reason="", readiness=false. Elapsed: 8.94489ms
    Apr 26 11:54:08.402: INFO: Pod "pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016484093s
    Apr 26 11:54:10.404: INFO: Pod "pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017935145s
    STEP: Saw pod success 04/26/24 11:54:10.404
    Apr 26 11:54:10.404: INFO: Pod "pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914" satisfied condition "Succeeded or Failed"
    Apr 26 11:54:10.409: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914 container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:54:10.479
    Apr 26 11:54:10.490: INFO: Waiting for pod pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914 to disappear
    Apr 26 11:54:10.499: INFO: Pod pod-projected-configmaps-4c3cf235-efd7-44cd-bbb1-c2a5c6501914 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 26 11:54:10.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6164" for this suite. 04/26/24 11:54:10.508
  << End Captured GinkgoWriter Output
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:54:10.514
Apr 26 11:54:10.514: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename sched-pred 04/26/24 11:54:10.515
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:10.53
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:10.536
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 26 11:54:10.544: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 26 11:54:10.563: INFO: Waiting for terminating namespaces to be deleted...
Apr 26 11:54:10.569: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw before test
Apr 26 11:54:10.587: INFO: apiserver-proxy-hzh4l from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.587: INFO: 	Container proxy ready: true, restart count 0
Apr 26 11:54:10.587: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 11:54:10.587: INFO: blackbox-exporter-754b59454b-9cprw from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.587: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 26 11:54:10.587: INFO: calico-node-m9nm9 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.587: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 11:54:10.587: INFO: calico-typha-deploy-84df84b854-fv5zl from kube-system started at 2024-04-26 09:50:55 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.587: INFO: 	Container calico-typha ready: true, restart count 0
Apr 26 11:54:10.587: INFO: coredns-86858b4d85-f7j7b from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.587: INFO: 	Container coredns ready: true, restart count 0
Apr 26 11:54:10.587: INFO: csi-driver-node-9wpbg from kube-system started at 2024-04-26 09:50:15 +0000 UTC (3 container statuses recorded)
Apr 26 11:54:10.587: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 11:54:10.587: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 11:54:10.587: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 11:54:10.587: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-z47h4 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.587: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 11:54:10.587: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 11:54:10.587: INFO: metrics-server-56cf547447-db2cf from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.587: INFO: 	Container metrics-server ready: true, restart count 0
Apr 26 11:54:10.587: INFO: node-exporter-mg7sm from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.587: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 11:54:10.587: INFO: node-problem-detector-w7mph from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.587: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 11:54:10.587: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-pkmm6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.588: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 11:54:10.588: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 11:54:10.588: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j before test
Apr 26 11:54:10.604: INFO: apiserver-proxy-qmgq4 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.604: INFO: 	Container proxy ready: true, restart count 0
Apr 26 11:54:10.604: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 11:54:10.604: INFO: calico-node-tddjl from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.604: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 11:54:10.604: INFO: csi-driver-node-xcdg9 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (3 container statuses recorded)
Apr 26 11:54:10.604: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 11:54:10.604: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 11:54:10.604: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 11:54:10.604: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-fpkn8 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.604: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 11:54:10.604: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 11:54:10.604: INFO: node-exporter-bdrxz from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.604: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 11:54:10.604: INFO: node-problem-detector-mmsx4 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.604: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 11:54:10.604: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-xznr8 from sonobuoy started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.604: INFO: 	Container sonobuoy-worker ready: false, restart count 8
Apr 26 11:54:10.605: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 11:54:10.605: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp before test
Apr 26 11:54:10.622: INFO: apiserver-proxy-hzgtj from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.622: INFO: 	Container proxy ready: true, restart count 0
Apr 26 11:54:10.622: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 11:54:10.622: INFO: calico-node-49gs5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.622: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 11:54:10.622: INFO: csi-driver-node-thmzv from kube-system started at 2024-04-26 09:50:09 +0000 UTC (3 container statuses recorded)
Apr 26 11:54:10.622: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 11:54:10.622: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 11:54:10.622: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 11:54:10.622: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-8h68w from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.626: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 11:54:10.626: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 11:54:10.626: INFO: node-exporter-mzmd5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.626: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 11:54:10.626: INFO: node-problem-detector-x8jsh from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.626: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 11:54:10.626: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-t2fb5 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.626: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 11:54:10.626: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 11:54:10.626: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w before test
Apr 26 11:54:10.649: INFO: apiserver-proxy-8bxw2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container proxy ready: true, restart count 0
Apr 26 11:54:10.649: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 11:54:10.649: INFO: blackbox-exporter-754b59454b-tqxxm from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 26 11:54:10.649: INFO: calico-kube-controllers-5bfbd9c84c-ggxxm from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 26 11:54:10.649: INFO: calico-node-nfp6q from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 11:54:10.649: INFO: calico-node-vertical-autoscaler-6b85ccc474-scqt5 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container autoscaler ready: true, restart count 0
Apr 26 11:54:10.649: INFO: calico-typha-deploy-84df84b854-grtfl from kube-system started at 2024-04-26 11:04:13 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container calico-typha ready: true, restart count 0
Apr 26 11:54:10.649: INFO: calico-typha-horizontal-autoscaler-765f9c86fd-x4mrd from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container autoscaler ready: true, restart count 0
Apr 26 11:54:10.649: INFO: calico-typha-vertical-autoscaler-8657c6b4fc-d6gnw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container autoscaler ready: true, restart count 0
Apr 26 11:54:10.649: INFO: coredns-86858b4d85-m4dg4 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container coredns ready: true, restart count 0
Apr 26 11:54:10.649: INFO: csi-driver-node-f4f5r from kube-system started at 2024-04-26 09:50:05 +0000 UTC (3 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 11:54:10.649: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 11:54:10.649: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 11:54:10.649: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-82vtz from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 11:54:10.649: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 11:54:10.649: INFO: metrics-server-56cf547447-sl4zk from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container metrics-server ready: true, restart count 0
Apr 26 11:54:10.649: INFO: node-exporter-r2wm2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 11:54:10.649: INFO: node-problem-detector-8w59w from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 11:54:10.649: INFO: vpn-shoot-849b6d5c85-z42mw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 26 11:54:10.649: INFO: sonobuoy from sonobuoy started at 2024-04-26 10:56:56 +0000 UTC (1 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 26 11:54:10.649: INFO: sonobuoy-e2e-job-ce2c772167a64049 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container e2e ready: true, restart count 0
Apr 26 11:54:10.649: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 11:54:10.649: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-6bgn6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 11:54:10.649: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 11:54:10.649: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326
STEP: verifying the node has the label node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw 04/26/24 11:54:10.684
STEP: verifying the node has the label node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j 04/26/24 11:54:10.726
STEP: verifying the node has the label node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp 04/26/24 11:54:10.759
STEP: verifying the node has the label node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w 04/26/24 11:54:10.795
Apr 26 11:54:10.825: INFO: Pod apiserver-proxy-8bxw2 requesting resource cpu=40m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod apiserver-proxy-hzgtj requesting resource cpu=40m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
Apr 26 11:54:10.825: INFO: Pod apiserver-proxy-hzh4l requesting resource cpu=40m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
Apr 26 11:54:10.825: INFO: Pod apiserver-proxy-qmgq4 requesting resource cpu=40m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
Apr 26 11:54:10.825: INFO: Pod blackbox-exporter-754b59454b-9cprw requesting resource cpu=10m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
Apr 26 11:54:10.825: INFO: Pod blackbox-exporter-754b59454b-tqxxm requesting resource cpu=10m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod calico-kube-controllers-5bfbd9c84c-ggxxm requesting resource cpu=10m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod calico-node-49gs5 requesting resource cpu=250m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
Apr 26 11:54:10.825: INFO: Pod calico-node-m9nm9 requesting resource cpu=250m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
Apr 26 11:54:10.825: INFO: Pod calico-node-nfp6q requesting resource cpu=250m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod calico-node-tddjl requesting resource cpu=250m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
Apr 26 11:54:10.825: INFO: Pod calico-node-vertical-autoscaler-6b85ccc474-scqt5 requesting resource cpu=10m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod calico-typha-deploy-84df84b854-fv5zl requesting resource cpu=320m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
Apr 26 11:54:10.825: INFO: Pod calico-typha-deploy-84df84b854-grtfl requesting resource cpu=320m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod calico-typha-horizontal-autoscaler-765f9c86fd-x4mrd requesting resource cpu=10m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod calico-typha-vertical-autoscaler-8657c6b4fc-d6gnw requesting resource cpu=10m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod coredns-86858b4d85-f7j7b requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
Apr 26 11:54:10.825: INFO: Pod coredns-86858b4d85-m4dg4 requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod csi-driver-node-9wpbg requesting resource cpu=37m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
Apr 26 11:54:10.825: INFO: Pod csi-driver-node-f4f5r requesting resource cpu=37m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod csi-driver-node-thmzv requesting resource cpu=37m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
Apr 26 11:54:10.825: INFO: Pod csi-driver-node-xcdg9 requesting resource cpu=37m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
Apr 26 11:54:10.825: INFO: Pod kube-proxy-worker-6a5hr-1-v1.25.16-82vtz requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod kube-proxy-worker-6a5hr-1-v1.25.16-8h68w requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
Apr 26 11:54:10.825: INFO: Pod kube-proxy-worker-6a5hr-1-v1.25.16-fpkn8 requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
Apr 26 11:54:10.825: INFO: Pod kube-proxy-worker-6a5hr-1-v1.25.16-z47h4 requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
Apr 26 11:54:10.825: INFO: Pod metrics-server-56cf547447-db2cf requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
Apr 26 11:54:10.825: INFO: Pod metrics-server-56cf547447-sl4zk requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod node-exporter-bdrxz requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
Apr 26 11:54:10.825: INFO: Pod node-exporter-mg7sm requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
Apr 26 11:54:10.825: INFO: Pod node-exporter-mzmd5 requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
Apr 26 11:54:10.825: INFO: Pod node-exporter-r2wm2 requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod node-problem-detector-8w59w requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod node-problem-detector-mmsx4 requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
Apr 26 11:54:10.825: INFO: Pod node-problem-detector-w7mph requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
Apr 26 11:54:10.825: INFO: Pod node-problem-detector-x8jsh requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
Apr 26 11:54:10.825: INFO: Pod vpn-shoot-849b6d5c85-z42mw requesting resource cpu=100m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod sonobuoy requesting resource cpu=0m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod sonobuoy-e2e-job-ce2c772167a64049 requesting resource cpu=0m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-6bgn6 requesting resource cpu=0m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.825: INFO: Pod sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-pkmm6 requesting resource cpu=0m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
Apr 26 11:54:10.825: INFO: Pod sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-t2fb5 requesting resource cpu=0m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
Apr 26 11:54:10.825: INFO: Pod sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-xznr8 requesting resource cpu=0m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
STEP: Starting Pods to consume most of the cluster CPU. 04/26/24 11:54:10.825
Apr 26 11:54:10.825: INFO: Creating a pod which consumes cpu=2452m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
Apr 26 11:54:10.846: INFO: Creating a pod which consumes cpu=2053m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
Apr 26 11:54:10.860: INFO: Creating a pod which consumes cpu=2151m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
Apr 26 11:54:10.871: INFO: Creating a pod which consumes cpu=2452m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
Apr 26 11:54:10.884: INFO: Waiting up to 5m0s for pod "filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d" in namespace "sched-pred-4781" to be "running"
Apr 26 11:54:10.897: INFO: Pod "filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.960045ms
Apr 26 11:54:12.903: INFO: Pod "filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d": Phase="Running", Reason="", readiness=true. Elapsed: 2.018815792s
Apr 26 11:54:12.903: INFO: Pod "filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d" satisfied condition "running"
Apr 26 11:54:12.903: INFO: Waiting up to 5m0s for pod "filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01" in namespace "sched-pred-4781" to be "running"
Apr 26 11:54:12.909: INFO: Pod "filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01": Phase="Running", Reason="", readiness=true. Elapsed: 6.028946ms
Apr 26 11:54:12.909: INFO: Pod "filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01" satisfied condition "running"
Apr 26 11:54:12.909: INFO: Waiting up to 5m0s for pod "filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964" in namespace "sched-pred-4781" to be "running"
Apr 26 11:54:12.916: INFO: Pod "filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964": Phase="Running", Reason="", readiness=true. Elapsed: 7.054742ms
Apr 26 11:54:12.916: INFO: Pod "filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964" satisfied condition "running"
Apr 26 11:54:12.917: INFO: Waiting up to 5m0s for pod "filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b" in namespace "sched-pred-4781" to be "running"
Apr 26 11:54:12.921: INFO: Pod "filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b": Phase="Running", Reason="", readiness=true. Elapsed: 4.463478ms
Apr 26 11:54:12.921: INFO: Pod "filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b" satisfied condition "running"
STEP: Creating another pod that requires unavailable amount of CPU. 04/26/24 11:54:12.921
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b.17c9d261d956ecc4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4781/filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b to shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j] 04/26/24 11:54:12.931
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b.17c9d261fd4413ae], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/26/24 11:54:12.932
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b.17c9d261fdd66ff1], Reason = [Created], Message = [Created container filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b] 04/26/24 11:54:12.932
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b.17c9d26201ccd06b], Reason = [Started], Message = [Started container filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b] 04/26/24 11:54:12.932
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01.17c9d261d79e23c6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4781/filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01 to shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w] 04/26/24 11:54:12.932
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01.17c9d261facf8093], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/26/24 11:54:12.932
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01.17c9d261fb49c397], Reason = [Created], Message = [Created container filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01] 04/26/24 11:54:12.932
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01.17c9d261ff8bf591], Reason = [Started], Message = [Started container filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01] 04/26/24 11:54:12.932
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964.17c9d261d8415594], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4781/filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964 to shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw] 04/26/24 11:54:12.933
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964.17c9d261ff94d792], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/26/24 11:54:12.933
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964.17c9d262004745bc], Reason = [Created], Message = [Created container filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964] 04/26/24 11:54:12.933
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964.17c9d2620512bf47], Reason = [Started], Message = [Started container filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964] 04/26/24 11:54:12.933
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d.17c9d261d748b79e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4781/filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d to shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp] 04/26/24 11:54:12.933
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d.17c9d261fbf49138], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/26/24 11:54:12.933
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d.17c9d261fc90b358], Reason = [Created], Message = [Created container filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d] 04/26/24 11:54:12.933
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d.17c9d2620138b2a0], Reason = [Started], Message = [Started container filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d] 04/26/24 11:54:12.933
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.17c9d2625357e46c], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu. preemption: 0/4 nodes are available: 4 No preemption victims found for incoming pod.] 04/26/24 11:54:12.95
STEP: removing the label node off the node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw 04/26/24 11:54:13.952
STEP: verifying the node doesn't have the label node 04/26/24 11:54:13.979
STEP: removing the label node off the node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j 04/26/24 11:54:13.996
STEP: verifying the node doesn't have the label node 04/26/24 11:54:14.03
STEP: removing the label node off the node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp 04/26/24 11:54:14.038
STEP: verifying the node doesn't have the label node 04/26/24 11:54:14.066
STEP: removing the label node off the node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w 04/26/24 11:54:14.075
STEP: verifying the node doesn't have the label node 04/26/24 11:54:14.107
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:54:14.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4781" for this suite. 04/26/24 11:54:14.128
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run  [Conformance]","completed":190,"skipped":3466,"failed":0}
------------------------------
â€¢ [3.625 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates resource limits of pods that are allowed to run  [Conformance]
  test/e2e/scheduling/predicates.go:326

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:54:10.514
    Apr 26 11:54:10.514: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename sched-pred 04/26/24 11:54:10.515
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:10.53
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:10.536
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 26 11:54:10.544: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 26 11:54:10.563: INFO: Waiting for terminating namespaces to be deleted...
    Apr 26 11:54:10.569: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw before test
    Apr 26 11:54:10.587: INFO: apiserver-proxy-hzh4l from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.587: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: blackbox-exporter-754b59454b-9cprw from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.587: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: calico-node-m9nm9 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.587: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: calico-typha-deploy-84df84b854-fv5zl from kube-system started at 2024-04-26 09:50:55 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.587: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: coredns-86858b4d85-f7j7b from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.587: INFO: 	Container coredns ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: csi-driver-node-9wpbg from kube-system started at 2024-04-26 09:50:15 +0000 UTC (3 container statuses recorded)
    Apr 26 11:54:10.587: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-z47h4 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.587: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: metrics-server-56cf547447-db2cf from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.587: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: node-exporter-mg7sm from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.587: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: node-problem-detector-w7mph from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.587: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 11:54:10.587: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-pkmm6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.588: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 11:54:10.588: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 11:54:10.588: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j before test
    Apr 26 11:54:10.604: INFO: apiserver-proxy-qmgq4 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.604: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 11:54:10.604: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 11:54:10.604: INFO: calico-node-tddjl from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.604: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 11:54:10.604: INFO: csi-driver-node-xcdg9 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (3 container statuses recorded)
    Apr 26 11:54:10.604: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 11:54:10.604: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 11:54:10.604: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 11:54:10.604: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-fpkn8 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.604: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 11:54:10.604: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 11:54:10.604: INFO: node-exporter-bdrxz from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.604: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 11:54:10.604: INFO: node-problem-detector-mmsx4 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.604: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 11:54:10.604: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-xznr8 from sonobuoy started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.604: INFO: 	Container sonobuoy-worker ready: false, restart count 8
    Apr 26 11:54:10.605: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 11:54:10.605: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp before test
    Apr 26 11:54:10.622: INFO: apiserver-proxy-hzgtj from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.622: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 11:54:10.622: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 11:54:10.622: INFO: calico-node-49gs5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.622: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 11:54:10.622: INFO: csi-driver-node-thmzv from kube-system started at 2024-04-26 09:50:09 +0000 UTC (3 container statuses recorded)
    Apr 26 11:54:10.622: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 11:54:10.622: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 11:54:10.622: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 11:54:10.622: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-8h68w from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.626: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 11:54:10.626: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 11:54:10.626: INFO: node-exporter-mzmd5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.626: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 11:54:10.626: INFO: node-problem-detector-x8jsh from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.626: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 11:54:10.626: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-t2fb5 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.626: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 11:54:10.626: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 11:54:10.626: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w before test
    Apr 26 11:54:10.649: INFO: apiserver-proxy-8bxw2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: blackbox-exporter-754b59454b-tqxxm from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: calico-kube-controllers-5bfbd9c84c-ggxxm from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: calico-node-nfp6q from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: calico-node-vertical-autoscaler-6b85ccc474-scqt5 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: calico-typha-deploy-84df84b854-grtfl from kube-system started at 2024-04-26 11:04:13 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: calico-typha-horizontal-autoscaler-765f9c86fd-x4mrd from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: calico-typha-vertical-autoscaler-8657c6b4fc-d6gnw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: coredns-86858b4d85-m4dg4 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container coredns ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: csi-driver-node-f4f5r from kube-system started at 2024-04-26 09:50:05 +0000 UTC (3 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-82vtz from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: metrics-server-56cf547447-sl4zk from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: node-exporter-r2wm2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: node-problem-detector-8w59w from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: vpn-shoot-849b6d5c85-z42mw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container vpn-shoot ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: sonobuoy from sonobuoy started at 2024-04-26 10:56:56 +0000 UTC (1 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: sonobuoy-e2e-job-ce2c772167a64049 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container e2e ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-6bgn6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 11:54:10.649: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 11:54:10.649: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates resource limits of pods that are allowed to run  [Conformance]
      test/e2e/scheduling/predicates.go:326
    STEP: verifying the node has the label node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw 04/26/24 11:54:10.684
    STEP: verifying the node has the label node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j 04/26/24 11:54:10.726
    STEP: verifying the node has the label node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp 04/26/24 11:54:10.759
    STEP: verifying the node has the label node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w 04/26/24 11:54:10.795
    Apr 26 11:54:10.825: INFO: Pod apiserver-proxy-8bxw2 requesting resource cpu=40m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod apiserver-proxy-hzgtj requesting resource cpu=40m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
    Apr 26 11:54:10.825: INFO: Pod apiserver-proxy-hzh4l requesting resource cpu=40m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
    Apr 26 11:54:10.825: INFO: Pod apiserver-proxy-qmgq4 requesting resource cpu=40m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
    Apr 26 11:54:10.825: INFO: Pod blackbox-exporter-754b59454b-9cprw requesting resource cpu=10m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
    Apr 26 11:54:10.825: INFO: Pod blackbox-exporter-754b59454b-tqxxm requesting resource cpu=10m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod calico-kube-controllers-5bfbd9c84c-ggxxm requesting resource cpu=10m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod calico-node-49gs5 requesting resource cpu=250m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
    Apr 26 11:54:10.825: INFO: Pod calico-node-m9nm9 requesting resource cpu=250m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
    Apr 26 11:54:10.825: INFO: Pod calico-node-nfp6q requesting resource cpu=250m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod calico-node-tddjl requesting resource cpu=250m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
    Apr 26 11:54:10.825: INFO: Pod calico-node-vertical-autoscaler-6b85ccc474-scqt5 requesting resource cpu=10m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod calico-typha-deploy-84df84b854-fv5zl requesting resource cpu=320m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
    Apr 26 11:54:10.825: INFO: Pod calico-typha-deploy-84df84b854-grtfl requesting resource cpu=320m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod calico-typha-horizontal-autoscaler-765f9c86fd-x4mrd requesting resource cpu=10m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod calico-typha-vertical-autoscaler-8657c6b4fc-d6gnw requesting resource cpu=10m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod coredns-86858b4d85-f7j7b requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
    Apr 26 11:54:10.825: INFO: Pod coredns-86858b4d85-m4dg4 requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod csi-driver-node-9wpbg requesting resource cpu=37m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
    Apr 26 11:54:10.825: INFO: Pod csi-driver-node-f4f5r requesting resource cpu=37m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod csi-driver-node-thmzv requesting resource cpu=37m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
    Apr 26 11:54:10.825: INFO: Pod csi-driver-node-xcdg9 requesting resource cpu=37m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
    Apr 26 11:54:10.825: INFO: Pod kube-proxy-worker-6a5hr-1-v1.25.16-82vtz requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod kube-proxy-worker-6a5hr-1-v1.25.16-8h68w requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
    Apr 26 11:54:10.825: INFO: Pod kube-proxy-worker-6a5hr-1-v1.25.16-fpkn8 requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
    Apr 26 11:54:10.825: INFO: Pod kube-proxy-worker-6a5hr-1-v1.25.16-z47h4 requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
    Apr 26 11:54:10.825: INFO: Pod metrics-server-56cf547447-db2cf requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
    Apr 26 11:54:10.825: INFO: Pod metrics-server-56cf547447-sl4zk requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod node-exporter-bdrxz requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
    Apr 26 11:54:10.825: INFO: Pod node-exporter-mg7sm requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
    Apr 26 11:54:10.825: INFO: Pod node-exporter-mzmd5 requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
    Apr 26 11:54:10.825: INFO: Pod node-exporter-r2wm2 requesting resource cpu=50m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod node-problem-detector-8w59w requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod node-problem-detector-mmsx4 requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
    Apr 26 11:54:10.825: INFO: Pod node-problem-detector-w7mph requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
    Apr 26 11:54:10.825: INFO: Pod node-problem-detector-x8jsh requesting resource cpu=20m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
    Apr 26 11:54:10.825: INFO: Pod vpn-shoot-849b6d5c85-z42mw requesting resource cpu=100m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod sonobuoy requesting resource cpu=0m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod sonobuoy-e2e-job-ce2c772167a64049 requesting resource cpu=0m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-6bgn6 requesting resource cpu=0m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.825: INFO: Pod sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-pkmm6 requesting resource cpu=0m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
    Apr 26 11:54:10.825: INFO: Pod sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-t2fb5 requesting resource cpu=0m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
    Apr 26 11:54:10.825: INFO: Pod sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-xznr8 requesting resource cpu=0m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
    STEP: Starting Pods to consume most of the cluster CPU. 04/26/24 11:54:10.825
    Apr 26 11:54:10.825: INFO: Creating a pod which consumes cpu=2452m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp
    Apr 26 11:54:10.846: INFO: Creating a pod which consumes cpu=2053m on Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w
    Apr 26 11:54:10.860: INFO: Creating a pod which consumes cpu=2151m on Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw
    Apr 26 11:54:10.871: INFO: Creating a pod which consumes cpu=2452m on Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j
    Apr 26 11:54:10.884: INFO: Waiting up to 5m0s for pod "filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d" in namespace "sched-pred-4781" to be "running"
    Apr 26 11:54:10.897: INFO: Pod "filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.960045ms
    Apr 26 11:54:12.903: INFO: Pod "filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d": Phase="Running", Reason="", readiness=true. Elapsed: 2.018815792s
    Apr 26 11:54:12.903: INFO: Pod "filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d" satisfied condition "running"
    Apr 26 11:54:12.903: INFO: Waiting up to 5m0s for pod "filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01" in namespace "sched-pred-4781" to be "running"
    Apr 26 11:54:12.909: INFO: Pod "filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01": Phase="Running", Reason="", readiness=true. Elapsed: 6.028946ms
    Apr 26 11:54:12.909: INFO: Pod "filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01" satisfied condition "running"
    Apr 26 11:54:12.909: INFO: Waiting up to 5m0s for pod "filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964" in namespace "sched-pred-4781" to be "running"
    Apr 26 11:54:12.916: INFO: Pod "filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964": Phase="Running", Reason="", readiness=true. Elapsed: 7.054742ms
    Apr 26 11:54:12.916: INFO: Pod "filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964" satisfied condition "running"
    Apr 26 11:54:12.917: INFO: Waiting up to 5m0s for pod "filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b" in namespace "sched-pred-4781" to be "running"
    Apr 26 11:54:12.921: INFO: Pod "filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b": Phase="Running", Reason="", readiness=true. Elapsed: 4.463478ms
    Apr 26 11:54:12.921: INFO: Pod "filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b" satisfied condition "running"
    STEP: Creating another pod that requires unavailable amount of CPU. 04/26/24 11:54:12.921
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b.17c9d261d956ecc4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4781/filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b to shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j] 04/26/24 11:54:12.931
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b.17c9d261fd4413ae], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/26/24 11:54:12.932
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b.17c9d261fdd66ff1], Reason = [Created], Message = [Created container filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b] 04/26/24 11:54:12.932
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b.17c9d26201ccd06b], Reason = [Started], Message = [Started container filler-pod-1b1eca80-ea51-4817-8df5-87e722c5786b] 04/26/24 11:54:12.932
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01.17c9d261d79e23c6], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4781/filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01 to shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w] 04/26/24 11:54:12.932
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01.17c9d261facf8093], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/26/24 11:54:12.932
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01.17c9d261fb49c397], Reason = [Created], Message = [Created container filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01] 04/26/24 11:54:12.932
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01.17c9d261ff8bf591], Reason = [Started], Message = [Started container filler-pod-40a6a25b-2262-4d12-bdfc-aa30d0a9fc01] 04/26/24 11:54:12.932
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964.17c9d261d8415594], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4781/filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964 to shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw] 04/26/24 11:54:12.933
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964.17c9d261ff94d792], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/26/24 11:54:12.933
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964.17c9d262004745bc], Reason = [Created], Message = [Created container filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964] 04/26/24 11:54:12.933
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964.17c9d2620512bf47], Reason = [Started], Message = [Started container filler-pod-e292480d-f5c1-40a2-acfc-47851cea3964] 04/26/24 11:54:12.933
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d.17c9d261d748b79e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-4781/filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d to shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp] 04/26/24 11:54:12.933
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d.17c9d261fbf49138], Reason = [Pulled], Message = [Container image "registry.k8s.io/pause:3.8" already present on machine] 04/26/24 11:54:12.933
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d.17c9d261fc90b358], Reason = [Created], Message = [Created container filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d] 04/26/24 11:54:12.933
    STEP: Considering event: 
    Type = [Normal], Name = [filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d.17c9d2620138b2a0], Reason = [Started], Message = [Started container filler-pod-eeeca055-972e-45cc-9bf7-9102df5bb31d] 04/26/24 11:54:12.933
    STEP: Considering event: 
    Type = [Warning], Name = [additional-pod.17c9d2625357e46c], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 Insufficient cpu. preemption: 0/4 nodes are available: 4 No preemption victims found for incoming pod.] 04/26/24 11:54:12.95
    STEP: removing the label node off the node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw 04/26/24 11:54:13.952
    STEP: verifying the node doesn't have the label node 04/26/24 11:54:13.979
    STEP: removing the label node off the node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j 04/26/24 11:54:13.996
    STEP: verifying the node doesn't have the label node 04/26/24 11:54:14.03
    STEP: removing the label node off the node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp 04/26/24 11:54:14.038
    STEP: verifying the node doesn't have the label node 04/26/24 11:54:14.066
    STEP: removing the label node off the node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w 04/26/24 11:54:14.075
    STEP: verifying the node doesn't have the label node 04/26/24 11:54:14.107
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:54:14.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-4781" for this suite. 04/26/24 11:54:14.128
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:54:14.144
Apr 26 11:54:14.144: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename aggregator 04/26/24 11:54:14.145
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:14.18
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:14.201
[BeforeEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:78
Apr 26 11:54:14.210: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
[It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100
STEP: Registering the sample API server. 04/26/24 11:54:14.211
Apr 26 11:54:14.440: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 26 11:54:16.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:54:18.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:54:20.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:54:22.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:54:24.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:54:26.532: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:54:28.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:54:30.532: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:54:32.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:54:34.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 26 11:54:36.779: INFO: Waited 239.09384ms for the sample-apiserver to be ready to handle requests.
STEP: Read Status for v1alpha1.wardle.example.com 04/26/24 11:54:37.435
STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 04/26/24 11:54:37.44
STEP: List APIServices 04/26/24 11:54:37.451
Apr 26 11:54:37.472: INFO: Found v1alpha1.wardle.example.com in APIServiceList
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  test/e2e/framework/framework.go:187
Apr 26 11:54:37.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-5519" for this suite. 04/26/24 11:54:37.712
{"msg":"PASSED [sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]","completed":191,"skipped":3498,"failed":0}
------------------------------
â€¢ [SLOW TEST] [23.575 seconds]
[sig-api-machinery] Aggregator
test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
  test/e2e/apimachinery/aggregator.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:54:14.144
    Apr 26 11:54:14.144: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename aggregator 04/26/24 11:54:14.145
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:14.18
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:14.201
    [BeforeEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:78
    Apr 26 11:54:14.210: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    [It] Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]
      test/e2e/apimachinery/aggregator.go:100
    STEP: Registering the sample API server. 04/26/24 11:54:14.211
    Apr 26 11:54:14.440: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
    Apr 26 11:54:16.522: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:54:18.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:54:20.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:54:22.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:54:24.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:54:26.532: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:54:28.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:54:30.532: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:54:32.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:54:34.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 11, 54, 14, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-66c77f7668\" is progressing."}}, CollisionCount:(*int32)(nil)}
    Apr 26 11:54:36.779: INFO: Waited 239.09384ms for the sample-apiserver to be ready to handle requests.
    STEP: Read Status for v1alpha1.wardle.example.com 04/26/24 11:54:37.435
    STEP: kubectl patch apiservice v1alpha1.wardle.example.com -p '{"spec":{"versionPriority": 400}}' 04/26/24 11:54:37.44
    STEP: List APIServices 04/26/24 11:54:37.451
    Apr 26 11:54:37.472: INFO: Found v1alpha1.wardle.example.com in APIServiceList
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/apimachinery/aggregator.go:68
    [AfterEach] [sig-api-machinery] Aggregator
      test/e2e/framework/framework.go:187
    Apr 26 11:54:37.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "aggregator-5519" for this suite. 04/26/24 11:54:37.712
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:54:37.72
Apr 26 11:54:37.720: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pods 04/26/24 11:54:37.72
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:37.738
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:37.745
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397
STEP: creating the pod 04/26/24 11:54:37.752
STEP: submitting the pod to kubernetes 04/26/24 11:54:37.753
Apr 26 11:54:37.767: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54" in namespace "pods-9923" to be "running and ready"
Apr 26 11:54:37.772: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54": Phase="Pending", Reason="", readiness=false. Elapsed: 5.021355ms
Apr 26 11:54:37.772: INFO: The phase of Pod pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:54:39.779: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54": Phase="Running", Reason="", readiness=true. Elapsed: 2.01206399s
Apr 26 11:54:39.779: INFO: The phase of Pod pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54 is Running (Ready = true)
Apr 26 11:54:39.779: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54" satisfied condition "running and ready"
STEP: verifying the pod is in kubernetes 04/26/24 11:54:39.784
STEP: updating the pod 04/26/24 11:54:39.788
Apr 26 11:54:40.318: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54"
Apr 26 11:54:40.318: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54" in namespace "pods-9923" to be "terminated with reason DeadlineExceeded"
Apr 26 11:54:40.362: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54": Phase="Running", Reason="", readiness=true. Elapsed: 44.070182ms
Apr 26 11:54:42.368: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54": Phase="Running", Reason="", readiness=true. Elapsed: 2.050280387s
Apr 26 11:54:44.369: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.051380061s
Apr 26 11:54:44.369: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54" satisfied condition "terminated with reason DeadlineExceeded"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 26 11:54:44.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9923" for this suite. 04/26/24 11:54:44.38
{"msg":"PASSED [sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]","completed":192,"skipped":3519,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.669 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:397

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:54:37.72
    Apr 26 11:54:37.720: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pods 04/26/24 11:54:37.72
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:37.738
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:37.745
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:397
    STEP: creating the pod 04/26/24 11:54:37.752
    STEP: submitting the pod to kubernetes 04/26/24 11:54:37.753
    Apr 26 11:54:37.767: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54" in namespace "pods-9923" to be "running and ready"
    Apr 26 11:54:37.772: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54": Phase="Pending", Reason="", readiness=false. Elapsed: 5.021355ms
    Apr 26 11:54:37.772: INFO: The phase of Pod pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:54:39.779: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54": Phase="Running", Reason="", readiness=true. Elapsed: 2.01206399s
    Apr 26 11:54:39.779: INFO: The phase of Pod pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54 is Running (Ready = true)
    Apr 26 11:54:39.779: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54" satisfied condition "running and ready"
    STEP: verifying the pod is in kubernetes 04/26/24 11:54:39.784
    STEP: updating the pod 04/26/24 11:54:39.788
    Apr 26 11:54:40.318: INFO: Successfully updated pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54"
    Apr 26 11:54:40.318: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54" in namespace "pods-9923" to be "terminated with reason DeadlineExceeded"
    Apr 26 11:54:40.362: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54": Phase="Running", Reason="", readiness=true. Elapsed: 44.070182ms
    Apr 26 11:54:42.368: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54": Phase="Running", Reason="", readiness=true. Elapsed: 2.050280387s
    Apr 26 11:54:44.369: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.051380061s
    Apr 26 11:54:44.369: INFO: Pod "pod-update-activedeadlineseconds-e6344279-721c-4167-815f-e1a9e43f6b54" satisfied condition "terminated with reason DeadlineExceeded"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 26 11:54:44.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-9923" for this suite. 04/26/24 11:54:44.38
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:54:44.39
Apr 26 11:54:44.390: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename svcaccounts 04/26/24 11:54:44.391
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:44.408
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:44.415
[It] should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158
Apr 26 11:54:44.449: INFO: created pod pod-service-account-defaultsa
Apr 26 11:54:44.449: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 26 11:54:44.459: INFO: created pod pod-service-account-mountsa
Apr 26 11:54:44.459: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 26 11:54:44.469: INFO: created pod pod-service-account-nomountsa
Apr 26 11:54:44.469: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 26 11:54:44.477: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 26 11:54:44.477: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 26 11:54:44.485: INFO: created pod pod-service-account-mountsa-mountspec
Apr 26 11:54:44.485: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 26 11:54:44.496: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 26 11:54:44.496: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 26 11:54:44.510: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 26 11:54:44.510: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 26 11:54:44.523: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 26 11:54:44.523: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 26 11:54:44.532: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 26 11:54:44.532: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 26 11:54:44.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9463" for this suite. 04/26/24 11:54:44.545
{"msg":"PASSED [sig-auth] ServiceAccounts should allow opting out of API token automount  [Conformance]","completed":193,"skipped":3528,"failed":0}
------------------------------
â€¢ [0.163 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  test/e2e/auth/service_accounts.go:158

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:54:44.39
    Apr 26 11:54:44.390: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename svcaccounts 04/26/24 11:54:44.391
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:44.408
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:44.415
    [It] should allow opting out of API token automount  [Conformance]
      test/e2e/auth/service_accounts.go:158
    Apr 26 11:54:44.449: INFO: created pod pod-service-account-defaultsa
    Apr 26 11:54:44.449: INFO: pod pod-service-account-defaultsa service account token volume mount: true
    Apr 26 11:54:44.459: INFO: created pod pod-service-account-mountsa
    Apr 26 11:54:44.459: INFO: pod pod-service-account-mountsa service account token volume mount: true
    Apr 26 11:54:44.469: INFO: created pod pod-service-account-nomountsa
    Apr 26 11:54:44.469: INFO: pod pod-service-account-nomountsa service account token volume mount: false
    Apr 26 11:54:44.477: INFO: created pod pod-service-account-defaultsa-mountspec
    Apr 26 11:54:44.477: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
    Apr 26 11:54:44.485: INFO: created pod pod-service-account-mountsa-mountspec
    Apr 26 11:54:44.485: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
    Apr 26 11:54:44.496: INFO: created pod pod-service-account-nomountsa-mountspec
    Apr 26 11:54:44.496: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
    Apr 26 11:54:44.510: INFO: created pod pod-service-account-defaultsa-nomountspec
    Apr 26 11:54:44.510: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
    Apr 26 11:54:44.523: INFO: created pod pod-service-account-mountsa-nomountspec
    Apr 26 11:54:44.523: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
    Apr 26 11:54:44.532: INFO: created pod pod-service-account-nomountsa-nomountspec
    Apr 26 11:54:44.532: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 26 11:54:44.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9463" for this suite. 04/26/24 11:54:44.545
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:54:44.555
Apr 26 11:54:44.555: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:54:44.556
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:44.57
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:44.578
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88
STEP: Creating configMap with name projected-configmap-test-volume-map-08a3e852-a2ae-44aa-bd1f-1fa40c1b6044 04/26/24 11:54:44.586
STEP: Creating a pod to test consume configMaps 04/26/24 11:54:44.593
Apr 26 11:54:44.605: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b" in namespace "projected-4346" to be "Succeeded or Failed"
Apr 26 11:54:44.617: INFO: Pod "pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.381524ms
Apr 26 11:54:46.627: INFO: Pod "pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021677848s
Apr 26 11:54:48.622: INFO: Pod "pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017129466s
STEP: Saw pod success 04/26/24 11:54:48.622
Apr 26 11:54:48.622: INFO: Pod "pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b" satisfied condition "Succeeded or Failed"
Apr 26 11:54:48.628: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:54:48.641
Apr 26 11:54:48.654: INFO: Waiting for pod pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b to disappear
Apr 26 11:54:48.660: INFO: Pod pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 26 11:54:48.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4346" for this suite. 04/26/24 11:54:48.669
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]","completed":194,"skipped":3540,"failed":0}
------------------------------
â€¢ [4.120 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:54:44.555
    Apr 26 11:54:44.555: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:54:44.556
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:44.57
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:44.578
    [It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:88
    STEP: Creating configMap with name projected-configmap-test-volume-map-08a3e852-a2ae-44aa-bd1f-1fa40c1b6044 04/26/24 11:54:44.586
    STEP: Creating a pod to test consume configMaps 04/26/24 11:54:44.593
    Apr 26 11:54:44.605: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b" in namespace "projected-4346" to be "Succeeded or Failed"
    Apr 26 11:54:44.617: INFO: Pod "pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.381524ms
    Apr 26 11:54:46.627: INFO: Pod "pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021677848s
    Apr 26 11:54:48.622: INFO: Pod "pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017129466s
    STEP: Saw pod success 04/26/24 11:54:48.622
    Apr 26 11:54:48.622: INFO: Pod "pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b" satisfied condition "Succeeded or Failed"
    Apr 26 11:54:48.628: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:54:48.641
    Apr 26 11:54:48.654: INFO: Waiting for pod pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b to disappear
    Apr 26 11:54:48.660: INFO: Pod pod-projected-configmaps-f8da1dd5-18d6-4cd2-9995-783be9fd941b no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 26 11:54:48.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-4346" for this suite. 04/26/24 11:54:48.669
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-network] Services
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:54:48.675
Apr 26 11:54:48.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 11:54:48.676
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:48.693
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:48.7
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268
STEP: creating service nodeport-test with type=NodePort in namespace services-5213 04/26/24 11:54:48.708
STEP: creating replication controller nodeport-test in namespace services-5213 04/26/24 11:54:48.727
I0426 11:54:48.736163      23 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-5213, replica count: 2
I0426 11:54:51.788798      23 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 26 11:54:51.788: INFO: Creating new exec pod
Apr 26 11:54:51.800: INFO: Waiting up to 5m0s for pod "execpodfmdx8" in namespace "services-5213" to be "running"
Apr 26 11:54:51.804: INFO: Pod "execpodfmdx8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.55472ms
Apr 26 11:54:53.810: INFO: Pod "execpodfmdx8": Phase="Running", Reason="", readiness=true. Elapsed: 2.010355602s
Apr 26 11:54:53.810: INFO: Pod "execpodfmdx8" satisfied condition "running"
Apr 26 11:54:54.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-5213 exec execpodfmdx8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Apr 26 11:54:55.459: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 26 11:54:55.459: INFO: stdout: ""
Apr 26 11:54:56.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-5213 exec execpodfmdx8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
Apr 26 11:54:56.999: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 26 11:54:56.999: INFO: stdout: "nodeport-test-f9fsx"
Apr 26 11:54:56.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-5213 exec execpodfmdx8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.64.255.129 80'
Apr 26 11:54:57.534: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.64.255.129 80\nConnection to 100.64.255.129 80 port [tcp/http] succeeded!\n"
Apr 26 11:54:57.534: INFO: stdout: "nodeport-test-gkt2g"
Apr 26 11:54:57.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-5213 exec execpodfmdx8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.152 31748'
Apr 26 11:54:58.044: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.152 31748\nConnection to 10.250.0.152 31748 port [tcp/*] succeeded!\n"
Apr 26 11:54:58.044: INFO: stdout: "nodeport-test-gkt2g"
Apr 26 11:54:58.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-5213 exec execpodfmdx8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.2.248 31748'
Apr 26 11:54:58.612: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.2.248 31748\nConnection to 10.250.2.248 31748 port [tcp/*] succeeded!\n"
Apr 26 11:54:58.612: INFO: stdout: "nodeport-test-f9fsx"
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 11:54:58.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5213" for this suite. 04/26/24 11:54:58.622
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should be able to create a functioning NodePort service [Conformance]","completed":195,"skipped":3546,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.955 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  test/e2e/network/service.go:1268

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:54:48.675
    Apr 26 11:54:48.675: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 11:54:48.676
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:48.693
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:48.7
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should be able to create a functioning NodePort service [Conformance]
      test/e2e/network/service.go:1268
    STEP: creating service nodeport-test with type=NodePort in namespace services-5213 04/26/24 11:54:48.708
    STEP: creating replication controller nodeport-test in namespace services-5213 04/26/24 11:54:48.727
    I0426 11:54:48.736163      23 runners.go:193] Created replication controller with name: nodeport-test, namespace: services-5213, replica count: 2
    I0426 11:54:51.788798      23 runners.go:193] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 26 11:54:51.788: INFO: Creating new exec pod
    Apr 26 11:54:51.800: INFO: Waiting up to 5m0s for pod "execpodfmdx8" in namespace "services-5213" to be "running"
    Apr 26 11:54:51.804: INFO: Pod "execpodfmdx8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.55472ms
    Apr 26 11:54:53.810: INFO: Pod "execpodfmdx8": Phase="Running", Reason="", readiness=true. Elapsed: 2.010355602s
    Apr 26 11:54:53.810: INFO: Pod "execpodfmdx8" satisfied condition "running"
    Apr 26 11:54:54.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-5213 exec execpodfmdx8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Apr 26 11:54:55.459: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Apr 26 11:54:55.459: INFO: stdout: ""
    Apr 26 11:54:56.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-5213 exec execpodfmdx8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 nodeport-test 80'
    Apr 26 11:54:56.999: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
    Apr 26 11:54:56.999: INFO: stdout: "nodeport-test-f9fsx"
    Apr 26 11:54:56.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-5213 exec execpodfmdx8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.64.255.129 80'
    Apr 26 11:54:57.534: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.64.255.129 80\nConnection to 100.64.255.129 80 port [tcp/http] succeeded!\n"
    Apr 26 11:54:57.534: INFO: stdout: "nodeport-test-gkt2g"
    Apr 26 11:54:57.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-5213 exec execpodfmdx8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.0.152 31748'
    Apr 26 11:54:58.044: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.0.152 31748\nConnection to 10.250.0.152 31748 port [tcp/*] succeeded!\n"
    Apr 26 11:54:58.044: INFO: stdout: "nodeport-test-gkt2g"
    Apr 26 11:54:58.044: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-5213 exec execpodfmdx8 -- /bin/sh -x -c echo hostName | nc -v -t -w 2 10.250.2.248 31748'
    Apr 26 11:54:58.612: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 10.250.2.248 31748\nConnection to 10.250.2.248 31748 port [tcp/*] succeeded!\n"
    Apr 26 11:54:58.612: INFO: stdout: "nodeport-test-f9fsx"
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 11:54:58.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-5213" for this suite. 04/26/24 11:54:58.622
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:54:58.633
Apr 26 11:54:58.633: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 11:54:58.635
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:58.652
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:58.659
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 11:54:58.683
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:54:58.902
STEP: Deploying the webhook pod 04/26/24 11:54:58.91
STEP: Wait for the deployment to be ready 04/26/24 11:54:58.926
Apr 26 11:54:58.939: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 11:55:00.956
STEP: Verifying the service has paired with the endpoint 04/26/24 11:55:00.969
Apr 26 11:55:01.970: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196
STEP: Registering the webhook via the AdmissionRegistration API 04/26/24 11:55:01.976
STEP: create a pod that should be denied by the webhook 04/26/24 11:55:02.107
STEP: create a pod that causes the webhook to hang 04/26/24 11:55:02.21
STEP: create a configmap that should be denied by the webhook 04/26/24 11:55:12.223
STEP: create a configmap that should be admitted by the webhook 04/26/24 11:55:12.26
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 04/26/24 11:55:12.37
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 04/26/24 11:55:12.429
STEP: create a namespace that bypass the webhook 04/26/24 11:55:12.483
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 04/26/24 11:55:12.492
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:55:12.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-544" for this suite. 04/26/24 11:55:12.603
STEP: Destroying namespace "webhook-544-markers" for this suite. 04/26/24 11:55:12.609
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]","completed":196,"skipped":3575,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.015 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  test/e2e/apimachinery/webhook.go:196

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:54:58.633
    Apr 26 11:54:58.633: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 11:54:58.635
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:54:58.652
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:54:58.659
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 11:54:58.683
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:54:58.902
    STEP: Deploying the webhook pod 04/26/24 11:54:58.91
    STEP: Wait for the deployment to be ready 04/26/24 11:54:58.926
    Apr 26 11:54:58.939: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 11:55:00.956
    STEP: Verifying the service has paired with the endpoint 04/26/24 11:55:00.969
    Apr 26 11:55:01.970: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny pod and configmap creation [Conformance]
      test/e2e/apimachinery/webhook.go:196
    STEP: Registering the webhook via the AdmissionRegistration API 04/26/24 11:55:01.976
    STEP: create a pod that should be denied by the webhook 04/26/24 11:55:02.107
    STEP: create a pod that causes the webhook to hang 04/26/24 11:55:02.21
    STEP: create a configmap that should be denied by the webhook 04/26/24 11:55:12.223
    STEP: create a configmap that should be admitted by the webhook 04/26/24 11:55:12.26
    STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook 04/26/24 11:55:12.37
    STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook 04/26/24 11:55:12.429
    STEP: create a namespace that bypass the webhook 04/26/24 11:55:12.483
    STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace 04/26/24 11:55:12.492
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:55:12.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-544" for this suite. 04/26/24 11:55:12.603
    STEP: Destroying namespace "webhook-544-markers" for this suite. 04/26/24 11:55:12.609
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:55:12.653
Apr 26 11:55:12.653: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 11:55:12.654
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:55:12.673
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:55:12.679
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 11:55:12.697
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:55:12.9
STEP: Deploying the webhook pod 04/26/24 11:55:12.907
STEP: Wait for the deployment to be ready 04/26/24 11:55:12.933
Apr 26 11:55:12.943: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 11:55:14.958
STEP: Verifying the service has paired with the endpoint 04/26/24 11:55:14.987
Apr 26 11:55:15.988: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307
STEP: Registering the crd webhook via the AdmissionRegistration API 04/26/24 11:55:15.994
STEP: Creating a custom resource definition that should be denied by the webhook 04/26/24 11:55:16.118
Apr 26 11:55:16.119: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:55:16.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9390" for this suite. 04/26/24 11:55:16.289
STEP: Destroying namespace "webhook-9390-markers" for this suite. 04/26/24 11:55:16.296
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]","completed":197,"skipped":3594,"failed":0}
------------------------------
â€¢ [3.700 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  test/e2e/apimachinery/webhook.go:307

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:55:12.653
    Apr 26 11:55:12.653: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 11:55:12.654
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:55:12.673
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:55:12.679
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 11:55:12.697
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:55:12.9
    STEP: Deploying the webhook pod 04/26/24 11:55:12.907
    STEP: Wait for the deployment to be ready 04/26/24 11:55:12.933
    Apr 26 11:55:12.943: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 11:55:14.958
    STEP: Verifying the service has paired with the endpoint 04/26/24 11:55:14.987
    Apr 26 11:55:15.988: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should deny crd creation [Conformance]
      test/e2e/apimachinery/webhook.go:307
    STEP: Registering the crd webhook via the AdmissionRegistration API 04/26/24 11:55:15.994
    STEP: Creating a custom resource definition that should be denied by the webhook 04/26/24 11:55:16.118
    Apr 26 11:55:16.119: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:55:16.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-9390" for this suite. 04/26/24 11:55:16.289
    STEP: Destroying namespace "webhook-9390-markers" for this suite. 04/26/24 11:55:16.296
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:55:16.36
Apr 26 11:55:16.360: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename dns 04/26/24 11:55:16.36
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:55:16.375
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:55:16.381
[It] should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-748.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-748.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
 04/26/24 11:55:16.389
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-748.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-748.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
 04/26/24 11:55:16.389
STEP: creating a pod to probe /etc/hosts 04/26/24 11:55:16.389
STEP: submitting the pod to kubernetes 04/26/24 11:55:16.389
Apr 26 11:55:16.402: INFO: Waiting up to 15m0s for pod "dns-test-1cfa7c01-6288-4a89-a3f2-567ab6eacb6b" in namespace "dns-748" to be "running"
Apr 26 11:55:16.409: INFO: Pod "dns-test-1cfa7c01-6288-4a89-a3f2-567ab6eacb6b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.836644ms
Apr 26 11:55:18.416: INFO: Pod "dns-test-1cfa7c01-6288-4a89-a3f2-567ab6eacb6b": Phase="Running", Reason="", readiness=true. Elapsed: 2.013477726s
Apr 26 11:55:18.416: INFO: Pod "dns-test-1cfa7c01-6288-4a89-a3f2-567ab6eacb6b" satisfied condition "running"
STEP: retrieving the pod 04/26/24 11:55:18.416
STEP: looking for the results for each expected name from probers 04/26/24 11:55:18.421
Apr 26 11:55:18.572: INFO: DNS probes using dns-748/dns-test-1cfa7c01-6288-4a89-a3f2-567ab6eacb6b succeeded

STEP: deleting the pod 04/26/24 11:55:18.572
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 26 11:55:18.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-748" for this suite. 04/26/24 11:55:18.598
{"msg":"PASSED [sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]","completed":198,"skipped":3647,"failed":0}
------------------------------
â€¢ [2.244 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide /etc/hosts entries for the cluster [Conformance]
  test/e2e/network/dns.go:117

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:55:16.36
    Apr 26 11:55:16.360: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename dns 04/26/24 11:55:16.36
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:55:16.375
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:55:16.381
    [It] should provide /etc/hosts entries for the cluster [Conformance]
      test/e2e/network/dns.go:117
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-748.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-748.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;sleep 1; done
     04/26/24 11:55:16.389
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-748.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-748.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;sleep 1; done
     04/26/24 11:55:16.389
    STEP: creating a pod to probe /etc/hosts 04/26/24 11:55:16.389
    STEP: submitting the pod to kubernetes 04/26/24 11:55:16.389
    Apr 26 11:55:16.402: INFO: Waiting up to 15m0s for pod "dns-test-1cfa7c01-6288-4a89-a3f2-567ab6eacb6b" in namespace "dns-748" to be "running"
    Apr 26 11:55:16.409: INFO: Pod "dns-test-1cfa7c01-6288-4a89-a3f2-567ab6eacb6b": Phase="Pending", Reason="", readiness=false. Elapsed: 6.836644ms
    Apr 26 11:55:18.416: INFO: Pod "dns-test-1cfa7c01-6288-4a89-a3f2-567ab6eacb6b": Phase="Running", Reason="", readiness=true. Elapsed: 2.013477726s
    Apr 26 11:55:18.416: INFO: Pod "dns-test-1cfa7c01-6288-4a89-a3f2-567ab6eacb6b" satisfied condition "running"
    STEP: retrieving the pod 04/26/24 11:55:18.416
    STEP: looking for the results for each expected name from probers 04/26/24 11:55:18.421
    Apr 26 11:55:18.572: INFO: DNS probes using dns-748/dns-test-1cfa7c01-6288-4a89-a3f2-567ab6eacb6b succeeded

    STEP: deleting the pod 04/26/24 11:55:18.572
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 26 11:55:18.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-748" for this suite. 04/26/24 11:55:18.598
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:55:18.605
Apr 26 11:55:18.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 11:55:18.606
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:55:18.622
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:55:18.628
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56
STEP: Creating configMap with name configmap-test-volume-1897c67e-4390-4609-a03a-2b078bf0bda8 04/26/24 11:55:18.635
STEP: Creating a pod to test consume configMaps 04/26/24 11:55:18.64
Apr 26 11:55:18.661: INFO: Waiting up to 5m0s for pod "pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd" in namespace "configmap-1177" to be "Succeeded or Failed"
Apr 26 11:55:18.667: INFO: Pod "pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.244222ms
Apr 26 11:55:20.680: INFO: Pod "pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd": Phase="Running", Reason="", readiness=false. Elapsed: 2.019435104s
Apr 26 11:55:22.701: INFO: Pod "pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039691364s
STEP: Saw pod success 04/26/24 11:55:22.701
Apr 26 11:55:22.701: INFO: Pod "pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd" satisfied condition "Succeeded or Failed"
Apr 26 11:55:22.711: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:55:22.723
Apr 26 11:55:22.735: INFO: Waiting for pod pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd to disappear
Apr 26 11:55:22.739: INFO: Pod pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 11:55:22.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1177" for this suite. 04/26/24 11:55:22.749
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":199,"skipped":3702,"failed":0}
------------------------------
â€¢ [4.150 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:55:18.605
    Apr 26 11:55:18.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 11:55:18.606
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:55:18.622
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:55:18.628
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:56
    STEP: Creating configMap with name configmap-test-volume-1897c67e-4390-4609-a03a-2b078bf0bda8 04/26/24 11:55:18.635
    STEP: Creating a pod to test consume configMaps 04/26/24 11:55:18.64
    Apr 26 11:55:18.661: INFO: Waiting up to 5m0s for pod "pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd" in namespace "configmap-1177" to be "Succeeded or Failed"
    Apr 26 11:55:18.667: INFO: Pod "pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.244222ms
    Apr 26 11:55:20.680: INFO: Pod "pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd": Phase="Running", Reason="", readiness=false. Elapsed: 2.019435104s
    Apr 26 11:55:22.701: INFO: Pod "pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039691364s
    STEP: Saw pod success 04/26/24 11:55:22.701
    Apr 26 11:55:22.701: INFO: Pod "pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd" satisfied condition "Succeeded or Failed"
    Apr 26 11:55:22.711: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:55:22.723
    Apr 26 11:55:22.735: INFO: Waiting for pod pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd to disappear
    Apr 26 11:55:22.739: INFO: Pod pod-configmaps-993561a7-1ee2-4ce2-8dfa-b321259e38bd no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 11:55:22.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-1177" for this suite. 04/26/24 11:55:22.749
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:55:22.757
Apr 26 11:55:22.757: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename resourcequota 04/26/24 11:55:22.757
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:55:22.773
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:55:22.78
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316
STEP: Counting existing ResourceQuota 04/26/24 11:55:39.795
STEP: Creating a ResourceQuota 04/26/24 11:55:44.803
STEP: Ensuring resource quota status is calculated 04/26/24 11:55:44.808
STEP: Creating a ConfigMap 04/26/24 11:55:46.816
STEP: Ensuring resource quota status captures configMap creation 04/26/24 11:55:46.833
STEP: Deleting a ConfigMap 04/26/24 11:55:48.84
STEP: Ensuring resource quota status released usage 04/26/24 11:55:48.847
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 26 11:55:50.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
Apr 26 11:55:50.867: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is false, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
Apr 26 11:55:52.879: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is false, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
Apr 26 11:55:54.880: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is false, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
Apr 26 11:55:56.877: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is false, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
Apr 26 11:55:58.879: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is false, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
Apr 26 11:56:00.883: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is true, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
Apr 26 11:56:02.881: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is true, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
STEP: Destroying namespace "resourcequota-4821" for this suite. 04/26/24 11:56:04.878
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]","completed":200,"skipped":3741,"failed":0}
------------------------------
â€¢ [SLOW TEST] [42.128 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  test/e2e/apimachinery/resource_quota.go:316

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:55:22.757
    Apr 26 11:55:22.757: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename resourcequota 04/26/24 11:55:22.757
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:55:22.773
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:55:22.78
    [It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
      test/e2e/apimachinery/resource_quota.go:316
    STEP: Counting existing ResourceQuota 04/26/24 11:55:39.795
    STEP: Creating a ResourceQuota 04/26/24 11:55:44.803
    STEP: Ensuring resource quota status is calculated 04/26/24 11:55:44.808
    STEP: Creating a ConfigMap 04/26/24 11:55:46.816
    STEP: Ensuring resource quota status captures configMap creation 04/26/24 11:55:46.833
    STEP: Deleting a ConfigMap 04/26/24 11:55:48.84
    STEP: Ensuring resource quota status released usage 04/26/24 11:55:48.847
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 26 11:55:50.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    Apr 26 11:55:50.867: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is false, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
    Apr 26 11:55:52.879: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is false, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
    Apr 26 11:55:54.880: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is false, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
    Apr 26 11:55:56.877: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is false, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
    Apr 26 11:55:58.879: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is false, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
    Apr 26 11:56:00.883: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is true, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
    Apr 26 11:56:02.881: INFO: Condition Ready of node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is true, but Node is tainted by NodeController with [{node.gardener.cloud/critical-components-not-ready  NoSchedule <nil>} {node.kubernetes.io/not-ready  NoExecute 2024-04-26 11:55:33 +0000 UTC}]. Failure
    STEP: Destroying namespace "resourcequota-4821" for this suite. 04/26/24 11:56:04.878
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:56:04.885
Apr 26 11:56:04.886: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-runtime 04/26/24 11:56:04.887
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:56:04.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:56:04.914
[It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:215
STEP: create the container 04/26/24 11:56:04.92
STEP: wait for the container to reach Failed 04/26/24 11:56:04.934
STEP: get the container status 04/26/24 11:56:08.968
STEP: the container should be terminated 04/26/24 11:56:08.974
STEP: the termination message should be set 04/26/24 11:56:08.974
Apr 26 11:56:08.974: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container 04/26/24 11:56:08.974
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 26 11:56:08.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4091" for this suite. 04/26/24 11:56:09.001
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":201,"skipped":3752,"failed":0}
------------------------------
â€¢ [4.121 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:56:04.885
    Apr 26 11:56:04.886: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-runtime 04/26/24 11:56:04.887
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:56:04.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:56:04.914
    [It] should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:215
    STEP: create the container 04/26/24 11:56:04.92
    STEP: wait for the container to reach Failed 04/26/24 11:56:04.934
    STEP: get the container status 04/26/24 11:56:08.968
    STEP: the container should be terminated 04/26/24 11:56:08.974
    STEP: the termination message should be set 04/26/24 11:56:08.974
    Apr 26 11:56:08.974: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
    STEP: delete the container 04/26/24 11:56:08.974
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 26 11:56:08.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-4091" for this suite. 04/26/24 11:56:09.001
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Services
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:56:09.007
Apr 26 11:56:09.007: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 11:56:09.008
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:56:09.025
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:56:09.032
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157
STEP: creating service in namespace services-89 04/26/24 11:56:09.038
STEP: creating service affinity-clusterip in namespace services-89 04/26/24 11:56:09.038
STEP: creating replication controller affinity-clusterip in namespace services-89 04/26/24 11:56:09.051
I0426 11:56:09.062945      23 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-89, replica count: 3
I0426 11:56:12.114859      23 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 26 11:56:12.128: INFO: Creating new exec pod
Apr 26 11:56:12.138: INFO: Waiting up to 5m0s for pod "execpod-affinityzrx8m" in namespace "services-89" to be "running"
Apr 26 11:56:12.155: INFO: Pod "execpod-affinityzrx8m": Phase="Pending", Reason="", readiness=false. Elapsed: 17.077531ms
Apr 26 11:56:14.162: INFO: Pod "execpod-affinityzrx8m": Phase="Running", Reason="", readiness=true. Elapsed: 2.024389372s
Apr 26 11:56:14.162: INFO: Pod "execpod-affinityzrx8m" satisfied condition "running"
Apr 26 11:56:15.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-89 exec execpod-affinityzrx8m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
Apr 26 11:56:15.594: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
Apr 26 11:56:15.594: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:56:15.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-89 exec execpod-affinityzrx8m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.71.38.248 80'
Apr 26 11:56:16.066: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 100.71.38.248 80\nConnection to 100.71.38.248 80 port [tcp/http] succeeded!\n"
Apr 26 11:56:16.066: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 11:56:16.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-89 exec execpod-affinityzrx8m -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.71.38.248:80/ ; done'
Apr 26 11:56:16.571: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n"
Apr 26 11:56:16.571: INFO: stdout: "\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j"
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
Apr 26 11:56:16.571: INFO: Cleaning up the exec pod
STEP: deleting ReplicationController affinity-clusterip in namespace services-89, will wait for the garbage collector to delete the pods 04/26/24 11:56:16.585
Apr 26 11:56:16.648: INFO: Deleting ReplicationController affinity-clusterip took: 8.05974ms
Apr 26 11:56:16.749: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.317822ms
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 11:56:18.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-89" for this suite. 04/26/24 11:56:18.775
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]","completed":202,"skipped":3754,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.775 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
  test/e2e/network/service.go:2157

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:56:09.007
    Apr 26 11:56:09.007: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 11:56:09.008
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:56:09.025
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:56:09.032
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]
      test/e2e/network/service.go:2157
    STEP: creating service in namespace services-89 04/26/24 11:56:09.038
    STEP: creating service affinity-clusterip in namespace services-89 04/26/24 11:56:09.038
    STEP: creating replication controller affinity-clusterip in namespace services-89 04/26/24 11:56:09.051
    I0426 11:56:09.062945      23 runners.go:193] Created replication controller with name: affinity-clusterip, namespace: services-89, replica count: 3
    I0426 11:56:12.114859      23 runners.go:193] affinity-clusterip Pods: 3 out of 3 created, 3 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 26 11:56:12.128: INFO: Creating new exec pod
    Apr 26 11:56:12.138: INFO: Waiting up to 5m0s for pod "execpod-affinityzrx8m" in namespace "services-89" to be "running"
    Apr 26 11:56:12.155: INFO: Pod "execpod-affinityzrx8m": Phase="Pending", Reason="", readiness=false. Elapsed: 17.077531ms
    Apr 26 11:56:14.162: INFO: Pod "execpod-affinityzrx8m": Phase="Running", Reason="", readiness=true. Elapsed: 2.024389372s
    Apr 26 11:56:14.162: INFO: Pod "execpod-affinityzrx8m" satisfied condition "running"
    Apr 26 11:56:15.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-89 exec execpod-affinityzrx8m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 affinity-clusterip 80'
    Apr 26 11:56:15.594: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 affinity-clusterip 80\nConnection to affinity-clusterip 80 port [tcp/http] succeeded!\n"
    Apr 26 11:56:15.594: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:56:15.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-89 exec execpod-affinityzrx8m -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.71.38.248 80'
    Apr 26 11:56:16.066: INFO: stderr: "+ + echonc -v hostName -t\n -w 2 100.71.38.248 80\nConnection to 100.71.38.248 80 port [tcp/http] succeeded!\n"
    Apr 26 11:56:16.066: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 11:56:16.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-89 exec execpod-affinityzrx8m -- /bin/sh -x -c for i in $(seq 0 15); do echo; curl -q -s --connect-timeout 2 http://100.71.38.248:80/ ; done'
    Apr 26 11:56:16.571: INFO: stderr: "+ seq 0 15\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n+ echo\n+ curl -q -s --connect-timeout 2 http://100.71.38.248:80/\n"
    Apr 26 11:56:16.571: INFO: stdout: "\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j\naffinity-clusterip-4742j"
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Received response from host: affinity-clusterip-4742j
    Apr 26 11:56:16.571: INFO: Cleaning up the exec pod
    STEP: deleting ReplicationController affinity-clusterip in namespace services-89, will wait for the garbage collector to delete the pods 04/26/24 11:56:16.585
    Apr 26 11:56:16.648: INFO: Deleting ReplicationController affinity-clusterip took: 8.05974ms
    Apr 26 11:56:16.749: INFO: Terminating ReplicationController affinity-clusterip pods took: 100.317822ms
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 11:56:18.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-89" for this suite. 04/26/24 11:56:18.775
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:56:18.784
Apr 26 11:56:18.784: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename deployment 04/26/24 11:56:18.785
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:56:18.803
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:56:18.809
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150
Apr 26 11:56:18.819: INFO: Creating simple deployment test-new-deployment
Apr 26 11:56:18.842: INFO: deployment "test-new-deployment" doesn't have the required revision set
STEP: getting scale subresource 04/26/24 11:56:20.863
STEP: updating a scale subresource 04/26/24 11:56:20.868
STEP: verifying the deployment Spec.Replicas was modified 04/26/24 11:56:20.874
STEP: Patch a scale subresource 04/26/24 11:56:20.88
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 26 11:56:20.903: INFO: Deployment "test-new-deployment":
&Deployment{ObjectMeta:{test-new-deployment  deployment-922  b86ca3bc-3ccf-4c4e-9759-01e9fe73a965 37094 3 2024-04-26 11:56:18 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2024-04-26 11:56:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b19578 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2024-04-26 11:56:20 +0000 UTC,LastTransitionTime:2024-04-26 11:56:18 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2024-04-26 11:56:20 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 26 11:56:20.920: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
&ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-922  931a3f34-c32d-4708-b366-cb980630e5cb 37098 3 2024-04-26 11:56:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment b86ca3bc-3ccf-4c4e-9759-01e9fe73a965 0xc005b74957 0xc005b74958}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b86ca3bc-3ccf-4c4e-9759-01e9fe73a965\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005b749e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 26 11:56:20.926: INFO: Pod "test-new-deployment-845c8977d9-kcl2g" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-kcl2g test-new-deployment-845c8977d9- deployment-922  b261a8d3-5173-4379-b927-4138d08611c6 37099 0 2024-04-26 11:56:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 931a3f34-c32d-4708-b366-cb980630e5cb 0xc005ba21d7 0xc005ba21d8}] [] [{kube-controller-manager Update v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"931a3f34-c32d-4708-b366-cb980630e5cb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fjhrw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fjhrw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.91,PodIP:,StartTime:2024-04-26 11:56:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:56:20.926: INFO: Pod "test-new-deployment-845c8977d9-pvs76" is available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-pvs76 test-new-deployment-845c8977d9- deployment-922  06cd9b30-a8fd-4c2b-8d49-3ac518cac2df 37082 0 2024-04-26 11:56:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:386598552cf55ab90631e8d4115d610510f52863b811a29df8f398607d45e6e3 cni.projectcalico.org/podIP:100.96.1.216/32 cni.projectcalico.org/podIPs:100.96.1.216/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 931a3f34-c32d-4708-b366-cb980630e5cb 0xc005ba23b7 0xc005ba23b8}] [] [{kube-controller-manager Update v1 2024-04-26 11:56:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"931a3f34-c32d-4708-b366-cb980630e5cb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:56:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.216\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c6vs9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c6vs9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.216,StartTime:2024-04-26 11:56:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:56:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b457380ec05559ef89fe4fd4335fdffa1878ef9d592ee4929c40c021291233c5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.216,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 11:56:20.926: INFO: Pod "test-new-deployment-845c8977d9-qdnsc" is not available:
&Pod{ObjectMeta:{test-new-deployment-845c8977d9-qdnsc test-new-deployment-845c8977d9- deployment-922  c386a138-e6cf-4e32-b081-327cbdc12a98 37100 0 2024-04-26 11:56:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 931a3f34-c32d-4708-b366-cb980630e5cb 0xc005ba25b7 0xc005ba25b8}] [] [{kube-controller-manager Update v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"931a3f34-c32d-4708-b366-cb980630e5cb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wzvx4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wzvx4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 26 11:56:20.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-922" for this suite. 04/26/24 11:56:20.943
{"msg":"PASSED [sig-apps] Deployment Deployment should have a working scale subresource [Conformance]","completed":203,"skipped":3779,"failed":0}
------------------------------
â€¢ [2.168 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  Deployment should have a working scale subresource [Conformance]
  test/e2e/apps/deployment.go:150

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:56:18.784
    Apr 26 11:56:18.784: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename deployment 04/26/24 11:56:18.785
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:56:18.803
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:56:18.809
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] Deployment should have a working scale subresource [Conformance]
      test/e2e/apps/deployment.go:150
    Apr 26 11:56:18.819: INFO: Creating simple deployment test-new-deployment
    Apr 26 11:56:18.842: INFO: deployment "test-new-deployment" doesn't have the required revision set
    STEP: getting scale subresource 04/26/24 11:56:20.863
    STEP: updating a scale subresource 04/26/24 11:56:20.868
    STEP: verifying the deployment Spec.Replicas was modified 04/26/24 11:56:20.874
    STEP: Patch a scale subresource 04/26/24 11:56:20.88
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 26 11:56:20.903: INFO: Deployment "test-new-deployment":
    &Deployment{ObjectMeta:{test-new-deployment  deployment-922  b86ca3bc-3ccf-4c4e-9759-01e9fe73a965 37094 3 2024-04-26 11:56:18 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 <nil> FieldsV1 {"f:spec":{"f:replicas":{}}} scale} {e2e.test Update apps/v1 2024-04-26 11:56:18 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003b19578 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-new-deployment-845c8977d9" has successfully progressed.,LastUpdateTime:2024-04-26 11:56:20 +0000 UTC,LastTransitionTime:2024-04-26 11:56:18 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2024-04-26 11:56:20 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 26 11:56:20.920: INFO: New ReplicaSet "test-new-deployment-845c8977d9" of Deployment "test-new-deployment":
    &ReplicaSet{ObjectMeta:{test-new-deployment-845c8977d9  deployment-922  931a3f34-c32d-4708-b366-cb980630e5cb 37098 3 2024-04-26 11:56:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[deployment.kubernetes.io/desired-replicas:4 deployment.kubernetes.io/max-replicas:5 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-new-deployment b86ca3bc-3ccf-4c4e-9759-01e9fe73a965 0xc005b74957 0xc005b74958}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"b86ca3bc-3ccf-4c4e-9759-01e9fe73a965\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*4,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 845c8977d9,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005b749e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:2,FullyLabeledReplicas:2,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 26 11:56:20.926: INFO: Pod "test-new-deployment-845c8977d9-kcl2g" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-kcl2g test-new-deployment-845c8977d9- deployment-922  b261a8d3-5173-4379-b927-4138d08611c6 37099 0 2024-04-26 11:56:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 931a3f34-c32d-4708-b366-cb980630e5cb 0xc005ba21d7 0xc005ba21d8}] [] [{kube-controller-manager Update v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"931a3f34-c32d-4708-b366-cb980630e5cb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fjhrw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fjhrw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.91,PodIP:,StartTime:2024-04-26 11:56:20 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:56:20.926: INFO: Pod "test-new-deployment-845c8977d9-pvs76" is available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-pvs76 test-new-deployment-845c8977d9- deployment-922  06cd9b30-a8fd-4c2b-8d49-3ac518cac2df 37082 0 2024-04-26 11:56:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[cni.projectcalico.org/containerID:386598552cf55ab90631e8d4115d610510f52863b811a29df8f398607d45e6e3 cni.projectcalico.org/podIP:100.96.1.216/32 cni.projectcalico.org/podIPs:100.96.1.216/32] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 931a3f34-c32d-4708-b366-cb980630e5cb 0xc005ba23b7 0xc005ba23b8}] [] [{kube-controller-manager Update v1 2024-04-26 11:56:18 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"931a3f34-c32d-4708-b366-cb980630e5cb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 11:56:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.216\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c6vs9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c6vs9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:56:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.216,StartTime:2024-04-26 11:56:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:56:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3,ContainerID:containerd://b457380ec05559ef89fe4fd4335fdffa1878ef9d592ee4929c40c021291233c5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.216,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 11:56:20.926: INFO: Pod "test-new-deployment-845c8977d9-qdnsc" is not available:
    &Pod{ObjectMeta:{test-new-deployment-845c8977d9-qdnsc test-new-deployment-845c8977d9- deployment-922  c386a138-e6cf-4e32-b081-327cbdc12a98 37100 0 2024-04-26 11:56:20 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:845c8977d9] map[] [{apps/v1 ReplicaSet test-new-deployment-845c8977d9 931a3f34-c32d-4708-b366-cb980630e5cb 0xc005ba25b7 0xc005ba25b8}] [] [{kube-controller-manager Update v1 2024-04-26 11:56:20 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"931a3f34-c32d-4708-b366-cb980630e5cb\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-wzvx4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-wzvx4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 26 11:56:20.926: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-922" for this suite. 04/26/24 11:56:20.943
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:56:20.953
Apr 26 11:56:20.953: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename var-expansion 04/26/24 11:56:20.954
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:56:20.973
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:56:20.98
[It] should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296
STEP: creating the pod 04/26/24 11:56:20.987
STEP: waiting for pod running 04/26/24 11:56:20.998
Apr 26 11:56:20.998: INFO: Waiting up to 2m0s for pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb" in namespace "var-expansion-2016" to be "running"
Apr 26 11:56:21.003: INFO: Pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.974368ms
Apr 26 11:56:23.014: INFO: Pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb": Phase="Running", Reason="", readiness=true. Elapsed: 2.015648312s
Apr 26 11:56:23.014: INFO: Pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb" satisfied condition "running"
STEP: creating a file in subpath 04/26/24 11:56:23.014
Apr 26 11:56:23.020: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2016 PodName:var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:56:23.020: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:56:23.021: INFO: ExecWithOptions: Clientset creation
Apr 26 11:56:23.021: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/var-expansion-2016/pods/var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: test for file in mounted path 04/26/24 11:56:23.357
Apr 26 11:56:23.363: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2016 PodName:var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:56:23.363: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:56:23.363: INFO: ExecWithOptions: Clientset creation
Apr 26 11:56:23.364: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/var-expansion-2016/pods/var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
STEP: updating the annotation value 04/26/24 11:56:23.885
Apr 26 11:56:24.404: INFO: Successfully updated pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb"
STEP: waiting for annotated pod running 04/26/24 11:56:24.404
Apr 26 11:56:24.404: INFO: Waiting up to 2m0s for pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb" in namespace "var-expansion-2016" to be "running"
Apr 26 11:56:24.411: INFO: Pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb": Phase="Running", Reason="", readiness=true. Elapsed: 6.03453ms
Apr 26 11:56:24.411: INFO: Pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb" satisfied condition "running"
STEP: deleting the pod gracefully 04/26/24 11:56:24.411
Apr 26 11:56:24.411: INFO: Deleting pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb" in namespace "var-expansion-2016"
Apr 26 11:56:24.421: INFO: Wait up to 5m0s for pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 26 11:56:58.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2016" for this suite. 04/26/24 11:56:58.447
{"msg":"PASSED [sig-node] Variable Expansion should succeed in writing subpaths in container [Slow] [Conformance]","completed":204,"skipped":3797,"failed":0}
------------------------------
â€¢ [SLOW TEST] [37.500 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should succeed in writing subpaths in container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:296

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:56:20.953
    Apr 26 11:56:20.953: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename var-expansion 04/26/24 11:56:20.954
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:56:20.973
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:56:20.98
    [It] should succeed in writing subpaths in container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:296
    STEP: creating the pod 04/26/24 11:56:20.987
    STEP: waiting for pod running 04/26/24 11:56:20.998
    Apr 26 11:56:20.998: INFO: Waiting up to 2m0s for pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb" in namespace "var-expansion-2016" to be "running"
    Apr 26 11:56:21.003: INFO: Pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.974368ms
    Apr 26 11:56:23.014: INFO: Pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb": Phase="Running", Reason="", readiness=true. Elapsed: 2.015648312s
    Apr 26 11:56:23.014: INFO: Pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb" satisfied condition "running"
    STEP: creating a file in subpath 04/26/24 11:56:23.014
    Apr 26 11:56:23.020: INFO: ExecWithOptions {Command:[/bin/sh -c touch /volume_mount/mypath/foo/test.log] Namespace:var-expansion-2016 PodName:var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:56:23.020: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:56:23.021: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:56:23.021: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/var-expansion-2016/pods/var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb/exec?command=%2Fbin%2Fsh&command=-c&command=touch+%2Fvolume_mount%2Fmypath%2Ffoo%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: test for file in mounted path 04/26/24 11:56:23.357
    Apr 26 11:56:23.363: INFO: ExecWithOptions {Command:[/bin/sh -c test -f /subpath_mount/test.log] Namespace:var-expansion-2016 PodName:var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb ContainerName:dapi-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:56:23.363: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:56:23.363: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:56:23.364: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/var-expansion-2016/pods/var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb/exec?command=%2Fbin%2Fsh&command=-c&command=test+-f+%2Fsubpath_mount%2Ftest.log&container=dapi-container&container=dapi-container&stderr=true&stdout=true)
    STEP: updating the annotation value 04/26/24 11:56:23.885
    Apr 26 11:56:24.404: INFO: Successfully updated pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb"
    STEP: waiting for annotated pod running 04/26/24 11:56:24.404
    Apr 26 11:56:24.404: INFO: Waiting up to 2m0s for pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb" in namespace "var-expansion-2016" to be "running"
    Apr 26 11:56:24.411: INFO: Pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb": Phase="Running", Reason="", readiness=true. Elapsed: 6.03453ms
    Apr 26 11:56:24.411: INFO: Pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb" satisfied condition "running"
    STEP: deleting the pod gracefully 04/26/24 11:56:24.411
    Apr 26 11:56:24.411: INFO: Deleting pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb" in namespace "var-expansion-2016"
    Apr 26 11:56:24.421: INFO: Wait up to 5m0s for pod "var-expansion-9644e1b5-0206-44b9-8656-556a45c378cb" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 26 11:56:58.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2016" for this suite. 04/26/24 11:56:58.447
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:56:58.455
Apr 26 11:56:58.455: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:56:58.456
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:56:58.473
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:56:58.479
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67
STEP: Creating a pod to test downward API volume plugin 04/26/24 11:56:58.487
Apr 26 11:56:58.504: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129" in namespace "projected-6653" to be "Succeeded or Failed"
Apr 26 11:56:58.533: INFO: Pod "downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129": Phase="Pending", Reason="", readiness=false. Elapsed: 29.612226ms
Apr 26 11:57:00.541: INFO: Pod "downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037078753s
Apr 26 11:57:02.540: INFO: Pod "downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036127618s
STEP: Saw pod success 04/26/24 11:57:02.54
Apr 26 11:57:02.540: INFO: Pod "downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129" satisfied condition "Succeeded or Failed"
Apr 26 11:57:02.544: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129 container client-container: <nil>
STEP: delete the pod 04/26/24 11:57:02.564
Apr 26 11:57:02.578: INFO: Waiting for pod downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129 to disappear
Apr 26 11:57:02.585: INFO: Pod downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 26 11:57:02.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6653" for this suite. 04/26/24 11:57:02.596
{"msg":"PASSED [sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":205,"skipped":3821,"failed":0}
------------------------------
â€¢ [4.148 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:56:58.455
    Apr 26 11:56:58.455: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:56:58.456
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:56:58.473
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:56:58.479
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:67
    STEP: Creating a pod to test downward API volume plugin 04/26/24 11:56:58.487
    Apr 26 11:56:58.504: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129" in namespace "projected-6653" to be "Succeeded or Failed"
    Apr 26 11:56:58.533: INFO: Pod "downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129": Phase="Pending", Reason="", readiness=false. Elapsed: 29.612226ms
    Apr 26 11:57:00.541: INFO: Pod "downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037078753s
    Apr 26 11:57:02.540: INFO: Pod "downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036127618s
    STEP: Saw pod success 04/26/24 11:57:02.54
    Apr 26 11:57:02.540: INFO: Pod "downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129" satisfied condition "Succeeded or Failed"
    Apr 26 11:57:02.544: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129 container client-container: <nil>
    STEP: delete the pod 04/26/24 11:57:02.564
    Apr 26 11:57:02.578: INFO: Waiting for pod downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129 to disappear
    Apr 26 11:57:02.585: INFO: Pod downwardapi-volume-7ef390bc-3319-4bcd-8040-0b6325a64129 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 26 11:57:02.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-6653" for this suite. 04/26/24 11:57:02.596
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:02.606
Apr 26 11:57:02.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:57:02.607
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:02.622
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:02.629
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83
STEP: Creating a pod to test downward API volume plugin 04/26/24 11:57:02.636
Apr 26 11:57:02.650: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb" in namespace "projected-3582" to be "Succeeded or Failed"
Apr 26 11:57:02.658: INFO: Pod "downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.320853ms
Apr 26 11:57:04.665: INFO: Pod "downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014969957s
Apr 26 11:57:06.667: INFO: Pod "downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016984812s
STEP: Saw pod success 04/26/24 11:57:06.667
Apr 26 11:57:06.667: INFO: Pod "downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb" satisfied condition "Succeeded or Failed"
Apr 26 11:57:06.671: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb container client-container: <nil>
STEP: delete the pod 04/26/24 11:57:06.685
Apr 26 11:57:06.702: INFO: Waiting for pod downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb to disappear
Apr 26 11:57:06.709: INFO: Pod downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 26 11:57:06.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3582" for this suite. 04/26/24 11:57:06.718
{"msg":"PASSED [sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":206,"skipped":3851,"failed":0}
------------------------------
â€¢ [4.118 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:02.606
    Apr 26 11:57:02.606: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:57:02.607
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:02.622
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:02.629
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:83
    STEP: Creating a pod to test downward API volume plugin 04/26/24 11:57:02.636
    Apr 26 11:57:02.650: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb" in namespace "projected-3582" to be "Succeeded or Failed"
    Apr 26 11:57:02.658: INFO: Pod "downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.320853ms
    Apr 26 11:57:04.665: INFO: Pod "downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014969957s
    Apr 26 11:57:06.667: INFO: Pod "downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016984812s
    STEP: Saw pod success 04/26/24 11:57:06.667
    Apr 26 11:57:06.667: INFO: Pod "downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb" satisfied condition "Succeeded or Failed"
    Apr 26 11:57:06.671: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb container client-container: <nil>
    STEP: delete the pod 04/26/24 11:57:06.685
    Apr 26 11:57:06.702: INFO: Waiting for pod downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb to disappear
    Apr 26 11:57:06.709: INFO: Pod downwardapi-volume-22f23e52-d761-4fcc-ad43-508761ca9fdb no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 26 11:57:06.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3582" for this suite. 04/26/24 11:57:06.718
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a pod with privileged
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:06.726
Apr 26 11:57:06.726: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename security-context-test 04/26/24 11:57:06.726
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:06.743
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:06.75
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:527
Apr 26 11:57:06.771: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-e242f5d5-5655-48e0-a335-5da2428794a5" in namespace "security-context-test-2777" to be "Succeeded or Failed"
Apr 26 11:57:06.780: INFO: Pod "busybox-privileged-false-e242f5d5-5655-48e0-a335-5da2428794a5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.486823ms
Apr 26 11:57:08.789: INFO: Pod "busybox-privileged-false-e242f5d5-5655-48e0-a335-5da2428794a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017550624s
Apr 26 11:57:10.789: INFO: Pod "busybox-privileged-false-e242f5d5-5655-48e0-a335-5da2428794a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018152348s
Apr 26 11:57:10.789: INFO: Pod "busybox-privileged-false-e242f5d5-5655-48e0-a335-5da2428794a5" satisfied condition "Succeeded or Failed"
Apr 26 11:57:10.806: INFO: Got logs for pod "busybox-privileged-false-e242f5d5-5655-48e0-a335-5da2428794a5": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 26 11:57:10.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2777" for this suite. 04/26/24 11:57:10.817
{"msg":"PASSED [sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]","completed":207,"skipped":3863,"failed":0}
------------------------------
â€¢ [4.101 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a pod with privileged
  test/e2e/common/node/security_context.go:490
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:527

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:06.726
    Apr 26 11:57:06.726: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename security-context-test 04/26/24 11:57:06.726
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:06.743
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:06.75
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:527
    Apr 26 11:57:06.771: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-e242f5d5-5655-48e0-a335-5da2428794a5" in namespace "security-context-test-2777" to be "Succeeded or Failed"
    Apr 26 11:57:06.780: INFO: Pod "busybox-privileged-false-e242f5d5-5655-48e0-a335-5da2428794a5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.486823ms
    Apr 26 11:57:08.789: INFO: Pod "busybox-privileged-false-e242f5d5-5655-48e0-a335-5da2428794a5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017550624s
    Apr 26 11:57:10.789: INFO: Pod "busybox-privileged-false-e242f5d5-5655-48e0-a335-5da2428794a5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018152348s
    Apr 26 11:57:10.789: INFO: Pod "busybox-privileged-false-e242f5d5-5655-48e0-a335-5da2428794a5" satisfied condition "Succeeded or Failed"
    Apr 26 11:57:10.806: INFO: Got logs for pod "busybox-privileged-false-e242f5d5-5655-48e0-a335-5da2428794a5": "ip: RTNETLINK answers: Operation not permitted\n"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 26 11:57:10.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-2777" for this suite. 04/26/24 11:57:10.817
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:10.827
Apr 26 11:57:10.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:57:10.828
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:10.851
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:10.861
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234
STEP: Creating a pod to test downward API volume plugin 04/26/24 11:57:10.871
Apr 26 11:57:10.884: INFO: Waiting up to 5m0s for pod "downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb" in namespace "projected-528" to be "Succeeded or Failed"
Apr 26 11:57:10.895: INFO: Pod "downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.871759ms
Apr 26 11:57:12.904: INFO: Pod "downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020103679s
Apr 26 11:57:14.904: INFO: Pod "downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020018804s
STEP: Saw pod success 04/26/24 11:57:14.904
Apr 26 11:57:14.904: INFO: Pod "downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb" satisfied condition "Succeeded or Failed"
Apr 26 11:57:14.911: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb container client-container: <nil>
STEP: delete the pod 04/26/24 11:57:14.925
Apr 26 11:57:14.982: INFO: Waiting for pod downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb to disappear
Apr 26 11:57:14.990: INFO: Pod downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 26 11:57:14.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-528" for this suite. 04/26/24 11:57:15.002
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]","completed":208,"skipped":3866,"failed":0}
------------------------------
â€¢ [4.180 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory request [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:234

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:10.827
    Apr 26 11:57:10.827: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:57:10.828
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:10.851
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:10.861
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory request [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:234
    STEP: Creating a pod to test downward API volume plugin 04/26/24 11:57:10.871
    Apr 26 11:57:10.884: INFO: Waiting up to 5m0s for pod "downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb" in namespace "projected-528" to be "Succeeded or Failed"
    Apr 26 11:57:10.895: INFO: Pod "downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.871759ms
    Apr 26 11:57:12.904: INFO: Pod "downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020103679s
    Apr 26 11:57:14.904: INFO: Pod "downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020018804s
    STEP: Saw pod success 04/26/24 11:57:14.904
    Apr 26 11:57:14.904: INFO: Pod "downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb" satisfied condition "Succeeded or Failed"
    Apr 26 11:57:14.911: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb container client-container: <nil>
    STEP: delete the pod 04/26/24 11:57:14.925
    Apr 26 11:57:14.982: INFO: Waiting for pod downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb to disappear
    Apr 26 11:57:14.990: INFO: Pod downwardapi-volume-24a32bf3-4e51-4961-8813-84aae951c0cb no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 26 11:57:14.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-528" for this suite. 04/26/24 11:57:15.002
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:15.008
Apr 26 11:57:15.008: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-runtime 04/26/24 11:57:15.009
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:15.026
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:15.032
[It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:231
STEP: create the container 04/26/24 11:57:15.039
STEP: wait for the container to reach Succeeded 04/26/24 11:57:15.053
STEP: get the container status 04/26/24 11:57:19.113
STEP: the container should be terminated 04/26/24 11:57:19.127
STEP: the termination message should be set 04/26/24 11:57:19.127
Apr 26 11:57:19.127: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container 04/26/24 11:57:19.127
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 26 11:57:19.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4652" for this suite. 04/26/24 11:57:19.158
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":209,"skipped":3879,"failed":0}
------------------------------
â€¢ [4.158 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:15.008
    Apr 26 11:57:15.008: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-runtime 04/26/24 11:57:15.009
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:15.026
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:15.032
    [It] should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:231
    STEP: create the container 04/26/24 11:57:15.039
    STEP: wait for the container to reach Succeeded 04/26/24 11:57:15.053
    STEP: get the container status 04/26/24 11:57:19.113
    STEP: the container should be terminated 04/26/24 11:57:19.127
    STEP: the termination message should be set 04/26/24 11:57:19.127
    Apr 26 11:57:19.127: INFO: Expected: &{} to match Container's Termination Message:  --
    STEP: delete the container 04/26/24 11:57:19.127
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 26 11:57:19.149: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-4652" for this suite. 04/26/24 11:57:19.158
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:19.171
Apr 26 11:57:19.171: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:57:19.171
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:19.202
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:19.21
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173
STEP: Creating configMap with name cm-test-opt-del-1a494e29-8b0a-435a-8eb9-b4fb146737fb 04/26/24 11:57:19.226
STEP: Creating configMap with name cm-test-opt-upd-8eba4bdf-7e1e-477e-a0fa-80d6b5404166 04/26/24 11:57:19.231
STEP: Creating the pod 04/26/24 11:57:19.237
Apr 26 11:57:19.251: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a6620c9c-706b-4246-b2a8-e453c1773465" in namespace "projected-7567" to be "running and ready"
Apr 26 11:57:19.259: INFO: Pod "pod-projected-configmaps-a6620c9c-706b-4246-b2a8-e453c1773465": Phase="Pending", Reason="", readiness=false. Elapsed: 8.268304ms
Apr 26 11:57:19.259: INFO: The phase of Pod pod-projected-configmaps-a6620c9c-706b-4246-b2a8-e453c1773465 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:57:21.267: INFO: Pod "pod-projected-configmaps-a6620c9c-706b-4246-b2a8-e453c1773465": Phase="Running", Reason="", readiness=true. Elapsed: 2.016187821s
Apr 26 11:57:21.267: INFO: The phase of Pod pod-projected-configmaps-a6620c9c-706b-4246-b2a8-e453c1773465 is Running (Ready = true)
Apr 26 11:57:21.267: INFO: Pod "pod-projected-configmaps-a6620c9c-706b-4246-b2a8-e453c1773465" satisfied condition "running and ready"
STEP: Deleting configmap cm-test-opt-del-1a494e29-8b0a-435a-8eb9-b4fb146737fb 04/26/24 11:57:21.459
STEP: Updating configmap cm-test-opt-upd-8eba4bdf-7e1e-477e-a0fa-80d6b5404166 04/26/24 11:57:21.467
STEP: Creating configMap with name cm-test-opt-create-1ee7140c-cbea-45e2-ba2b-46c550cc5b2f 04/26/24 11:57:21.473
STEP: waiting to observe update in volume 04/26/24 11:57:21.479
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 26 11:57:23.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7567" for this suite. 04/26/24 11:57:23.767
{"msg":"PASSED [sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":210,"skipped":3988,"failed":0}
------------------------------
â€¢ [4.604 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:173

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:19.171
    Apr 26 11:57:19.171: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:57:19.171
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:19.202
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:19.21
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:173
    STEP: Creating configMap with name cm-test-opt-del-1a494e29-8b0a-435a-8eb9-b4fb146737fb 04/26/24 11:57:19.226
    STEP: Creating configMap with name cm-test-opt-upd-8eba4bdf-7e1e-477e-a0fa-80d6b5404166 04/26/24 11:57:19.231
    STEP: Creating the pod 04/26/24 11:57:19.237
    Apr 26 11:57:19.251: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a6620c9c-706b-4246-b2a8-e453c1773465" in namespace "projected-7567" to be "running and ready"
    Apr 26 11:57:19.259: INFO: Pod "pod-projected-configmaps-a6620c9c-706b-4246-b2a8-e453c1773465": Phase="Pending", Reason="", readiness=false. Elapsed: 8.268304ms
    Apr 26 11:57:19.259: INFO: The phase of Pod pod-projected-configmaps-a6620c9c-706b-4246-b2a8-e453c1773465 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:57:21.267: INFO: Pod "pod-projected-configmaps-a6620c9c-706b-4246-b2a8-e453c1773465": Phase="Running", Reason="", readiness=true. Elapsed: 2.016187821s
    Apr 26 11:57:21.267: INFO: The phase of Pod pod-projected-configmaps-a6620c9c-706b-4246-b2a8-e453c1773465 is Running (Ready = true)
    Apr 26 11:57:21.267: INFO: Pod "pod-projected-configmaps-a6620c9c-706b-4246-b2a8-e453c1773465" satisfied condition "running and ready"
    STEP: Deleting configmap cm-test-opt-del-1a494e29-8b0a-435a-8eb9-b4fb146737fb 04/26/24 11:57:21.459
    STEP: Updating configmap cm-test-opt-upd-8eba4bdf-7e1e-477e-a0fa-80d6b5404166 04/26/24 11:57:21.467
    STEP: Creating configMap with name cm-test-opt-create-1ee7140c-cbea-45e2-ba2b-46c550cc5b2f 04/26/24 11:57:21.473
    STEP: waiting to observe update in volume 04/26/24 11:57:21.479
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 26 11:57:23.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-7567" for this suite. 04/26/24 11:57:23.767
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label
  should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:23.775
Apr 26 11:57:23.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 11:57:23.776
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:23.796
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:23.802
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1492
STEP: creating the pod 04/26/24 11:57:23.808
Apr 26 11:57:23.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 create -f -'
Apr 26 11:57:24.424: INFO: stderr: ""
Apr 26 11:57:24.424: INFO: stdout: "pod/pause created\n"
Apr 26 11:57:24.424: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 26 11:57:24.424: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2642" to be "running and ready"
Apr 26 11:57:24.432: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.851081ms
Apr 26 11:57:24.432: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j' to be 'Running' but was 'Pending'
Apr 26 11:57:26.439: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.014981723s
Apr 26 11:57:26.439: INFO: Pod "pause" satisfied condition "running and ready"
Apr 26 11:57:26.439: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  test/e2e/kubectl/kubectl.go:1507
STEP: adding the label testing-label with value testing-label-value to a pod 04/26/24 11:57:26.439
Apr 26 11:57:26.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 label pods pause testing-label=testing-label-value'
Apr 26 11:57:26.519: INFO: stderr: ""
Apr 26 11:57:26.519: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value 04/26/24 11:57:26.519
Apr 26 11:57:26.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 get pod pause -L testing-label'
Apr 26 11:57:26.588: INFO: stderr: ""
Apr 26 11:57:26.589: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod 04/26/24 11:57:26.589
Apr 26 11:57:26.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 label pods pause testing-label-'
Apr 26 11:57:26.669: INFO: stderr: ""
Apr 26 11:57:26.669: INFO: stdout: "pod/pause unlabeled\n"
STEP: verifying the pod doesn't have the label testing-label 04/26/24 11:57:26.669
Apr 26 11:57:26.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 get pod pause -L testing-label'
Apr 26 11:57:26.737: INFO: stderr: ""
Apr 26 11:57:26.737: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  test/e2e/kubectl/kubectl.go:1498
STEP: using delete to clean up resources 04/26/24 11:57:26.737
Apr 26 11:57:26.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 delete --grace-period=0 --force -f -'
Apr 26 11:57:26.804: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 26 11:57:26.804: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 26 11:57:26.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 get rc,svc -l name=pause --no-headers'
Apr 26 11:57:26.876: INFO: stderr: "No resources found in kubectl-2642 namespace.\n"
Apr 26 11:57:26.876: INFO: stdout: ""
Apr 26 11:57:26.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 26 11:57:26.947: INFO: stderr: ""
Apr 26 11:57:26.947: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 11:57:26.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2642" for this suite. 04/26/24 11:57:26.96
{"msg":"PASSED [sig-cli] Kubectl client Kubectl label should update the label on a resource  [Conformance]","completed":211,"skipped":3999,"failed":0}
------------------------------
â€¢ [3.192 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl label
  test/e2e/kubectl/kubectl.go:1490
    should update the label on a resource  [Conformance]
    test/e2e/kubectl/kubectl.go:1507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:23.775
    Apr 26 11:57:23.775: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 11:57:23.776
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:23.796
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:23.802
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1492
    STEP: creating the pod 04/26/24 11:57:23.808
    Apr 26 11:57:23.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 create -f -'
    Apr 26 11:57:24.424: INFO: stderr: ""
    Apr 26 11:57:24.424: INFO: stdout: "pod/pause created\n"
    Apr 26 11:57:24.424: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
    Apr 26 11:57:24.424: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2642" to be "running and ready"
    Apr 26 11:57:24.432: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 7.851081ms
    Apr 26 11:57:24.432: INFO: Error evaluating pod condition running and ready: want pod 'pause' on 'shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j' to be 'Running' but was 'Pending'
    Apr 26 11:57:26.439: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.014981723s
    Apr 26 11:57:26.439: INFO: Pod "pause" satisfied condition "running and ready"
    Apr 26 11:57:26.439: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
    [It] should update the label on a resource  [Conformance]
      test/e2e/kubectl/kubectl.go:1507
    STEP: adding the label testing-label with value testing-label-value to a pod 04/26/24 11:57:26.439
    Apr 26 11:57:26.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 label pods pause testing-label=testing-label-value'
    Apr 26 11:57:26.519: INFO: stderr: ""
    Apr 26 11:57:26.519: INFO: stdout: "pod/pause labeled\n"
    STEP: verifying the pod has the label testing-label with the value testing-label-value 04/26/24 11:57:26.519
    Apr 26 11:57:26.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 get pod pause -L testing-label'
    Apr 26 11:57:26.588: INFO: stderr: ""
    Apr 26 11:57:26.589: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
    STEP: removing the label testing-label of a pod 04/26/24 11:57:26.589
    Apr 26 11:57:26.589: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 label pods pause testing-label-'
    Apr 26 11:57:26.669: INFO: stderr: ""
    Apr 26 11:57:26.669: INFO: stdout: "pod/pause unlabeled\n"
    STEP: verifying the pod doesn't have the label testing-label 04/26/24 11:57:26.669
    Apr 26 11:57:26.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 get pod pause -L testing-label'
    Apr 26 11:57:26.737: INFO: stderr: ""
    Apr 26 11:57:26.737: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
    [AfterEach] Kubectl label
      test/e2e/kubectl/kubectl.go:1498
    STEP: using delete to clean up resources 04/26/24 11:57:26.737
    Apr 26 11:57:26.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 delete --grace-period=0 --force -f -'
    Apr 26 11:57:26.804: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 26 11:57:26.804: INFO: stdout: "pod \"pause\" force deleted\n"
    Apr 26 11:57:26.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 get rc,svc -l name=pause --no-headers'
    Apr 26 11:57:26.876: INFO: stderr: "No resources found in kubectl-2642 namespace.\n"
    Apr 26 11:57:26.876: INFO: stdout: ""
    Apr 26 11:57:26.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2642 get pods -l name=pause -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
    Apr 26 11:57:26.947: INFO: stderr: ""
    Apr 26 11:57:26.947: INFO: stdout: ""
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 11:57:26.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2642" for this suite. 04/26/24 11:57:26.96
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] DisruptionController
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:26.969
Apr 26 11:57:26.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename disruption 04/26/24 11:57:26.971
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:26.988
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:26.995
[BeforeEach] [sig-apps] DisruptionController
  test/e2e/apps/disruption.go:71
[It] should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140
STEP: Waiting for the pdb to be processed 04/26/24 11:57:27.015
STEP: Waiting for all pods to be running 04/26/24 11:57:27.066
Apr 26 11:57:27.083: INFO: running pods: 0 < 3
[AfterEach] [sig-apps] DisruptionController
  test/e2e/framework/framework.go:187
Apr 26 11:57:29.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "disruption-2002" for this suite. 04/26/24 11:57:29.109
{"msg":"PASSED [sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]","completed":212,"skipped":4049,"failed":0}
------------------------------
â€¢ [2.145 seconds]
[sig-apps] DisruptionController
test/e2e/apps/framework.go:23
  should observe PodDisruptionBudget status updated [Conformance]
  test/e2e/apps/disruption.go:140

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:26.969
    Apr 26 11:57:26.970: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename disruption 04/26/24 11:57:26.971
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:26.988
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:26.995
    [BeforeEach] [sig-apps] DisruptionController
      test/e2e/apps/disruption.go:71
    [It] should observe PodDisruptionBudget status updated [Conformance]
      test/e2e/apps/disruption.go:140
    STEP: Waiting for the pdb to be processed 04/26/24 11:57:27.015
    STEP: Waiting for all pods to be running 04/26/24 11:57:27.066
    Apr 26 11:57:27.083: INFO: running pods: 0 < 3
    [AfterEach] [sig-apps] DisruptionController
      test/e2e/framework/framework.go:187
    Apr 26 11:57:29.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "disruption-2002" for this suite. 04/26/24 11:57:29.109
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:29.115
Apr 26 11:57:29.115: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename svcaccounts 04/26/24 11:57:29.116
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:29.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:29.145
[It] should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75
Apr 26 11:57:29.214: INFO: Waiting up to 5m0s for pod "pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd" in namespace "svcaccounts-1246" to be "running"
Apr 26 11:57:29.220: INFO: Pod "pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.883195ms
Apr 26 11:57:31.226: INFO: Pod "pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd": Phase="Running", Reason="", readiness=true. Elapsed: 2.01202153s
Apr 26 11:57:31.226: INFO: Pod "pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd" satisfied condition "running"
STEP: reading a file in the container 04/26/24 11:57:31.226
Apr 26 11:57:31.227: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1246 pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container 04/26/24 11:57:31.79
Apr 26 11:57:31.790: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1246 pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container 04/26/24 11:57:32.326
Apr 26 11:57:32.327: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1246 pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
Apr 26 11:57:32.859: INFO: Got root ca configmap in namespace "svcaccounts-1246"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 26 11:57:32.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1246" for this suite. 04/26/24 11:57:32.879
{"msg":"PASSED [sig-auth] ServiceAccounts should mount an API token into pods  [Conformance]","completed":213,"skipped":4056,"failed":0}
------------------------------
â€¢ [3.772 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  test/e2e/auth/service_accounts.go:75

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:29.115
    Apr 26 11:57:29.115: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename svcaccounts 04/26/24 11:57:29.116
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:29.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:29.145
    [It] should mount an API token into pods  [Conformance]
      test/e2e/auth/service_accounts.go:75
    Apr 26 11:57:29.214: INFO: Waiting up to 5m0s for pod "pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd" in namespace "svcaccounts-1246" to be "running"
    Apr 26 11:57:29.220: INFO: Pod "pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd": Phase="Pending", Reason="", readiness=false. Elapsed: 5.883195ms
    Apr 26 11:57:31.226: INFO: Pod "pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd": Phase="Running", Reason="", readiness=true. Elapsed: 2.01202153s
    Apr 26 11:57:31.226: INFO: Pod "pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd" satisfied condition "running"
    STEP: reading a file in the container 04/26/24 11:57:31.226
    Apr 26 11:57:31.227: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1246 pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
    STEP: reading a file in the container 04/26/24 11:57:31.79
    Apr 26 11:57:31.790: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1246 pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
    STEP: reading a file in the container 04/26/24 11:57:32.326
    Apr 26 11:57:32.327: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1246 pod-service-account-6b76a4d3-56ed-4c15-9ec5-c95ef38ff9bd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
    Apr 26 11:57:32.859: INFO: Got root ca configmap in namespace "svcaccounts-1246"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 26 11:57:32.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-1246" for this suite. 04/26/24 11:57:32.879
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:32.888
Apr 26 11:57:32.888: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename replication-controller 04/26/24 11:57:32.889
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:32.906
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:32.914
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109
STEP: creating a ReplicationController 04/26/24 11:57:32.926
STEP: waiting for RC to be added 04/26/24 11:57:32.933
STEP: waiting for available Replicas 04/26/24 11:57:32.933
STEP: patching ReplicationController 04/26/24 11:57:33.761
STEP: waiting for RC to be modified 04/26/24 11:57:33.778
STEP: patching ReplicationController status 04/26/24 11:57:33.778
STEP: waiting for RC to be modified 04/26/24 11:57:33.829
STEP: waiting for available Replicas 04/26/24 11:57:33.829
STEP: fetching ReplicationController status 04/26/24 11:57:33.832
STEP: patching ReplicationController scale 04/26/24 11:57:33.851
STEP: waiting for RC to be modified 04/26/24 11:57:33.887
STEP: waiting for ReplicationController's scale to be the max amount 04/26/24 11:57:33.887
STEP: fetching ReplicationController; ensuring that it's patched 04/26/24 11:57:35.821
STEP: updating ReplicationController status 04/26/24 11:57:35.826
STEP: waiting for RC to be modified 04/26/24 11:57:35.836
STEP: listing all ReplicationControllers 04/26/24 11:57:35.836
STEP: checking that ReplicationController has expected values 04/26/24 11:57:35.843
STEP: deleting ReplicationControllers by collection 04/26/24 11:57:35.844
STEP: waiting for ReplicationController to have a DELETED watchEvent 04/26/24 11:57:35.855
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 26 11:57:35.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6256" for this suite. 04/26/24 11:57:35.927
{"msg":"PASSED [sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]","completed":214,"skipped":4089,"failed":0}
------------------------------
â€¢ [3.046 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should test the lifecycle of a ReplicationController [Conformance]
  test/e2e/apps/rc.go:109

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:32.888
    Apr 26 11:57:32.888: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename replication-controller 04/26/24 11:57:32.889
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:32.906
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:32.914
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should test the lifecycle of a ReplicationController [Conformance]
      test/e2e/apps/rc.go:109
    STEP: creating a ReplicationController 04/26/24 11:57:32.926
    STEP: waiting for RC to be added 04/26/24 11:57:32.933
    STEP: waiting for available Replicas 04/26/24 11:57:32.933
    STEP: patching ReplicationController 04/26/24 11:57:33.761
    STEP: waiting for RC to be modified 04/26/24 11:57:33.778
    STEP: patching ReplicationController status 04/26/24 11:57:33.778
    STEP: waiting for RC to be modified 04/26/24 11:57:33.829
    STEP: waiting for available Replicas 04/26/24 11:57:33.829
    STEP: fetching ReplicationController status 04/26/24 11:57:33.832
    STEP: patching ReplicationController scale 04/26/24 11:57:33.851
    STEP: waiting for RC to be modified 04/26/24 11:57:33.887
    STEP: waiting for ReplicationController's scale to be the max amount 04/26/24 11:57:33.887
    STEP: fetching ReplicationController; ensuring that it's patched 04/26/24 11:57:35.821
    STEP: updating ReplicationController status 04/26/24 11:57:35.826
    STEP: waiting for RC to be modified 04/26/24 11:57:35.836
    STEP: listing all ReplicationControllers 04/26/24 11:57:35.836
    STEP: checking that ReplicationController has expected values 04/26/24 11:57:35.843
    STEP: deleting ReplicationControllers by collection 04/26/24 11:57:35.844
    STEP: waiting for ReplicationController to have a DELETED watchEvent 04/26/24 11:57:35.855
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 26 11:57:35.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-6256" for this suite. 04/26/24 11:57:35.927
  << End Captured GinkgoWriter Output
------------------------------
[sig-cli] Kubectl client Kubectl expose
  should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:35.934
Apr 26 11:57:35.935: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 11:57:35.936
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:35.949
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:35.954
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create services for rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1413
STEP: creating Agnhost RC 04/26/24 11:57:35.961
Apr 26 11:57:35.961: INFO: namespace kubectl-9563
Apr 26 11:57:35.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9563 create -f -'
Apr 26 11:57:36.120: INFO: stderr: ""
Apr 26 11:57:36.120: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/26/24 11:57:36.12
Apr 26 11:57:37.126: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 26 11:57:37.126: INFO: Found 0 / 1
Apr 26 11:57:38.126: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 26 11:57:38.126: INFO: Found 1 / 1
Apr 26 11:57:38.126: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 26 11:57:38.131: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 26 11:57:38.131: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 26 11:57:38.131: INFO: wait on agnhost-primary startup in kubectl-9563 
Apr 26 11:57:38.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9563 logs agnhost-primary-k7zg7 agnhost-primary'
Apr 26 11:57:38.217: INFO: stderr: ""
Apr 26 11:57:38.217: INFO: stdout: "Paused\n"
STEP: exposing RC 04/26/24 11:57:38.217
Apr 26 11:57:38.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9563 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
Apr 26 11:57:38.305: INFO: stderr: ""
Apr 26 11:57:38.305: INFO: stdout: "service/rm2 exposed\n"
Apr 26 11:57:38.364: INFO: Service rm2 in namespace kubectl-9563 found.
STEP: exposing service 04/26/24 11:57:40.378
Apr 26 11:57:40.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9563 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
Apr 26 11:57:40.460: INFO: stderr: ""
Apr 26 11:57:40.460: INFO: stdout: "service/rm3 exposed\n"
Apr 26 11:57:40.466: INFO: Service rm3 in namespace kubectl-9563 found.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 11:57:42.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9563" for this suite. 04/26/24 11:57:42.488
{"msg":"PASSED [sig-cli] Kubectl client Kubectl expose should create services for rc  [Conformance]","completed":215,"skipped":4089,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.561 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl expose
  test/e2e/kubectl/kubectl.go:1407
    should create services for rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1413

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:35.934
    Apr 26 11:57:35.935: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 11:57:35.936
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:35.949
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:35.954
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create services for rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1413
    STEP: creating Agnhost RC 04/26/24 11:57:35.961
    Apr 26 11:57:35.961: INFO: namespace kubectl-9563
    Apr 26 11:57:35.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9563 create -f -'
    Apr 26 11:57:36.120: INFO: stderr: ""
    Apr 26 11:57:36.120: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/26/24 11:57:36.12
    Apr 26 11:57:37.126: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 26 11:57:37.126: INFO: Found 0 / 1
    Apr 26 11:57:38.126: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 26 11:57:38.126: INFO: Found 1 / 1
    Apr 26 11:57:38.126: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Apr 26 11:57:38.131: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 26 11:57:38.131: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 26 11:57:38.131: INFO: wait on agnhost-primary startup in kubectl-9563 
    Apr 26 11:57:38.131: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9563 logs agnhost-primary-k7zg7 agnhost-primary'
    Apr 26 11:57:38.217: INFO: stderr: ""
    Apr 26 11:57:38.217: INFO: stdout: "Paused\n"
    STEP: exposing RC 04/26/24 11:57:38.217
    Apr 26 11:57:38.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9563 expose rc agnhost-primary --name=rm2 --port=1234 --target-port=6379'
    Apr 26 11:57:38.305: INFO: stderr: ""
    Apr 26 11:57:38.305: INFO: stdout: "service/rm2 exposed\n"
    Apr 26 11:57:38.364: INFO: Service rm2 in namespace kubectl-9563 found.
    STEP: exposing service 04/26/24 11:57:40.378
    Apr 26 11:57:40.378: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-9563 expose service rm2 --name=rm3 --port=2345 --target-port=6379'
    Apr 26 11:57:40.460: INFO: stderr: ""
    Apr 26 11:57:40.460: INFO: stdout: "service/rm3 exposed\n"
    Apr 26 11:57:40.466: INFO: Service rm3 in namespace kubectl-9563 found.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 11:57:42.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-9563" for this suite. 04/26/24 11:57:42.488
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-apps] ControllerRevision [Serial]
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:42.498
Apr 26 11:57:42.498: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename controllerrevisions 04/26/24 11:57:42.499
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:42.514
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:42.52
[BeforeEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:93
[It] should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124
STEP: Creating DaemonSet "e2e-2tm4q-daemon-set" 04/26/24 11:57:42.579
STEP: Check that daemon pods launch on every node of the cluster. 04/26/24 11:57:42.587
Apr 26 11:57:42.601: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 0
Apr 26 11:57:42.601: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:57:43.686: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 2
Apr 26 11:57:43.686: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:57:44.622: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 4
Apr 26 11:57:44.622: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:57:45.618: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 4
Apr 26 11:57:45.618: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:57:46.624: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 4
Apr 26 11:57:46.624: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:57:47.655: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 5
Apr 26 11:57:47.655: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset e2e-2tm4q-daemon-set
STEP: Confirm DaemonSet "e2e-2tm4q-daemon-set" successfully created with "daemonset-name=e2e-2tm4q-daemon-set" label 04/26/24 11:57:47.671
STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-2tm4q-daemon-set" 04/26/24 11:57:47.683
Apr 26 11:57:47.689: INFO: Located ControllerRevision: "e2e-2tm4q-daemon-set-7bc9b777b9"
STEP: Patching ControllerRevision "e2e-2tm4q-daemon-set-7bc9b777b9" 04/26/24 11:57:47.693
Apr 26 11:57:47.700: INFO: e2e-2tm4q-daemon-set-7bc9b777b9 has been patched
STEP: Create a new ControllerRevision 04/26/24 11:57:47.7
Apr 26 11:57:47.706: INFO: Created ControllerRevision: e2e-2tm4q-daemon-set-6b984c787c
STEP: Confirm that there are two ControllerRevisions 04/26/24 11:57:47.706
Apr 26 11:57:47.706: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 26 11:57:47.711: INFO: Found 2 ControllerRevisions
STEP: Deleting ControllerRevision "e2e-2tm4q-daemon-set-7bc9b777b9" 04/26/24 11:57:47.711
STEP: Confirm that there is only one ControllerRevision 04/26/24 11:57:47.716
Apr 26 11:57:47.716: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 26 11:57:47.719: INFO: Found 1 ControllerRevisions
STEP: Updating ControllerRevision "e2e-2tm4q-daemon-set-6b984c787c" 04/26/24 11:57:47.722
Apr 26 11:57:47.739: INFO: e2e-2tm4q-daemon-set-6b984c787c has been updated
STEP: Generate another ControllerRevision by patching the Daemonset 04/26/24 11:57:47.739
W0426 11:57:47.751707      23 warnings.go:70] unknown field "updateStrategy"
STEP: Confirm that there are two ControllerRevisions 04/26/24 11:57:47.751
Apr 26 11:57:47.751: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 26 11:57:48.763: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 26 11:57:48.774: INFO: Found 2 ControllerRevisions
STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-2tm4q-daemon-set-6b984c787c=updated" 04/26/24 11:57:48.774
STEP: Confirm that there is only one ControllerRevision 04/26/24 11:57:48.786
Apr 26 11:57:48.786: INFO: Requesting list of ControllerRevisions to confirm quantity
Apr 26 11:57:48.791: INFO: Found 1 ControllerRevisions
Apr 26 11:57:48.795: INFO: ControllerRevision "e2e-2tm4q-daemon-set-cc9c4f58d" has revision 3
[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/apps/controller_revision.go:58
STEP: Deleting DaemonSet "e2e-2tm4q-daemon-set" 04/26/24 11:57:48.8
STEP: deleting DaemonSet.extensions e2e-2tm4q-daemon-set in namespace controllerrevisions-5589, will wait for the garbage collector to delete the pods 04/26/24 11:57:48.8
Apr 26 11:57:48.862: INFO: Deleting DaemonSet.extensions e2e-2tm4q-daemon-set took: 7.006495ms
Apr 26 11:57:48.962: INFO: Terminating DaemonSet.extensions e2e-2tm4q-daemon-set pods took: 100.259408ms
Apr 26 11:57:50.009: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 0
Apr 26 11:57:50.009: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-2tm4q-daemon-set
Apr 26 11:57:50.050: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"37870"},"items":null}

Apr 26 11:57:50.054: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"37870"},"items":null}

[AfterEach] [sig-apps] ControllerRevision [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:57:50.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "controllerrevisions-5589" for this suite. 04/26/24 11:57:50.106
{"msg":"PASSED [sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]","completed":216,"skipped":4092,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.630 seconds]
[sig-apps] ControllerRevision [Serial]
test/e2e/apps/framework.go:23
  should manage the lifecycle of a ControllerRevision [Conformance]
  test/e2e/apps/controller_revision.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:42.498
    Apr 26 11:57:42.498: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename controllerrevisions 04/26/24 11:57:42.499
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:42.514
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:42.52
    [BeforeEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:93
    [It] should manage the lifecycle of a ControllerRevision [Conformance]
      test/e2e/apps/controller_revision.go:124
    STEP: Creating DaemonSet "e2e-2tm4q-daemon-set" 04/26/24 11:57:42.579
    STEP: Check that daemon pods launch on every node of the cluster. 04/26/24 11:57:42.587
    Apr 26 11:57:42.601: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 0
    Apr 26 11:57:42.601: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:57:43.686: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 2
    Apr 26 11:57:43.686: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:57:44.622: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 4
    Apr 26 11:57:44.622: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:57:45.618: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 4
    Apr 26 11:57:45.618: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:57:46.624: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 4
    Apr 26 11:57:46.624: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:57:47.655: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 5
    Apr 26 11:57:47.655: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset e2e-2tm4q-daemon-set
    STEP: Confirm DaemonSet "e2e-2tm4q-daemon-set" successfully created with "daemonset-name=e2e-2tm4q-daemon-set" label 04/26/24 11:57:47.671
    STEP: Listing all ControllerRevisions with label "daemonset-name=e2e-2tm4q-daemon-set" 04/26/24 11:57:47.683
    Apr 26 11:57:47.689: INFO: Located ControllerRevision: "e2e-2tm4q-daemon-set-7bc9b777b9"
    STEP: Patching ControllerRevision "e2e-2tm4q-daemon-set-7bc9b777b9" 04/26/24 11:57:47.693
    Apr 26 11:57:47.700: INFO: e2e-2tm4q-daemon-set-7bc9b777b9 has been patched
    STEP: Create a new ControllerRevision 04/26/24 11:57:47.7
    Apr 26 11:57:47.706: INFO: Created ControllerRevision: e2e-2tm4q-daemon-set-6b984c787c
    STEP: Confirm that there are two ControllerRevisions 04/26/24 11:57:47.706
    Apr 26 11:57:47.706: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 26 11:57:47.711: INFO: Found 2 ControllerRevisions
    STEP: Deleting ControllerRevision "e2e-2tm4q-daemon-set-7bc9b777b9" 04/26/24 11:57:47.711
    STEP: Confirm that there is only one ControllerRevision 04/26/24 11:57:47.716
    Apr 26 11:57:47.716: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 26 11:57:47.719: INFO: Found 1 ControllerRevisions
    STEP: Updating ControllerRevision "e2e-2tm4q-daemon-set-6b984c787c" 04/26/24 11:57:47.722
    Apr 26 11:57:47.739: INFO: e2e-2tm4q-daemon-set-6b984c787c has been updated
    STEP: Generate another ControllerRevision by patching the Daemonset 04/26/24 11:57:47.739
    W0426 11:57:47.751707      23 warnings.go:70] unknown field "updateStrategy"
    STEP: Confirm that there are two ControllerRevisions 04/26/24 11:57:47.751
    Apr 26 11:57:47.751: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 26 11:57:48.763: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 26 11:57:48.774: INFO: Found 2 ControllerRevisions
    STEP: Removing a ControllerRevision via 'DeleteCollection' with labelSelector: "e2e-2tm4q-daemon-set-6b984c787c=updated" 04/26/24 11:57:48.774
    STEP: Confirm that there is only one ControllerRevision 04/26/24 11:57:48.786
    Apr 26 11:57:48.786: INFO: Requesting list of ControllerRevisions to confirm quantity
    Apr 26 11:57:48.791: INFO: Found 1 ControllerRevisions
    Apr 26 11:57:48.795: INFO: ControllerRevision "e2e-2tm4q-daemon-set-cc9c4f58d" has revision 3
    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/apps/controller_revision.go:58
    STEP: Deleting DaemonSet "e2e-2tm4q-daemon-set" 04/26/24 11:57:48.8
    STEP: deleting DaemonSet.extensions e2e-2tm4q-daemon-set in namespace controllerrevisions-5589, will wait for the garbage collector to delete the pods 04/26/24 11:57:48.8
    Apr 26 11:57:48.862: INFO: Deleting DaemonSet.extensions e2e-2tm4q-daemon-set took: 7.006495ms
    Apr 26 11:57:48.962: INFO: Terminating DaemonSet.extensions e2e-2tm4q-daemon-set pods took: 100.259408ms
    Apr 26 11:57:50.009: INFO: Number of nodes with available pods controlled by daemonset e2e-2tm4q-daemon-set: 0
    Apr 26 11:57:50.009: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset e2e-2tm4q-daemon-set
    Apr 26 11:57:50.050: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"37870"},"items":null}

    Apr 26 11:57:50.054: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"37870"},"items":null}

    [AfterEach] [sig-apps] ControllerRevision [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:57:50.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "controllerrevisions-5589" for this suite. 04/26/24 11:57:50.106
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:50.131
Apr 26 11:57:50.132: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 11:57:50.133
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:50.149
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:50.158
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 11:57:50.18
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:57:50.434
STEP: Deploying the webhook pod 04/26/24 11:57:50.442
STEP: Wait for the deployment to be ready 04/26/24 11:57:50.456
Apr 26 11:57:50.465: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 11:57:52.484
STEP: Verifying the service has paired with the endpoint 04/26/24 11:57:52.5
Apr 26 11:57:53.500: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322
Apr 26 11:57:53.507: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9945-crds.webhook.example.com via the AdmissionRegistration API 04/26/24 11:57:54.027
STEP: Creating a custom resource while v1 is storage version 04/26/24 11:57:54.124
STEP: Patching Custom Resource Definition to set v2 as storage 04/26/24 11:57:56.292
STEP: Patching the custom resource while v2 is storage version 04/26/24 11:57:56.305
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 11:57:56.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7650" for this suite. 04/26/24 11:57:56.943
STEP: Destroying namespace "webhook-7650-markers" for this suite. 04/26/24 11:57:56.95
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]","completed":217,"skipped":4101,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.886 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  test/e2e/apimachinery/webhook.go:322

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:50.131
    Apr 26 11:57:50.132: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 11:57:50.133
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:50.149
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:50.158
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 11:57:50.18
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 11:57:50.434
    STEP: Deploying the webhook pod 04/26/24 11:57:50.442
    STEP: Wait for the deployment to be ready 04/26/24 11:57:50.456
    Apr 26 11:57:50.465: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 11:57:52.484
    STEP: Verifying the service has paired with the endpoint 04/26/24 11:57:52.5
    Apr 26 11:57:53.500: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource with different stored version [Conformance]
      test/e2e/apimachinery/webhook.go:322
    Apr 26 11:57:53.507: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9945-crds.webhook.example.com via the AdmissionRegistration API 04/26/24 11:57:54.027
    STEP: Creating a custom resource while v1 is storage version 04/26/24 11:57:54.124
    STEP: Patching Custom Resource Definition to set v2 as storage 04/26/24 11:57:56.292
    STEP: Patching the custom resource while v2 is storage version 04/26/24 11:57:56.305
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 11:57:56.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-7650" for this suite. 04/26/24 11:57:56.943
    STEP: Destroying namespace "webhook-7650-markers" for this suite. 04/26/24 11:57:56.95
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:57:57.018
Apr 26 11:57:57.018: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:57:57.019
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:57.034
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:57.04
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56
STEP: Creating configMap with name projected-configmap-test-volume-0f8623c3-7e3b-4c95-a39b-1868b328236e 04/26/24 11:57:57.047
STEP: Creating a pod to test consume configMaps 04/26/24 11:57:57.051
Apr 26 11:57:57.064: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f" in namespace "projected-8461" to be "Succeeded or Failed"
Apr 26 11:57:57.071: INFO: Pod "pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.58314ms
Apr 26 11:57:59.081: INFO: Pod "pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016797529s
Apr 26 11:58:01.077: INFO: Pod "pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012634814s
STEP: Saw pod success 04/26/24 11:58:01.077
Apr 26 11:58:01.077: INFO: Pod "pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f" satisfied condition "Succeeded or Failed"
Apr 26 11:58:01.082: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:58:01.101
Apr 26 11:58:01.114: INFO: Waiting for pod pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f to disappear
Apr 26 11:58:01.118: INFO: Pod pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 26 11:58:01.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8461" for this suite. 04/26/24 11:58:01.13
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]","completed":218,"skipped":4111,"failed":0}
------------------------------
â€¢ [4.117 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:56

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:57:57.018
    Apr 26 11:57:57.018: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:57:57.019
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:57:57.034
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:57:57.04
    [It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:56
    STEP: Creating configMap with name projected-configmap-test-volume-0f8623c3-7e3b-4c95-a39b-1868b328236e 04/26/24 11:57:57.047
    STEP: Creating a pod to test consume configMaps 04/26/24 11:57:57.051
    Apr 26 11:57:57.064: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f" in namespace "projected-8461" to be "Succeeded or Failed"
    Apr 26 11:57:57.071: INFO: Pod "pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.58314ms
    Apr 26 11:57:59.081: INFO: Pod "pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016797529s
    Apr 26 11:58:01.077: INFO: Pod "pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012634814s
    STEP: Saw pod success 04/26/24 11:58:01.077
    Apr 26 11:58:01.077: INFO: Pod "pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f" satisfied condition "Succeeded or Failed"
    Apr 26 11:58:01.082: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:58:01.101
    Apr 26 11:58:01.114: INFO: Waiting for pod pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f to disappear
    Apr 26 11:58:01.118: INFO: Pod pod-projected-configmaps-0cdeab04-f13e-43cd-9e55-ae86fdea689f no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 26 11:58:01.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8461" for this suite. 04/26/24 11:58:01.13
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:01.137
Apr 26 11:58:01.137: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename daemonsets 04/26/24 11:58:01.137
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:01.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:01.158
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193
Apr 26 11:58:01.216: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes. 04/26/24 11:58:01.221
Apr 26 11:58:01.225: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:58:01.225: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Change node label to blue, check that daemon pod is launched. 04/26/24 11:58:01.225
Apr 26 11:58:01.274: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:58:01.274: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
Apr 26 11:58:02.280: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:58:02.280: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
Apr 26 11:58:03.280: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 26 11:58:03.280: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
STEP: Update the node label to green, and wait for daemons to be unscheduled 04/26/24 11:58:03.285
Apr 26 11:58:03.324: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 26 11:58:03.324: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
Apr 26 11:58:04.330: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:58:04.330: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 04/26/24 11:58:04.33
Apr 26 11:58:04.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:58:04.343: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
Apr 26 11:58:05.350: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:58:05.350: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
Apr 26 11:58:06.353: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:58:06.353: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
Apr 26 11:58:07.351: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 26 11:58:07.351: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/26/24 11:58:07.36
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5972, will wait for the garbage collector to delete the pods 04/26/24 11:58:07.36
Apr 26 11:58:07.423: INFO: Deleting DaemonSet.extensions daemon-set took: 6.927868ms
Apr 26 11:58:07.524: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.121109ms
Apr 26 11:58:09.733: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:58:09.733: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 26 11:58:09.737: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38082"},"items":null}

Apr 26 11:58:09.742: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38082"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:58:09.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5972" for this suite. 04/26/24 11:58:09.82
{"msg":"PASSED [sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]","completed":219,"skipped":4134,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.692 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  test/e2e/apps/daemon_set.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:01.137
    Apr 26 11:58:01.137: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename daemonsets 04/26/24 11:58:01.137
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:01.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:01.158
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should run and stop complex daemon [Conformance]
      test/e2e/apps/daemon_set.go:193
    Apr 26 11:58:01.216: INFO: Creating daemon "daemon-set" with a node selector
    STEP: Initially, daemon pods should not be running on any nodes. 04/26/24 11:58:01.221
    Apr 26 11:58:01.225: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:58:01.225: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Change node label to blue, check that daemon pod is launched. 04/26/24 11:58:01.225
    Apr 26 11:58:01.274: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:58:01.274: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
    Apr 26 11:58:02.280: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:58:02.280: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
    Apr 26 11:58:03.280: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 26 11:58:03.280: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    STEP: Update the node label to green, and wait for daemons to be unscheduled 04/26/24 11:58:03.285
    Apr 26 11:58:03.324: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 26 11:58:03.324: INFO: Number of running nodes: 0, number of available pods: 1 in daemonset daemon-set
    Apr 26 11:58:04.330: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:58:04.330: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate 04/26/24 11:58:04.33
    Apr 26 11:58:04.343: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:58:04.343: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
    Apr 26 11:58:05.350: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:58:05.350: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
    Apr 26 11:58:06.353: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:58:06.353: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw is running 0 daemon pod, expected 1
    Apr 26 11:58:07.351: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 26 11:58:07.351: INFO: Number of running nodes: 1, number of available pods: 1 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/26/24 11:58:07.36
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5972, will wait for the garbage collector to delete the pods 04/26/24 11:58:07.36
    Apr 26 11:58:07.423: INFO: Deleting DaemonSet.extensions daemon-set took: 6.927868ms
    Apr 26 11:58:07.524: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.121109ms
    Apr 26 11:58:09.733: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:58:09.733: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 26 11:58:09.737: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38082"},"items":null}

    Apr 26 11:58:09.742: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38082"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:58:09.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-5972" for this suite. 04/26/24 11:58:09.82
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:09.831
Apr 26 11:58:09.831: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename daemonsets 04/26/24 11:58:09.832
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:09.847
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:09.853
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293
STEP: Creating a simple DaemonSet "daemon-set" 04/26/24 11:58:09.919
STEP: Check that daemon pods launch on every node of the cluster. 04/26/24 11:58:09.925
Apr 26 11:58:09.946: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:58:09.947: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:58:10.971: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Apr 26 11:58:10.971: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j is running 0 daemon pod, expected 1
Apr 26 11:58:11.967: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Apr 26 11:58:11.967: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 04/26/24 11:58:11.971
Apr 26 11:58:12.004: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Apr 26 11:58:12.004: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w is running 0 daemon pod, expected 1
Apr 26 11:58:13.032: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Apr 26 11:58:13.032: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
STEP: Wait for the failed daemon pod to be completely deleted. 04/26/24 11:58:13.032
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/26/24 11:58:13.042
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5118, will wait for the garbage collector to delete the pods 04/26/24 11:58:13.042
Apr 26 11:58:13.108: INFO: Deleting DaemonSet.extensions daemon-set took: 10.371043ms
Apr 26 11:58:13.208: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.382995ms
Apr 26 11:58:16.030: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:58:16.030: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 26 11:58:16.034: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38189"},"items":null}

Apr 26 11:58:16.038: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38189"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:58:16.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5118" for this suite. 04/26/24 11:58:16.115
{"msg":"PASSED [sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]","completed":220,"skipped":4167,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.290 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  test/e2e/apps/daemon_set.go:293

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:09.831
    Apr 26 11:58:09.831: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename daemonsets 04/26/24 11:58:09.832
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:09.847
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:09.853
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should retry creating failed daemon pods [Conformance]
      test/e2e/apps/daemon_set.go:293
    STEP: Creating a simple DaemonSet "daemon-set" 04/26/24 11:58:09.919
    STEP: Check that daemon pods launch on every node of the cluster. 04/26/24 11:58:09.925
    Apr 26 11:58:09.946: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:58:09.947: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:58:10.971: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Apr 26 11:58:10.971: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j is running 0 daemon pod, expected 1
    Apr 26 11:58:11.967: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
    Apr 26 11:58:11.967: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
    STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived. 04/26/24 11:58:11.971
    Apr 26 11:58:12.004: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Apr 26 11:58:12.004: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w is running 0 daemon pod, expected 1
    Apr 26 11:58:13.032: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
    Apr 26 11:58:13.032: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
    STEP: Wait for the failed daemon pod to be completely deleted. 04/26/24 11:58:13.032
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/26/24 11:58:13.042
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5118, will wait for the garbage collector to delete the pods 04/26/24 11:58:13.042
    Apr 26 11:58:13.108: INFO: Deleting DaemonSet.extensions daemon-set took: 10.371043ms
    Apr 26 11:58:13.208: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.382995ms
    Apr 26 11:58:16.030: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:58:16.030: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 26 11:58:16.034: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38189"},"items":null}

    Apr 26 11:58:16.038: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38189"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:58:16.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-5118" for this suite. 04/26/24 11:58:16.115
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:16.122
Apr 26 11:58:16.122: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename replication-controller 04/26/24 11:58:16.123
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:16.163
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:16.17
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66
STEP: Creating replication controller my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172 04/26/24 11:58:16.178
Apr 26 11:58:16.196: INFO: Pod name my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172: Found 0 pods out of 1
Apr 26 11:58:21.205: INFO: Pod name my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172: Found 1 pods out of 1
Apr 26 11:58:21.205: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172" are running
Apr 26 11:58:21.206: INFO: Waiting up to 5m0s for pod "my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172-ch5k9" in namespace "replication-controller-8894" to be "running"
Apr 26 11:58:21.210: INFO: Pod "my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172-ch5k9": Phase="Running", Reason="", readiness=true. Elapsed: 4.320953ms
Apr 26 11:58:21.210: INFO: Pod "my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172-ch5k9" satisfied condition "running"
Apr 26 11:58:21.210: INFO: Pod "my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172-ch5k9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:58:16 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:58:17 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:58:17 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:58:16 +0000 UTC Reason: Message:}])
Apr 26 11:58:21.210: INFO: Trying to dial the pod
Apr 26 11:58:26.325: INFO: Controller my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172: Got expected result from replica 1 [my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172-ch5k9]: "my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172-ch5k9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 26 11:58:26.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8894" for this suite. 04/26/24 11:58:26.336
{"msg":"PASSED [sig-apps] ReplicationController should serve a basic image on each replica with a public image  [Conformance]","completed":221,"skipped":4185,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.226 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  test/e2e/apps/rc.go:66

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:16.122
    Apr 26 11:58:16.122: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename replication-controller 04/26/24 11:58:16.123
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:16.163
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:16.17
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should serve a basic image on each replica with a public image  [Conformance]
      test/e2e/apps/rc.go:66
    STEP: Creating replication controller my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172 04/26/24 11:58:16.178
    Apr 26 11:58:16.196: INFO: Pod name my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172: Found 0 pods out of 1
    Apr 26 11:58:21.205: INFO: Pod name my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172: Found 1 pods out of 1
    Apr 26 11:58:21.205: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172" are running
    Apr 26 11:58:21.206: INFO: Waiting up to 5m0s for pod "my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172-ch5k9" in namespace "replication-controller-8894" to be "running"
    Apr 26 11:58:21.210: INFO: Pod "my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172-ch5k9": Phase="Running", Reason="", readiness=true. Elapsed: 4.320953ms
    Apr 26 11:58:21.210: INFO: Pod "my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172-ch5k9" satisfied condition "running"
    Apr 26 11:58:21.210: INFO: Pod "my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172-ch5k9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:58:16 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:58:17 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:58:17 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2024-04-26 11:58:16 +0000 UTC Reason: Message:}])
    Apr 26 11:58:21.210: INFO: Trying to dial the pod
    Apr 26 11:58:26.325: INFO: Controller my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172: Got expected result from replica 1 [my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172-ch5k9]: "my-hostname-basic-8f1979a7-6d6c-499e-abb1-116fbe069172-ch5k9", 1 of 1 required successes so far
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 26 11:58:26.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-8894" for this suite. 04/26/24 11:58:26.336
  << End Captured GinkgoWriter Output
------------------------------
[sig-instrumentation] Events API
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:26.35
Apr 26 11:58:26.351: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename events 04/26/24 11:58:26.352
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:26.37
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:26.38
[BeforeEach] [sig-instrumentation] Events API
  test/e2e/instrumentation/events.go:84
[It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98
STEP: creating a test event 04/26/24 11:58:26.386
STEP: listing events in all namespaces 04/26/24 11:58:26.397
STEP: listing events in test namespace 04/26/24 11:58:26.451
STEP: listing events with field selection filtering on source 04/26/24 11:58:26.456
STEP: listing events with field selection filtering on reportingController 04/26/24 11:58:26.461
STEP: getting the test event 04/26/24 11:58:26.467
STEP: patching the test event 04/26/24 11:58:26.471
STEP: getting the test event 04/26/24 11:58:26.479
STEP: updating the test event 04/26/24 11:58:26.485
STEP: getting the test event 04/26/24 11:58:26.493
STEP: deleting the test event 04/26/24 11:58:26.501
STEP: listing events in all namespaces 04/26/24 11:58:26.507
STEP: listing events in test namespace 04/26/24 11:58:26.533
[AfterEach] [sig-instrumentation] Events API
  test/e2e/framework/framework.go:187
Apr 26 11:58:26.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-258" for this suite. 04/26/24 11:58:26.552
{"msg":"PASSED [sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]","completed":222,"skipped":4185,"failed":0}
------------------------------
â€¢ [0.210 seconds]
[sig-instrumentation] Events API
test/e2e/instrumentation/common/framework.go:23
  should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
  test/e2e/instrumentation/events.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:26.35
    Apr 26 11:58:26.351: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename events 04/26/24 11:58:26.352
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:26.37
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:26.38
    [BeforeEach] [sig-instrumentation] Events API
      test/e2e/instrumentation/events.go:84
    [It] should ensure that an event can be fetched, patched, deleted, and listed [Conformance]
      test/e2e/instrumentation/events.go:98
    STEP: creating a test event 04/26/24 11:58:26.386
    STEP: listing events in all namespaces 04/26/24 11:58:26.397
    STEP: listing events in test namespace 04/26/24 11:58:26.451
    STEP: listing events with field selection filtering on source 04/26/24 11:58:26.456
    STEP: listing events with field selection filtering on reportingController 04/26/24 11:58:26.461
    STEP: getting the test event 04/26/24 11:58:26.467
    STEP: patching the test event 04/26/24 11:58:26.471
    STEP: getting the test event 04/26/24 11:58:26.479
    STEP: updating the test event 04/26/24 11:58:26.485
    STEP: getting the test event 04/26/24 11:58:26.493
    STEP: deleting the test event 04/26/24 11:58:26.501
    STEP: listing events in all namespaces 04/26/24 11:58:26.507
    STEP: listing events in test namespace 04/26/24 11:58:26.533
    [AfterEach] [sig-instrumentation] Events API
      test/e2e/framework/framework.go:187
    Apr 26 11:58:26.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-258" for this suite. 04/26/24 11:58:26.552
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:26.561
Apr 26 11:58:26.561: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename gc 04/26/24 11:58:26.562
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:26.578
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:26.584
[It] should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491
STEP: create the deployment 04/26/24 11:58:26.591
STEP: Wait for the Deployment to create new ReplicaSet 04/26/24 11:58:26.599
STEP: delete the deployment 04/26/24 11:58:27.115
STEP: wait for all rs to be garbage collected 04/26/24 11:58:27.122
STEP: expected 0 rs, got 1 rs 04/26/24 11:58:27.132
STEP: expected 0 pods, got 2 pods 04/26/24 11:58:27.138
STEP: Gathering metrics 04/26/24 11:58:27.66
W0426 11:58:27.679212      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 26 11:58:27.679: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 26 11:58:27.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5786" for this suite. 04/26/24 11:58:27.689
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]","completed":223,"skipped":4190,"failed":0}
------------------------------
â€¢ [1.136 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:491

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:26.561
    Apr 26 11:58:26.561: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename gc 04/26/24 11:58:26.562
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:26.578
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:26.584
    [It] should delete RS created by deployment when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:491
    STEP: create the deployment 04/26/24 11:58:26.591
    STEP: Wait for the Deployment to create new ReplicaSet 04/26/24 11:58:26.599
    STEP: delete the deployment 04/26/24 11:58:27.115
    STEP: wait for all rs to be garbage collected 04/26/24 11:58:27.122
    STEP: expected 0 rs, got 1 rs 04/26/24 11:58:27.132
    STEP: expected 0 pods, got 2 pods 04/26/24 11:58:27.138
    STEP: Gathering metrics 04/26/24 11:58:27.66
    W0426 11:58:27.679212      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 26 11:58:27.679: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 26 11:58:27.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-5786" for this suite. 04/26/24 11:58:27.689
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Kubelet when scheduling a busybox command in a pod
  should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
[BeforeEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:27.697
Apr 26 11:58:27.697: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubelet-test 04/26/24 11:58:27.698
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:27.717
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:27.725
[BeforeEach] [sig-node] Kubelet
  test/e2e/common/node/kubelet.go:41
[It] should print the output to logs [NodeConformance] [Conformance]
  test/e2e/common/node/kubelet.go:52
Apr 26 11:58:27.745: INFO: Waiting up to 5m0s for pod "busybox-scheduling-0e458b71-6b0d-4c84-837a-09a56e033b4c" in namespace "kubelet-test-9665" to be "running and ready"
Apr 26 11:58:27.753: INFO: Pod "busybox-scheduling-0e458b71-6b0d-4c84-837a-09a56e033b4c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.951491ms
Apr 26 11:58:27.753: INFO: The phase of Pod busybox-scheduling-0e458b71-6b0d-4c84-837a-09a56e033b4c is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:58:29.761: INFO: Pod "busybox-scheduling-0e458b71-6b0d-4c84-837a-09a56e033b4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.015180075s
Apr 26 11:58:29.761: INFO: The phase of Pod busybox-scheduling-0e458b71-6b0d-4c84-837a-09a56e033b4c is Running (Ready = true)
Apr 26 11:58:29.761: INFO: Pod "busybox-scheduling-0e458b71-6b0d-4c84-837a-09a56e033b4c" satisfied condition "running and ready"
[AfterEach] [sig-node] Kubelet
  test/e2e/framework/framework.go:187
Apr 26 11:58:29.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9665" for this suite. 04/26/24 11:58:29.8
{"msg":"PASSED [sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]","completed":224,"skipped":4208,"failed":0}
------------------------------
â€¢ [2.110 seconds]
[sig-node] Kubelet
test/e2e/common/node/framework.go:23
  when scheduling a busybox command in a pod
  test/e2e/common/node/kubelet.go:44
    should print the output to logs [NodeConformance] [Conformance]
    test/e2e/common/node/kubelet.go:52

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:27.697
    Apr 26 11:58:27.697: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubelet-test 04/26/24 11:58:27.698
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:27.717
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:27.725
    [BeforeEach] [sig-node] Kubelet
      test/e2e/common/node/kubelet.go:41
    [It] should print the output to logs [NodeConformance] [Conformance]
      test/e2e/common/node/kubelet.go:52
    Apr 26 11:58:27.745: INFO: Waiting up to 5m0s for pod "busybox-scheduling-0e458b71-6b0d-4c84-837a-09a56e033b4c" in namespace "kubelet-test-9665" to be "running and ready"
    Apr 26 11:58:27.753: INFO: Pod "busybox-scheduling-0e458b71-6b0d-4c84-837a-09a56e033b4c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.951491ms
    Apr 26 11:58:27.753: INFO: The phase of Pod busybox-scheduling-0e458b71-6b0d-4c84-837a-09a56e033b4c is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:58:29.761: INFO: Pod "busybox-scheduling-0e458b71-6b0d-4c84-837a-09a56e033b4c": Phase="Running", Reason="", readiness=true. Elapsed: 2.015180075s
    Apr 26 11:58:29.761: INFO: The phase of Pod busybox-scheduling-0e458b71-6b0d-4c84-837a-09a56e033b4c is Running (Ready = true)
    Apr 26 11:58:29.761: INFO: Pod "busybox-scheduling-0e458b71-6b0d-4c84-837a-09a56e033b4c" satisfied condition "running and ready"
    [AfterEach] [sig-node] Kubelet
      test/e2e/framework/framework.go:187
    Apr 26 11:58:29.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubelet-test-9665" for this suite. 04/26/24 11:58:29.8
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:29.809
Apr 26 11:58:29.809: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 11:58:29.81
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:29.826
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:29.833
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248
STEP: Creating a pod to test downward API volume plugin 04/26/24 11:58:29.84
Apr 26 11:58:29.852: INFO: Waiting up to 5m0s for pod "downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796" in namespace "downward-api-4528" to be "Succeeded or Failed"
Apr 26 11:58:29.865: INFO: Pod "downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796": Phase="Pending", Reason="", readiness=false. Elapsed: 13.031059ms
Apr 26 11:58:31.873: INFO: Pod "downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020955553s
Apr 26 11:58:33.876: INFO: Pod "downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024487607s
STEP: Saw pod success 04/26/24 11:58:33.876
Apr 26 11:58:33.877: INFO: Pod "downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796" satisfied condition "Succeeded or Failed"
Apr 26 11:58:33.883: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796 container client-container: <nil>
STEP: delete the pod 04/26/24 11:58:33.929
Apr 26 11:58:33.947: INFO: Waiting for pod downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796 to disappear
Apr 26 11:58:33.952: INFO: Pod downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 26 11:58:33.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4528" for this suite. 04/26/24 11:58:33.962
{"msg":"PASSED [sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]","completed":225,"skipped":4234,"failed":0}
------------------------------
â€¢ [4.159 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:29.809
    Apr 26 11:58:29.809: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 11:58:29.81
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:29.826
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:29.833
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:248
    STEP: Creating a pod to test downward API volume plugin 04/26/24 11:58:29.84
    Apr 26 11:58:29.852: INFO: Waiting up to 5m0s for pod "downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796" in namespace "downward-api-4528" to be "Succeeded or Failed"
    Apr 26 11:58:29.865: INFO: Pod "downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796": Phase="Pending", Reason="", readiness=false. Elapsed: 13.031059ms
    Apr 26 11:58:31.873: INFO: Pod "downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020955553s
    Apr 26 11:58:33.876: INFO: Pod "downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.024487607s
    STEP: Saw pod success 04/26/24 11:58:33.876
    Apr 26 11:58:33.877: INFO: Pod "downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796" satisfied condition "Succeeded or Failed"
    Apr 26 11:58:33.883: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796 container client-container: <nil>
    STEP: delete the pod 04/26/24 11:58:33.929
    Apr 26 11:58:33.947: INFO: Waiting for pod downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796 to disappear
    Apr 26 11:58:33.952: INFO: Pod downwardapi-volume-90a09fbc-77cc-4c2d-a553-298b0ca6a796 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 26 11:58:33.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4528" for this suite. 04/26/24 11:58:33.962
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Pods
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:33.969
Apr 26 11:58:33.969: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pods 04/26/24 11:58:33.969
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:33.989
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:33.998
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225
STEP: creating the pod 04/26/24 11:58:34.005
STEP: setting up watch 04/26/24 11:58:34.005
STEP: submitting the pod to kubernetes 04/26/24 11:58:34.114
STEP: verifying the pod is in kubernetes 04/26/24 11:58:34.128
STEP: verifying pod creation was observed 04/26/24 11:58:34.136
Apr 26 11:58:34.136: INFO: Waiting up to 5m0s for pod "pod-submit-remove-d898aad2-b05d-40eb-8b03-9068318dbf68" in namespace "pods-3125" to be "running"
Apr 26 11:58:34.144: INFO: Pod "pod-submit-remove-d898aad2-b05d-40eb-8b03-9068318dbf68": Phase="Pending", Reason="", readiness=false. Elapsed: 7.777044ms
Apr 26 11:58:36.153: INFO: Pod "pod-submit-remove-d898aad2-b05d-40eb-8b03-9068318dbf68": Phase="Running", Reason="", readiness=true. Elapsed: 2.016797762s
Apr 26 11:58:36.153: INFO: Pod "pod-submit-remove-d898aad2-b05d-40eb-8b03-9068318dbf68" satisfied condition "running"
STEP: deleting the pod gracefully 04/26/24 11:58:36.158
STEP: verifying pod deletion was observed 04/26/24 11:58:36.165
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 26 11:58:38.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3125" for this suite. 04/26/24 11:58:38.586
{"msg":"PASSED [sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]","completed":226,"skipped":4245,"failed":0}
------------------------------
â€¢ [4.623 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should be submitted and removed [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:225

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:33.969
    Apr 26 11:58:33.969: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pods 04/26/24 11:58:33.969
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:33.989
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:33.998
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should be submitted and removed [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:225
    STEP: creating the pod 04/26/24 11:58:34.005
    STEP: setting up watch 04/26/24 11:58:34.005
    STEP: submitting the pod to kubernetes 04/26/24 11:58:34.114
    STEP: verifying the pod is in kubernetes 04/26/24 11:58:34.128
    STEP: verifying pod creation was observed 04/26/24 11:58:34.136
    Apr 26 11:58:34.136: INFO: Waiting up to 5m0s for pod "pod-submit-remove-d898aad2-b05d-40eb-8b03-9068318dbf68" in namespace "pods-3125" to be "running"
    Apr 26 11:58:34.144: INFO: Pod "pod-submit-remove-d898aad2-b05d-40eb-8b03-9068318dbf68": Phase="Pending", Reason="", readiness=false. Elapsed: 7.777044ms
    Apr 26 11:58:36.153: INFO: Pod "pod-submit-remove-d898aad2-b05d-40eb-8b03-9068318dbf68": Phase="Running", Reason="", readiness=true. Elapsed: 2.016797762s
    Apr 26 11:58:36.153: INFO: Pod "pod-submit-remove-d898aad2-b05d-40eb-8b03-9068318dbf68" satisfied condition "running"
    STEP: deleting the pod gracefully 04/26/24 11:58:36.158
    STEP: verifying pod deletion was observed 04/26/24 11:58:36.165
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 26 11:58:38.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-3125" for this suite. 04/26/24 11:58:38.586
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Ephemeral Containers [NodeConformance]
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:38.592
Apr 26 11:58:38.592: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename ephemeral-containers-test 04/26/24 11:58:38.594
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:38.609
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:38.614
[BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/common/node/ephemeral_containers.go:38
[It] will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45
STEP: creating a target pod 04/26/24 11:58:38.621
Apr 26 11:58:38.631: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6418" to be "running and ready"
Apr 26 11:58:38.639: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.673999ms
Apr 26 11:58:38.639: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:58:40.645: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014504361s
Apr 26 11:58:40.646: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
Apr 26 11:58:40.646: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
STEP: adding an ephemeral container 04/26/24 11:58:40.651
Apr 26 11:58:40.665: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6418" to be "container debugger running"
Apr 26 11:58:40.697: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 31.892566ms
Apr 26 11:58:42.708: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.043118535s
Apr 26 11:58:42.708: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
STEP: checking pod container endpoints 04/26/24 11:58:42.708
Apr 26 11:58:42.709: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-6418 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 11:58:42.709: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 11:58:42.709: INFO: ExecWithOptions: Clientset creation
Apr 26 11:58:42.709: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/ephemeral-containers-test-6418/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
Apr 26 11:58:43.089: INFO: Exec stderr: ""
[AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 26 11:58:43.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ephemeral-containers-test-6418" for this suite. 04/26/24 11:58:43.195
{"msg":"PASSED [sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]","completed":227,"skipped":4246,"failed":0}
------------------------------
â€¢ [4.610 seconds]
[sig-node] Ephemeral Containers [NodeConformance]
test/e2e/common/node/framework.go:23
  will start an ephemeral container in an existing pod [Conformance]
  test/e2e/common/node/ephemeral_containers.go:45

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:38.592
    Apr 26 11:58:38.592: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename ephemeral-containers-test 04/26/24 11:58:38.594
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:38.609
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:38.614
    [BeforeEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/common/node/ephemeral_containers.go:38
    [It] will start an ephemeral container in an existing pod [Conformance]
      test/e2e/common/node/ephemeral_containers.go:45
    STEP: creating a target pod 04/26/24 11:58:38.621
    Apr 26 11:58:38.631: INFO: Waiting up to 5m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6418" to be "running and ready"
    Apr 26 11:58:38.639: INFO: Pod "ephemeral-containers-target-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.673999ms
    Apr 26 11:58:38.639: INFO: The phase of Pod ephemeral-containers-target-pod is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:58:40.645: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014504361s
    Apr 26 11:58:40.646: INFO: The phase of Pod ephemeral-containers-target-pod is Running (Ready = true)
    Apr 26 11:58:40.646: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "running and ready"
    STEP: adding an ephemeral container 04/26/24 11:58:40.651
    Apr 26 11:58:40.665: INFO: Waiting up to 1m0s for pod "ephemeral-containers-target-pod" in namespace "ephemeral-containers-test-6418" to be "container debugger running"
    Apr 26 11:58:40.697: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 31.892566ms
    Apr 26 11:58:42.708: INFO: Pod "ephemeral-containers-target-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.043118535s
    Apr 26 11:58:42.708: INFO: Pod "ephemeral-containers-target-pod" satisfied condition "container debugger running"
    STEP: checking pod container endpoints 04/26/24 11:58:42.708
    Apr 26 11:58:42.709: INFO: ExecWithOptions {Command:[/bin/echo marco] Namespace:ephemeral-containers-test-6418 PodName:ephemeral-containers-target-pod ContainerName:debugger Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 11:58:42.709: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 11:58:42.709: INFO: ExecWithOptions: Clientset creation
    Apr 26 11:58:42.709: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/ephemeral-containers-test-6418/pods/ephemeral-containers-target-pod/exec?command=%2Fbin%2Fecho&command=marco&container=debugger&container=debugger&stderr=true&stdout=true)
    Apr 26 11:58:43.089: INFO: Exec stderr: ""
    [AfterEach] [sig-node] Ephemeral Containers [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 26 11:58:43.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ephemeral-containers-test-6418" for this suite. 04/26/24 11:58:43.195
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:43.207
Apr 26 11:58:43.207: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename deployment 04/26/24 11:58:43.207
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:43.223
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:43.23
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122
Apr 26 11:58:43.248: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 26 11:58:48.253: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/26/24 11:58:48.253
Apr 26 11:58:48.254: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 04/26/24 11:58:48.269
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 26 11:58:50.303: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-852  20cdf3ea-a109-4b9b-ae60-a9c25cf8f327 38496 1 2024-04-26 11:58:48 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2024-04-26 11:58:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002fba628 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2024-04-26 11:58:48 +0000 UTC,LastTransitionTime:2024-04-26 11:58:48 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2024-04-26 11:58:50 +0000 UTC,LastTransitionTime:2024-04-26 11:58:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 26 11:58:50.308: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-852  3a62ff4e-f207-4386-b9a5-2d5292bba97e 38489 1 2024-04-26 11:58:48 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 20cdf3ea-a109-4b9b-ae60-a9c25cf8f327 0xc0046f4737 0xc0046f4738}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:58:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20cdf3ea-a109-4b9b-ae60-a9c25cf8f327\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:58:49 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0046f47e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 26 11:58:50.313: INFO: Pod "test-cleanup-deployment-69cb9c5497-s8t84" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-s8t84 test-cleanup-deployment-69cb9c5497- deployment-852  8a60fde7-ad89-4f0b-9602-ac1e1604c3bc 38488 0 2024-04-26 11:58:48 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:2cd123b185ebb38d129526d932dfcfb74cdbc6bca95cda6ab5843250ef8fd3d9 cni.projectcalico.org/podIP:100.96.1.229/32 cni.projectcalico.org/podIPs:100.96.1.229/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 3a62ff4e-f207-4386-b9a5-2d5292bba97e 0xc0046f4b87 0xc0046f4b88}] [] [{calico Update v1 2024-04-26 11:58:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:58:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a62ff4e-f207-4386-b9a5-2d5292bba97e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:58:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.229\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5llss,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5llss,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:58:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:58:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:58:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:58:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.229,StartTime:2024-04-26 11:58:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:58:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://ca32810b5c071e050abfee1979e12aa37aff98a2fc9482fe33da2a9ce8af724e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.229,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 26 11:58:50.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-852" for this suite. 04/26/24 11:58:50.324
{"msg":"PASSED [sig-apps] Deployment deployment should delete old replica sets [Conformance]","completed":228,"skipped":4307,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.124 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  test/e2e/apps/deployment.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:43.207
    Apr 26 11:58:43.207: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename deployment 04/26/24 11:58:43.207
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:43.223
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:43.23
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] deployment should delete old replica sets [Conformance]
      test/e2e/apps/deployment.go:122
    Apr 26 11:58:43.248: INFO: Pod name cleanup-pod: Found 0 pods out of 1
    Apr 26 11:58:48.253: INFO: Pod name cleanup-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/26/24 11:58:48.253
    Apr 26 11:58:48.254: INFO: Creating deployment test-cleanup-deployment
    STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up 04/26/24 11:58:48.269
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 26 11:58:50.303: INFO: Deployment "test-cleanup-deployment":
    &Deployment{ObjectMeta:{test-cleanup-deployment  deployment-852  20cdf3ea-a109-4b9b-ae60-a9c25cf8f327 38496 1 2024-04-26 11:58:48 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] [] [{e2e.test Update apps/v1 2024-04-26 11:58:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:58:50 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc002fba628 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2024-04-26 11:58:48 +0000 UTC,LastTransitionTime:2024-04-26 11:58:48 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-69cb9c5497" has successfully progressed.,LastUpdateTime:2024-04-26 11:58:50 +0000 UTC,LastTransitionTime:2024-04-26 11:58:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 26 11:58:50.308: INFO: New ReplicaSet "test-cleanup-deployment-69cb9c5497" of Deployment "test-cleanup-deployment":
    &ReplicaSet{ObjectMeta:{test-cleanup-deployment-69cb9c5497  deployment-852  3a62ff4e-f207-4386-b9a5-2d5292bba97e 38489 1 2024-04-26 11:58:48 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 20cdf3ea-a109-4b9b-ae60-a9c25cf8f327 0xc0046f4737 0xc0046f4738}] [] [{kube-controller-manager Update apps/v1 2024-04-26 11:58:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"20cdf3ea-a109-4b9b-ae60-a9c25cf8f327\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 11:58:49 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 69cb9c5497,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0046f47e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 26 11:58:50.313: INFO: Pod "test-cleanup-deployment-69cb9c5497-s8t84" is available:
    &Pod{ObjectMeta:{test-cleanup-deployment-69cb9c5497-s8t84 test-cleanup-deployment-69cb9c5497- deployment-852  8a60fde7-ad89-4f0b-9602-ac1e1604c3bc 38488 0 2024-04-26 11:58:48 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:69cb9c5497] map[cni.projectcalico.org/containerID:2cd123b185ebb38d129526d932dfcfb74cdbc6bca95cda6ab5843250ef8fd3d9 cni.projectcalico.org/podIP:100.96.1.229/32 cni.projectcalico.org/podIPs:100.96.1.229/32] [{apps/v1 ReplicaSet test-cleanup-deployment-69cb9c5497 3a62ff4e-f207-4386-b9a5-2d5292bba97e 0xc0046f4b87 0xc0046f4b88}] [] [{calico Update v1 2024-04-26 11:58:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kube-controller-manager Update v1 2024-04-26 11:58:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"3a62ff4e-f207-4386-b9a5-2d5292bba97e\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 11:58:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.229\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-5llss,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-5llss,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:58:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:58:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:58:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 11:58:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.229,StartTime:2024-04-26 11:58:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 11:58:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://ca32810b5c071e050abfee1979e12aa37aff98a2fc9482fe33da2a9ce8af724e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.229,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 26 11:58:50.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-852" for this suite. 04/26/24 11:58:50.324
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Containers
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:50.336
Apr 26 11:58:50.336: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename containers 04/26/24 11:58:50.337
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:50.356
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:50.362
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86
STEP: Creating a pod to test override all 04/26/24 11:58:50.37
Apr 26 11:58:50.381: INFO: Waiting up to 5m0s for pod "client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761" in namespace "containers-5891" to be "Succeeded or Failed"
Apr 26 11:58:50.388: INFO: Pod "client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761": Phase="Pending", Reason="", readiness=false. Elapsed: 6.682949ms
Apr 26 11:58:52.394: INFO: Pod "client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012642558s
Apr 26 11:58:54.394: INFO: Pod "client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013046963s
STEP: Saw pod success 04/26/24 11:58:54.394
Apr 26 11:58:54.394: INFO: Pod "client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761" satisfied condition "Succeeded or Failed"
Apr 26 11:58:54.399: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761 container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:58:54.413
Apr 26 11:58:54.427: INFO: Waiting for pod client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761 to disappear
Apr 26 11:58:54.432: INFO: Pod client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761 no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 26 11:58:54.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5891" for this suite. 04/26/24 11:58:54.442
{"msg":"PASSED [sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]","completed":229,"skipped":4338,"failed":0}
------------------------------
â€¢ [4.112 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:86

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:50.336
    Apr 26 11:58:50.336: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename containers 04/26/24 11:58:50.337
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:50.356
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:50.362
    [It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:86
    STEP: Creating a pod to test override all 04/26/24 11:58:50.37
    Apr 26 11:58:50.381: INFO: Waiting up to 5m0s for pod "client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761" in namespace "containers-5891" to be "Succeeded or Failed"
    Apr 26 11:58:50.388: INFO: Pod "client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761": Phase="Pending", Reason="", readiness=false. Elapsed: 6.682949ms
    Apr 26 11:58:52.394: INFO: Pod "client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012642558s
    Apr 26 11:58:54.394: INFO: Pod "client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013046963s
    STEP: Saw pod success 04/26/24 11:58:54.394
    Apr 26 11:58:54.394: INFO: Pod "client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761" satisfied condition "Succeeded or Failed"
    Apr 26 11:58:54.399: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761 container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:58:54.413
    Apr 26 11:58:54.427: INFO: Waiting for pod client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761 to disappear
    Apr 26 11:58:54.432: INFO: Pod client-containers-16ee35c4-5453-44c3-b16f-2f06968ff761 no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 26 11:58:54.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-5891" for this suite. 04/26/24 11:58:54.442
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
[BeforeEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:54.448
Apr 26 11:58:54.449: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:58:54.45
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:54.469
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:54.474
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87
STEP: Creating projection with secret that has name projected-secret-test-map-691ef095-5939-4227-aabb-2bc8ff46012d 04/26/24 11:58:54.481
STEP: Creating a pod to test consume secrets 04/26/24 11:58:54.486
Apr 26 11:58:54.499: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6" in namespace "projected-5561" to be "Succeeded or Failed"
Apr 26 11:58:54.507: INFO: Pod "pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.894654ms
Apr 26 11:58:56.515: INFO: Pod "pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015279366s
Apr 26 11:58:58.514: INFO: Pod "pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014421872s
STEP: Saw pod success 04/26/24 11:58:58.514
Apr 26 11:58:58.514: INFO: Pod "pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6" satisfied condition "Succeeded or Failed"
Apr 26 11:58:58.521: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6 container projected-secret-volume-test: <nil>
STEP: delete the pod 04/26/24 11:58:58.539
Apr 26 11:58:58.553: INFO: Waiting for pod pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6 to disappear
Apr 26 11:58:58.558: INFO: Pod pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6 no longer exists
[AfterEach] [sig-storage] Projected secret
  test/e2e/framework/framework.go:187
Apr 26 11:58:58.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5561" for this suite. 04/26/24 11:58:58.57
{"msg":"PASSED [sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":230,"skipped":4359,"failed":0}
------------------------------
â€¢ [4.131 seconds]
[sig-storage] Projected secret
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_secret.go:87

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:54.448
    Apr 26 11:58:54.449: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:58:54.45
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:54.469
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:54.474
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_secret.go:87
    STEP: Creating projection with secret that has name projected-secret-test-map-691ef095-5939-4227-aabb-2bc8ff46012d 04/26/24 11:58:54.481
    STEP: Creating a pod to test consume secrets 04/26/24 11:58:54.486
    Apr 26 11:58:54.499: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6" in namespace "projected-5561" to be "Succeeded or Failed"
    Apr 26 11:58:54.507: INFO: Pod "pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.894654ms
    Apr 26 11:58:56.515: INFO: Pod "pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015279366s
    Apr 26 11:58:58.514: INFO: Pod "pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014421872s
    STEP: Saw pod success 04/26/24 11:58:58.514
    Apr 26 11:58:58.514: INFO: Pod "pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6" satisfied condition "Succeeded or Failed"
    Apr 26 11:58:58.521: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6 container projected-secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 11:58:58.539
    Apr 26 11:58:58.553: INFO: Waiting for pod pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6 to disappear
    Apr 26 11:58:58.558: INFO: Pod pod-projected-secrets-25f45e1c-24b1-4c4e-87af-c9b2f97d63a6 no longer exists
    [AfterEach] [sig-storage] Projected secret
      test/e2e/framework/framework.go:187
    Apr 26 11:58:58.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-5561" for this suite. 04/26/24 11:58:58.57
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:58:58.583
Apr 26 11:58:58.583: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 11:58:58.584
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:58.6
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:58.607
[It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108
STEP: Creating configMap with name projected-configmap-test-volume-map-5f364448-a526-422f-84c5-e94868702b9c 04/26/24 11:58:58.615
STEP: Creating a pod to test consume configMaps 04/26/24 11:58:58.62
Apr 26 11:58:58.633: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a" in namespace "projected-3695" to be "Succeeded or Failed"
Apr 26 11:58:58.641: INFO: Pod "pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.381007ms
Apr 26 11:59:00.650: INFO: Pod "pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017313784s
Apr 26 11:59:02.650: INFO: Pod "pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017308404s
STEP: Saw pod success 04/26/24 11:59:02.65
Apr 26 11:59:02.650: INFO: Pod "pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a" satisfied condition "Succeeded or Failed"
Apr 26 11:59:02.656: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:59:02.71
Apr 26 11:59:02.724: INFO: Waiting for pod pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a to disappear
Apr 26 11:59:02.729: INFO: Pod pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 26 11:59:02.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3695" for this suite. 04/26/24 11:59:02.74
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]","completed":231,"skipped":4377,"failed":0}
------------------------------
â€¢ [4.163 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:108

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:58:58.583
    Apr 26 11:58:58.583: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 11:58:58.584
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:58:58.6
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:58:58.607
    [It] should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:108
    STEP: Creating configMap with name projected-configmap-test-volume-map-5f364448-a526-422f-84c5-e94868702b9c 04/26/24 11:58:58.615
    STEP: Creating a pod to test consume configMaps 04/26/24 11:58:58.62
    Apr 26 11:58:58.633: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a" in namespace "projected-3695" to be "Succeeded or Failed"
    Apr 26 11:58:58.641: INFO: Pod "pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.381007ms
    Apr 26 11:59:00.650: INFO: Pod "pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017313784s
    Apr 26 11:59:02.650: INFO: Pod "pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017308404s
    STEP: Saw pod success 04/26/24 11:59:02.65
    Apr 26 11:59:02.650: INFO: Pod "pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a" satisfied condition "Succeeded or Failed"
    Apr 26 11:59:02.656: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:59:02.71
    Apr 26 11:59:02.724: INFO: Waiting for pod pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a to disappear
    Apr 26 11:59:02.729: INFO: Pod pod-projected-configmaps-d45d0c7c-069b-4a27-a621-5558fe129b8a no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 26 11:59:02.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-3695" for this suite. 04/26/24 11:59:02.74
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:59:02.747
Apr 26 11:59:02.747: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename sysctl 04/26/24 11:59:02.748
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:02.765
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:02.772
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123
STEP: Creating a pod with one valid and two invalid sysctls 04/26/24 11:59:02.78
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 26 11:59:02.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-4282" for this suite. 04/26/24 11:59:02.801
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":232,"skipped":4386,"failed":0}
------------------------------
â€¢ [0.061 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:123

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:59:02.747
    Apr 26 11:59:02.747: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename sysctl 04/26/24 11:59:02.748
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:02.765
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:02.772
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:123
    STEP: Creating a pod with one valid and two invalid sysctls 04/26/24 11:59:02.78
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 26 11:59:02.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-4282" for this suite. 04/26/24 11:59:02.801
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:59:02.808
Apr 26 11:59:02.808: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename gc 04/26/24 11:59:02.81
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:02.831
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:02.838
[It] should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849
Apr 26 11:59:02.885: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"87589364-2ac6-4995-b100-0243db9c2556", Controller:(*bool)(0xc0040a73d6), BlockOwnerDeletion:(*bool)(0xc0040a73d7)}}
Apr 26 11:59:02.893: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"66c5331f-6511-4979-b2d5-045e43f35759", Controller:(*bool)(0xc003b7d2b6), BlockOwnerDeletion:(*bool)(0xc003b7d2b7)}}
Apr 26 11:59:02.899: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"140f7257-2aeb-494b-9345-b8a4e7b6c591", Controller:(*bool)(0xc003b7d50a), BlockOwnerDeletion:(*bool)(0xc003b7d50b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 26 11:59:07.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8620" for this suite. 04/26/24 11:59:07.929
{"msg":"PASSED [sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]","completed":233,"skipped":4391,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.126 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  test/e2e/apimachinery/garbage_collector.go:849

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:59:02.808
    Apr 26 11:59:02.808: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename gc 04/26/24 11:59:02.81
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:02.831
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:02.838
    [It] should not be blocked by dependency circle [Conformance]
      test/e2e/apimachinery/garbage_collector.go:849
    Apr 26 11:59:02.885: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"87589364-2ac6-4995-b100-0243db9c2556", Controller:(*bool)(0xc0040a73d6), BlockOwnerDeletion:(*bool)(0xc0040a73d7)}}
    Apr 26 11:59:02.893: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"66c5331f-6511-4979-b2d5-045e43f35759", Controller:(*bool)(0xc003b7d2b6), BlockOwnerDeletion:(*bool)(0xc003b7d2b7)}}
    Apr 26 11:59:02.899: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"140f7257-2aeb-494b-9345-b8a4e7b6c591", Controller:(*bool)(0xc003b7d50a), BlockOwnerDeletion:(*bool)(0xc003b7d50b)}}
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 26 11:59:07.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8620" for this suite. 04/26/24 11:59:07.929
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial]
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:59:07.935
Apr 26 11:59:07.935: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename daemonsets 04/26/24 11:59:07.936
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:07.955
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:07.963
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861
STEP: Creating simple DaemonSet "daemon-set" 04/26/24 11:59:08.025
STEP: Check that daemon pods launch on every node of the cluster. 04/26/24 11:59:08.033
Apr 26 11:59:08.048: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:59:08.048: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:59:09.068: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
Apr 26 11:59:09.068: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:59:10.067: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Apr 26 11:59:10.067: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
STEP: Getting /status 04/26/24 11:59:10.071
Apr 26 11:59:10.076: INFO: Daemon Set daemon-set has Conditions: []
STEP: updating the DaemonSet Status 04/26/24 11:59:10.077
Apr 26 11:59:10.089: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the daemon set status to be updated 04/26/24 11:59:10.089
Apr 26 11:59:10.093: INFO: Observed &DaemonSet event: ADDED
Apr 26 11:59:10.093: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.093: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.093: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.093: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.093: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.094: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.094: INFO: Found daemon set daemon-set in namespace daemonsets-4257 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 26 11:59:10.094: INFO: Daemon set daemon-set has an updated status
STEP: patching the DaemonSet Status 04/26/24 11:59:10.094
STEP: watching for the daemon set status to be patched 04/26/24 11:59:10.102
Apr 26 11:59:10.106: INFO: Observed &DaemonSet event: ADDED
Apr 26 11:59:10.106: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.107: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.107: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.107: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.108: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.108: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.108: INFO: Observed daemon set daemon-set in namespace daemonsets-4257 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 26 11:59:10.108: INFO: Observed &DaemonSet event: MODIFIED
Apr 26 11:59:10.108: INFO: Found daemon set daemon-set in namespace daemonsets-4257 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
Apr 26 11:59:10.108: INFO: Daemon set daemon-set has a patched status
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/26/24 11:59:10.113
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4257, will wait for the garbage collector to delete the pods 04/26/24 11:59:10.113
Apr 26 11:59:10.174: INFO: Deleting DaemonSet.extensions daemon-set took: 6.55065ms
Apr 26 11:59:10.275: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.715832ms
Apr 26 11:59:12.781: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:59:12.782: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 26 11:59:12.788: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38756"},"items":null}

Apr 26 11:59:12.793: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38756"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:59:12.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4257" for this suite. 04/26/24 11:59:12.851
{"msg":"PASSED [sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]","completed":234,"skipped":4393,"failed":0}
------------------------------
â€¢ [4.923 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should verify changes to a daemon set status [Conformance]
  test/e2e/apps/daemon_set.go:861

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:59:07.935
    Apr 26 11:59:07.935: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename daemonsets 04/26/24 11:59:07.936
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:07.955
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:07.963
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should verify changes to a daemon set status [Conformance]
      test/e2e/apps/daemon_set.go:861
    STEP: Creating simple DaemonSet "daemon-set" 04/26/24 11:59:08.025
    STEP: Check that daemon pods launch on every node of the cluster. 04/26/24 11:59:08.033
    Apr 26 11:59:08.048: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:59:08.048: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:59:09.068: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 2
    Apr 26 11:59:09.068: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:59:10.067: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
    Apr 26 11:59:10.067: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
    STEP: Getting /status 04/26/24 11:59:10.071
    Apr 26 11:59:10.076: INFO: Daemon Set daemon-set has Conditions: []
    STEP: updating the DaemonSet Status 04/26/24 11:59:10.077
    Apr 26 11:59:10.089: INFO: updatedStatus.Conditions: []v1.DaemonSetCondition{v1.DaemonSetCondition{Type:"StatusUpdate", Status:"True", LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the daemon set status to be updated 04/26/24 11:59:10.089
    Apr 26 11:59:10.093: INFO: Observed &DaemonSet event: ADDED
    Apr 26 11:59:10.093: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.093: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.093: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.093: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.093: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.094: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.094: INFO: Found daemon set daemon-set in namespace daemonsets-4257 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 26 11:59:10.094: INFO: Daemon set daemon-set has an updated status
    STEP: patching the DaemonSet Status 04/26/24 11:59:10.094
    STEP: watching for the daemon set status to be patched 04/26/24 11:59:10.102
    Apr 26 11:59:10.106: INFO: Observed &DaemonSet event: ADDED
    Apr 26 11:59:10.106: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.107: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.107: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.107: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.108: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.108: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.108: INFO: Observed daemon set daemon-set in namespace daemonsets-4257 with annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusUpdate True 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 26 11:59:10.108: INFO: Observed &DaemonSet event: MODIFIED
    Apr 26 11:59:10.108: INFO: Found daemon set daemon-set in namespace daemonsets-4257 with labels: map[daemonset-name:daemon-set] annotations: map[deprecated.daemonset.template.generation:1] & Conditions: [{StatusPatched True 0001-01-01 00:00:00 +0000 UTC  }]
    Apr 26 11:59:10.108: INFO: Daemon set daemon-set has a patched status
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/26/24 11:59:10.113
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4257, will wait for the garbage collector to delete the pods 04/26/24 11:59:10.113
    Apr 26 11:59:10.174: INFO: Deleting DaemonSet.extensions daemon-set took: 6.55065ms
    Apr 26 11:59:10.275: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.715832ms
    Apr 26 11:59:12.781: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:59:12.782: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 26 11:59:12.788: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"38756"},"items":null}

    Apr 26 11:59:12.793: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"38756"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:59:12.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-4257" for this suite. 04/26/24 11:59:12.851
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:59:12.86
Apr 26 11:59:12.860: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename gc 04/26/24 11:59:12.861
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:12.881
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:12.887
[It] should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312
STEP: create the rc 04/26/24 11:59:12.895
STEP: delete the rc 04/26/24 11:59:17.918
STEP: wait for all pods to be garbage collected 04/26/24 11:59:17.926
STEP: Gathering metrics 04/26/24 11:59:22.938
W0426 11:59:22.953971      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 26 11:59:22.953: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 26 11:59:22.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-761" for this suite. 04/26/24 11:59:22.967
{"msg":"PASSED [sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]","completed":235,"skipped":4412,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.115 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  test/e2e/apimachinery/garbage_collector.go:312

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:59:12.86
    Apr 26 11:59:12.860: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename gc 04/26/24 11:59:12.861
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:12.881
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:12.887
    [It] should delete pods created by rc when not orphaning [Conformance]
      test/e2e/apimachinery/garbage_collector.go:312
    STEP: create the rc 04/26/24 11:59:12.895
    STEP: delete the rc 04/26/24 11:59:17.918
    STEP: wait for all pods to be garbage collected 04/26/24 11:59:17.926
    STEP: Gathering metrics 04/26/24 11:59:22.938
    W0426 11:59:22.953971      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 26 11:59:22.953: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 26 11:59:22.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-761" for this suite. 04/26/24 11:59:22.967
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:59:22.976
Apr 26 11:59:22.976: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 11:59:22.977
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:22.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:23.005
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should provide secure master service  [Conformance]
  test/e2e/network/service.go:781
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 11:59:23.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6288" for this suite. 04/26/24 11:59:23.025
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should provide secure master service  [Conformance]","completed":236,"skipped":4450,"failed":0}
------------------------------
â€¢ [0.058 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should provide secure master service  [Conformance]
  test/e2e/network/service.go:781

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:59:22.976
    Apr 26 11:59:22.976: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 11:59:22.977
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:22.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:23.005
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should provide secure master service  [Conformance]
      test/e2e/network/service.go:781
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 11:59:23.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-6288" for this suite. 04/26/24 11:59:23.025
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:59:23.035
Apr 26 11:59:23.035: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename podtemplate 04/26/24 11:59:23.036
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:23.051
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:23.057
[It] should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122
STEP: Create set of pod templates 04/26/24 11:59:23.063
Apr 26 11:59:23.067: INFO: created test-podtemplate-1
Apr 26 11:59:23.074: INFO: created test-podtemplate-2
Apr 26 11:59:23.079: INFO: created test-podtemplate-3
STEP: get a list of pod templates with a label in the current namespace 04/26/24 11:59:23.079
STEP: delete collection of pod templates 04/26/24 11:59:23.085
Apr 26 11:59:23.085: INFO: requesting DeleteCollection of pod templates
STEP: check that the list of pod templates matches the requested quantity 04/26/24 11:59:23.101
Apr 26 11:59:23.101: INFO: requesting list of pod templates to confirm quantity
[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 26 11:59:23.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-8313" for this suite. 04/26/24 11:59:23.119
{"msg":"PASSED [sig-node] PodTemplates should delete a collection of pod templates [Conformance]","completed":237,"skipped":4459,"failed":0}
------------------------------
â€¢ [0.089 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should delete a collection of pod templates [Conformance]
  test/e2e/common/node/podtemplates.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:59:23.035
    Apr 26 11:59:23.035: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename podtemplate 04/26/24 11:59:23.036
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:23.051
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:23.057
    [It] should delete a collection of pod templates [Conformance]
      test/e2e/common/node/podtemplates.go:122
    STEP: Create set of pod templates 04/26/24 11:59:23.063
    Apr 26 11:59:23.067: INFO: created test-podtemplate-1
    Apr 26 11:59:23.074: INFO: created test-podtemplate-2
    Apr 26 11:59:23.079: INFO: created test-podtemplate-3
    STEP: get a list of pod templates with a label in the current namespace 04/26/24 11:59:23.079
    STEP: delete collection of pod templates 04/26/24 11:59:23.085
    Apr 26 11:59:23.085: INFO: requesting DeleteCollection of pod templates
    STEP: check that the list of pod templates matches the requested quantity 04/26/24 11:59:23.101
    Apr 26 11:59:23.101: INFO: requesting list of pod templates to confirm quantity
    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 26 11:59:23.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-8313" for this suite. 04/26/24 11:59:23.119
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] CSIStorageCapacity
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
[BeforeEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:59:23.128
Apr 26 11:59:23.128: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename csistoragecapacity 04/26/24 11:59:23.129
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:23.143
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:23.149
[It]  should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49
STEP: getting /apis 04/26/24 11:59:23.159
STEP: getting /apis/storage.k8s.io 04/26/24 11:59:23.166
STEP: getting /apis/storage.k8s.io/v1 04/26/24 11:59:23.171
STEP: creating 04/26/24 11:59:23.174
STEP: watching 04/26/24 11:59:23.193
Apr 26 11:59:23.193: INFO: starting watch
STEP: getting 04/26/24 11:59:23.205
STEP: listing in namespace 04/26/24 11:59:23.209
STEP: listing across namespaces 04/26/24 11:59:23.214
STEP: patching 04/26/24 11:59:23.219
STEP: updating 04/26/24 11:59:23.225
Apr 26 11:59:23.238: INFO: waiting for watch events with expected annotations in namespace
Apr 26 11:59:23.238: INFO: waiting for watch events with expected annotations across namespace
STEP: deleting 04/26/24 11:59:23.238
STEP: deleting a collection 04/26/24 11:59:23.256
[AfterEach] [sig-storage] CSIStorageCapacity
  test/e2e/framework/framework.go:187
Apr 26 11:59:23.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "csistoragecapacity-411" for this suite. 04/26/24 11:59:23.301
{"msg":"PASSED [sig-storage] CSIStorageCapacity  should support CSIStorageCapacities API operations [Conformance]","completed":238,"skipped":4476,"failed":0}
------------------------------
â€¢ [0.181 seconds]
[sig-storage] CSIStorageCapacity
test/e2e/storage/utils/framework.go:23
   should support CSIStorageCapacities API operations [Conformance]
  test/e2e/storage/csistoragecapacity.go:49

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:59:23.128
    Apr 26 11:59:23.128: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename csistoragecapacity 04/26/24 11:59:23.129
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:23.143
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:23.149
    [It]  should support CSIStorageCapacities API operations [Conformance]
      test/e2e/storage/csistoragecapacity.go:49
    STEP: getting /apis 04/26/24 11:59:23.159
    STEP: getting /apis/storage.k8s.io 04/26/24 11:59:23.166
    STEP: getting /apis/storage.k8s.io/v1 04/26/24 11:59:23.171
    STEP: creating 04/26/24 11:59:23.174
    STEP: watching 04/26/24 11:59:23.193
    Apr 26 11:59:23.193: INFO: starting watch
    STEP: getting 04/26/24 11:59:23.205
    STEP: listing in namespace 04/26/24 11:59:23.209
    STEP: listing across namespaces 04/26/24 11:59:23.214
    STEP: patching 04/26/24 11:59:23.219
    STEP: updating 04/26/24 11:59:23.225
    Apr 26 11:59:23.238: INFO: waiting for watch events with expected annotations in namespace
    Apr 26 11:59:23.238: INFO: waiting for watch events with expected annotations across namespace
    STEP: deleting 04/26/24 11:59:23.238
    STEP: deleting a collection 04/26/24 11:59:23.256
    [AfterEach] [sig-storage] CSIStorageCapacity
      test/e2e/framework/framework.go:187
    Apr 26 11:59:23.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "csistoragecapacity-411" for this suite. 04/26/24 11:59:23.301
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:59:23.309
Apr 26 11:59:23.309: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-lifecycle-hook 04/26/24 11:59:23.311
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:23.325
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:23.332
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/26/24 11:59:23.357
Apr 26 11:59:23.368: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-432" to be "running and ready"
Apr 26 11:59:23.372: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 4.163508ms
Apr 26 11:59:23.372: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:59:25.383: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.015292139s
Apr 26 11:59:25.383: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 26 11:59:25.383: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:152
STEP: create the pod with lifecycle hook 04/26/24 11:59:25.388
Apr 26 11:59:25.397: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-432" to be "running and ready"
Apr 26 11:59:25.406: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.737718ms
Apr 26 11:59:25.406: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 26 11:59:27.415: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.017547866s
Apr 26 11:59:27.415: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
Apr 26 11:59:27.415: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
STEP: delete the pod with lifecycle hook 04/26/24 11:59:27.421
Apr 26 11:59:27.427: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 26 11:59:27.434: INFO: Pod pod-with-prestop-http-hook still exists
Apr 26 11:59:29.435: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 26 11:59:29.442: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook 04/26/24 11:59:29.442
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 26 11:59:29.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-432" for this suite. 04/26/24 11:59:29.507
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]","completed":239,"skipped":4483,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.204 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute prestop http hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:59:23.309
    Apr 26 11:59:23.309: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/26/24 11:59:23.311
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:23.325
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:23.332
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/26/24 11:59:23.357
    Apr 26 11:59:23.368: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-432" to be "running and ready"
    Apr 26 11:59:23.372: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 4.163508ms
    Apr 26 11:59:23.372: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:59:25.383: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.015292139s
    Apr 26 11:59:25.383: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 26 11:59:25.383: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute prestop http hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:152
    STEP: create the pod with lifecycle hook 04/26/24 11:59:25.388
    Apr 26 11:59:25.397: INFO: Waiting up to 5m0s for pod "pod-with-prestop-http-hook" in namespace "container-lifecycle-hook-432" to be "running and ready"
    Apr 26 11:59:25.406: INFO: Pod "pod-with-prestop-http-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 8.737718ms
    Apr 26 11:59:25.406: INFO: The phase of Pod pod-with-prestop-http-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 11:59:27.415: INFO: Pod "pod-with-prestop-http-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.017547866s
    Apr 26 11:59:27.415: INFO: The phase of Pod pod-with-prestop-http-hook is Running (Ready = true)
    Apr 26 11:59:27.415: INFO: Pod "pod-with-prestop-http-hook" satisfied condition "running and ready"
    STEP: delete the pod with lifecycle hook 04/26/24 11:59:27.421
    Apr 26 11:59:27.427: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 26 11:59:27.434: INFO: Pod pod-with-prestop-http-hook still exists
    Apr 26 11:59:29.435: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
    Apr 26 11:59:29.442: INFO: Pod pod-with-prestop-http-hook no longer exists
    STEP: check prestop hook 04/26/24 11:59:29.442
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 26 11:59:29.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-432" for this suite. 04/26/24 11:59:29.507
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] Containers
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
[BeforeEach] [sig-node] Containers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:59:29.514
Apr 26 11:59:29.514: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename containers 04/26/24 11:59:29.515
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:29.533
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:29.541
[It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58
STEP: Creating a pod to test override arguments 04/26/24 11:59:29.549
Apr 26 11:59:29.582: INFO: Waiting up to 5m0s for pod "client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca" in namespace "containers-6858" to be "Succeeded or Failed"
Apr 26 11:59:29.589: INFO: Pod "client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.865492ms
Apr 26 11:59:31.596: INFO: Pod "client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014388438s
Apr 26 11:59:33.596: INFO: Pod "client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014197898s
STEP: Saw pod success 04/26/24 11:59:33.596
Apr 26 11:59:33.596: INFO: Pod "client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca" satisfied condition "Succeeded or Failed"
Apr 26 11:59:33.601: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca container agnhost-container: <nil>
STEP: delete the pod 04/26/24 11:59:33.619
Apr 26 11:59:33.633: INFO: Waiting for pod client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca to disappear
Apr 26 11:59:33.638: INFO: Pod client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca no longer exists
[AfterEach] [sig-node] Containers
  test/e2e/framework/framework.go:187
Apr 26 11:59:33.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6858" for this suite. 04/26/24 11:59:33.649
{"msg":"PASSED [sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]","completed":240,"skipped":4485,"failed":0}
------------------------------
â€¢ [4.163 seconds]
[sig-node] Containers
test/e2e/common/node/framework.go:23
  should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
  test/e2e/common/node/containers.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Containers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:59:29.514
    Apr 26 11:59:29.514: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename containers 04/26/24 11:59:29.515
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:29.533
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:29.541
    [It] should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]
      test/e2e/common/node/containers.go:58
    STEP: Creating a pod to test override arguments 04/26/24 11:59:29.549
    Apr 26 11:59:29.582: INFO: Waiting up to 5m0s for pod "client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca" in namespace "containers-6858" to be "Succeeded or Failed"
    Apr 26 11:59:29.589: INFO: Pod "client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca": Phase="Pending", Reason="", readiness=false. Elapsed: 6.865492ms
    Apr 26 11:59:31.596: INFO: Pod "client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014388438s
    Apr 26 11:59:33.596: INFO: Pod "client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014197898s
    STEP: Saw pod success 04/26/24 11:59:33.596
    Apr 26 11:59:33.596: INFO: Pod "client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca" satisfied condition "Succeeded or Failed"
    Apr 26 11:59:33.601: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 11:59:33.619
    Apr 26 11:59:33.633: INFO: Waiting for pod client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca to disappear
    Apr 26 11:59:33.638: INFO: Pod client-containers-2643e41b-04fd-47a9-8b90-0b0dd3e929ca no longer exists
    [AfterEach] [sig-node] Containers
      test/e2e/framework/framework.go:187
    Apr 26 11:59:33.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "containers-6858" for this suite. 04/26/24 11:59:33.649
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:59:33.684
Apr 26 11:59:33.685: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename daemonsets 04/26/24 11:59:33.685
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:33.7
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:33.706
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373
Apr 26 11:59:33.759: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster. 04/26/24 11:59:33.764
Apr 26 11:59:33.784: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:59:33.784: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:59:34.802: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 26 11:59:34.802: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:59:35.804: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Apr 26 11:59:35.804: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
STEP: Update daemon pods image. 04/26/24 11:59:35.827
STEP: Check that daemon pods images are updated. 04/26/24 11:59:35.852
Apr 26 11:59:35.860: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:35.860: INFO: Wrong image for pod: daemon-set-kfw2d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:35.860: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:35.860: INFO: Wrong image for pod: daemon-set-wxdf8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:36.884: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:36.884: INFO: Wrong image for pod: daemon-set-kfw2d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:36.884: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:36.884: INFO: Wrong image for pod: daemon-set-wxdf8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:37.881: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:37.881: INFO: Wrong image for pod: daemon-set-kfw2d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:37.881: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:37.881: INFO: Wrong image for pod: daemon-set-wxdf8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:38.883: INFO: Pod daemon-set-85xbq is not available
Apr 26 11:59:38.883: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:38.883: INFO: Wrong image for pod: daemon-set-kfw2d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:38.883: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:38.883: INFO: Wrong image for pod: daemon-set-wxdf8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:39.883: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:39.883: INFO: Wrong image for pod: daemon-set-kfw2d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:39.883: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:40.880: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:40.880: INFO: Pod daemon-set-fg2vh is not available
Apr 26 11:59:40.880: INFO: Wrong image for pod: daemon-set-kfw2d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:40.880: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:41.881: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:41.881: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:41.881: INFO: Pod daemon-set-vqpl7 is not available
Apr 26 11:59:42.915: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:43.882: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:44.881: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
Apr 26 11:59:44.881: INFO: Pod daemon-set-mk2l5 is not available
Apr 26 11:59:46.883: INFO: Pod daemon-set-srk6c is not available
STEP: Check that daemon pods are still running on every node of the cluster. 04/26/24 11:59:46.895
Apr 26 11:59:46.911: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Apr 26 11:59:46.911: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:59:47.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Apr 26 11:59:47.930: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:59:48.965: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
Apr 26 11:59:48.965: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 11:59:49.932: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Apr 26 11:59:49.932: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/26/24 11:59:49.956
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5625, will wait for the garbage collector to delete the pods 04/26/24 11:59:49.956
Apr 26 11:59:50.018: INFO: Deleting DaemonSet.extensions daemon-set took: 6.68308ms
Apr 26 11:59:50.119: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.187074ms
Apr 26 11:59:52.325: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 11:59:52.325: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 26 11:59:52.331: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"39171"},"items":null}

Apr 26 11:59:52.336: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"39171"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 26 11:59:52.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5625" for this suite. 04/26/24 11:59:52.401
{"msg":"PASSED [sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]","completed":241,"skipped":4514,"failed":0}
------------------------------
â€¢ [SLOW TEST] [18.723 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  test/e2e/apps/daemon_set.go:373

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:59:33.684
    Apr 26 11:59:33.685: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename daemonsets 04/26/24 11:59:33.685
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:33.7
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:33.706
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
      test/e2e/apps/daemon_set.go:373
    Apr 26 11:59:33.759: INFO: Creating simple daemon set daemon-set
    STEP: Check that daemon pods launch on every node of the cluster. 04/26/24 11:59:33.764
    Apr 26 11:59:33.784: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:59:33.784: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:59:34.802: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 26 11:59:34.802: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:59:35.804: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
    Apr 26 11:59:35.804: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
    STEP: Update daemon pods image. 04/26/24 11:59:35.827
    STEP: Check that daemon pods images are updated. 04/26/24 11:59:35.852
    Apr 26 11:59:35.860: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:35.860: INFO: Wrong image for pod: daemon-set-kfw2d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:35.860: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:35.860: INFO: Wrong image for pod: daemon-set-wxdf8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:36.884: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:36.884: INFO: Wrong image for pod: daemon-set-kfw2d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:36.884: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:36.884: INFO: Wrong image for pod: daemon-set-wxdf8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:37.881: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:37.881: INFO: Wrong image for pod: daemon-set-kfw2d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:37.881: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:37.881: INFO: Wrong image for pod: daemon-set-wxdf8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:38.883: INFO: Pod daemon-set-85xbq is not available
    Apr 26 11:59:38.883: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:38.883: INFO: Wrong image for pod: daemon-set-kfw2d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:38.883: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:38.883: INFO: Wrong image for pod: daemon-set-wxdf8. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:39.883: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:39.883: INFO: Wrong image for pod: daemon-set-kfw2d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:39.883: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:40.880: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:40.880: INFO: Pod daemon-set-fg2vh is not available
    Apr 26 11:59:40.880: INFO: Wrong image for pod: daemon-set-kfw2d. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:40.880: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:41.881: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:41.881: INFO: Wrong image for pod: daemon-set-mvltp. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:41.881: INFO: Pod daemon-set-vqpl7 is not available
    Apr 26 11:59:42.915: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:43.882: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:44.881: INFO: Wrong image for pod: daemon-set-f8dgj. Expected: registry.k8s.io/e2e-test-images/agnhost:2.40, got: registry.k8s.io/e2e-test-images/httpd:2.4.38-2.
    Apr 26 11:59:44.881: INFO: Pod daemon-set-mk2l5 is not available
    Apr 26 11:59:46.883: INFO: Pod daemon-set-srk6c is not available
    STEP: Check that daemon pods are still running on every node of the cluster. 04/26/24 11:59:46.895
    Apr 26 11:59:46.911: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Apr 26 11:59:46.911: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:59:47.930: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Apr 26 11:59:47.930: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:59:48.965: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 4
    Apr 26 11:59:48.965: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 11:59:49.932: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
    Apr 26 11:59:49.932: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/26/24 11:59:49.956
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5625, will wait for the garbage collector to delete the pods 04/26/24 11:59:49.956
    Apr 26 11:59:50.018: INFO: Deleting DaemonSet.extensions daemon-set took: 6.68308ms
    Apr 26 11:59:50.119: INFO: Terminating DaemonSet.extensions daemon-set pods took: 101.187074ms
    Apr 26 11:59:52.325: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 11:59:52.325: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 26 11:59:52.331: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"39171"},"items":null}

    Apr 26 11:59:52.336: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"39171"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 11:59:52.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-5625" for this suite. 04/26/24 11:59:52.401
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:59:52.411
Apr 26 11:59:52.411: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename svcaccounts 04/26/24 11:59:52.413
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:52.432
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:52.439
[It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739
Apr 26 11:59:52.455: INFO: Got root ca configmap in namespace "svcaccounts-4906"
Apr 26 11:59:52.460: INFO: Deleted root ca configmap in namespace "svcaccounts-4906"
STEP: waiting for a new root ca configmap created 04/26/24 11:59:52.961
Apr 26 11:59:52.967: INFO: Recreated root ca configmap in namespace "svcaccounts-4906"
Apr 26 11:59:52.972: INFO: Updated root ca configmap in namespace "svcaccounts-4906"
STEP: waiting for the root ca configmap reconciled 04/26/24 11:59:53.473
Apr 26 11:59:53.479: INFO: Reconciled root ca configmap in namespace "svcaccounts-4906"
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 26 11:59:53.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4906" for this suite. 04/26/24 11:59:53.492
{"msg":"PASSED [sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]","completed":242,"skipped":4535,"failed":0}
------------------------------
â€¢ [1.087 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should guarantee kube-root-ca.crt exist in any namespace [Conformance]
  test/e2e/auth/service_accounts.go:739

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:59:52.411
    Apr 26 11:59:52.411: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename svcaccounts 04/26/24 11:59:52.413
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:52.432
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:52.439
    [It] should guarantee kube-root-ca.crt exist in any namespace [Conformance]
      test/e2e/auth/service_accounts.go:739
    Apr 26 11:59:52.455: INFO: Got root ca configmap in namespace "svcaccounts-4906"
    Apr 26 11:59:52.460: INFO: Deleted root ca configmap in namespace "svcaccounts-4906"
    STEP: waiting for a new root ca configmap created 04/26/24 11:59:52.961
    Apr 26 11:59:52.967: INFO: Recreated root ca configmap in namespace "svcaccounts-4906"
    Apr 26 11:59:52.972: INFO: Updated root ca configmap in namespace "svcaccounts-4906"
    STEP: waiting for the root ca configmap reconciled 04/26/24 11:59:53.473
    Apr 26 11:59:53.479: INFO: Reconciled root ca configmap in namespace "svcaccounts-4906"
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 26 11:59:53.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-4906" for this suite. 04/26/24 11:59:53.492
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 11:59:53.5
Apr 26 11:59:53.500: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename resourcequota 04/26/24 11:59:53.501
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:53.518
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:53.524
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680
STEP: Creating a ResourceQuota with terminating scope 04/26/24 11:59:53.532
STEP: Ensuring ResourceQuota status is calculated 04/26/24 11:59:53.54
STEP: Creating a ResourceQuota with not terminating scope 04/26/24 11:59:55.547
STEP: Ensuring ResourceQuota status is calculated 04/26/24 11:59:55.555
STEP: Creating a long running pod 04/26/24 11:59:57.561
STEP: Ensuring resource quota with not terminating scope captures the pod usage 04/26/24 11:59:57.578
STEP: Ensuring resource quota with terminating scope ignored the pod usage 04/26/24 11:59:59.586
STEP: Deleting the pod 04/26/24 12:00:01.594
STEP: Ensuring resource quota status released the pod usage 04/26/24 12:00:01.609
STEP: Creating a terminating pod 04/26/24 12:00:03.616
STEP: Ensuring resource quota with terminating scope captures the pod usage 04/26/24 12:00:03.63
STEP: Ensuring resource quota with not terminating scope ignored the pod usage 04/26/24 12:00:05.637
STEP: Deleting the pod 04/26/24 12:00:07.643
STEP: Ensuring resource quota status released the pod usage 04/26/24 12:00:07.657
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 26 12:00:09.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6368" for this suite. 04/26/24 12:00:09.681
{"msg":"PASSED [sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]","completed":243,"skipped":4558,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.189 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  test/e2e/apimachinery/resource_quota.go:680

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 11:59:53.5
    Apr 26 11:59:53.500: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename resourcequota 04/26/24 11:59:53.501
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 11:59:53.518
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 11:59:53.524
    [It] should verify ResourceQuota with terminating scopes. [Conformance]
      test/e2e/apimachinery/resource_quota.go:680
    STEP: Creating a ResourceQuota with terminating scope 04/26/24 11:59:53.532
    STEP: Ensuring ResourceQuota status is calculated 04/26/24 11:59:53.54
    STEP: Creating a ResourceQuota with not terminating scope 04/26/24 11:59:55.547
    STEP: Ensuring ResourceQuota status is calculated 04/26/24 11:59:55.555
    STEP: Creating a long running pod 04/26/24 11:59:57.561
    STEP: Ensuring resource quota with not terminating scope captures the pod usage 04/26/24 11:59:57.578
    STEP: Ensuring resource quota with terminating scope ignored the pod usage 04/26/24 11:59:59.586
    STEP: Deleting the pod 04/26/24 12:00:01.594
    STEP: Ensuring resource quota status released the pod usage 04/26/24 12:00:01.609
    STEP: Creating a terminating pod 04/26/24 12:00:03.616
    STEP: Ensuring resource quota with terminating scope captures the pod usage 04/26/24 12:00:03.63
    STEP: Ensuring resource quota with not terminating scope ignored the pod usage 04/26/24 12:00:05.637
    STEP: Deleting the pod 04/26/24 12:00:07.643
    STEP: Ensuring resource quota status released the pod usage 04/26/24 12:00:07.657
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 26 12:00:09.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-6368" for this suite. 04/26/24 12:00:09.681
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:09.69
Apr 26 12:00:09.690: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 12:00:09.691
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:09.711
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:09.718
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67
STEP: Creating a pod to test downward API volume plugin 04/26/24 12:00:09.727
Apr 26 12:00:09.736: INFO: Waiting up to 5m0s for pod "downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4" in namespace "downward-api-5133" to be "Succeeded or Failed"
Apr 26 12:00:09.766: INFO: Pod "downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4": Phase="Pending", Reason="", readiness=false. Elapsed: 29.374923ms
Apr 26 12:00:11.773: INFO: Pod "downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036558805s
Apr 26 12:00:13.772: INFO: Pod "downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035812823s
STEP: Saw pod success 04/26/24 12:00:13.772
Apr 26 12:00:13.772: INFO: Pod "downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4" satisfied condition "Succeeded or Failed"
Apr 26 12:00:13.777: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4 container client-container: <nil>
STEP: delete the pod 04/26/24 12:00:13.789
Apr 26 12:00:13.800: INFO: Waiting for pod downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4 to disappear
Apr 26 12:00:13.803: INFO: Pod downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 26 12:00:13.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5133" for this suite. 04/26/24 12:00:13.812
{"msg":"PASSED [sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]","completed":244,"skipped":4565,"failed":0}
------------------------------
â€¢ [4.128 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:09.69
    Apr 26 12:00:09.690: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 12:00:09.691
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:09.711
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:09.718
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:67
    STEP: Creating a pod to test downward API volume plugin 04/26/24 12:00:09.727
    Apr 26 12:00:09.736: INFO: Waiting up to 5m0s for pod "downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4" in namespace "downward-api-5133" to be "Succeeded or Failed"
    Apr 26 12:00:09.766: INFO: Pod "downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4": Phase="Pending", Reason="", readiness=false. Elapsed: 29.374923ms
    Apr 26 12:00:11.773: INFO: Pod "downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036558805s
    Apr 26 12:00:13.772: INFO: Pod "downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035812823s
    STEP: Saw pod success 04/26/24 12:00:13.772
    Apr 26 12:00:13.772: INFO: Pod "downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4" satisfied condition "Succeeded or Failed"
    Apr 26 12:00:13.777: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4 container client-container: <nil>
    STEP: delete the pod 04/26/24 12:00:13.789
    Apr 26 12:00:13.800: INFO: Waiting for pod downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4 to disappear
    Apr 26 12:00:13.803: INFO: Pod downwardapi-volume-145b98d9-07ba-4d4b-b24f-bac78fc27ec4 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 26 12:00:13.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-5133" for this suite. 04/26/24 12:00:13.812
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:13.819
Apr 26 12:00:13.819: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 12:00:13.82
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:13.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:13.846
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  test/e2e/kubectl/kubectl.go:1274
Apr 26 12:00:13.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 create -f -'
Apr 26 12:00:14.417: INFO: stderr: ""
Apr 26 12:00:14.417: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
Apr 26 12:00:14.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 create -f -'
Apr 26 12:00:14.577: INFO: stderr: ""
Apr 26 12:00:14.577: INFO: stdout: "service/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/26/24 12:00:14.577
Apr 26 12:00:15.584: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 26 12:00:15.584: INFO: Found 0 / 1
Apr 26 12:00:16.584: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 26 12:00:16.584: INFO: Found 1 / 1
Apr 26 12:00:16.584: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 26 12:00:16.590: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 26 12:00:16.590: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 26 12:00:16.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 describe pod agnhost-primary-h2zwm'
Apr 26 12:00:16.676: INFO: stderr: ""
Apr 26 12:00:16.676: INFO: stdout: "Name:             agnhost-primary-h2zwm\nNamespace:        kubectl-2739\nPriority:         0\nService Account:  default\nNode:             shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j/10.250.0.152\nStart Time:       Fri, 26 Apr 2024 12:00:14 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 63963cf9815464319fae1ffc634ec28d5888384440f6f5a609250ae80f8489cf\n                  cni.projectcalico.org/podIP: 100.96.3.63/32\n                  cni.projectcalico.org/podIPs: 100.96.3.63/32\nStatus:           Running\nIP:               100.96.3.63\nIPs:\n  IP:           100.96.3.63\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://8f2bb6b5e627ecc3ec5f6c782dc5503041c5b04b0845025fe06539c685de9190\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 26 Apr 2024 12:00:15 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:\n      KUBERNETES_SERVICE_HOST:  api.conf-125.thomas.internal.emk.fuga.cloud\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-l5ptr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-l5ptr:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-2739/agnhost-primary-h2zwm to shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
Apr 26 12:00:16.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 describe rc agnhost-primary'
Apr 26 12:00:16.771: INFO: stderr: ""
Apr 26 12:00:16.771: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-2739\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-h2zwm\n"
Apr 26 12:00:16.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 describe service agnhost-primary'
Apr 26 12:00:16.849: INFO: stderr: ""
Apr 26 12:00:16.849: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-2739\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                100.67.54.178\nIPs:               100.67.54.178\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         100.96.3.63:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 26 12:00:16.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 describe node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh'
Apr 26 12:00:17.019: INFO: stderr: ""
Apr 26 12:00:17.019: INFO: stdout: "Name:               shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=emk1.medium\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=fra\n                    failure-domain.beta.kubernetes.io/zone=fra-a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh\n                    kubernetes.io/os=linux\n                    networking.gardener.cloud/node-local-dns-enabled=false\n                    node.kubernetes.io/instance-type=emk1.medium\n                    node.kubernetes.io/role=node\n                    topology.cinder.csi.openstack.org/zone=fra-a\n                    topology.kubernetes.io/region=fra\n                    topology.kubernetes.io/zone=fra-a\n                    worker.garden.sapcloud.io/group=worker-6a5hr-1\n                    worker.gardener.cloud/cri-name=containerd\n                    worker.gardener.cloud/kubernetes-version=1.25.16\n                    worker.gardener.cloud/pool=worker-6a5hr-1\n                    worker.gardener.cloud/system-components=true\nAnnotations:        checksum/cloud-config-data: a3e5597986e7461cde93f498180279fe3b7e305b6d818eefac50914bace0621c\n                    csi.volume.kubernetes.io/nodeid: {\"cinder.csi.openstack.org\":\"0579c19c-be9f-4e9f-877e-2e31bf456a1f\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    node.machine.sapcloud.io/last-applied-anno-labels-taints:\n                      {\"metadata\":{\"creationTimestamp\":null,\"labels\":{\"kubernetes.io/arch\":\"amd64\",\"networking.gardener.cloud/node-local-dns-enabled\":\"false\",\"n...\n                    projectcalico.org/IPv4Address: 10.250.0.91/16\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.96.4.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 26 Apr 2024 11:55:29 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 26 Apr 2024 12:00:15 +0000\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  CorruptDockerOverlay2         False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentUnregisterNetDevice   False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  NetworkUnavailable            False   Fri, 26 Apr 2024 11:56:06 +0000   Fri, 26 Apr 2024 11:56:06 +0000   CalicoIsUp                      Calico is running on this node\n  MemoryPressure                False   Fri, 26 Apr 2024 11:57:53 +0000   Fri, 26 Apr 2024 11:55:29 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Fri, 26 Apr 2024 11:57:53 +0000   Fri, 26 Apr 2024 11:55:29 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Fri, 26 Apr 2024 11:57:53 +0000   Fri, 26 Apr 2024 11:55:29 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Fri, 26 Apr 2024 11:57:53 +0000   Fri, 26 Apr 2024 11:56:00 +0000   KubeletReady                    kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.250.0.91\n  Hostname:    shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh\nCapacity:\n  cpu:                4\n  ephemeral-storage:  101591732Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16389292Ki\n  pods:               110\nAllocatable:\n  cpu:                3920m\n  ephemeral-storage:  98828436813\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             15238316Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 0579c19cbe9f4e9f877e2e31bf456a1f\n  System UUID:                0579c19c-be9f-4e9f-877e-2e31bf456a1f\n  Boot ID:                    92893a04-81e3-41a3-8e5e-28e57d8388e5\n  Kernel Version:             6.1.77-gardenlinux-cloud-amd64\n  OS Image:                   Garden Linux 1312.3\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.24\n  Kubelet Version:            v1.25.16\n  Kube-Proxy Version:         v1.25.16\nPodCIDR:                      100.96.4.0/24\nPodCIDRs:                     100.96.4.0/24\nProviderID:                   openstack:///0579c19c-be9f-4e9f-877e-2e31bf456a1f\nNon-terminated Pods:          (7 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits     Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------     ---\n  kube-system                 apiserver-proxy-qltrf                                      40m (1%)      0 (0%)      40Mi (0%)        1114Mi (7%)       4m47s\n  kube-system                 calico-node-nj95n                                          250m (6%)     0 (0%)      104857600 (0%)   2936012800 (18%)  4m47s\n  kube-system                 csi-driver-node-fp59p                                      37m (0%)      0 (0%)      106Mi (0%)       0 (0%)            4m47s\n  kube-system                 kube-proxy-worker-6a5hr-1-v1.25.16-lsz8x                   20m (0%)      0 (0%)      64Mi (0%)        0 (0%)            4m47s\n  kube-system                 node-exporter-nssqr                                        50m (1%)      0 (0%)      50Mi (0%)        250Mi (1%)        4m47s\n  kube-system                 node-problem-detector-7vd2p                                20m (0%)      0 (0%)      20Mi (0%)        500Mi (3%)        4m47s\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-n89vg    0 (0%)        0 (0%)      0 (0%)           0 (0%)            4m47s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                417m (10%)  0 (0%)\n  memory             380Mi (2%)  4664Mi (31%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type     Reason                             Age                    From                      Message\n  ----     ------                             ----                   ----                      -------\n  Normal   Starting                           4m18s                  kube-proxy                \n  Normal   NodeHasSufficientMemory            4m48s (x8 over 5m)     kubelet                   Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh status is now: NodeHasSufficientMemory\n  Warning  UnscheduledNodeCriticalDaemonSets  4m47s                  gardener-node-controller  Node-critical DaemonSets found that were not scheduled to Node yet: kube-system/calico-node, kube-system/kube-proxy-worker-6a5hr-1-v1.25.16, kube-system/csi-driver-node, kube-system/apiserver-proxy\n  Normal   Synced                             4m47s                  cloud-node-controller     Node synced successfully\n  Normal   RegisteredNode                     4m44s                  node-controller           Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh event: Registered Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh in Controller\n  Warning  UnreadyNodeCriticalPods            4m17s (x3 over 4m37s)  gardener-node-controller  Unready node-critical Pods found on Node: kube-system/csi-driver-node-fp59p, kube-system/apiserver-proxy-qltrf, kube-system/calico-node-nj95n, kube-system/kube-proxy-worker-6a5hr-1-v1.25.16-lsz8x\n  Warning  UnreadyNodeCriticalPods            4m7s                   gardener-node-controller  Unready node-critical Pods found on Node: kube-system/csi-driver-node-fp59p, kube-system/calico-node-nj95n, kube-system/kube-proxy-worker-6a5hr-1-v1.25.16-lsz8x\n  Normal   NodeCriticalComponentsReady        3m57s                  gardener-node-controller  All node-critical components got ready, removing taint\n"
Apr 26 12:00:17.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 describe namespace kubectl-2739'
Apr 26 12:00:17.098: INFO: stderr: ""
Apr 26 12:00:17.098: INFO: stdout: "Name:         kubectl-2739\nLabels:       e2e-framework=kubectl\n              e2e-run=e803992f-bfbe-4749-88d1-ca8f68f31e73\n              kubernetes.io/metadata.name=kubectl-2739\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 12:00:17.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2739" for this suite. 04/26/24 12:00:17.11
{"msg":"PASSED [sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods  [Conformance]","completed":245,"skipped":4573,"failed":0}
------------------------------
â€¢ [3.297 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl describe
  test/e2e/kubectl/kubectl.go:1268
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    test/e2e/kubectl/kubectl.go:1274

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:13.819
    Apr 26 12:00:13.819: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 12:00:13.82
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:13.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:13.846
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
      test/e2e/kubectl/kubectl.go:1274
    Apr 26 12:00:13.853: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 create -f -'
    Apr 26 12:00:14.417: INFO: stderr: ""
    Apr 26 12:00:14.417: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    Apr 26 12:00:14.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 create -f -'
    Apr 26 12:00:14.577: INFO: stderr: ""
    Apr 26 12:00:14.577: INFO: stdout: "service/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/26/24 12:00:14.577
    Apr 26 12:00:15.584: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 26 12:00:15.584: INFO: Found 0 / 1
    Apr 26 12:00:16.584: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 26 12:00:16.584: INFO: Found 1 / 1
    Apr 26 12:00:16.584: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    Apr 26 12:00:16.590: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 26 12:00:16.590: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 26 12:00:16.590: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 describe pod agnhost-primary-h2zwm'
    Apr 26 12:00:16.676: INFO: stderr: ""
    Apr 26 12:00:16.676: INFO: stdout: "Name:             agnhost-primary-h2zwm\nNamespace:        kubectl-2739\nPriority:         0\nService Account:  default\nNode:             shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j/10.250.0.152\nStart Time:       Fri, 26 Apr 2024 12:00:14 +0000\nLabels:           app=agnhost\n                  role=primary\nAnnotations:      cni.projectcalico.org/containerID: 63963cf9815464319fae1ffc634ec28d5888384440f6f5a609250ae80f8489cf\n                  cni.projectcalico.org/podIP: 100.96.3.63/32\n                  cni.projectcalico.org/podIPs: 100.96.3.63/32\nStatus:           Running\nIP:               100.96.3.63\nIPs:\n  IP:           100.96.3.63\nControlled By:  ReplicationController/agnhost-primary\nContainers:\n  agnhost-primary:\n    Container ID:   containerd://8f2bb6b5e627ecc3ec5f6c782dc5503041c5b04b0845025fe06539c685de9190\n    Image:          registry.k8s.io/e2e-test-images/agnhost:2.40\n    Image ID:       registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 26 Apr 2024 12:00:15 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:\n      KUBERNETES_SERVICE_HOST:  api.conf-125.thomas.internal.emk.fuga.cloud\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-l5ptr (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  kube-api-access-l5ptr:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       <nil>\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              <none>\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-2739/agnhost-primary-h2zwm to shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j\n  Normal  Pulled     2s    kubelet            Container image \"registry.k8s.io/e2e-test-images/agnhost:2.40\" already present on machine\n  Normal  Created    2s    kubelet            Created container agnhost-primary\n  Normal  Started    1s    kubelet            Started container agnhost-primary\n"
    Apr 26 12:00:16.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 describe rc agnhost-primary'
    Apr 26 12:00:16.771: INFO: stderr: ""
    Apr 26 12:00:16.771: INFO: stdout: "Name:         agnhost-primary\nNamespace:    kubectl-2739\nSelector:     app=agnhost,role=primary\nLabels:       app=agnhost\n              role=primary\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=agnhost\n           role=primary\n  Containers:\n   agnhost-primary:\n    Image:        registry.k8s.io/e2e-test-images/agnhost:2.40\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: agnhost-primary-h2zwm\n"
    Apr 26 12:00:16.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 describe service agnhost-primary'
    Apr 26 12:00:16.849: INFO: stderr: ""
    Apr 26 12:00:16.849: INFO: stdout: "Name:              agnhost-primary\nNamespace:         kubectl-2739\nLabels:            app=agnhost\n                   role=primary\nAnnotations:       <none>\nSelector:          app=agnhost,role=primary\nType:              ClusterIP\nIP Family Policy:  SingleStack\nIP Families:       IPv4\nIP:                100.67.54.178\nIPs:               100.67.54.178\nPort:              <unset>  6379/TCP\nTargetPort:        agnhost-server/TCP\nEndpoints:         100.96.3.63:6379\nSession Affinity:  None\nEvents:            <none>\n"
    Apr 26 12:00:16.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 describe node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh'
    Apr 26 12:00:17.019: INFO: stderr: ""
    Apr 26 12:00:17.019: INFO: stdout: "Name:               shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=emk1.medium\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=fra\n                    failure-domain.beta.kubernetes.io/zone=fra-a\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh\n                    kubernetes.io/os=linux\n                    networking.gardener.cloud/node-local-dns-enabled=false\n                    node.kubernetes.io/instance-type=emk1.medium\n                    node.kubernetes.io/role=node\n                    topology.cinder.csi.openstack.org/zone=fra-a\n                    topology.kubernetes.io/region=fra\n                    topology.kubernetes.io/zone=fra-a\n                    worker.garden.sapcloud.io/group=worker-6a5hr-1\n                    worker.gardener.cloud/cri-name=containerd\n                    worker.gardener.cloud/kubernetes-version=1.25.16\n                    worker.gardener.cloud/pool=worker-6a5hr-1\n                    worker.gardener.cloud/system-components=true\nAnnotations:        checksum/cloud-config-data: a3e5597986e7461cde93f498180279fe3b7e305b6d818eefac50914bace0621c\n                    csi.volume.kubernetes.io/nodeid: {\"cinder.csi.openstack.org\":\"0579c19c-be9f-4e9f-877e-2e31bf456a1f\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    node.machine.sapcloud.io/last-applied-anno-labels-taints:\n                      {\"metadata\":{\"creationTimestamp\":null,\"labels\":{\"kubernetes.io/arch\":\"amd64\",\"networking.gardener.cloud/node-local-dns-enabled\":\"false\",\"n...\n                    projectcalico.org/IPv4Address: 10.250.0.91/16\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.96.4.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Fri, 26 Apr 2024 11:55:29 +0000\nTaints:             <none>\nUnschedulable:      false\nLease:\n  HolderIdentity:  shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh\n  AcquireTime:     <unset>\n  RenewTime:       Fri, 26 Apr 2024 12:00:15 +0000\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  CorruptDockerOverlay2         False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentUnregisterNetDevice   False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Fri, 26 Apr 2024 11:56:20 +0000   Fri, 26 Apr 2024 11:56:19 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  NetworkUnavailable            False   Fri, 26 Apr 2024 11:56:06 +0000   Fri, 26 Apr 2024 11:56:06 +0000   CalicoIsUp                      Calico is running on this node\n  MemoryPressure                False   Fri, 26 Apr 2024 11:57:53 +0000   Fri, 26 Apr 2024 11:55:29 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Fri, 26 Apr 2024 11:57:53 +0000   Fri, 26 Apr 2024 11:55:29 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Fri, 26 Apr 2024 11:57:53 +0000   Fri, 26 Apr 2024 11:55:29 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Fri, 26 Apr 2024 11:57:53 +0000   Fri, 26 Apr 2024 11:56:00 +0000   KubeletReady                    kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.250.0.91\n  Hostname:    shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh\nCapacity:\n  cpu:                4\n  ephemeral-storage:  101591732Ki\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             16389292Ki\n  pods:               110\nAllocatable:\n  cpu:                3920m\n  ephemeral-storage:  98828436813\n  hugepages-1Gi:      0\n  hugepages-2Mi:      0\n  memory:             15238316Ki\n  pods:               110\nSystem Info:\n  Machine ID:                 0579c19cbe9f4e9f877e2e31bf456a1f\n  System UUID:                0579c19c-be9f-4e9f-877e-2e31bf456a1f\n  Boot ID:                    92893a04-81e3-41a3-8e5e-28e57d8388e5\n  Kernel Version:             6.1.77-gardenlinux-cloud-amd64\n  OS Image:                   Garden Linux 1312.3\n  Operating System:           linux\n  Architecture:               amd64\n  Container Runtime Version:  containerd://1.6.24\n  Kubelet Version:            v1.25.16\n  Kube-Proxy Version:         v1.25.16\nPodCIDR:                      100.96.4.0/24\nPodCIDRs:                     100.96.4.0/24\nProviderID:                   openstack:///0579c19c-be9f-4e9f-877e-2e31bf456a1f\nNon-terminated Pods:          (7 in total)\n  Namespace                   Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits     Age\n  ---------                   ----                                                       ------------  ----------  ---------------  -------------     ---\n  kube-system                 apiserver-proxy-qltrf                                      40m (1%)      0 (0%)      40Mi (0%)        1114Mi (7%)       4m47s\n  kube-system                 calico-node-nj95n                                          250m (6%)     0 (0%)      104857600 (0%)   2936012800 (18%)  4m47s\n  kube-system                 csi-driver-node-fp59p                                      37m (0%)      0 (0%)      106Mi (0%)       0 (0%)            4m47s\n  kube-system                 kube-proxy-worker-6a5hr-1-v1.25.16-lsz8x                   20m (0%)      0 (0%)      64Mi (0%)        0 (0%)            4m47s\n  kube-system                 node-exporter-nssqr                                        50m (1%)      0 (0%)      50Mi (0%)        250Mi (1%)        4m47s\n  kube-system                 node-problem-detector-7vd2p                                20m (0%)      0 (0%)      20Mi (0%)        500Mi (3%)        4m47s\n  sonobuoy                    sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-n89vg    0 (0%)        0 (0%)      0 (0%)           0 (0%)            4m47s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                417m (10%)  0 (0%)\n  memory             380Mi (2%)  4664Mi (31%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-1Gi      0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:\n  Type     Reason                             Age                    From                      Message\n  ----     ------                             ----                   ----                      -------\n  Normal   Starting                           4m18s                  kube-proxy                \n  Normal   NodeHasSufficientMemory            4m48s (x8 over 5m)     kubelet                   Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh status is now: NodeHasSufficientMemory\n  Warning  UnscheduledNodeCriticalDaemonSets  4m47s                  gardener-node-controller  Node-critical DaemonSets found that were not scheduled to Node yet: kube-system/calico-node, kube-system/kube-proxy-worker-6a5hr-1-v1.25.16, kube-system/csi-driver-node, kube-system/apiserver-proxy\n  Normal   Synced                             4m47s                  cloud-node-controller     Node synced successfully\n  Normal   RegisteredNode                     4m44s                  node-controller           Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh event: Registered Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh in Controller\n  Warning  UnreadyNodeCriticalPods            4m17s (x3 over 4m37s)  gardener-node-controller  Unready node-critical Pods found on Node: kube-system/csi-driver-node-fp59p, kube-system/apiserver-proxy-qltrf, kube-system/calico-node-nj95n, kube-system/kube-proxy-worker-6a5hr-1-v1.25.16-lsz8x\n  Warning  UnreadyNodeCriticalPods            4m7s                   gardener-node-controller  Unready node-critical Pods found on Node: kube-system/csi-driver-node-fp59p, kube-system/calico-node-nj95n, kube-system/kube-proxy-worker-6a5hr-1-v1.25.16-lsz8x\n  Normal   NodeCriticalComponentsReady        3m57s                  gardener-node-controller  All node-critical components got ready, removing taint\n"
    Apr 26 12:00:17.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-2739 describe namespace kubectl-2739'
    Apr 26 12:00:17.098: INFO: stderr: ""
    Apr 26 12:00:17.098: INFO: stdout: "Name:         kubectl-2739\nLabels:       e2e-framework=kubectl\n              e2e-run=e803992f-bfbe-4749-88d1-ca8f68f31e73\n              kubernetes.io/metadata.name=kubectl-2739\n              pod-security.kubernetes.io/enforce=baseline\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo LimitRange resource.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 12:00:17.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-2739" for this suite. 04/26/24 12:00:17.11
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:17.125
Apr 26 12:00:17.125: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename deployment 04/26/24 12:00:17.126
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:17.14
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:17.146
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113
Apr 26 12:00:17.152: INFO: Creating deployment "test-recreate-deployment"
Apr 26 12:00:17.167: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 26 12:00:17.175: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 26 12:00:19.189: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 26 12:00:19.209: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 26 12:00:19.255: INFO: Updating deployment test-recreate-deployment
Apr 26 12:00:19.255: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 26 12:00:19.319: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-3598  8c886e82-72e6-4deb-9b89-bd354fc847ff 39390 2 2024-04-26 12:00:17 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006037f38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2024-04-26 12:00:19 +0000 UTC,LastTransitionTime:2024-04-26 12:00:19 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2024-04-26 12:00:19 +0000 UTC,LastTransitionTime:2024-04-26 12:00:17 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr 26 12:00:19.324: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-3598  f7db1310-7512-4c8b-9ba9-04c73c9828a7 39389 1 2024-04-26 12:00:19 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 8c886e82-72e6-4deb-9b89-bd354fc847ff 0xc005f5cb00 0xc005f5cb01}] [] [{kube-controller-manager Update apps/v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c886e82-72e6-4deb-9b89-bd354fc847ff\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005f5cdf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 26 12:00:19.324: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 26 12:00:19.325: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-3598  d78d2c54-7550-4f5d-99b7-86bb188e7a35 39383 2 2024-04-26 12:00:17 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 8c886e82-72e6-4deb-9b89-bd354fc847ff 0xc005f5c8a7 0xc005f5c8a8}] [] [{kube-controller-manager Update apps/v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c886e82-72e6-4deb-9b89-bd354fc847ff\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005f5c9b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 26 12:00:19.328: INFO: Pod "test-recreate-deployment-9d58999df-9vzrj" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-9d58999df-9vzrj test-recreate-deployment-9d58999df- deployment-3598  1872a440-eb02-4487-887b-9b3d4d475962 39391 0 2024-04-26 12:00:19 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df f7db1310-7512-4c8b-9ba9-04c73c9828a7 0xc005f5d270 0xc005f5d271}] [] [{kube-controller-manager Update v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f7db1310-7512-4c8b-9ba9-04c73c9828a7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fwtxk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fwtxk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:00:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:00:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:00:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:00:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.91,PodIP:,StartTime:2024-04-26 12:00:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 26 12:00:19.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3598" for this suite. 04/26/24 12:00:19.338
{"msg":"PASSED [sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]","completed":246,"skipped":4624,"failed":0}
------------------------------
â€¢ [2.219 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:113

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:17.125
    Apr 26 12:00:17.125: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename deployment 04/26/24 12:00:17.126
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:17.14
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:17.146
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RecreateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:113
    Apr 26 12:00:17.152: INFO: Creating deployment "test-recreate-deployment"
    Apr 26 12:00:17.167: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
    Apr 26 12:00:17.175: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
    Apr 26 12:00:19.189: INFO: Waiting deployment "test-recreate-deployment" to complete
    Apr 26 12:00:19.209: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
    Apr 26 12:00:19.255: INFO: Updating deployment test-recreate-deployment
    Apr 26 12:00:19.255: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 26 12:00:19.319: INFO: Deployment "test-recreate-deployment":
    &Deployment{ObjectMeta:{test-recreate-deployment  deployment-3598  8c886e82-72e6-4deb-9b89-bd354fc847ff 39390 2 2024-04-26 12:00:17 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] [] [{e2e.test Update apps/v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:replicas":{},"f:unavailableReplicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc006037f38 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2024-04-26 12:00:19 +0000 UTC,LastTransitionTime:2024-04-26 12:00:19 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-9d58999df" is progressing.,LastUpdateTime:2024-04-26 12:00:19 +0000 UTC,LastTransitionTime:2024-04-26 12:00:17 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

    Apr 26 12:00:19.324: INFO: New ReplicaSet "test-recreate-deployment-9d58999df" of Deployment "test-recreate-deployment":
    &ReplicaSet{ObjectMeta:{test-recreate-deployment-9d58999df  deployment-3598  f7db1310-7512-4c8b-9ba9-04c73c9828a7 39389 1 2024-04-26 12:00:19 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 8c886e82-72e6-4deb-9b89-bd354fc847ff 0xc005f5cb00 0xc005f5cb01}] [] [{kube-controller-manager Update apps/v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c886e82-72e6-4deb-9b89-bd354fc847ff\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:status":{"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 9d58999df,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005f5cdf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 26 12:00:19.324: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
    Apr 26 12:00:19.325: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-7d8b6f647f  deployment-3598  d78d2c54-7550-4f5d-99b7-86bb188e7a35 39383 2 2024-04-26 12:00:17 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 8c886e82-72e6-4deb-9b89-bd354fc847ff 0xc005f5c8a7 0xc005f5c8a8}] [] [{kube-controller-manager Update apps/v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8c886e82-72e6-4deb-9b89-bd354fc847ff\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 7d8b6f647f,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:7d8b6f647f] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc005f5c9b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 26 12:00:19.328: INFO: Pod "test-recreate-deployment-9d58999df-9vzrj" is not available:
    &Pod{ObjectMeta:{test-recreate-deployment-9d58999df-9vzrj test-recreate-deployment-9d58999df- deployment-3598  1872a440-eb02-4487-887b-9b3d4d475962 39391 0 2024-04-26 12:00:19 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:9d58999df] map[] [{apps/v1 ReplicaSet test-recreate-deployment-9d58999df f7db1310-7512-4c8b-9ba9-04c73c9828a7 0xc005f5d270 0xc005f5d271}] [] [{kube-controller-manager Update v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"f7db1310-7512-4c8b-9ba9-04c73c9828a7\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {kubelet Update v1 2024-04-26 12:00:19 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-fwtxk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:httpd,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-fwtxk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:00:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:00:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:00:19 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:00:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.91,PodIP:,StartTime:2024-04-26 12:00:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:registry.k8s.io/e2e-test-images/httpd:2.4.38-2,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 26 12:00:19.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-3598" for this suite. 04/26/24 12:00:19.338
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:19.349
Apr 26 12:00:19.349: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 12:00:19.35
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:19.366
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:19.372
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88
STEP: Creating secret with name secret-test-map-c44d18c8-d6cd-4a55-a1ca-a5c545c13f83 04/26/24 12:00:19.378
STEP: Creating a pod to test consume secrets 04/26/24 12:00:19.384
Apr 26 12:00:19.399: INFO: Waiting up to 5m0s for pod "pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2" in namespace "secrets-8520" to be "Succeeded or Failed"
Apr 26 12:00:19.412: INFO: Pod "pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.044687ms
Apr 26 12:00:21.421: INFO: Pod "pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022872422s
Apr 26 12:00:23.420: INFO: Pod "pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02189109s
STEP: Saw pod success 04/26/24 12:00:23.42
Apr 26 12:00:23.421: INFO: Pod "pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2" satisfied condition "Succeeded or Failed"
Apr 26 12:00:23.429: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2 container secret-volume-test: <nil>
STEP: delete the pod 04/26/24 12:00:23.483
Apr 26 12:00:23.496: INFO: Waiting for pod pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2 to disappear
Apr 26 12:00:23.500: INFO: Pod pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 26 12:00:23.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8520" for this suite. 04/26/24 12:00:23.509
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":247,"skipped":4656,"failed":0}
------------------------------
â€¢ [4.174 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:88

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:19.349
    Apr 26 12:00:19.349: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 12:00:19.35
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:19.366
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:19.372
    [It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:88
    STEP: Creating secret with name secret-test-map-c44d18c8-d6cd-4a55-a1ca-a5c545c13f83 04/26/24 12:00:19.378
    STEP: Creating a pod to test consume secrets 04/26/24 12:00:19.384
    Apr 26 12:00:19.399: INFO: Waiting up to 5m0s for pod "pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2" in namespace "secrets-8520" to be "Succeeded or Failed"
    Apr 26 12:00:19.412: INFO: Pod "pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.044687ms
    Apr 26 12:00:21.421: INFO: Pod "pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022872422s
    Apr 26 12:00:23.420: INFO: Pod "pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02189109s
    STEP: Saw pod success 04/26/24 12:00:23.42
    Apr 26 12:00:23.421: INFO: Pod "pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2" satisfied condition "Succeeded or Failed"
    Apr 26 12:00:23.429: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2 container secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 12:00:23.483
    Apr 26 12:00:23.496: INFO: Waiting for pod pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2 to disappear
    Apr 26 12:00:23.500: INFO: Pod pod-secrets-28ddbf94-654e-41cd-b3a3-f7cc1d89e6a2 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 12:00:23.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-8520" for this suite. 04/26/24 12:00:23.509
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial]
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:23.525
Apr 26 12:00:23.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename daemonsets 04/26/24 12:00:23.526
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:23.541
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:23.548
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822
STEP: Creating simple DaemonSet "daemon-set" 04/26/24 12:00:23.603
STEP: Check that daemon pods launch on every node of the cluster. 04/26/24 12:00:23.61
Apr 26 12:00:23.647: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 12:00:23.647: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 12:00:24.670: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
Apr 26 12:00:24.670: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 12:00:25.668: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Apr 26 12:00:25.668: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
STEP: listing all DeamonSets 04/26/24 12:00:25.673
STEP: DeleteCollection of the DaemonSets 04/26/24 12:00:25.678
STEP: Verify that ReplicaSets have been deleted 04/26/24 12:00:25.686
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
Apr 26 12:00:25.804: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"39498"},"items":null}

Apr 26 12:00:25.813: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"39498"},"items":[{"metadata":{"name":"daemon-set-8hrxd","generateName":"daemon-set-","namespace":"daemonsets-7145","uid":"ced33769-6e27-490a-873b-950e3b891e2d","resourceVersion":"39495","creationTimestamp":"2024-04-26T12:00:23Z","deletionTimestamp":"2024-04-26T12:00:55Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"07eca712e7f8f73fd4c39d0108279098db7e639d6efef497f29a0ba85c8cb8cb","cni.projectcalico.org/podIP":"100.96.3.64/32","cni.projectcalico.org/podIPs":"100.96.3.64/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0416410-bd88-4073-a511-ea7a52652ce6","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0416410-bd88-4073-a511-ea7a52652ce6\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.64\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-ksrrh","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.conf-125.thomas.internal.emk.fuga.cloud"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-ksrrh","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:24Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:24Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"}],"hostIP":"10.250.0.152","podIP":"100.96.3.64","podIPs":[{"ip":"100.96.3.64"}],"startTime":"2024-04-26T12:00:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-26T12:00:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://08d7c18a27e5b43e3a9c91e611bd15a1215ce9f8953088660a80327587695e80","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-pcvbz","generateName":"daemon-set-","namespace":"daemonsets-7145","uid":"4b971a51-6d29-4285-b8e4-89e8f2a130b2","resourceVersion":"39496","creationTimestamp":"2024-04-26T12:00:23Z","deletionTimestamp":"2024-04-26T12:00:55Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"e3fda4e7dd7732b5444bc12a0d3b790baf8cc9c903f11fc45bbdf096c8e3e848","cni.projectcalico.org/podIP":"100.96.2.95/32","cni.projectcalico.org/podIPs":"100.96.2.95/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0416410-bd88-4073-a511-ea7a52652ce6","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0416410-bd88-4073-a511-ea7a52652ce6\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.95\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-ndsbg","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.conf-125.thomas.internal.emk.fuga.cloud"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-ndsbg","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:25Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:25Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"}],"hostIP":"10.250.0.121","podIP":"100.96.2.95","podIPs":[{"ip":"100.96.2.95"}],"startTime":"2024-04-26T12:00:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-26T12:00:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://178e096c457bd3271ac8dd4fcb75421f029b8ed1db66eaa55570470797b096b4","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-pfjwc","generateName":"daemon-set-","namespace":"daemonsets-7145","uid":"d2c32aed-3040-46d2-b346-3cb2013fbbf8","resourceVersion":"39493","creationTimestamp":"2024-04-26T12:00:23Z","deletionTimestamp":"2024-04-26T12:00:55Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"62cb44ab791d240a33b4fe67b11f180402d7943f40cd6facecc3f6352e479183","cni.projectcalico.org/podIP":"100.96.4.15/32","cni.projectcalico.org/podIPs":"100.96.4.15/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0416410-bd88-4073-a511-ea7a52652ce6","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0416410-bd88-4073-a511-ea7a52652ce6\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.4.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-l726k","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.conf-125.thomas.internal.emk.fuga.cloud"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-l726k","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:25Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:25Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"}],"hostIP":"10.250.0.91","podIP":"100.96.4.15","podIPs":[{"ip":"100.96.4.15"}],"startTime":"2024-04-26T12:00:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-26T12:00:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://83dfc7c688f0b4c3fabf946f234672c451d68fcdfe5a874ab5b76b3d5ef329f5","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-smcj6","generateName":"daemon-set-","namespace":"daemonsets-7145","uid":"7230f8fc-81df-475f-a331-8d2b358c3b0a","resourceVersion":"39498","creationTimestamp":"2024-04-26T12:00:23Z","deletionTimestamp":"2024-04-26T12:00:55Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f276c769c44528fac8dfd055a8ab43400a3435c40a3687dd5b5771a3ca1ef233","cni.projectcalico.org/podIP":"100.96.0.86/32","cni.projectcalico.org/podIPs":"100.96.0.86/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0416410-bd88-4073-a511-ea7a52652ce6","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0416410-bd88-4073-a511-ea7a52652ce6\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.86\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-htxlw","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.conf-125.thomas.internal.emk.fuga.cloud"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-htxlw","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:24Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:24Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"}],"hostIP":"10.250.1.183","podIP":"100.96.0.86","podIPs":[{"ip":"100.96.0.86"}],"startTime":"2024-04-26T12:00:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-26T12:00:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://6c3147167128a766a205b3ba6a4ed3fa3be190465e31ee9321274b343fbfc2d6","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-tdhpv","generateName":"daemon-set-","namespace":"daemonsets-7145","uid":"dcc75daf-e598-4b03-a451-018d6560ac75","resourceVersion":"39497","creationTimestamp":"2024-04-26T12:00:23Z","deletionTimestamp":"2024-04-26T12:00:55Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"9bfdf59dd48015c17e64651885f6d50b5ebbf7d56404b650a8fe3da36a626286","cni.projectcalico.org/podIP":"100.96.1.239/32","cni.projectcalico.org/podIPs":"100.96.1.239/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0416410-bd88-4073-a511-ea7a52652ce6","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0416410-bd88-4073-a511-ea7a52652ce6\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.239\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-f88bk","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.conf-125.thomas.internal.emk.fuga.cloud"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-f88bk","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:25Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:25Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"}],"hostIP":"10.250.2.248","podIP":"100.96.1.239","podIPs":[{"ip":"100.96.1.239"}],"startTime":"2024-04-26T12:00:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-26T12:00:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://9b1ebee989e3a7b12511247ab638a6e7e19b8933d50a657ecb8dd05877a0d929","started":true}],"qosClass":"BestEffort"}}]}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 26 12:00:25.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7145" for this suite. 04/26/24 12:00:25.872
{"msg":"PASSED [sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]","completed":248,"skipped":4658,"failed":0}
------------------------------
â€¢ [2.391 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should list and delete a collection of DaemonSets [Conformance]
  test/e2e/apps/daemon_set.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:23.525
    Apr 26 12:00:23.525: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename daemonsets 04/26/24 12:00:23.526
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:23.541
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:23.548
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should list and delete a collection of DaemonSets [Conformance]
      test/e2e/apps/daemon_set.go:822
    STEP: Creating simple DaemonSet "daemon-set" 04/26/24 12:00:23.603
    STEP: Check that daemon pods launch on every node of the cluster. 04/26/24 12:00:23.61
    Apr 26 12:00:23.647: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 12:00:23.647: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 12:00:24.670: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 1
    Apr 26 12:00:24.670: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 12:00:25.668: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
    Apr 26 12:00:25.668: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
    STEP: listing all DeamonSets 04/26/24 12:00:25.673
    STEP: DeleteCollection of the DaemonSets 04/26/24 12:00:25.678
    STEP: Verify that ReplicaSets have been deleted 04/26/24 12:00:25.686
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    Apr 26 12:00:25.804: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"39498"},"items":null}

    Apr 26 12:00:25.813: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"39498"},"items":[{"metadata":{"name":"daemon-set-8hrxd","generateName":"daemon-set-","namespace":"daemonsets-7145","uid":"ced33769-6e27-490a-873b-950e3b891e2d","resourceVersion":"39495","creationTimestamp":"2024-04-26T12:00:23Z","deletionTimestamp":"2024-04-26T12:00:55Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"07eca712e7f8f73fd4c39d0108279098db7e639d6efef497f29a0ba85c8cb8cb","cni.projectcalico.org/podIP":"100.96.3.64/32","cni.projectcalico.org/podIPs":"100.96.3.64/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0416410-bd88-4073-a511-ea7a52652ce6","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0416410-bd88-4073-a511-ea7a52652ce6\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.3.64\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-ksrrh","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.conf-125.thomas.internal.emk.fuga.cloud"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-ksrrh","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:24Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:24Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"}],"hostIP":"10.250.0.152","podIP":"100.96.3.64","podIPs":[{"ip":"100.96.3.64"}],"startTime":"2024-04-26T12:00:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-26T12:00:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://08d7c18a27e5b43e3a9c91e611bd15a1215ce9f8953088660a80327587695e80","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-pcvbz","generateName":"daemon-set-","namespace":"daemonsets-7145","uid":"4b971a51-6d29-4285-b8e4-89e8f2a130b2","resourceVersion":"39496","creationTimestamp":"2024-04-26T12:00:23Z","deletionTimestamp":"2024-04-26T12:00:55Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"e3fda4e7dd7732b5444bc12a0d3b790baf8cc9c903f11fc45bbdf096c8e3e848","cni.projectcalico.org/podIP":"100.96.2.95/32","cni.projectcalico.org/podIPs":"100.96.2.95/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0416410-bd88-4073-a511-ea7a52652ce6","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0416410-bd88-4073-a511-ea7a52652ce6\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.2.95\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-ndsbg","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.conf-125.thomas.internal.emk.fuga.cloud"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-ndsbg","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:25Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:25Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"}],"hostIP":"10.250.0.121","podIP":"100.96.2.95","podIPs":[{"ip":"100.96.2.95"}],"startTime":"2024-04-26T12:00:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-26T12:00:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://178e096c457bd3271ac8dd4fcb75421f029b8ed1db66eaa55570470797b096b4","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-pfjwc","generateName":"daemon-set-","namespace":"daemonsets-7145","uid":"d2c32aed-3040-46d2-b346-3cb2013fbbf8","resourceVersion":"39493","creationTimestamp":"2024-04-26T12:00:23Z","deletionTimestamp":"2024-04-26T12:00:55Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"62cb44ab791d240a33b4fe67b11f180402d7943f40cd6facecc3f6352e479183","cni.projectcalico.org/podIP":"100.96.4.15/32","cni.projectcalico.org/podIPs":"100.96.4.15/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0416410-bd88-4073-a511-ea7a52652ce6","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0416410-bd88-4073-a511-ea7a52652ce6\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.4.15\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-l726k","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.conf-125.thomas.internal.emk.fuga.cloud"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-l726k","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:25Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:25Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"}],"hostIP":"10.250.0.91","podIP":"100.96.4.15","podIPs":[{"ip":"100.96.4.15"}],"startTime":"2024-04-26T12:00:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-26T12:00:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://83dfc7c688f0b4c3fabf946f234672c451d68fcdfe5a874ab5b76b3d5ef329f5","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-smcj6","generateName":"daemon-set-","namespace":"daemonsets-7145","uid":"7230f8fc-81df-475f-a331-8d2b358c3b0a","resourceVersion":"39498","creationTimestamp":"2024-04-26T12:00:23Z","deletionTimestamp":"2024-04-26T12:00:55Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"f276c769c44528fac8dfd055a8ab43400a3435c40a3687dd5b5771a3ca1ef233","cni.projectcalico.org/podIP":"100.96.0.86/32","cni.projectcalico.org/podIPs":"100.96.0.86/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0416410-bd88-4073-a511-ea7a52652ce6","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0416410-bd88-4073-a511-ea7a52652ce6\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.0.86\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-htxlw","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.conf-125.thomas.internal.emk.fuga.cloud"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-htxlw","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:24Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:24Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"}],"hostIP":"10.250.1.183","podIP":"100.96.0.86","podIPs":[{"ip":"100.96.0.86"}],"startTime":"2024-04-26T12:00:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-26T12:00:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://6c3147167128a766a205b3ba6a4ed3fa3be190465e31ee9321274b343fbfc2d6","started":true}],"qosClass":"BestEffort"}},{"metadata":{"name":"daemon-set-tdhpv","generateName":"daemon-set-","namespace":"daemonsets-7145","uid":"dcc75daf-e598-4b03-a451-018d6560ac75","resourceVersion":"39497","creationTimestamp":"2024-04-26T12:00:23Z","deletionTimestamp":"2024-04-26T12:00:55Z","deletionGracePeriodSeconds":30,"labels":{"controller-revision-hash":"7f7ffb4fcc","daemonset-name":"daemon-set","pod-template-generation":"1"},"annotations":{"cni.projectcalico.org/containerID":"9bfdf59dd48015c17e64651885f6d50b5ebbf7d56404b650a8fe3da36a626286","cni.projectcalico.org/podIP":"100.96.1.239/32","cni.projectcalico.org/podIPs":"100.96.1.239/32"},"ownerReferences":[{"apiVersion":"apps/v1","kind":"DaemonSet","name":"daemon-set","uid":"c0416410-bd88-4073-a511-ea7a52652ce6","controller":true,"blockOwnerDeletion":true}],"managedFields":[{"manager":"kube-controller-manager","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:23Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:controller-revision-hash":{},"f:daemonset-name":{},"f:pod-template-generation":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"c0416410-bd88-4073-a511-ea7a52652ce6\"}":{}}},"f:spec":{"f:affinity":{".":{},"f:nodeAffinity":{".":{},"f:requiredDuringSchedulingIgnoredDuringExecution":{}}},"f:containers":{"k:{\"name\":\"app\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:ports":{".":{},"k:{\"containerPort\":9376,\"protocol\":\"TCP\"}":{".":{},"f:containerPort":{},"f:protocol":{}}},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{},"f:tolerations":{}}}},{"manager":"calico","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:24Z","fieldsType":"FieldsV1","fieldsV1":{"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}},"subresource":"status"},{"manager":"kubelet","operation":"Update","apiVersion":"v1","time":"2024-04-26T12:00:25Z","fieldsType":"FieldsV1","fieldsV1":{"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.239\"}":{".":{},"f:ip":{}}},"f:startTime":{}}},"subresource":"status"}]},"spec":{"volumes":[{"name":"kube-api-access-f88bk","projected":{"sources":[{"serviceAccountToken":{"expirationSeconds":3607,"path":"token"}},{"configMap":{"name":"kube-root-ca.crt","items":[{"key":"ca.crt","path":"ca.crt"}]}},{"downwardAPI":{"items":[{"path":"namespace","fieldRef":{"apiVersion":"v1","fieldPath":"metadata.namespace"}}]}}],"defaultMode":420}}],"containers":[{"name":"app","image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","ports":[{"containerPort":9376,"protocol":"TCP"}],"env":[{"name":"KUBERNETES_SERVICE_HOST","value":"api.conf-125.thomas.internal.emk.fuga.cloud"}],"resources":{},"volumeMounts":[{"name":"kube-api-access-f88bk","readOnly":true,"mountPath":"/var/run/secrets/kubernetes.io/serviceaccount"}],"terminationMessagePath":"/dev/termination-log","terminationMessagePolicy":"File","imagePullPolicy":"IfNotPresent","securityContext":{}}],"restartPolicy":"Always","terminationGracePeriodSeconds":30,"dnsPolicy":"ClusterFirst","serviceAccountName":"default","serviceAccount":"default","nodeName":"shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp","securityContext":{},"affinity":{"nodeAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":{"nodeSelectorTerms":[{"matchFields":[{"key":"metadata.name","operator":"In","values":["shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp"]}]}]}}},"schedulerName":"default-scheduler","tolerations":[{"key":"node.kubernetes.io/not-ready","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/unreachable","operator":"Exists","effect":"NoExecute"},{"key":"node.kubernetes.io/disk-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/memory-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/pid-pressure","operator":"Exists","effect":"NoSchedule"},{"key":"node.kubernetes.io/unschedulable","operator":"Exists","effect":"NoSchedule"}],"priority":0,"enableServiceLinks":true,"preemptionPolicy":"PreemptLowerPriority"},"status":{"phase":"Running","conditions":[{"type":"Initialized","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"},{"type":"Ready","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:25Z"},{"type":"ContainersReady","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:25Z"},{"type":"PodScheduled","status":"True","lastProbeTime":null,"lastTransitionTime":"2024-04-26T12:00:23Z"}],"hostIP":"10.250.2.248","podIP":"100.96.1.239","podIPs":[{"ip":"100.96.1.239"}],"startTime":"2024-04-26T12:00:23Z","containerStatuses":[{"name":"app","state":{"running":{"startedAt":"2024-04-26T12:00:24Z"}},"lastState":{},"ready":true,"restartCount":0,"image":"registry.k8s.io/e2e-test-images/httpd:2.4.38-2","imageID":"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3","containerID":"containerd://9b1ebee989e3a7b12511247ab638a6e7e19b8933d50a657ecb8dd05877a0d929","started":true}],"qosClass":"BestEffort"}}]}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 12:00:25.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-7145" for this suite. 04/26/24 12:00:25.872
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:25.919
Apr 26 12:00:25.919: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename dns 04/26/24 12:00:25.921
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:25.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:25.945
[It] should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411
STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 04/26/24 12:00:25.952
Apr 26 12:00:25.965: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-6912  f314a503-9c08-4b93-8cf4-81439b8d2c98 39504 0 2024-04-26 12:00:25 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-04-26 12:00:25 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c5t9f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c5t9f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 26 12:00:25.965: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-6912" to be "running and ready"
Apr 26 12:00:26.001: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 35.485219ms
Apr 26 12:00:26.001: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:00:28.007: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.041476364s
Apr 26 12:00:28.007: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
Apr 26 12:00:28.007: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
STEP: Verifying customized DNS suffix list is configured on pod... 04/26/24 12:00:28.007
Apr 26 12:00:28.007: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6912 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:00:28.007: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:00:28.008: INFO: ExecWithOptions: Clientset creation
Apr 26 12:00:28.008: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/dns-6912/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
STEP: Verifying customized DNS server is configured on pod... 04/26/24 12:00:28.481
Apr 26 12:00:28.481: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6912 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:00:28.481: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:00:28.482: INFO: ExecWithOptions: Clientset creation
Apr 26 12:00:28.482: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/dns-6912/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 26 12:00:28.873: INFO: Deleting pod test-dns-nameservers...
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 26 12:00:28.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6912" for this suite. 04/26/24 12:00:28.971
{"msg":"PASSED [sig-network] DNS should support configurable pod DNS nameservers [Conformance]","completed":249,"skipped":4683,"failed":0}
------------------------------
â€¢ [3.057 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should support configurable pod DNS nameservers [Conformance]
  test/e2e/network/dns.go:411

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:25.919
    Apr 26 12:00:25.919: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename dns 04/26/24 12:00:25.921
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:25.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:25.945
    [It] should support configurable pod DNS nameservers [Conformance]
      test/e2e/network/dns.go:411
    STEP: Creating a pod with dnsPolicy=None and customized dnsConfig... 04/26/24 12:00:25.952
    Apr 26 12:00:25.965: INFO: Created pod &Pod{ObjectMeta:{test-dns-nameservers  dns-6912  f314a503-9c08-4b93-8cf4-81439b8d2c98 39504 0 2024-04-26 12:00:25 +0000 UTC <nil> <nil> map[] map[] [] [] [{e2e.test Update v1 2024-04-26 12:00:25 +0000 UTC FieldsV1 {"f:spec":{"f:containers":{"k:{\"name\":\"agnhost-container\"}":{".":{},"f:args":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsConfig":{".":{},"f:nameservers":{},"f:searches":{}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} }]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-c5t9f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost-container,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[pause],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-c5t9f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:None,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:&PodDNSConfig{Nameservers:[1.1.1.1],Searches:[resolv.conf.local],Options:[]PodDNSConfigOption{},},ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
    Apr 26 12:00:25.965: INFO: Waiting up to 5m0s for pod "test-dns-nameservers" in namespace "dns-6912" to be "running and ready"
    Apr 26 12:00:26.001: INFO: Pod "test-dns-nameservers": Phase="Pending", Reason="", readiness=false. Elapsed: 35.485219ms
    Apr 26 12:00:26.001: INFO: The phase of Pod test-dns-nameservers is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:00:28.007: INFO: Pod "test-dns-nameservers": Phase="Running", Reason="", readiness=true. Elapsed: 2.041476364s
    Apr 26 12:00:28.007: INFO: The phase of Pod test-dns-nameservers is Running (Ready = true)
    Apr 26 12:00:28.007: INFO: Pod "test-dns-nameservers" satisfied condition "running and ready"
    STEP: Verifying customized DNS suffix list is configured on pod... 04/26/24 12:00:28.007
    Apr 26 12:00:28.007: INFO: ExecWithOptions {Command:[/agnhost dns-suffix] Namespace:dns-6912 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:00:28.007: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:00:28.008: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:00:28.008: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/dns-6912/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-suffix&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    STEP: Verifying customized DNS server is configured on pod... 04/26/24 12:00:28.481
    Apr 26 12:00:28.481: INFO: ExecWithOptions {Command:[/agnhost dns-server-list] Namespace:dns-6912 PodName:test-dns-nameservers ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:00:28.481: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:00:28.482: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:00:28.482: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/dns-6912/pods/test-dns-nameservers/exec?command=%2Fagnhost&command=dns-server-list&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 26 12:00:28.873: INFO: Deleting pod test-dns-nameservers...
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 26 12:00:28.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-6912" for this suite. 04/26/24 12:00:28.971
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:28.977
Apr 26 12:00:28.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 12:00:28.978
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:29.002
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:29.009
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206
STEP: Creating a pod to test downward API volume plugin 04/26/24 12:00:29.017
Apr 26 12:00:29.032: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0" in namespace "projected-8152" to be "Succeeded or Failed"
Apr 26 12:00:29.052: INFO: Pod "downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0": Phase="Pending", Reason="", readiness=false. Elapsed: 19.699304ms
Apr 26 12:00:31.059: INFO: Pod "downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026847125s
Apr 26 12:00:33.062: INFO: Pod "downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029862852s
STEP: Saw pod success 04/26/24 12:00:33.062
Apr 26 12:00:33.062: INFO: Pod "downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0" satisfied condition "Succeeded or Failed"
Apr 26 12:00:33.067: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh pod downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0 container client-container: <nil>
STEP: delete the pod 04/26/24 12:00:33.1
Apr 26 12:00:33.141: INFO: Waiting for pod downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0 to disappear
Apr 26 12:00:33.145: INFO: Pod downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 26 12:00:33.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8152" for this suite. 04/26/24 12:00:33.155
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]","completed":250,"skipped":4698,"failed":0}
------------------------------
â€¢ [4.185 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's memory limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:206

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:28.977
    Apr 26 12:00:28.978: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 12:00:28.978
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:29.002
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:29.009
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's memory limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:206
    STEP: Creating a pod to test downward API volume plugin 04/26/24 12:00:29.017
    Apr 26 12:00:29.032: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0" in namespace "projected-8152" to be "Succeeded or Failed"
    Apr 26 12:00:29.052: INFO: Pod "downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0": Phase="Pending", Reason="", readiness=false. Elapsed: 19.699304ms
    Apr 26 12:00:31.059: INFO: Pod "downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026847125s
    Apr 26 12:00:33.062: INFO: Pod "downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.029862852s
    STEP: Saw pod success 04/26/24 12:00:33.062
    Apr 26 12:00:33.062: INFO: Pod "downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0" satisfied condition "Succeeded or Failed"
    Apr 26 12:00:33.067: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh pod downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0 container client-container: <nil>
    STEP: delete the pod 04/26/24 12:00:33.1
    Apr 26 12:00:33.141: INFO: Waiting for pod downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0 to disappear
    Apr 26 12:00:33.145: INFO: Pod downwardapi-volume-4bf9ce7b-0ce9-43f9-bc79-837cb02ce3e0 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 26 12:00:33.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8152" for this suite. 04/26/24 12:00:33.155
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:33.164
Apr 26 12:00:33.164: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 12:00:33.165
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:33.183
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:33.188
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235
Apr 26 12:00:33.195: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/26/24 12:00:36.389
Apr 26 12:00:36.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-2149 --namespace=crd-publish-openapi-2149 create -f -'
Apr 26 12:00:36.903: INFO: stderr: ""
Apr 26 12:00:36.903: INFO: stdout: "e2e-test-crd-publish-openapi-5996-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 26 12:00:36.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-2149 --namespace=crd-publish-openapi-2149 delete e2e-test-crd-publish-openapi-5996-crds test-cr'
Apr 26 12:00:37.000: INFO: stderr: ""
Apr 26 12:00:37.000: INFO: stdout: "e2e-test-crd-publish-openapi-5996-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr 26 12:00:37.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-2149 --namespace=crd-publish-openapi-2149 apply -f -'
Apr 26 12:00:37.426: INFO: stderr: ""
Apr 26 12:00:37.426: INFO: stdout: "e2e-test-crd-publish-openapi-5996-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 26 12:00:37.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-2149 --namespace=crd-publish-openapi-2149 delete e2e-test-crd-publish-openapi-5996-crds test-cr'
Apr 26 12:00:37.500: INFO: stderr: ""
Apr 26 12:00:37.500: INFO: stdout: "e2e-test-crd-publish-openapi-5996-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 04/26/24 12:00:37.5
Apr 26 12:00:37.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-2149 explain e2e-test-crd-publish-openapi-5996-crds'
Apr 26 12:00:37.647: INFO: stderr: ""
Apr 26 12:00:37.647: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5996-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:00:39.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2149" for this suite. 04/26/24 12:00:39.908
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]","completed":251,"skipped":4707,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.751 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:235

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:33.164
    Apr 26 12:00:33.164: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 12:00:33.165
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:33.183
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:33.188
    [It] works for CRD preserving unknown fields in an embedded object [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:235
    Apr 26 12:00:33.195: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/26/24 12:00:36.389
    Apr 26 12:00:36.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-2149 --namespace=crd-publish-openapi-2149 create -f -'
    Apr 26 12:00:36.903: INFO: stderr: ""
    Apr 26 12:00:36.903: INFO: stdout: "e2e-test-crd-publish-openapi-5996-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Apr 26 12:00:36.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-2149 --namespace=crd-publish-openapi-2149 delete e2e-test-crd-publish-openapi-5996-crds test-cr'
    Apr 26 12:00:37.000: INFO: stderr: ""
    Apr 26 12:00:37.000: INFO: stdout: "e2e-test-crd-publish-openapi-5996-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    Apr 26 12:00:37.000: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-2149 --namespace=crd-publish-openapi-2149 apply -f -'
    Apr 26 12:00:37.426: INFO: stderr: ""
    Apr 26 12:00:37.426: INFO: stdout: "e2e-test-crd-publish-openapi-5996-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
    Apr 26 12:00:37.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-2149 --namespace=crd-publish-openapi-2149 delete e2e-test-crd-publish-openapi-5996-crds test-cr'
    Apr 26 12:00:37.500: INFO: stderr: ""
    Apr 26 12:00:37.500: INFO: stdout: "e2e-test-crd-publish-openapi-5996-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 04/26/24 12:00:37.5
    Apr 26 12:00:37.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-2149 explain e2e-test-crd-publish-openapi-5996-crds'
    Apr 26 12:00:37.647: INFO: stderr: ""
    Apr 26 12:00:37.647: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-5996-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:00:39.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2149" for this suite. 04/26/24 12:00:39.908
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:39.917
Apr 26 12:00:39.917: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 12:00:39.918
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:39.934
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:39.94
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 12:00:39.958
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 12:00:40.203
STEP: Deploying the webhook pod 04/26/24 12:00:40.212
STEP: Wait for the deployment to be ready 04/26/24 12:00:40.224
Apr 26 12:00:40.237: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 12:00:42.254
STEP: Verifying the service has paired with the endpoint 04/26/24 12:00:42.28
Apr 26 12:00:43.281: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220
Apr 26 12:00:43.288: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Registering the custom resource webhook via the AdmissionRegistration API 04/26/24 12:00:43.802
STEP: Creating a custom resource that should be denied by the webhook 04/26/24 12:00:43.944
STEP: Creating a custom resource whose deletion would be denied by the webhook 04/26/24 12:00:46.07
STEP: Updating the custom resource with disallowed data should be denied 04/26/24 12:00:46.088
STEP: Deleting the custom resource should be denied 04/26/24 12:00:46.173
STEP: Remove the offending key and value from the custom resource data 04/26/24 12:00:46.233
STEP: Deleting the updated custom resource should be successful 04/26/24 12:00:46.294
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:00:46.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1932" for this suite. 04/26/24 12:00:46.898
STEP: Destroying namespace "webhook-1932-markers" for this suite. 04/26/24 12:00:46.904
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]","completed":252,"skipped":4707,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.063 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  test/e2e/apimachinery/webhook.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:39.917
    Apr 26 12:00:39.917: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 12:00:39.918
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:39.934
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:39.94
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 12:00:39.958
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 12:00:40.203
    STEP: Deploying the webhook pod 04/26/24 12:00:40.212
    STEP: Wait for the deployment to be ready 04/26/24 12:00:40.224
    Apr 26 12:00:40.237: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 12:00:42.254
    STEP: Verifying the service has paired with the endpoint 04/26/24 12:00:42.28
    Apr 26 12:00:43.281: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny custom resource creation, update and deletion [Conformance]
      test/e2e/apimachinery/webhook.go:220
    Apr 26 12:00:43.288: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Registering the custom resource webhook via the AdmissionRegistration API 04/26/24 12:00:43.802
    STEP: Creating a custom resource that should be denied by the webhook 04/26/24 12:00:43.944
    STEP: Creating a custom resource whose deletion would be denied by the webhook 04/26/24 12:00:46.07
    STEP: Updating the custom resource with disallowed data should be denied 04/26/24 12:00:46.088
    STEP: Deleting the custom resource should be denied 04/26/24 12:00:46.173
    STEP: Remove the offending key and value from the custom resource data 04/26/24 12:00:46.233
    STEP: Deleting the updated custom resource should be successful 04/26/24 12:00:46.294
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:00:46.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1932" for this suite. 04/26/24 12:00:46.898
    STEP: Destroying namespace "webhook-1932-markers" for this suite. 04/26/24 12:00:46.904
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:46.981
Apr 26 12:00:46.981: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename init-container 04/26/24 12:00:46.982
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:46.998
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:47.003
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254
STEP: creating the pod 04/26/24 12:00:47.01
Apr 26 12:00:47.011: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 26 12:00:50.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2499" for this suite. 04/26/24 12:00:50.316
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]","completed":253,"skipped":4717,"failed":0}
------------------------------
â€¢ [3.342 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartAlways pod [Conformance]
  test/e2e/common/node/init_container.go:254

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:46.981
    Apr 26 12:00:46.981: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename init-container 04/26/24 12:00:46.982
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:46.998
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:47.003
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartAlways pod [Conformance]
      test/e2e/common/node/init_container.go:254
    STEP: creating the pod 04/26/24 12:00:47.01
    Apr 26 12:00:47.011: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 26 12:00:50.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-2499" for this suite. 04/26/24 12:00:50.316
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch
  should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:50.329
Apr 26 12:00:50.329: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 12:00:50.33
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:50.35
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:50.356
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should add annotations for pods in rc  [Conformance]
  test/e2e/kubectl/kubectl.go:1650
STEP: creating Agnhost RC 04/26/24 12:00:50.361
Apr 26 12:00:50.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-8164 create -f -'
Apr 26 12:00:50.974: INFO: stderr: ""
Apr 26 12:00:50.974: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
STEP: Waiting for Agnhost primary to start. 04/26/24 12:00:50.974
Apr 26 12:00:51.982: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 26 12:00:51.982: INFO: Found 0 / 1
Apr 26 12:00:52.982: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 26 12:00:52.982: INFO: Found 1 / 1
Apr 26 12:00:52.982: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods 04/26/24 12:00:52.982
Apr 26 12:00:52.991: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 26 12:00:52.991: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 26 12:00:52.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-8164 patch pod agnhost-primary-6gfjj -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 26 12:00:53.065: INFO: stderr: ""
Apr 26 12:00:53.065: INFO: stdout: "pod/agnhost-primary-6gfjj patched\n"
STEP: checking annotations 04/26/24 12:00:53.065
Apr 26 12:00:53.071: INFO: Selector matched 1 pods for map[app:agnhost]
Apr 26 12:00:53.071: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 12:00:53.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8164" for this suite. 04/26/24 12:00:53.09
{"msg":"PASSED [sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc  [Conformance]","completed":254,"skipped":4748,"failed":0}
------------------------------
â€¢ [2.770 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl patch
  test/e2e/kubectl/kubectl.go:1644
    should add annotations for pods in rc  [Conformance]
    test/e2e/kubectl/kubectl.go:1650

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:50.329
    Apr 26 12:00:50.329: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 12:00:50.33
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:50.35
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:50.356
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should add annotations for pods in rc  [Conformance]
      test/e2e/kubectl/kubectl.go:1650
    STEP: creating Agnhost RC 04/26/24 12:00:50.361
    Apr 26 12:00:50.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-8164 create -f -'
    Apr 26 12:00:50.974: INFO: stderr: ""
    Apr 26 12:00:50.974: INFO: stdout: "replicationcontroller/agnhost-primary created\n"
    STEP: Waiting for Agnhost primary to start. 04/26/24 12:00:50.974
    Apr 26 12:00:51.982: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 26 12:00:51.982: INFO: Found 0 / 1
    Apr 26 12:00:52.982: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 26 12:00:52.982: INFO: Found 1 / 1
    Apr 26 12:00:52.982: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
    STEP: patching all pods 04/26/24 12:00:52.982
    Apr 26 12:00:52.991: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 26 12:00:52.991: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    Apr 26 12:00:52.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-8164 patch pod agnhost-primary-6gfjj -p {"metadata":{"annotations":{"x":"y"}}}'
    Apr 26 12:00:53.065: INFO: stderr: ""
    Apr 26 12:00:53.065: INFO: stdout: "pod/agnhost-primary-6gfjj patched\n"
    STEP: checking annotations 04/26/24 12:00:53.065
    Apr 26 12:00:53.071: INFO: Selector matched 1 pods for map[app:agnhost]
    Apr 26 12:00:53.071: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 12:00:53.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-8164" for this suite. 04/26/24 12:00:53.09
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:37
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:53.1
Apr 26 12:00:53.100: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename sysctl 04/26/24 12:00:53.1
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:53.119
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:53.125
[BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/common/node/sysctl.go:67
[It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77
STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 04/26/24 12:00:53.131
STEP: Watching for error events or started pod 04/26/24 12:00:53.142
STEP: Waiting for pod completion 04/26/24 12:00:55.15
Apr 26 12:00:55.150: INFO: Waiting up to 3m0s for pod "sysctl-23ed60c3-3aaf-42a5-8096-9f1f0e2c2f87" in namespace "sysctl-5103" to be "completed"
Apr 26 12:00:55.155: INFO: Pod "sysctl-23ed60c3-3aaf-42a5-8096-9f1f0e2c2f87": Phase="Pending", Reason="", readiness=false. Elapsed: 4.912014ms
Apr 26 12:00:57.163: INFO: Pod "sysctl-23ed60c3-3aaf-42a5-8096-9f1f0e2c2f87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013642536s
Apr 26 12:00:57.163: INFO: Pod "sysctl-23ed60c3-3aaf-42a5-8096-9f1f0e2c2f87" satisfied condition "completed"
STEP: Checking that the pod succeeded 04/26/24 12:00:57.168
STEP: Getting logs from the pod 04/26/24 12:00:57.168
STEP: Checking that the sysctl is actually updated 04/26/24 12:00:57.228
[AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 26 12:00:57.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sysctl-5103" for this suite. 04/26/24 12:00:57.242
{"msg":"PASSED [sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]","completed":255,"skipped":4764,"failed":0}
------------------------------
â€¢ [4.148 seconds]
[sig-node] Sysctls [LinuxOnly] [NodeConformance]
test/e2e/common/node/framework.go:23
  should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
  test/e2e/common/node/sysctl.go:77

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:37
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:53.1
    Apr 26 12:00:53.100: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename sysctl 04/26/24 12:00:53.1
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:53.119
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:53.125
    [BeforeEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/common/node/sysctl.go:67
    [It] should support sysctls [MinimumKubeletVersion:1.21] [Conformance]
      test/e2e/common/node/sysctl.go:77
    STEP: Creating a pod with the kernel.shm_rmid_forced sysctl 04/26/24 12:00:53.131
    STEP: Watching for error events or started pod 04/26/24 12:00:53.142
    STEP: Waiting for pod completion 04/26/24 12:00:55.15
    Apr 26 12:00:55.150: INFO: Waiting up to 3m0s for pod "sysctl-23ed60c3-3aaf-42a5-8096-9f1f0e2c2f87" in namespace "sysctl-5103" to be "completed"
    Apr 26 12:00:55.155: INFO: Pod "sysctl-23ed60c3-3aaf-42a5-8096-9f1f0e2c2f87": Phase="Pending", Reason="", readiness=false. Elapsed: 4.912014ms
    Apr 26 12:00:57.163: INFO: Pod "sysctl-23ed60c3-3aaf-42a5-8096-9f1f0e2c2f87": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013642536s
    Apr 26 12:00:57.163: INFO: Pod "sysctl-23ed60c3-3aaf-42a5-8096-9f1f0e2c2f87" satisfied condition "completed"
    STEP: Checking that the pod succeeded 04/26/24 12:00:57.168
    STEP: Getting logs from the pod 04/26/24 12:00:57.168
    STEP: Checking that the sysctl is actually updated 04/26/24 12:00:57.228
    [AfterEach] [sig-node] Sysctls [LinuxOnly] [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 26 12:00:57.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sysctl-5103" for this suite. 04/26/24 12:00:57.242
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:00:57.248
Apr 26 12:00:57.248: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 12:00:57.249
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:57.276
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:57.281
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216
STEP: Creating a pod to test downward api env vars 04/26/24 12:00:57.286
Apr 26 12:00:57.297: INFO: Waiting up to 5m0s for pod "downward-api-a5d8464f-600a-45f5-9e81-114997d075d9" in namespace "downward-api-932" to be "Succeeded or Failed"
Apr 26 12:00:57.305: INFO: Pod "downward-api-a5d8464f-600a-45f5-9e81-114997d075d9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.725147ms
Apr 26 12:00:59.312: INFO: Pod "downward-api-a5d8464f-600a-45f5-9e81-114997d075d9": Phase="Running", Reason="", readiness=false. Elapsed: 2.015293394s
Apr 26 12:01:01.312: INFO: Pod "downward-api-a5d8464f-600a-45f5-9e81-114997d075d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014693076s
STEP: Saw pod success 04/26/24 12:01:01.312
Apr 26 12:01:01.312: INFO: Pod "downward-api-a5d8464f-600a-45f5-9e81-114997d075d9" satisfied condition "Succeeded or Failed"
Apr 26 12:01:01.318: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod downward-api-a5d8464f-600a-45f5-9e81-114997d075d9 container dapi-container: <nil>
STEP: delete the pod 04/26/24 12:01:01.332
Apr 26 12:01:01.346: INFO: Waiting for pod downward-api-a5d8464f-600a-45f5-9e81-114997d075d9 to disappear
Apr 26 12:01:01.352: INFO: Pod downward-api-a5d8464f-600a-45f5-9e81-114997d075d9 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 26 12:01:01.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-932" for this suite. 04/26/24 12:01:01.364
{"msg":"PASSED [sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]","completed":256,"skipped":4781,"failed":0}
------------------------------
â€¢ [4.129 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:00:57.248
    Apr 26 12:00:57.248: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 12:00:57.249
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:00:57.276
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:00:57.281
    [It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:216
    STEP: Creating a pod to test downward api env vars 04/26/24 12:00:57.286
    Apr 26 12:00:57.297: INFO: Waiting up to 5m0s for pod "downward-api-a5d8464f-600a-45f5-9e81-114997d075d9" in namespace "downward-api-932" to be "Succeeded or Failed"
    Apr 26 12:00:57.305: INFO: Pod "downward-api-a5d8464f-600a-45f5-9e81-114997d075d9": Phase="Pending", Reason="", readiness=false. Elapsed: 7.725147ms
    Apr 26 12:00:59.312: INFO: Pod "downward-api-a5d8464f-600a-45f5-9e81-114997d075d9": Phase="Running", Reason="", readiness=false. Elapsed: 2.015293394s
    Apr 26 12:01:01.312: INFO: Pod "downward-api-a5d8464f-600a-45f5-9e81-114997d075d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014693076s
    STEP: Saw pod success 04/26/24 12:01:01.312
    Apr 26 12:01:01.312: INFO: Pod "downward-api-a5d8464f-600a-45f5-9e81-114997d075d9" satisfied condition "Succeeded or Failed"
    Apr 26 12:01:01.318: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod downward-api-a5d8464f-600a-45f5-9e81-114997d075d9 container dapi-container: <nil>
    STEP: delete the pod 04/26/24 12:01:01.332
    Apr 26 12:01:01.346: INFO: Waiting for pod downward-api-a5d8464f-600a-45f5-9e81-114997d075d9 to disappear
    Apr 26 12:01:01.352: INFO: Pod downward-api-a5d8464f-600a-45f5-9e81-114997d075d9 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 26 12:01:01.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-932" for this suite. 04/26/24 12:01:01.364
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:01:01.381
Apr 26 12:01:01.381: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 12:01:01.382
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:01.398
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:01.406
[It] should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168
STEP: creating a ConfigMap 04/26/24 12:01:01.412
STEP: fetching the ConfigMap 04/26/24 12:01:01.417
STEP: patching the ConfigMap 04/26/24 12:01:01.421
STEP: listing all ConfigMaps in all namespaces with a label selector 04/26/24 12:01:01.427
STEP: deleting the ConfigMap by collection with a label selector 04/26/24 12:01:01.434
STEP: listing all ConfigMaps in test namespace 04/26/24 12:01:01.441
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 12:01:01.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6237" for this suite. 04/26/24 12:01:01.459
{"msg":"PASSED [sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]","completed":257,"skipped":4806,"failed":0}
------------------------------
â€¢ [0.086 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should run through a ConfigMap lifecycle [Conformance]
  test/e2e/common/node/configmap.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:01:01.381
    Apr 26 12:01:01.381: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 12:01:01.382
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:01.398
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:01.406
    [It] should run through a ConfigMap lifecycle [Conformance]
      test/e2e/common/node/configmap.go:168
    STEP: creating a ConfigMap 04/26/24 12:01:01.412
    STEP: fetching the ConfigMap 04/26/24 12:01:01.417
    STEP: patching the ConfigMap 04/26/24 12:01:01.421
    STEP: listing all ConfigMaps in all namespaces with a label selector 04/26/24 12:01:01.427
    STEP: deleting the ConfigMap by collection with a label selector 04/26/24 12:01:01.434
    STEP: listing all ConfigMaps in test namespace 04/26/24 12:01:01.441
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 12:01:01.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-6237" for this suite. 04/26/24 12:01:01.459
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:01:01.467
Apr 26 12:01:01.467: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename custom-resource-definition 04/26/24 12:01:01.468
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:01.485
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:01.49
[It] creating/deleting custom resource definition objects works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:58
Apr 26 12:01:01.496: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:01:02.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4910" for this suite. 04/26/24 12:01:02.544
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]","completed":258,"skipped":4824,"failed":0}
------------------------------
â€¢ [1.083 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    creating/deleting custom resource definition objects works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:58

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:01:01.467
    Apr 26 12:01:01.467: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename custom-resource-definition 04/26/24 12:01:01.468
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:01.485
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:01.49
    [It] creating/deleting custom resource definition objects works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:58
    Apr 26 12:01:01.496: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:01:02.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-4910" for this suite. 04/26/24 12:01:02.544
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions
  should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:01:02.551
Apr 26 12:01:02.551: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 12:01:02.551
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:02.565
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:02.57
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if v1 is in available api versions  [Conformance]
  test/e2e/kubectl/kubectl.go:822
STEP: validating api versions 04/26/24 12:01:02.575
Apr 26 12:01:02.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-5225 api-versions'
Apr 26 12:01:02.640: INFO: stderr: ""
Apr 26 12:01:02.640: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 12:01:02.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5225" for this suite. 04/26/24 12:01:02.653
{"msg":"PASSED [sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions  [Conformance]","completed":259,"skipped":4828,"failed":0}
------------------------------
â€¢ [0.108 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  test/e2e/kubectl/kubectl.go:816
    should check if v1 is in available api versions  [Conformance]
    test/e2e/kubectl/kubectl.go:822

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:01:02.551
    Apr 26 12:01:02.551: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 12:01:02.551
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:02.565
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:02.57
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if v1 is in available api versions  [Conformance]
      test/e2e/kubectl/kubectl.go:822
    STEP: validating api versions 04/26/24 12:01:02.575
    Apr 26 12:01:02.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-5225 api-versions'
    Apr 26 12:01:02.640: INFO: stderr: ""
    Apr 26 12:01:02.640: INFO: stdout: "admissionregistration.k8s.io/v1\napiextensions.k8s.io/v1\napiregistration.k8s.io/v1\napps/v1\nauthentication.k8s.io/v1\nauthorization.k8s.io/v1\nautoscaling/v1\nautoscaling/v2\nautoscaling/v2beta2\nbatch/v1\ncertificates.k8s.io/v1\ncoordination.k8s.io/v1\ncrd.projectcalico.org/v1\ndiscovery.k8s.io/v1\nevents.k8s.io/v1\nflowcontrol.apiserver.k8s.io/v1beta1\nflowcontrol.apiserver.k8s.io/v1beta2\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnode.k8s.io/v1\npolicy/v1\nrbac.authorization.k8s.io/v1\nscheduling.k8s.io/v1\nsnapshot.storage.k8s.io/v1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 12:01:02.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-5225" for this suite. 04/26/24 12:01:02.653
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:01:02.662
Apr 26 12:01:02.663: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename statefulset 04/26/24 12:01:02.664
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:02.678
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:02.685
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-1290 04/26/24 12:01:02.691
[It] should have a working scale subresource [Conformance]
  test/e2e/apps/statefulset.go:846
STEP: Creating statefulset ss in namespace statefulset-1290 04/26/24 12:01:02.698
Apr 26 12:01:02.717: INFO: Found 0 stateful pods, waiting for 1
Apr 26 12:01:12.726: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource 04/26/24 12:01:12.736
STEP: updating a scale subresource 04/26/24 12:01:12.741
STEP: verifying the statefulset Spec.Replicas was modified 04/26/24 12:01:12.747
STEP: Patch a scale subresource 04/26/24 12:01:12.752
STEP: verifying the statefulset Spec.Replicas was modified 04/26/24 12:01:12.758
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 26 12:01:12.764: INFO: Deleting all statefulset in ns statefulset-1290
Apr 26 12:01:12.771: INFO: Scaling statefulset ss to 0
Apr 26 12:01:22.795: INFO: Waiting for statefulset status.replicas updated to 0
Apr 26 12:01:22.801: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 26 12:01:22.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1290" for this suite. 04/26/24 12:01:22.836
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]","completed":260,"skipped":4849,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.181 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should have a working scale subresource [Conformance]
    test/e2e/apps/statefulset.go:846

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:01:02.662
    Apr 26 12:01:02.663: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename statefulset 04/26/24 12:01:02.664
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:02.678
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:02.685
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-1290 04/26/24 12:01:02.691
    [It] should have a working scale subresource [Conformance]
      test/e2e/apps/statefulset.go:846
    STEP: Creating statefulset ss in namespace statefulset-1290 04/26/24 12:01:02.698
    Apr 26 12:01:02.717: INFO: Found 0 stateful pods, waiting for 1
    Apr 26 12:01:12.726: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: getting scale subresource 04/26/24 12:01:12.736
    STEP: updating a scale subresource 04/26/24 12:01:12.741
    STEP: verifying the statefulset Spec.Replicas was modified 04/26/24 12:01:12.747
    STEP: Patch a scale subresource 04/26/24 12:01:12.752
    STEP: verifying the statefulset Spec.Replicas was modified 04/26/24 12:01:12.758
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 26 12:01:12.764: INFO: Deleting all statefulset in ns statefulset-1290
    Apr 26 12:01:12.771: INFO: Scaling statefulset ss to 0
    Apr 26 12:01:22.795: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 26 12:01:22.801: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 26 12:01:22.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-1290" for this suite. 04/26/24 12:01:22.836
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:01:22.845
Apr 26 12:01:22.845: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename job 04/26/24 12:01:22.846
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:22.863
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:22.872
[It] should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531
STEP: Creating a suspended job 04/26/24 12:01:22.885
STEP: Patching the Job 04/26/24 12:01:22.892
STEP: Watching for Job to be patched 04/26/24 12:01:22.908
Apr 26 12:01:22.911: INFO: Event ADDED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl] and annotations: map[batch.kubernetes.io/job-tracking:]
Apr 26 12:01:22.912: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl] and annotations: map[batch.kubernetes.io/job-tracking:]
Apr 26 12:01:22.912: INFO: Event MODIFIED found for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
STEP: Updating the job 04/26/24 12:01:22.912
STEP: Watching for Job to be updated 04/26/24 12:01:22.924
Apr 26 12:01:22.927: INFO: Event MODIFIED found for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 26 12:01:22.927: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
STEP: Listing all Jobs with LabelSelector 04/26/24 12:01:22.927
Apr 26 12:01:22.933: INFO: Job: e2e-p8qwl as labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched]
STEP: Waiting for job to complete 04/26/24 12:01:22.933
STEP: Delete a job collection with a labelselector 04/26/24 12:01:30.94
STEP: Watching for Job to be deleted 04/26/24 12:01:30.949
Apr 26 12:01:30.952: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 26 12:01:30.952: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 26 12:01:30.953: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 26 12:01:30.953: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 26 12:01:30.953: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 26 12:01:30.953: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 26 12:01:30.953: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
Apr 26 12:01:30.953: INFO: Event DELETED found for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
STEP: Relist jobs to confirm deletion 04/26/24 12:01:30.953
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 26 12:01:30.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-2232" for this suite. 04/26/24 12:01:30.984
{"msg":"PASSED [sig-apps] Job should manage the lifecycle of a job [Conformance]","completed":261,"skipped":4870,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.145 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should manage the lifecycle of a job [Conformance]
  test/e2e/apps/job.go:531

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:01:22.845
    Apr 26 12:01:22.845: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename job 04/26/24 12:01:22.846
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:22.863
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:22.872
    [It] should manage the lifecycle of a job [Conformance]
      test/e2e/apps/job.go:531
    STEP: Creating a suspended job 04/26/24 12:01:22.885
    STEP: Patching the Job 04/26/24 12:01:22.892
    STEP: Watching for Job to be patched 04/26/24 12:01:22.908
    Apr 26 12:01:22.911: INFO: Event ADDED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl] and annotations: map[batch.kubernetes.io/job-tracking:]
    Apr 26 12:01:22.912: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl] and annotations: map[batch.kubernetes.io/job-tracking:]
    Apr 26 12:01:22.912: INFO: Event MODIFIED found for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking:]
    STEP: Updating the job 04/26/24 12:01:22.912
    STEP: Watching for Job to be updated 04/26/24 12:01:22.924
    Apr 26 12:01:22.927: INFO: Event MODIFIED found for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 26 12:01:22.927: INFO: Found Job annotations: map[string]string{"batch.kubernetes.io/job-tracking":"", "updated":"true"}
    STEP: Listing all Jobs with LabelSelector 04/26/24 12:01:22.927
    Apr 26 12:01:22.933: INFO: Job: e2e-p8qwl as labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched]
    STEP: Waiting for job to complete 04/26/24 12:01:22.933
    STEP: Delete a job collection with a labelselector 04/26/24 12:01:30.94
    STEP: Watching for Job to be deleted 04/26/24 12:01:30.949
    Apr 26 12:01:30.952: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 26 12:01:30.952: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 26 12:01:30.953: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 26 12:01:30.953: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 26 12:01:30.953: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 26 12:01:30.953: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 26 12:01:30.953: INFO: Event MODIFIED observed for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    Apr 26 12:01:30.953: INFO: Event DELETED found for Job e2e-p8qwl in namespace job-2232 with labels: map[e2e-job-label:e2e-p8qwl e2e-p8qwl:patched] and annotations: map[batch.kubernetes.io/job-tracking: updated:true]
    STEP: Relist jobs to confirm deletion 04/26/24 12:01:30.953
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 26 12:01:30.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-2232" for this suite. 04/26/24 12:01:30.984
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:01:30.991
Apr 26 12:01:30.992: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename gc 04/26/24 12:01:30.992
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:31.01
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:31.016
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550
STEP: create the deployment 04/26/24 12:01:31.022
STEP: Wait for the Deployment to create new ReplicaSet 04/26/24 12:01:31.032
STEP: delete the deployment 04/26/24 12:01:31.549
STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 04/26/24 12:01:31.557
STEP: Gathering metrics 04/26/24 12:01:32.139
W0426 12:01:32.174430      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 26 12:01:32.174: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 26 12:01:32.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1078" for this suite. 04/26/24 12:01:32.208
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]","completed":262,"skipped":4881,"failed":0}
------------------------------
â€¢ [1.223 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  test/e2e/apimachinery/garbage_collector.go:550

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:01:30.991
    Apr 26 12:01:30.992: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename gc 04/26/24 12:01:30.992
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:31.01
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:31.016
    [It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
      test/e2e/apimachinery/garbage_collector.go:550
    STEP: create the deployment 04/26/24 12:01:31.022
    STEP: Wait for the Deployment to create new ReplicaSet 04/26/24 12:01:31.032
    STEP: delete the deployment 04/26/24 12:01:31.549
    STEP: wait for deployment deletion to see if the garbage collector mistakenly deletes the rs 04/26/24 12:01:31.557
    STEP: Gathering metrics 04/26/24 12:01:32.139
    W0426 12:01:32.174430      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 26 12:01:32.174: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 26 12:01:32.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-1078" for this suite. 04/26/24 12:01:32.208
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:01:32.215
Apr 26 12:01:32.216: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 12:01:32.216
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:32.248
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:32.254
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 12:01:32.359
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 12:01:32.721
STEP: Deploying the webhook pod 04/26/24 12:01:32.729
STEP: Wait for the deployment to be ready 04/26/24 12:01:32.742
Apr 26 12:01:32.773: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 12:01:34.791
STEP: Verifying the service has paired with the endpoint 04/26/24 12:01:34.824
Apr 26 12:01:35.824: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/26/24 12:01:35.83
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/26/24 12:01:35.958
STEP: Creating a dummy validating-webhook-configuration object 04/26/24 12:01:36.086
STEP: Deleting the validating-webhook-configuration, which should be possible to remove 04/26/24 12:01:36.142
STEP: Creating a dummy mutating-webhook-configuration object 04/26/24 12:01:36.15
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 04/26/24 12:01:36.209
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:01:36.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8159" for this suite. 04/26/24 12:01:36.243
STEP: Destroying namespace "webhook-8159-markers" for this suite. 04/26/24 12:01:36.25
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]","completed":263,"skipped":4889,"failed":0}
------------------------------
â€¢ [4.091 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  test/e2e/apimachinery/webhook.go:276

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:01:32.215
    Apr 26 12:01:32.216: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 12:01:32.216
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:32.248
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:32.254
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 12:01:32.359
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 12:01:32.721
    STEP: Deploying the webhook pod 04/26/24 12:01:32.729
    STEP: Wait for the deployment to be ready 04/26/24 12:01:32.742
    Apr 26 12:01:32.773: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 12:01:34.791
    STEP: Verifying the service has paired with the endpoint 04/26/24 12:01:34.824
    Apr 26 12:01:35.824: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
      test/e2e/apimachinery/webhook.go:276
    STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/26/24 12:01:35.83
    STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API 04/26/24 12:01:35.958
    STEP: Creating a dummy validating-webhook-configuration object 04/26/24 12:01:36.086
    STEP: Deleting the validating-webhook-configuration, which should be possible to remove 04/26/24 12:01:36.142
    STEP: Creating a dummy mutating-webhook-configuration object 04/26/24 12:01:36.15
    STEP: Deleting the mutating-webhook-configuration, which should be possible to remove 04/26/24 12:01:36.209
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:01:36.230: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8159" for this suite. 04/26/24 12:01:36.243
    STEP: Destroying namespace "webhook-8159-markers" for this suite. 04/26/24 12:01:36.25
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:01:36.307
Apr 26 12:01:36.308: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename sched-pred 04/26/24 12:01:36.308
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:36.328
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:36.333
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 26 12:01:36.342: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 26 12:01:36.382: INFO: Waiting for terminating namespaces to be deleted...
Apr 26 12:01:36.388: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh before test
Apr 26 12:01:36.421: INFO: simpletest.deployment-7545d6ddcc-687c2 from gc-1078 started at 2024-04-26 12:01:31 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.421: INFO: 	Container nginx ready: true, restart count 0
Apr 26 12:01:36.421: INFO: apiserver-proxy-qltrf from kube-system started at 2024-04-26 11:55:36 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.421: INFO: 	Container proxy ready: true, restart count 0
Apr 26 12:01:36.421: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 12:01:36.421: INFO: calico-node-nj95n from kube-system started at 2024-04-26 11:55:36 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.421: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 12:01:36.421: INFO: csi-driver-node-fp59p from kube-system started at 2024-04-26 11:55:36 +0000 UTC (3 container statuses recorded)
Apr 26 12:01:36.421: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 12:01:36.421: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 12:01:36.421: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 12:01:36.421: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-lsz8x from kube-system started at 2024-04-26 11:55:36 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.421: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 12:01:36.421: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 12:01:36.421: INFO: node-exporter-nssqr from kube-system started at 2024-04-26 11:55:36 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.421: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 12:01:36.421: INFO: node-problem-detector-7vd2p from kube-system started at 2024-04-26 11:55:36 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.421: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 12:01:36.421: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-n89vg from sonobuoy started at 2024-04-26 11:55:36 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.421: INFO: 	Container sonobuoy-worker ready: false, restart count 4
Apr 26 12:01:36.421: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 12:01:36.421: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw before test
Apr 26 12:01:36.458: INFO: apiserver-proxy-hzh4l from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.462: INFO: 	Container proxy ready: true, restart count 0
Apr 26 12:01:36.462: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 12:01:36.462: INFO: blackbox-exporter-754b59454b-9cprw from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.462: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 26 12:01:36.462: INFO: calico-node-m9nm9 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.462: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 12:01:36.462: INFO: calico-typha-deploy-84df84b854-fv5zl from kube-system started at 2024-04-26 09:50:55 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.462: INFO: 	Container calico-typha ready: true, restart count 0
Apr 26 12:01:36.462: INFO: coredns-86858b4d85-f7j7b from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.462: INFO: 	Container coredns ready: true, restart count 0
Apr 26 12:01:36.462: INFO: csi-driver-node-9wpbg from kube-system started at 2024-04-26 09:50:15 +0000 UTC (3 container statuses recorded)
Apr 26 12:01:36.462: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 12:01:36.462: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 12:01:36.462: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 12:01:36.462: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-z47h4 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.463: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 12:01:36.463: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 12:01:36.463: INFO: metrics-server-56cf547447-db2cf from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.463: INFO: 	Container metrics-server ready: true, restart count 0
Apr 26 12:01:36.463: INFO: node-exporter-mg7sm from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.463: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 12:01:36.463: INFO: node-problem-detector-w7mph from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.463: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 12:01:36.463: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-pkmm6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.463: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 12:01:36.463: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 12:01:36.463: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j before test
Apr 26 12:01:36.501: INFO: simpletest.deployment-7545d6ddcc-bcbjn from gc-1078 started at 2024-04-26 12:01:31 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.501: INFO: 	Container nginx ready: true, restart count 0
Apr 26 12:01:36.501: INFO: apiserver-proxy-qmgq4 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.501: INFO: 	Container proxy ready: true, restart count 0
Apr 26 12:01:36.501: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 12:01:36.501: INFO: calico-node-tddjl from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.501: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 12:01:36.501: INFO: csi-driver-node-xcdg9 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (3 container statuses recorded)
Apr 26 12:01:36.501: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 12:01:36.501: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 12:01:36.501: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 12:01:36.501: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-fpkn8 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.501: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 12:01:36.501: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 12:01:36.501: INFO: node-exporter-bdrxz from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.501: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 12:01:36.501: INFO: node-problem-detector-mmsx4 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.501: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 12:01:36.501: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-xznr8 from sonobuoy started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.501: INFO: 	Container sonobuoy-worker ready: false, restart count 9
Apr 26 12:01:36.501: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 12:01:36.501: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp before test
Apr 26 12:01:36.536: INFO: apiserver-proxy-hzgtj from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.536: INFO: 	Container proxy ready: true, restart count 0
Apr 26 12:01:36.536: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 12:01:36.536: INFO: calico-node-49gs5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.536: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 12:01:36.536: INFO: csi-driver-node-thmzv from kube-system started at 2024-04-26 09:50:09 +0000 UTC (3 container statuses recorded)
Apr 26 12:01:36.536: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 12:01:36.536: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 12:01:36.536: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 12:01:36.536: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-8h68w from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.536: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 12:01:36.536: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 12:01:36.536: INFO: node-exporter-mzmd5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.536: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 12:01:36.536: INFO: node-problem-detector-x8jsh from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.536: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 12:01:36.536: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-t2fb5 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.536: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 12:01:36.536: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 12:01:36.536: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w before test
Apr 26 12:01:36.589: INFO: apiserver-proxy-8bxw2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container proxy ready: true, restart count 0
Apr 26 12:01:36.589: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 12:01:36.589: INFO: blackbox-exporter-754b59454b-tqxxm from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 26 12:01:36.589: INFO: calico-kube-controllers-5bfbd9c84c-ggxxm from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 26 12:01:36.589: INFO: calico-node-nfp6q from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 12:01:36.589: INFO: calico-node-vertical-autoscaler-6b85ccc474-scqt5 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container autoscaler ready: true, restart count 0
Apr 26 12:01:36.589: INFO: calico-typha-deploy-84df84b854-grtfl from kube-system started at 2024-04-26 11:04:13 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container calico-typha ready: true, restart count 0
Apr 26 12:01:36.589: INFO: calico-typha-horizontal-autoscaler-765f9c86fd-x4mrd from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container autoscaler ready: true, restart count 0
Apr 26 12:01:36.589: INFO: calico-typha-vertical-autoscaler-8657c6b4fc-d6gnw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container autoscaler ready: true, restart count 0
Apr 26 12:01:36.589: INFO: coredns-86858b4d85-m4dg4 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container coredns ready: true, restart count 0
Apr 26 12:01:36.589: INFO: csi-driver-node-f4f5r from kube-system started at 2024-04-26 09:50:05 +0000 UTC (3 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 12:01:36.589: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 12:01:36.589: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 12:01:36.589: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-82vtz from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 12:01:36.589: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 12:01:36.589: INFO: metrics-server-56cf547447-sl4zk from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container metrics-server ready: true, restart count 0
Apr 26 12:01:36.589: INFO: node-exporter-r2wm2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 12:01:36.589: INFO: node-problem-detector-8w59w from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 12:01:36.589: INFO: vpn-shoot-849b6d5c85-z42mw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 26 12:01:36.589: INFO: sonobuoy from sonobuoy started at 2024-04-26 10:56:56 +0000 UTC (1 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 26 12:01:36.589: INFO: sonobuoy-e2e-job-ce2c772167a64049 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container e2e ready: true, restart count 0
Apr 26 12:01:36.589: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 12:01:36.589: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-6bgn6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 12:01:36.589: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 12:01:36.589: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461
STEP: Trying to launch a pod without a label to get a node which can launch it. 04/26/24 12:01:36.589
Apr 26 12:01:36.602: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9829" to be "running"
Apr 26 12:01:36.607: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 4.974993ms
Apr 26 12:01:38.613: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.011422121s
Apr 26 12:01:38.613: INFO: Pod "without-label" satisfied condition "running"
STEP: Explicitly delete pod here to free the resource it takes. 04/26/24 12:01:38.618
STEP: Trying to apply a random label on the found node. 04/26/24 12:01:38.628
STEP: verifying the node has the label kubernetes.io/e2e-d5ec44a9-edad-4b2f-a9c2-53f116a89aa8 42 04/26/24 12:01:38.659
STEP: Trying to relaunch the pod, now with labels. 04/26/24 12:01:38.664
Apr 26 12:01:38.673: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-9829" to be "not pending"
Apr 26 12:01:38.678: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 4.156326ms
Apr 26 12:01:40.685: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.011458596s
Apr 26 12:01:40.685: INFO: Pod "with-labels" satisfied condition "not pending"
STEP: removing the label kubernetes.io/e2e-d5ec44a9-edad-4b2f-a9c2-53f116a89aa8 off the node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp 04/26/24 12:01:40.692
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d5ec44a9-edad-4b2f-a9c2-53f116a89aa8 04/26/24 12:01:40.714
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 26 12:01:40.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9829" for this suite. 04/26/24 12:01:40.749
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching  [Conformance]","completed":264,"skipped":4893,"failed":0}
------------------------------
â€¢ [4.449 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if matching  [Conformance]
  test/e2e/scheduling/predicates.go:461

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:01:36.307
    Apr 26 12:01:36.308: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename sched-pred 04/26/24 12:01:36.308
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:36.328
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:36.333
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 26 12:01:36.342: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 26 12:01:36.382: INFO: Waiting for terminating namespaces to be deleted...
    Apr 26 12:01:36.388: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh before test
    Apr 26 12:01:36.421: INFO: simpletest.deployment-7545d6ddcc-687c2 from gc-1078 started at 2024-04-26 12:01:31 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.421: INFO: 	Container nginx ready: true, restart count 0
    Apr 26 12:01:36.421: INFO: apiserver-proxy-qltrf from kube-system started at 2024-04-26 11:55:36 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.421: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 12:01:36.421: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 12:01:36.421: INFO: calico-node-nj95n from kube-system started at 2024-04-26 11:55:36 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.421: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 12:01:36.421: INFO: csi-driver-node-fp59p from kube-system started at 2024-04-26 11:55:36 +0000 UTC (3 container statuses recorded)
    Apr 26 12:01:36.421: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 12:01:36.421: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 12:01:36.421: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 12:01:36.421: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-lsz8x from kube-system started at 2024-04-26 11:55:36 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.421: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 12:01:36.421: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 12:01:36.421: INFO: node-exporter-nssqr from kube-system started at 2024-04-26 11:55:36 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.421: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 12:01:36.421: INFO: node-problem-detector-7vd2p from kube-system started at 2024-04-26 11:55:36 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.421: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 12:01:36.421: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-n89vg from sonobuoy started at 2024-04-26 11:55:36 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.421: INFO: 	Container sonobuoy-worker ready: false, restart count 4
    Apr 26 12:01:36.421: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 12:01:36.421: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw before test
    Apr 26 12:01:36.458: INFO: apiserver-proxy-hzh4l from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.462: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 12:01:36.462: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 12:01:36.462: INFO: blackbox-exporter-754b59454b-9cprw from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.462: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Apr 26 12:01:36.462: INFO: calico-node-m9nm9 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.462: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 12:01:36.462: INFO: calico-typha-deploy-84df84b854-fv5zl from kube-system started at 2024-04-26 09:50:55 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.462: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 26 12:01:36.462: INFO: coredns-86858b4d85-f7j7b from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.462: INFO: 	Container coredns ready: true, restart count 0
    Apr 26 12:01:36.462: INFO: csi-driver-node-9wpbg from kube-system started at 2024-04-26 09:50:15 +0000 UTC (3 container statuses recorded)
    Apr 26 12:01:36.462: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 12:01:36.462: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 12:01:36.462: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 12:01:36.462: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-z47h4 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.463: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 12:01:36.463: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 12:01:36.463: INFO: metrics-server-56cf547447-db2cf from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.463: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 26 12:01:36.463: INFO: node-exporter-mg7sm from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.463: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 12:01:36.463: INFO: node-problem-detector-w7mph from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.463: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 12:01:36.463: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-pkmm6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.463: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 12:01:36.463: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 12:01:36.463: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j before test
    Apr 26 12:01:36.501: INFO: simpletest.deployment-7545d6ddcc-bcbjn from gc-1078 started at 2024-04-26 12:01:31 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.501: INFO: 	Container nginx ready: true, restart count 0
    Apr 26 12:01:36.501: INFO: apiserver-proxy-qmgq4 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.501: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 12:01:36.501: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 12:01:36.501: INFO: calico-node-tddjl from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.501: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 12:01:36.501: INFO: csi-driver-node-xcdg9 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (3 container statuses recorded)
    Apr 26 12:01:36.501: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 12:01:36.501: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 12:01:36.501: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 12:01:36.501: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-fpkn8 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.501: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 12:01:36.501: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 12:01:36.501: INFO: node-exporter-bdrxz from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.501: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 12:01:36.501: INFO: node-problem-detector-mmsx4 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.501: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 12:01:36.501: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-xznr8 from sonobuoy started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.501: INFO: 	Container sonobuoy-worker ready: false, restart count 9
    Apr 26 12:01:36.501: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 12:01:36.501: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp before test
    Apr 26 12:01:36.536: INFO: apiserver-proxy-hzgtj from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.536: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 12:01:36.536: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 12:01:36.536: INFO: calico-node-49gs5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.536: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 12:01:36.536: INFO: csi-driver-node-thmzv from kube-system started at 2024-04-26 09:50:09 +0000 UTC (3 container statuses recorded)
    Apr 26 12:01:36.536: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 12:01:36.536: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 12:01:36.536: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 12:01:36.536: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-8h68w from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.536: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 12:01:36.536: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 12:01:36.536: INFO: node-exporter-mzmd5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.536: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 12:01:36.536: INFO: node-problem-detector-x8jsh from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.536: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 12:01:36.536: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-t2fb5 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.536: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 12:01:36.536: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 12:01:36.536: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w before test
    Apr 26 12:01:36.589: INFO: apiserver-proxy-8bxw2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: blackbox-exporter-754b59454b-tqxxm from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: calico-kube-controllers-5bfbd9c84c-ggxxm from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: calico-node-nfp6q from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: calico-node-vertical-autoscaler-6b85ccc474-scqt5 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: calico-typha-deploy-84df84b854-grtfl from kube-system started at 2024-04-26 11:04:13 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: calico-typha-horizontal-autoscaler-765f9c86fd-x4mrd from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: calico-typha-vertical-autoscaler-8657c6b4fc-d6gnw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: coredns-86858b4d85-m4dg4 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container coredns ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: csi-driver-node-f4f5r from kube-system started at 2024-04-26 09:50:05 +0000 UTC (3 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-82vtz from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: metrics-server-56cf547447-sl4zk from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: node-exporter-r2wm2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: node-problem-detector-8w59w from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: vpn-shoot-849b6d5c85-z42mw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container vpn-shoot ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: sonobuoy from sonobuoy started at 2024-04-26 10:56:56 +0000 UTC (1 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: sonobuoy-e2e-job-ce2c772167a64049 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container e2e ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-6bgn6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 12:01:36.589: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 12:01:36.589: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if matching  [Conformance]
      test/e2e/scheduling/predicates.go:461
    STEP: Trying to launch a pod without a label to get a node which can launch it. 04/26/24 12:01:36.589
    Apr 26 12:01:36.602: INFO: Waiting up to 1m0s for pod "without-label" in namespace "sched-pred-9829" to be "running"
    Apr 26 12:01:36.607: INFO: Pod "without-label": Phase="Pending", Reason="", readiness=false. Elapsed: 4.974993ms
    Apr 26 12:01:38.613: INFO: Pod "without-label": Phase="Running", Reason="", readiness=true. Elapsed: 2.011422121s
    Apr 26 12:01:38.613: INFO: Pod "without-label" satisfied condition "running"
    STEP: Explicitly delete pod here to free the resource it takes. 04/26/24 12:01:38.618
    STEP: Trying to apply a random label on the found node. 04/26/24 12:01:38.628
    STEP: verifying the node has the label kubernetes.io/e2e-d5ec44a9-edad-4b2f-a9c2-53f116a89aa8 42 04/26/24 12:01:38.659
    STEP: Trying to relaunch the pod, now with labels. 04/26/24 12:01:38.664
    Apr 26 12:01:38.673: INFO: Waiting up to 5m0s for pod "with-labels" in namespace "sched-pred-9829" to be "not pending"
    Apr 26 12:01:38.678: INFO: Pod "with-labels": Phase="Pending", Reason="", readiness=false. Elapsed: 4.156326ms
    Apr 26 12:01:40.685: INFO: Pod "with-labels": Phase="Running", Reason="", readiness=true. Elapsed: 2.011458596s
    Apr 26 12:01:40.685: INFO: Pod "with-labels" satisfied condition "not pending"
    STEP: removing the label kubernetes.io/e2e-d5ec44a9-edad-4b2f-a9c2-53f116a89aa8 off the node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp 04/26/24 12:01:40.692
    STEP: verifying the node doesn't have the label kubernetes.io/e2e-d5ec44a9-edad-4b2f-a9c2-53f116a89aa8 04/26/24 12:01:40.714
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 12:01:40.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-9829" for this suite. 04/26/24 12:01:40.749
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] HostPort
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
[BeforeEach] [sig-network] HostPort
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:01:40.759
Apr 26 12:01:40.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename hostport 04/26/24 12:01:40.759
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:40.775
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:40.781
[BeforeEach] [sig-network] HostPort
  test/e2e/network/hostport.go:49
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63
STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 04/26/24 12:01:40.809
Apr 26 12:01:40.821: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-8673" to be "running and ready"
Apr 26 12:01:40.825: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.943777ms
Apr 26 12:01:40.825: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:01:42.832: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.010733339s
Apr 26 12:01:42.832: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 26 12:01:42.832: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.250.1.183 on the node which pod1 resides and expect scheduled 04/26/24 12:01:42.832
Apr 26 12:01:42.844: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-8673" to be "running and ready"
Apr 26 12:01:42.849: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.630697ms
Apr 26 12:01:42.849: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:01:44.860: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.015717663s
Apr 26 12:01:44.860: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 26 12:01:44.860: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.250.1.183 but use UDP protocol on the node which pod2 resides 04/26/24 12:01:44.86
Apr 26 12:01:44.872: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-8673" to be "running and ready"
Apr 26 12:01:44.878: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.647567ms
Apr 26 12:01:44.878: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:01:46.908: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.035943699s
Apr 26 12:01:46.908: INFO: The phase of Pod pod3 is Running (Ready = true)
Apr 26 12:01:46.908: INFO: Pod "pod3" satisfied condition "running and ready"
Apr 26 12:01:46.950: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-8673" to be "running and ready"
Apr 26 12:01:46.974: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 24.050508ms
Apr 26 12:01:46.974: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:01:48.983: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.03303466s
Apr 26 12:01:48.983: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
Apr 26 12:01:48.983: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 04/26/24 12:01:48.988
Apr 26 12:01:48.988: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.250.1.183 http://127.0.0.1:54323/hostname] Namespace:hostport-8673 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:01:48.988: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:01:48.989: INFO: ExecWithOptions: Clientset creation
Apr 26 12:01:48.989: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/hostport-8673/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.250.1.183+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.250.1.183, port: 54323 04/26/24 12:01:49.474
Apr 26 12:01:49.474: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.250.1.183:54323/hostname] Namespace:hostport-8673 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:01:49.474: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:01:49.475: INFO: ExecWithOptions: Clientset creation
Apr 26 12:01:49.475: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/hostport-8673/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.250.1.183%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.250.1.183, port: 54323 UDP 04/26/24 12:01:49.881
Apr 26 12:01:49.881: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.250.1.183 54323] Namespace:hostport-8673 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:01:49.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:01:49.882: INFO: ExecWithOptions: Clientset creation
Apr 26 12:01:49.882: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/hostport-8673/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.250.1.183+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
[AfterEach] [sig-network] HostPort
  test/e2e/framework/framework.go:187
Apr 26 12:01:55.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostport-8673" for this suite. 04/26/24 12:01:55.506
{"msg":"PASSED [sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]","completed":265,"skipped":4917,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.755 seconds]
[sig-network] HostPort
test/e2e/network/common/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
  test/e2e/network/hostport.go:63

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] HostPort
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:01:40.759
    Apr 26 12:01:40.759: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename hostport 04/26/24 12:01:40.759
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:40.775
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:40.781
    [BeforeEach] [sig-network] HostPort
      test/e2e/network/hostport.go:49
    [It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]
      test/e2e/network/hostport.go:63
    STEP: Trying to create a pod(pod1) with hostport 54323 and hostIP 127.0.0.1 and expect scheduled 04/26/24 12:01:40.809
    Apr 26 12:01:40.821: INFO: Waiting up to 5m0s for pod "pod1" in namespace "hostport-8673" to be "running and ready"
    Apr 26 12:01:40.825: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.943777ms
    Apr 26 12:01:40.825: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:01:42.832: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.010733339s
    Apr 26 12:01:42.832: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 26 12:01:42.832: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: Trying to create another pod(pod2) with hostport 54323 but hostIP 10.250.1.183 on the node which pod1 resides and expect scheduled 04/26/24 12:01:42.832
    Apr 26 12:01:42.844: INFO: Waiting up to 5m0s for pod "pod2" in namespace "hostport-8673" to be "running and ready"
    Apr 26 12:01:42.849: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.630697ms
    Apr 26 12:01:42.849: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:01:44.860: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.015717663s
    Apr 26 12:01:44.860: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 26 12:01:44.860: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: Trying to create a third pod(pod3) with hostport 54323, hostIP 10.250.1.183 but use UDP protocol on the node which pod2 resides 04/26/24 12:01:44.86
    Apr 26 12:01:44.872: INFO: Waiting up to 5m0s for pod "pod3" in namespace "hostport-8673" to be "running and ready"
    Apr 26 12:01:44.878: INFO: Pod "pod3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.647567ms
    Apr 26 12:01:44.878: INFO: The phase of Pod pod3 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:01:46.908: INFO: Pod "pod3": Phase="Running", Reason="", readiness=true. Elapsed: 2.035943699s
    Apr 26 12:01:46.908: INFO: The phase of Pod pod3 is Running (Ready = true)
    Apr 26 12:01:46.908: INFO: Pod "pod3" satisfied condition "running and ready"
    Apr 26 12:01:46.950: INFO: Waiting up to 5m0s for pod "e2e-host-exec" in namespace "hostport-8673" to be "running and ready"
    Apr 26 12:01:46.974: INFO: Pod "e2e-host-exec": Phase="Pending", Reason="", readiness=false. Elapsed: 24.050508ms
    Apr 26 12:01:46.974: INFO: The phase of Pod e2e-host-exec is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:01:48.983: INFO: Pod "e2e-host-exec": Phase="Running", Reason="", readiness=true. Elapsed: 2.03303466s
    Apr 26 12:01:48.983: INFO: The phase of Pod e2e-host-exec is Running (Ready = true)
    Apr 26 12:01:48.983: INFO: Pod "e2e-host-exec" satisfied condition "running and ready"
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 127.0.0.1, port: 54323 04/26/24 12:01:48.988
    Apr 26 12:01:48.988: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 --interface 10.250.1.183 http://127.0.0.1:54323/hostname] Namespace:hostport-8673 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:01:48.988: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:01:48.989: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:01:48.989: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/hostport-8673/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+--interface+10.250.1.183+http%3A%2F%2F127.0.0.1%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.250.1.183, port: 54323 04/26/24 12:01:49.474
    Apr 26 12:01:49.474: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g --connect-timeout 5 http://10.250.1.183:54323/hostname] Namespace:hostport-8673 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:01:49.474: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:01:49.475: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:01:49.475: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/hostport-8673/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+--connect-timeout+5+http%3A%2F%2F10.250.1.183%3A54323%2Fhostname&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    STEP: checking connectivity from pod e2e-host-exec to serverIP: 10.250.1.183, port: 54323 UDP 04/26/24 12:01:49.881
    Apr 26 12:01:49.881: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostname | nc -u -w 5 10.250.1.183 54323] Namespace:hostport-8673 PodName:e2e-host-exec ContainerName:e2e-host-exec Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:01:49.881: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:01:49.882: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:01:49.882: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/hostport-8673/pods/e2e-host-exec/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostname+%7C+nc+-u+-w+5+10.250.1.183+54323&container=e2e-host-exec&container=e2e-host-exec&stderr=true&stdout=true)
    [AfterEach] [sig-network] HostPort
      test/e2e/framework/framework.go:187
    Apr 26 12:01:55.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "hostport-8673" for this suite. 04/26/24 12:01:55.506
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:01:55.515
Apr 26 12:01:55.515: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename subpath 04/26/24 12:01:55.515
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:55.534
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:55.542
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/26/24 12:01:55.547
[It] should support subpaths with downward pod [Conformance]
  test/e2e/storage/subpath.go:92
STEP: Creating pod pod-subpath-test-downwardapi-sdx6 04/26/24 12:01:55.56
STEP: Creating a pod to test atomic-volume-subpath 04/26/24 12:01:55.56
Apr 26 12:01:55.574: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-sdx6" in namespace "subpath-9611" to be "Succeeded or Failed"
Apr 26 12:01:55.582: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.538929ms
Apr 26 12:01:57.589: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 2.014478277s
Apr 26 12:01:59.589: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 4.014441327s
Apr 26 12:02:01.592: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 6.018153967s
Apr 26 12:02:03.588: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 8.014089032s
Apr 26 12:02:05.590: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 10.016022783s
Apr 26 12:02:07.590: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 12.015639194s
Apr 26 12:02:09.588: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 14.013823945s
Apr 26 12:02:11.591: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 16.016860344s
Apr 26 12:02:13.590: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 18.015624364s
Apr 26 12:02:15.589: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 20.014900212s
Apr 26 12:02:17.614: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=false. Elapsed: 22.040067821s
Apr 26 12:02:19.591: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.017157383s
STEP: Saw pod success 04/26/24 12:02:19.591
Apr 26 12:02:19.591: INFO: Pod "pod-subpath-test-downwardapi-sdx6" satisfied condition "Succeeded or Failed"
Apr 26 12:02:19.596: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-subpath-test-downwardapi-sdx6 container test-container-subpath-downwardapi-sdx6: <nil>
STEP: delete the pod 04/26/24 12:02:19.643
Apr 26 12:02:19.656: INFO: Waiting for pod pod-subpath-test-downwardapi-sdx6 to disappear
Apr 26 12:02:19.660: INFO: Pod pod-subpath-test-downwardapi-sdx6 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-sdx6 04/26/24 12:02:19.66
Apr 26 12:02:19.660: INFO: Deleting pod "pod-subpath-test-downwardapi-sdx6" in namespace "subpath-9611"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 26 12:02:19.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9611" for this suite. 04/26/24 12:02:19.68
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]","completed":266,"skipped":4952,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.174 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with downward pod [Conformance]
    test/e2e/storage/subpath.go:92

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:01:55.515
    Apr 26 12:01:55.515: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename subpath 04/26/24 12:01:55.515
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:01:55.534
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:01:55.542
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/26/24 12:01:55.547
    [It] should support subpaths with downward pod [Conformance]
      test/e2e/storage/subpath.go:92
    STEP: Creating pod pod-subpath-test-downwardapi-sdx6 04/26/24 12:01:55.56
    STEP: Creating a pod to test atomic-volume-subpath 04/26/24 12:01:55.56
    Apr 26 12:01:55.574: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-sdx6" in namespace "subpath-9611" to be "Succeeded or Failed"
    Apr 26 12:01:55.582: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Pending", Reason="", readiness=false. Elapsed: 7.538929ms
    Apr 26 12:01:57.589: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 2.014478277s
    Apr 26 12:01:59.589: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 4.014441327s
    Apr 26 12:02:01.592: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 6.018153967s
    Apr 26 12:02:03.588: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 8.014089032s
    Apr 26 12:02:05.590: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 10.016022783s
    Apr 26 12:02:07.590: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 12.015639194s
    Apr 26 12:02:09.588: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 14.013823945s
    Apr 26 12:02:11.591: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 16.016860344s
    Apr 26 12:02:13.590: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 18.015624364s
    Apr 26 12:02:15.589: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=true. Elapsed: 20.014900212s
    Apr 26 12:02:17.614: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Running", Reason="", readiness=false. Elapsed: 22.040067821s
    Apr 26 12:02:19.591: INFO: Pod "pod-subpath-test-downwardapi-sdx6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.017157383s
    STEP: Saw pod success 04/26/24 12:02:19.591
    Apr 26 12:02:19.591: INFO: Pod "pod-subpath-test-downwardapi-sdx6" satisfied condition "Succeeded or Failed"
    Apr 26 12:02:19.596: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-subpath-test-downwardapi-sdx6 container test-container-subpath-downwardapi-sdx6: <nil>
    STEP: delete the pod 04/26/24 12:02:19.643
    Apr 26 12:02:19.656: INFO: Waiting for pod pod-subpath-test-downwardapi-sdx6 to disappear
    Apr 26 12:02:19.660: INFO: Pod pod-subpath-test-downwardapi-sdx6 no longer exists
    STEP: Deleting pod pod-subpath-test-downwardapi-sdx6 04/26/24 12:02:19.66
    Apr 26 12:02:19.660: INFO: Deleting pod "pod-subpath-test-downwardapi-sdx6" in namespace "subpath-9611"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 26 12:02:19.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-9611" for this suite. 04/26/24 12:02:19.68
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:02:19.694
Apr 26 12:02:19.696: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename var-expansion 04/26/24 12:02:19.696
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:19.713
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:19.719
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91
STEP: Creating a pod to test substitution in container's args 04/26/24 12:02:19.725
Apr 26 12:02:19.737: INFO: Waiting up to 5m0s for pod "var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc" in namespace "var-expansion-2229" to be "Succeeded or Failed"
Apr 26 12:02:19.742: INFO: Pod "var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.464936ms
Apr 26 12:02:21.752: INFO: Pod "var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014340817s
Apr 26 12:02:23.750: INFO: Pod "var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012211368s
STEP: Saw pod success 04/26/24 12:02:23.75
Apr 26 12:02:23.750: INFO: Pod "var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc" satisfied condition "Succeeded or Failed"
Apr 26 12:02:23.755: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc container dapi-container: <nil>
STEP: delete the pod 04/26/24 12:02:23.772
Apr 26 12:02:23.797: INFO: Waiting for pod var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc to disappear
Apr 26 12:02:23.803: INFO: Pod var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 26 12:02:23.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2229" for this suite. 04/26/24 12:02:23.819
{"msg":"PASSED [sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]","completed":267,"skipped":4965,"failed":0}
------------------------------
â€¢ [4.132 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:91

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:02:19.694
    Apr 26 12:02:19.696: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename var-expansion 04/26/24 12:02:19.696
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:19.713
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:19.719
    [It] should allow substituting values in a container's args [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:91
    STEP: Creating a pod to test substitution in container's args 04/26/24 12:02:19.725
    Apr 26 12:02:19.737: INFO: Waiting up to 5m0s for pod "var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc" in namespace "var-expansion-2229" to be "Succeeded or Failed"
    Apr 26 12:02:19.742: INFO: Pod "var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.464936ms
    Apr 26 12:02:21.752: INFO: Pod "var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014340817s
    Apr 26 12:02:23.750: INFO: Pod "var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012211368s
    STEP: Saw pod success 04/26/24 12:02:23.75
    Apr 26 12:02:23.750: INFO: Pod "var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc" satisfied condition "Succeeded or Failed"
    Apr 26 12:02:23.755: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc container dapi-container: <nil>
    STEP: delete the pod 04/26/24 12:02:23.772
    Apr 26 12:02:23.797: INFO: Waiting for pod var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc to disappear
    Apr 26 12:02:23.803: INFO: Pod var-expansion-c71582d6-aa6c-4150-9c79-204e777699fc no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 26 12:02:23.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-2229" for this suite. 04/26/24 12:02:23.819
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:02:23.831
Apr 26 12:02:23.831: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 12:02:23.832
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:23.849
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:23.855
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192
STEP: Creating a pod to test downward API volume plugin 04/26/24 12:02:23.861
Apr 26 12:02:23.873: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3" in namespace "projected-8681" to be "Succeeded or Failed"
Apr 26 12:02:23.878: INFO: Pod "downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.926101ms
Apr 26 12:02:25.887: INFO: Pod "downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01402607s
Apr 26 12:02:27.888: INFO: Pod "downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015281451s
STEP: Saw pod success 04/26/24 12:02:27.888
Apr 26 12:02:27.889: INFO: Pod "downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3" satisfied condition "Succeeded or Failed"
Apr 26 12:02:27.893: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3 container client-container: <nil>
STEP: delete the pod 04/26/24 12:02:27.907
Apr 26 12:02:27.921: INFO: Waiting for pod downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3 to disappear
Apr 26 12:02:27.925: INFO: Pod downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 26 12:02:27.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8681" for this suite. 04/26/24 12:02:27.936
{"msg":"PASSED [sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]","completed":268,"skipped":4971,"failed":0}
------------------------------
â€¢ [4.113 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should provide container's cpu limit [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:192

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:02:23.831
    Apr 26 12:02:23.831: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 12:02:23.832
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:23.849
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:23.855
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should provide container's cpu limit [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:192
    STEP: Creating a pod to test downward API volume plugin 04/26/24 12:02:23.861
    Apr 26 12:02:23.873: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3" in namespace "projected-8681" to be "Succeeded or Failed"
    Apr 26 12:02:23.878: INFO: Pod "downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.926101ms
    Apr 26 12:02:25.887: INFO: Pod "downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01402607s
    Apr 26 12:02:27.888: INFO: Pod "downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015281451s
    STEP: Saw pod success 04/26/24 12:02:27.888
    Apr 26 12:02:27.889: INFO: Pod "downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3" satisfied condition "Succeeded or Failed"
    Apr 26 12:02:27.893: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3 container client-container: <nil>
    STEP: delete the pod 04/26/24 12:02:27.907
    Apr 26 12:02:27.921: INFO: Waiting for pod downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3 to disappear
    Apr 26 12:02:27.925: INFO: Pod downwardapi-volume-e41c5204-2cfc-423d-813a-2909103b72f3 no longer exists
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 26 12:02:27.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-8681" for this suite. 04/26/24 12:02:27.936
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:02:27.945
Apr 26 12:02:27.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir-wrapper 04/26/24 12:02:27.947
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:27.966
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:27.972
[It] should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67
Apr 26 12:02:28.006: INFO: Waiting up to 5m0s for pod "pod-secrets-ffdd6a78-e5cb-4569-9f19-5709ba6023f6" in namespace "emptydir-wrapper-9760" to be "running and ready"
Apr 26 12:02:28.016: INFO: Pod "pod-secrets-ffdd6a78-e5cb-4569-9f19-5709ba6023f6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.808612ms
Apr 26 12:02:28.016: INFO: The phase of Pod pod-secrets-ffdd6a78-e5cb-4569-9f19-5709ba6023f6 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:02:30.023: INFO: Pod "pod-secrets-ffdd6a78-e5cb-4569-9f19-5709ba6023f6": Phase="Running", Reason="", readiness=true. Elapsed: 2.016995083s
Apr 26 12:02:30.023: INFO: The phase of Pod pod-secrets-ffdd6a78-e5cb-4569-9f19-5709ba6023f6 is Running (Ready = true)
Apr 26 12:02:30.023: INFO: Pod "pod-secrets-ffdd6a78-e5cb-4569-9f19-5709ba6023f6" satisfied condition "running and ready"
STEP: Cleaning up the secret 04/26/24 12:02:30.029
STEP: Cleaning up the configmap 04/26/24 12:02:30.037
STEP: Cleaning up the pod 04/26/24 12:02:30.044
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Apr 26 12:02:30.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9760" for this suite. 04/26/24 12:02:30.073
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]","completed":269,"skipped":4975,"failed":0}
------------------------------
â€¢ [2.137 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:02:27.945
    Apr 26 12:02:27.946: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir-wrapper 04/26/24 12:02:27.947
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:27.966
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:27.972
    [It] should not conflict [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:67
    Apr 26 12:02:28.006: INFO: Waiting up to 5m0s for pod "pod-secrets-ffdd6a78-e5cb-4569-9f19-5709ba6023f6" in namespace "emptydir-wrapper-9760" to be "running and ready"
    Apr 26 12:02:28.016: INFO: Pod "pod-secrets-ffdd6a78-e5cb-4569-9f19-5709ba6023f6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.808612ms
    Apr 26 12:02:28.016: INFO: The phase of Pod pod-secrets-ffdd6a78-e5cb-4569-9f19-5709ba6023f6 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:02:30.023: INFO: Pod "pod-secrets-ffdd6a78-e5cb-4569-9f19-5709ba6023f6": Phase="Running", Reason="", readiness=true. Elapsed: 2.016995083s
    Apr 26 12:02:30.023: INFO: The phase of Pod pod-secrets-ffdd6a78-e5cb-4569-9f19-5709ba6023f6 is Running (Ready = true)
    Apr 26 12:02:30.023: INFO: Pod "pod-secrets-ffdd6a78-e5cb-4569-9f19-5709ba6023f6" satisfied condition "running and ready"
    STEP: Cleaning up the secret 04/26/24 12:02:30.029
    STEP: Cleaning up the configmap 04/26/24 12:02:30.037
    STEP: Cleaning up the pod 04/26/24 12:02:30.044
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Apr 26 12:02:30.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-9760" for this suite. 04/26/24 12:02:30.073
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:02:30.082
Apr 26 12:02:30.083: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 12:02:30.084
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:30.1
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:30.106
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98
STEP: Creating configMap with name configmap-test-volume-map-bcdb65a3-3af0-41fb-89b6-ba8e243faac4 04/26/24 12:02:30.112
STEP: Creating a pod to test consume configMaps 04/26/24 12:02:30.118
Apr 26 12:02:30.145: INFO: Waiting up to 5m0s for pod "pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7" in namespace "configmap-8974" to be "Succeeded or Failed"
Apr 26 12:02:30.155: INFO: Pod "pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.627019ms
Apr 26 12:02:32.163: INFO: Pod "pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017843588s
Apr 26 12:02:34.164: INFO: Pod "pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019241191s
STEP: Saw pod success 04/26/24 12:02:34.164
Apr 26 12:02:34.164: INFO: Pod "pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7" satisfied condition "Succeeded or Failed"
Apr 26 12:02:34.169: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7 container agnhost-container: <nil>
STEP: delete the pod 04/26/24 12:02:34.193
Apr 26 12:02:34.208: INFO: Waiting for pod pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7 to disappear
Apr 26 12:02:34.216: INFO: Pod pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 12:02:34.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8974" for this suite. 04/26/24 12:02:34.232
{"msg":"PASSED [sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]","completed":270,"skipped":4980,"failed":0}
------------------------------
â€¢ [4.158 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/configmap_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:02:30.082
    Apr 26 12:02:30.083: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 12:02:30.084
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:30.1
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:30.106
    [It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/configmap_volume.go:98
    STEP: Creating configMap with name configmap-test-volume-map-bcdb65a3-3af0-41fb-89b6-ba8e243faac4 04/26/24 12:02:30.112
    STEP: Creating a pod to test consume configMaps 04/26/24 12:02:30.118
    Apr 26 12:02:30.145: INFO: Waiting up to 5m0s for pod "pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7" in namespace "configmap-8974" to be "Succeeded or Failed"
    Apr 26 12:02:30.155: INFO: Pod "pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.627019ms
    Apr 26 12:02:32.163: INFO: Pod "pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017843588s
    Apr 26 12:02:34.164: INFO: Pod "pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019241191s
    STEP: Saw pod success 04/26/24 12:02:34.164
    Apr 26 12:02:34.164: INFO: Pod "pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7" satisfied condition "Succeeded or Failed"
    Apr 26 12:02:34.169: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7 container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 12:02:34.193
    Apr 26 12:02:34.208: INFO: Waiting for pod pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7 to disappear
    Apr 26 12:02:34.216: INFO: Pod pod-configmaps-f4eba2a1-56c7-4226-a253-192a99caabb7 no longer exists
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 12:02:34.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-8974" for this suite. 04/26/24 12:02:34.232
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PodTemplates
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
[BeforeEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:02:34.248
Apr 26 12:02:34.248: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename podtemplate 04/26/24 12:02:34.249
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:34.264
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:34.27
[It] should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176
STEP: Create a pod template 04/26/24 12:02:34.277
STEP: Replace a pod template 04/26/24 12:02:34.284
Apr 26 12:02:34.297: INFO: Found updated podtemplate annotation: "true"

[AfterEach] [sig-node] PodTemplates
  test/e2e/framework/framework.go:187
Apr 26 12:02:34.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "podtemplate-1067" for this suite. 04/26/24 12:02:34.312
{"msg":"PASSED [sig-node] PodTemplates should replace a pod template [Conformance]","completed":271,"skipped":5044,"failed":0}
------------------------------
â€¢ [0.073 seconds]
[sig-node] PodTemplates
test/e2e/common/node/framework.go:23
  should replace a pod template [Conformance]
  test/e2e/common/node/podtemplates.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:02:34.248
    Apr 26 12:02:34.248: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename podtemplate 04/26/24 12:02:34.249
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:34.264
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:34.27
    [It] should replace a pod template [Conformance]
      test/e2e/common/node/podtemplates.go:176
    STEP: Create a pod template 04/26/24 12:02:34.277
    STEP: Replace a pod template 04/26/24 12:02:34.284
    Apr 26 12:02:34.297: INFO: Found updated podtemplate annotation: "true"

    [AfterEach] [sig-node] PodTemplates
      test/e2e/framework/framework.go:187
    Apr 26 12:02:34.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "podtemplate-1067" for this suite. 04/26/24 12:02:34.312
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:02:34.325
Apr 26 12:02:34.325: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename resourcequota 04/26/24 12:02:34.327
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:34.351
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:34.356
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220
STEP: Counting existing ResourceQuota 04/26/24 12:02:34.362
STEP: Creating a ResourceQuota 04/26/24 12:02:39.401
STEP: Ensuring resource quota status is calculated 04/26/24 12:02:39.412
STEP: Creating a Pod that fits quota 04/26/24 12:02:41.42
STEP: Ensuring ResourceQuota status captures the pod usage 04/26/24 12:02:41.455
STEP: Not allowing a pod to be created that exceeds remaining quota 04/26/24 12:02:43.462
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 04/26/24 12:02:43.469
STEP: Ensuring a pod cannot update its resource requirements 04/26/24 12:02:43.475
STEP: Ensuring attempts to update pod resource requirements did not change quota usage 04/26/24 12:02:43.486
STEP: Deleting the pod 04/26/24 12:02:45.493
STEP: Ensuring resource quota status released the pod usage 04/26/24 12:02:45.507
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 26 12:02:47.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8729" for this suite. 04/26/24 12:02:47.527
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]","completed":272,"skipped":5054,"failed":0}
------------------------------
â€¢ [SLOW TEST] [13.213 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  test/e2e/apimachinery/resource_quota.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:02:34.325
    Apr 26 12:02:34.325: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename resourcequota 04/26/24 12:02:34.327
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:34.351
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:34.356
    [It] should create a ResourceQuota and capture the life of a pod. [Conformance]
      test/e2e/apimachinery/resource_quota.go:220
    STEP: Counting existing ResourceQuota 04/26/24 12:02:34.362
    STEP: Creating a ResourceQuota 04/26/24 12:02:39.401
    STEP: Ensuring resource quota status is calculated 04/26/24 12:02:39.412
    STEP: Creating a Pod that fits quota 04/26/24 12:02:41.42
    STEP: Ensuring ResourceQuota status captures the pod usage 04/26/24 12:02:41.455
    STEP: Not allowing a pod to be created that exceeds remaining quota 04/26/24 12:02:43.462
    STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources) 04/26/24 12:02:43.469
    STEP: Ensuring a pod cannot update its resource requirements 04/26/24 12:02:43.475
    STEP: Ensuring attempts to update pod resource requirements did not change quota usage 04/26/24 12:02:43.486
    STEP: Deleting the pod 04/26/24 12:02:45.493
    STEP: Ensuring resource quota status released the pod usage 04/26/24 12:02:45.507
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 26 12:02:47.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-8729" for this suite. 04/26/24 12:02:47.527
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:02:47.541
Apr 26 12:02:47.541: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename custom-resource-definition 04/26/24 12:02:47.542
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:47.556
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:47.562
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:145
Apr 26 12:02:47.568: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:02:48.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-749" for this suite. 04/26/24 12:02:48.135
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works  [Conformance]","completed":273,"skipped":5079,"failed":0}
------------------------------
â€¢ [0.627 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  test/e2e/apimachinery/custom_resource_definition.go:50
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    test/e2e/apimachinery/custom_resource_definition.go:145

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:02:47.541
    Apr 26 12:02:47.541: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename custom-resource-definition 04/26/24 12:02:47.542
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:47.556
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:47.562
    [It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:145
    Apr 26 12:02:47.568: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:02:48.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-749" for this suite. 04/26/24 12:02:48.135
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:02:48.169
Apr 26 12:02:48.169: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename dns 04/26/24 12:02:48.169
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:48.222
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:48.228
[It] should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333
STEP: Creating a test externalName service 04/26/24 12:02:48.234
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8452.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local; sleep 1; done
 04/26/24 12:02:48.256
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8452.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local; sleep 1; done
 04/26/24 12:02:48.256
STEP: creating a pod to probe DNS 04/26/24 12:02:48.257
STEP: submitting the pod to kubernetes 04/26/24 12:02:48.257
Apr 26 12:02:48.313: INFO: Waiting up to 15m0s for pod "dns-test-648efd8e-b957-48b9-af16-91863ef93f0f" in namespace "dns-8452" to be "running"
Apr 26 12:02:48.331: INFO: Pod "dns-test-648efd8e-b957-48b9-af16-91863ef93f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.620163ms
Apr 26 12:02:50.342: INFO: Pod "dns-test-648efd8e-b957-48b9-af16-91863ef93f0f": Phase="Running", Reason="", readiness=true. Elapsed: 2.028892637s
Apr 26 12:02:50.342: INFO: Pod "dns-test-648efd8e-b957-48b9-af16-91863ef93f0f" satisfied condition "running"
STEP: retrieving the pod 04/26/24 12:02:50.342
STEP: looking for the results for each expected name from probers 04/26/24 12:02:50.348
Apr 26 12:02:50.516: INFO: DNS probes using dns-test-648efd8e-b957-48b9-af16-91863ef93f0f succeeded

STEP: deleting the pod 04/26/24 12:02:50.516
STEP: changing the externalName to bar.example.com 04/26/24 12:02:50.533
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8452.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local; sleep 1; done
 04/26/24 12:02:50.545
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8452.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local; sleep 1; done
 04/26/24 12:02:50.546
STEP: creating a second pod to probe DNS 04/26/24 12:02:50.546
STEP: submitting the pod to kubernetes 04/26/24 12:02:50.546
Apr 26 12:02:50.556: INFO: Waiting up to 15m0s for pod "dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3" in namespace "dns-8452" to be "running"
Apr 26 12:02:50.564: INFO: Pod "dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.519511ms
Apr 26 12:02:52.572: INFO: Pod "dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3": Phase="Running", Reason="", readiness=true. Elapsed: 2.01637482s
Apr 26 12:02:52.572: INFO: Pod "dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3" satisfied condition "running"
STEP: retrieving the pod 04/26/24 12:02:52.572
STEP: looking for the results for each expected name from probers 04/26/24 12:02:52.577
Apr 26 12:02:52.696: INFO: File wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 26 12:02:52.755: INFO: File jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 26 12:02:52.755: INFO: Lookups using dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 failed for: [wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local]

Apr 26 12:02:57.768: INFO: File wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 26 12:02:57.815: INFO: File jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 26 12:02:57.815: INFO: Lookups using dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 failed for: [wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local]

Apr 26 12:03:02.769: INFO: File wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 26 12:03:02.816: INFO: File jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 26 12:03:02.816: INFO: Lookups using dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 failed for: [wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local]

Apr 26 12:03:07.767: INFO: File wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 26 12:03:07.834: INFO: File jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 26 12:03:07.834: INFO: Lookups using dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 failed for: [wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local]

Apr 26 12:03:12.773: INFO: File wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 26 12:03:12.819: INFO: File jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 26 12:03:12.819: INFO: Lookups using dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 failed for: [wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local]

Apr 26 12:03:17.771: INFO: File wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 26 12:03:17.810: INFO: File jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 26 12:03:17.810: INFO: Lookups using dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 failed for: [wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local]

Apr 26 12:03:22.801: INFO: DNS probes using dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 succeeded

STEP: deleting the pod 04/26/24 12:03:22.801
STEP: changing the service to type=ClusterIP 04/26/24 12:03:22.818
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8452.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local; sleep 1; done
 04/26/24 12:03:22.847
STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8452.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local; sleep 1; done
 04/26/24 12:03:22.847
STEP: creating a third pod to probe DNS 04/26/24 12:03:22.848
STEP: submitting the pod to kubernetes 04/26/24 12:03:22.854
Apr 26 12:03:22.870: INFO: Waiting up to 15m0s for pod "dns-test-db4a7e59-9437-4cc5-99fb-60c091f7f9d9" in namespace "dns-8452" to be "running"
Apr 26 12:03:22.879: INFO: Pod "dns-test-db4a7e59-9437-4cc5-99fb-60c091f7f9d9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.834383ms
Apr 26 12:03:24.913: INFO: Pod "dns-test-db4a7e59-9437-4cc5-99fb-60c091f7f9d9": Phase="Running", Reason="", readiness=true. Elapsed: 2.042376682s
Apr 26 12:03:24.913: INFO: Pod "dns-test-db4a7e59-9437-4cc5-99fb-60c091f7f9d9" satisfied condition "running"
STEP: retrieving the pod 04/26/24 12:03:24.913
STEP: looking for the results for each expected name from probers 04/26/24 12:03:24.92
Apr 26 12:03:25.075: INFO: DNS probes using dns-test-db4a7e59-9437-4cc5-99fb-60c091f7f9d9 succeeded

STEP: deleting the pod 04/26/24 12:03:25.075
STEP: deleting the test externalName service 04/26/24 12:03:25.092
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 26 12:03:25.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8452" for this suite. 04/26/24 12:03:25.124
{"msg":"PASSED [sig-network] DNS should provide DNS for ExternalName services [Conformance]","completed":274,"skipped":5091,"failed":0}
------------------------------
â€¢ [SLOW TEST] [36.963 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  test/e2e/network/dns.go:333

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:02:48.169
    Apr 26 12:02:48.169: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename dns 04/26/24 12:02:48.169
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:02:48.222
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:02:48.228
    [It] should provide DNS for ExternalName services [Conformance]
      test/e2e/network/dns.go:333
    STEP: Creating a test externalName service 04/26/24 12:02:48.234
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8452.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local; sleep 1; done
     04/26/24 12:02:48.256
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8452.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local; sleep 1; done
     04/26/24 12:02:48.256
    STEP: creating a pod to probe DNS 04/26/24 12:02:48.257
    STEP: submitting the pod to kubernetes 04/26/24 12:02:48.257
    Apr 26 12:02:48.313: INFO: Waiting up to 15m0s for pod "dns-test-648efd8e-b957-48b9-af16-91863ef93f0f" in namespace "dns-8452" to be "running"
    Apr 26 12:02:48.331: INFO: Pod "dns-test-648efd8e-b957-48b9-af16-91863ef93f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.620163ms
    Apr 26 12:02:50.342: INFO: Pod "dns-test-648efd8e-b957-48b9-af16-91863ef93f0f": Phase="Running", Reason="", readiness=true. Elapsed: 2.028892637s
    Apr 26 12:02:50.342: INFO: Pod "dns-test-648efd8e-b957-48b9-af16-91863ef93f0f" satisfied condition "running"
    STEP: retrieving the pod 04/26/24 12:02:50.342
    STEP: looking for the results for each expected name from probers 04/26/24 12:02:50.348
    Apr 26 12:02:50.516: INFO: DNS probes using dns-test-648efd8e-b957-48b9-af16-91863ef93f0f succeeded

    STEP: deleting the pod 04/26/24 12:02:50.516
    STEP: changing the externalName to bar.example.com 04/26/24 12:02:50.533
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8452.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local; sleep 1; done
     04/26/24 12:02:50.545
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8452.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local; sleep 1; done
     04/26/24 12:02:50.546
    STEP: creating a second pod to probe DNS 04/26/24 12:02:50.546
    STEP: submitting the pod to kubernetes 04/26/24 12:02:50.546
    Apr 26 12:02:50.556: INFO: Waiting up to 15m0s for pod "dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3" in namespace "dns-8452" to be "running"
    Apr 26 12:02:50.564: INFO: Pod "dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.519511ms
    Apr 26 12:02:52.572: INFO: Pod "dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3": Phase="Running", Reason="", readiness=true. Elapsed: 2.01637482s
    Apr 26 12:02:52.572: INFO: Pod "dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3" satisfied condition "running"
    STEP: retrieving the pod 04/26/24 12:02:52.572
    STEP: looking for the results for each expected name from probers 04/26/24 12:02:52.577
    Apr 26 12:02:52.696: INFO: File wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 26 12:02:52.755: INFO: File jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 26 12:02:52.755: INFO: Lookups using dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 failed for: [wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local]

    Apr 26 12:02:57.768: INFO: File wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 26 12:02:57.815: INFO: File jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 26 12:02:57.815: INFO: Lookups using dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 failed for: [wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local]

    Apr 26 12:03:02.769: INFO: File wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 26 12:03:02.816: INFO: File jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 26 12:03:02.816: INFO: Lookups using dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 failed for: [wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local]

    Apr 26 12:03:07.767: INFO: File wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 26 12:03:07.834: INFO: File jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 26 12:03:07.834: INFO: Lookups using dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 failed for: [wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local]

    Apr 26 12:03:12.773: INFO: File wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 26 12:03:12.819: INFO: File jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 26 12:03:12.819: INFO: Lookups using dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 failed for: [wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local]

    Apr 26 12:03:17.771: INFO: File wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 26 12:03:17.810: INFO: File jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local from pod  dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 contains 'foo.example.com.
    ' instead of 'bar.example.com.'
    Apr 26 12:03:17.810: INFO: Lookups using dns-8452/dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 failed for: [wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local]

    Apr 26 12:03:22.801: INFO: DNS probes using dns-test-af397fe8-eed7-47a6-8ec8-c5ef02be37a3 succeeded

    STEP: deleting the pod 04/26/24 12:03:22.801
    STEP: changing the service to type=ClusterIP 04/26/24 12:03:22.818
    STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8452.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8452.svc.cluster.local; sleep 1; done
     04/26/24 12:03:22.847
    STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8452.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8452.svc.cluster.local; sleep 1; done
     04/26/24 12:03:22.847
    STEP: creating a third pod to probe DNS 04/26/24 12:03:22.848
    STEP: submitting the pod to kubernetes 04/26/24 12:03:22.854
    Apr 26 12:03:22.870: INFO: Waiting up to 15m0s for pod "dns-test-db4a7e59-9437-4cc5-99fb-60c091f7f9d9" in namespace "dns-8452" to be "running"
    Apr 26 12:03:22.879: INFO: Pod "dns-test-db4a7e59-9437-4cc5-99fb-60c091f7f9d9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.834383ms
    Apr 26 12:03:24.913: INFO: Pod "dns-test-db4a7e59-9437-4cc5-99fb-60c091f7f9d9": Phase="Running", Reason="", readiness=true. Elapsed: 2.042376682s
    Apr 26 12:03:24.913: INFO: Pod "dns-test-db4a7e59-9437-4cc5-99fb-60c091f7f9d9" satisfied condition "running"
    STEP: retrieving the pod 04/26/24 12:03:24.913
    STEP: looking for the results for each expected name from probers 04/26/24 12:03:24.92
    Apr 26 12:03:25.075: INFO: DNS probes using dns-test-db4a7e59-9437-4cc5-99fb-60c091f7f9d9 succeeded

    STEP: deleting the pod 04/26/24 12:03:25.075
    STEP: deleting the test externalName service 04/26/24 12:03:25.092
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 26 12:03:25.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-8452" for this suite. 04/26/24 12:03:25.124
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Container Runtime blackbox test on terminated container
  should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
[BeforeEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:03:25.132
Apr 26 12:03:25.132: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-runtime 04/26/24 12:03:25.133
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:03:25.151
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:03:25.157
[It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  test/e2e/common/node/runtime.go:247
STEP: create the container 04/26/24 12:03:25.163
STEP: wait for the container to reach Succeeded 04/26/24 12:03:25.174
STEP: get the container status 04/26/24 12:03:29.228
STEP: the container should be terminated 04/26/24 12:03:29.233
STEP: the termination message should be set 04/26/24 12:03:29.233
Apr 26 12:03:29.233: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container 04/26/24 12:03:29.233
[AfterEach] [sig-node] Container Runtime
  test/e2e/framework/framework.go:187
Apr 26 12:03:29.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-782" for this suite. 04/26/24 12:03:29.293
{"msg":"PASSED [sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]","completed":275,"skipped":5096,"failed":0}
------------------------------
â€¢ [4.168 seconds]
[sig-node] Container Runtime
test/e2e/common/node/framework.go:23
  blackbox test
  test/e2e/common/node/runtime.go:43
    on terminated container
    test/e2e/common/node/runtime.go:136
      should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:03:25.132
    Apr 26 12:03:25.132: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-runtime 04/26/24 12:03:25.133
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:03:25.151
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:03:25.157
    [It] should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      test/e2e/common/node/runtime.go:247
    STEP: create the container 04/26/24 12:03:25.163
    STEP: wait for the container to reach Succeeded 04/26/24 12:03:25.174
    STEP: get the container status 04/26/24 12:03:29.228
    STEP: the container should be terminated 04/26/24 12:03:29.233
    STEP: the termination message should be set 04/26/24 12:03:29.233
    Apr 26 12:03:29.233: INFO: Expected: &{OK} to match Container's Termination Message: OK --
    STEP: delete the container 04/26/24 12:03:29.233
    [AfterEach] [sig-node] Container Runtime
      test/e2e/framework/framework.go:187
    Apr 26 12:03:29.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-runtime-782" for this suite. 04/26/24 12:03:29.293
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-network] Service endpoints latency
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
[BeforeEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:03:29.3
Apr 26 12:03:29.301: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename svc-latency 04/26/24 12:03:29.301
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:03:29.317
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:03:29.322
[It] should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59
Apr 26 12:03:29.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: creating replication controller svc-latency-rc in namespace svc-latency-4856 04/26/24 12:03:29.329
I0426 12:03:29.336823      23 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4856, replica count: 1
I0426 12:03:30.387960      23 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0426 12:03:31.388153      23 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 26 12:03:31.513: INFO: Created: latency-svc-4mgdk
Apr 26 12:03:31.517: INFO: Got endpoints: latency-svc-4mgdk [29.488834ms]
Apr 26 12:03:31.541: INFO: Created: latency-svc-vcskt
Apr 26 12:03:31.553: INFO: Got endpoints: latency-svc-vcskt [34.852449ms]
Apr 26 12:03:31.559: INFO: Created: latency-svc-fn8vt
Apr 26 12:03:31.570: INFO: Got endpoints: latency-svc-fn8vt [52.157933ms]
Apr 26 12:03:31.590: INFO: Created: latency-svc-nq4bl
Apr 26 12:03:31.595: INFO: Got endpoints: latency-svc-nq4bl [77.631688ms]
Apr 26 12:03:31.597: INFO: Created: latency-svc-tl2qz
Apr 26 12:03:31.606: INFO: Got endpoints: latency-svc-tl2qz [87.800867ms]
Apr 26 12:03:31.613: INFO: Created: latency-svc-l5t9z
Apr 26 12:03:31.623: INFO: Got endpoints: latency-svc-l5t9z [105.297448ms]
Apr 26 12:03:31.628: INFO: Created: latency-svc-9jt58
Apr 26 12:03:31.637: INFO: Got endpoints: latency-svc-9jt58 [119.036103ms]
Apr 26 12:03:31.648: INFO: Created: latency-svc-wlhtw
Apr 26 12:03:31.651: INFO: Got endpoints: latency-svc-wlhtw [133.316103ms]
Apr 26 12:03:31.664: INFO: Created: latency-svc-w9twl
Apr 26 12:03:31.668: INFO: Got endpoints: latency-svc-w9twl [150.494588ms]
Apr 26 12:03:31.682: INFO: Created: latency-svc-x4h7w
Apr 26 12:03:31.690: INFO: Got endpoints: latency-svc-x4h7w [171.835009ms]
Apr 26 12:03:31.696: INFO: Created: latency-svc-mbknr
Apr 26 12:03:31.716: INFO: Created: latency-svc-hn8sm
Apr 26 12:03:31.716: INFO: Got endpoints: latency-svc-mbknr [198.045347ms]
Apr 26 12:03:31.724: INFO: Created: latency-svc-rxghq
Apr 26 12:03:31.725: INFO: Got endpoints: latency-svc-hn8sm [207.104713ms]
Apr 26 12:03:31.733: INFO: Got endpoints: latency-svc-rxghq [215.150735ms]
Apr 26 12:03:31.737: INFO: Created: latency-svc-p6dml
Apr 26 12:03:31.745: INFO: Got endpoints: latency-svc-p6dml [227.057387ms]
Apr 26 12:03:31.761: INFO: Created: latency-svc-57gzz
Apr 26 12:03:31.779: INFO: Got endpoints: latency-svc-57gzz [260.635544ms]
Apr 26 12:03:31.787: INFO: Created: latency-svc-4hcff
Apr 26 12:03:31.804: INFO: Got endpoints: latency-svc-4hcff [285.783818ms]
Apr 26 12:03:31.807: INFO: Created: latency-svc-w4jt8
Apr 26 12:03:31.822: INFO: Got endpoints: latency-svc-w4jt8 [269.625971ms]
Apr 26 12:03:31.823: INFO: Created: latency-svc-bzjxn
Apr 26 12:03:31.840: INFO: Created: latency-svc-57fwq
Apr 26 12:03:31.843: INFO: Got endpoints: latency-svc-bzjxn [273.472034ms]
Apr 26 12:03:31.850: INFO: Got endpoints: latency-svc-57fwq [254.753467ms]
Apr 26 12:03:31.852: INFO: Created: latency-svc-h44mq
Apr 26 12:03:31.860: INFO: Got endpoints: latency-svc-h44mq [254.681702ms]
Apr 26 12:03:31.864: INFO: Created: latency-svc-fbx57
Apr 26 12:03:31.874: INFO: Got endpoints: latency-svc-fbx57 [251.170969ms]
Apr 26 12:03:31.891: INFO: Created: latency-svc-5hssz
Apr 26 12:03:31.899: INFO: Got endpoints: latency-svc-5hssz [262.05466ms]
Apr 26 12:03:31.900: INFO: Created: latency-svc-85m94
Apr 26 12:03:31.915: INFO: Got endpoints: latency-svc-85m94 [263.40745ms]
Apr 26 12:03:31.923: INFO: Created: latency-svc-28kn6
Apr 26 12:03:31.926: INFO: Got endpoints: latency-svc-28kn6 [257.664063ms]
Apr 26 12:03:31.930: INFO: Created: latency-svc-hzvgz
Apr 26 12:03:31.943: INFO: Got endpoints: latency-svc-hzvgz [252.640878ms]
Apr 26 12:03:31.947: INFO: Created: latency-svc-rg6vx
Apr 26 12:03:31.962: INFO: Created: latency-svc-9drq9
Apr 26 12:03:31.963: INFO: Got endpoints: latency-svc-rg6vx [246.583652ms]
Apr 26 12:03:31.977: INFO: Got endpoints: latency-svc-9drq9 [251.924042ms]
Apr 26 12:03:31.986: INFO: Created: latency-svc-scnx2
Apr 26 12:03:31.991: INFO: Got endpoints: latency-svc-scnx2 [257.655347ms]
Apr 26 12:03:31.998: INFO: Created: latency-svc-8r86d
Apr 26 12:03:32.014: INFO: Got endpoints: latency-svc-8r86d [268.7158ms]
Apr 26 12:03:32.017: INFO: Created: latency-svc-h8ts2
Apr 26 12:03:32.028: INFO: Got endpoints: latency-svc-h8ts2 [249.484682ms]
Apr 26 12:03:32.032: INFO: Created: latency-svc-xmfxb
Apr 26 12:03:32.042: INFO: Got endpoints: latency-svc-xmfxb [237.866931ms]
Apr 26 12:03:32.049: INFO: Created: latency-svc-z8fnl
Apr 26 12:03:32.061: INFO: Got endpoints: latency-svc-z8fnl [238.475233ms]
Apr 26 12:03:32.067: INFO: Created: latency-svc-9wqwx
Apr 26 12:03:32.071: INFO: Got endpoints: latency-svc-9wqwx [227.826122ms]
Apr 26 12:03:32.082: INFO: Created: latency-svc-8j6rg
Apr 26 12:03:32.088: INFO: Got endpoints: latency-svc-8j6rg [237.806398ms]
Apr 26 12:03:32.104: INFO: Created: latency-svc-lqzxk
Apr 26 12:03:32.110: INFO: Got endpoints: latency-svc-lqzxk [249.291128ms]
Apr 26 12:03:32.119: INFO: Created: latency-svc-kdctq
Apr 26 12:03:32.126: INFO: Got endpoints: latency-svc-kdctq [251.871284ms]
Apr 26 12:03:32.150: INFO: Created: latency-svc-2x5pg
Apr 26 12:03:32.157: INFO: Got endpoints: latency-svc-2x5pg [241.82173ms]
Apr 26 12:03:32.169: INFO: Created: latency-svc-d9slg
Apr 26 12:03:32.171: INFO: Got endpoints: latency-svc-d9slg [244.814812ms]
Apr 26 12:03:32.177: INFO: Created: latency-svc-blk7v
Apr 26 12:03:32.186: INFO: Got endpoints: latency-svc-blk7v [243.389783ms]
Apr 26 12:03:32.190: INFO: Created: latency-svc-rcfd4
Apr 26 12:03:32.202: INFO: Got endpoints: latency-svc-rcfd4 [239.673595ms]
Apr 26 12:03:32.212: INFO: Created: latency-svc-4f2nf
Apr 26 12:03:32.219: INFO: Got endpoints: latency-svc-4f2nf [241.438538ms]
Apr 26 12:03:32.225: INFO: Created: latency-svc-bvlxw
Apr 26 12:03:32.234: INFO: Got endpoints: latency-svc-bvlxw [243.361489ms]
Apr 26 12:03:32.240: INFO: Created: latency-svc-vcnr2
Apr 26 12:03:32.245: INFO: Got endpoints: latency-svc-vcnr2 [230.85984ms]
Apr 26 12:03:32.251: INFO: Created: latency-svc-5f6z5
Apr 26 12:03:32.261: INFO: Got endpoints: latency-svc-5f6z5 [232.240855ms]
Apr 26 12:03:32.268: INFO: Created: latency-svc-kc9vm
Apr 26 12:03:32.279: INFO: Got endpoints: latency-svc-kc9vm [237.519237ms]
Apr 26 12:03:32.290: INFO: Created: latency-svc-zwmfd
Apr 26 12:03:32.309: INFO: Created: latency-svc-9vb5t
Apr 26 12:03:32.324: INFO: Got endpoints: latency-svc-zwmfd [263.199332ms]
Apr 26 12:03:32.327: INFO: Created: latency-svc-dgxsm
Apr 26 12:03:32.340: INFO: Created: latency-svc-4z4b2
Apr 26 12:03:32.341: INFO: Created: latency-svc-24fj5
Apr 26 12:03:32.351: INFO: Created: latency-svc-5n9zp
Apr 26 12:03:32.368: INFO: Created: latency-svc-ssb6d
Apr 26 12:03:32.377: INFO: Got endpoints: latency-svc-9vb5t [305.855817ms]
Apr 26 12:03:32.388: INFO: Created: latency-svc-5jwgs
Apr 26 12:03:32.407: INFO: Created: latency-svc-v4hq9
Apr 26 12:03:32.417: INFO: Got endpoints: latency-svc-dgxsm [328.678523ms]
Apr 26 12:03:32.421: INFO: Created: latency-svc-4rphg
Apr 26 12:03:32.439: INFO: Created: latency-svc-8k66n
Apr 26 12:03:32.461: INFO: Created: latency-svc-vnqnv
Apr 26 12:03:32.467: INFO: Got endpoints: latency-svc-24fj5 [357.52923ms]
Apr 26 12:03:32.468: INFO: Created: latency-svc-jhfvg
Apr 26 12:03:32.486: INFO: Created: latency-svc-xdjqj
Apr 26 12:03:32.508: INFO: Created: latency-svc-ljwrz
Apr 26 12:03:32.517: INFO: Created: latency-svc-tht54
Apr 26 12:03:32.557: INFO: Got endpoints: latency-svc-4z4b2 [657.324416ms]
Apr 26 12:03:32.566: INFO: Created: latency-svc-79lnc
Apr 26 12:03:32.575: INFO: Got endpoints: latency-svc-5n9zp [448.383534ms]
Apr 26 12:03:32.583: INFO: Created: latency-svc-r5bc8
Apr 26 12:03:32.602: INFO: Created: latency-svc-cfhkr
Apr 26 12:03:32.611: INFO: Created: latency-svc-m4txl
Apr 26 12:03:32.622: INFO: Got endpoints: latency-svc-ssb6d [464.816136ms]
Apr 26 12:03:32.628: INFO: Created: latency-svc-9bwmf
Apr 26 12:03:32.652: INFO: Created: latency-svc-26skx
Apr 26 12:03:32.666: INFO: Got endpoints: latency-svc-5jwgs [495.494155ms]
Apr 26 12:03:32.688: INFO: Created: latency-svc-wxcdn
Apr 26 12:03:32.718: INFO: Got endpoints: latency-svc-v4hq9 [531.726016ms]
Apr 26 12:03:32.742: INFO: Created: latency-svc-mqgnm
Apr 26 12:03:32.770: INFO: Got endpoints: latency-svc-4rphg [567.924192ms]
Apr 26 12:03:32.790: INFO: Created: latency-svc-5bhvv
Apr 26 12:03:32.817: INFO: Got endpoints: latency-svc-8k66n [598.498028ms]
Apr 26 12:03:32.841: INFO: Created: latency-svc-csqn5
Apr 26 12:03:32.879: INFO: Got endpoints: latency-svc-vnqnv [645.146191ms]
Apr 26 12:03:32.899: INFO: Created: latency-svc-c28dr
Apr 26 12:03:32.916: INFO: Got endpoints: latency-svc-jhfvg [671.584879ms]
Apr 26 12:03:32.941: INFO: Created: latency-svc-jhrxw
Apr 26 12:03:32.972: INFO: Got endpoints: latency-svc-xdjqj [711.929063ms]
Apr 26 12:03:32.995: INFO: Created: latency-svc-vzjwn
Apr 26 12:03:33.017: INFO: Got endpoints: latency-svc-ljwrz [737.35737ms]
Apr 26 12:03:33.045: INFO: Created: latency-svc-trglh
Apr 26 12:03:33.071: INFO: Got endpoints: latency-svc-tht54 [746.379257ms]
Apr 26 12:03:33.102: INFO: Created: latency-svc-ch92t
Apr 26 12:03:33.121: INFO: Got endpoints: latency-svc-79lnc [743.688253ms]
Apr 26 12:03:33.143: INFO: Created: latency-svc-vwlzk
Apr 26 12:03:33.168: INFO: Got endpoints: latency-svc-r5bc8 [750.873528ms]
Apr 26 12:03:33.191: INFO: Created: latency-svc-nstcz
Apr 26 12:03:33.218: INFO: Got endpoints: latency-svc-cfhkr [750.615684ms]
Apr 26 12:03:33.244: INFO: Created: latency-svc-chdsj
Apr 26 12:03:33.272: INFO: Got endpoints: latency-svc-m4txl [715.114405ms]
Apr 26 12:03:33.293: INFO: Created: latency-svc-s2xj4
Apr 26 12:03:33.319: INFO: Got endpoints: latency-svc-9bwmf [744.302215ms]
Apr 26 12:03:33.339: INFO: Created: latency-svc-kznr6
Apr 26 12:03:33.371: INFO: Got endpoints: latency-svc-26skx [749.060152ms]
Apr 26 12:03:33.400: INFO: Created: latency-svc-n8dxh
Apr 26 12:03:33.422: INFO: Got endpoints: latency-svc-wxcdn [755.086202ms]
Apr 26 12:03:33.443: INFO: Created: latency-svc-vpkrx
Apr 26 12:03:33.475: INFO: Got endpoints: latency-svc-mqgnm [756.824334ms]
Apr 26 12:03:33.499: INFO: Created: latency-svc-gb97d
Apr 26 12:03:33.520: INFO: Got endpoints: latency-svc-5bhvv [749.678735ms]
Apr 26 12:03:33.539: INFO: Created: latency-svc-vklr7
Apr 26 12:03:33.569: INFO: Got endpoints: latency-svc-csqn5 [751.472825ms]
Apr 26 12:03:33.594: INFO: Created: latency-svc-mg9ff
Apr 26 12:03:33.621: INFO: Got endpoints: latency-svc-c28dr [741.314616ms]
Apr 26 12:03:33.641: INFO: Created: latency-svc-hv2hf
Apr 26 12:03:33.670: INFO: Got endpoints: latency-svc-jhrxw [753.331845ms]
Apr 26 12:03:33.691: INFO: Created: latency-svc-c7pbr
Apr 26 12:03:33.718: INFO: Got endpoints: latency-svc-vzjwn [744.951265ms]
Apr 26 12:03:33.738: INFO: Created: latency-svc-l4w49
Apr 26 12:03:33.767: INFO: Got endpoints: latency-svc-trglh [750.209261ms]
Apr 26 12:03:33.790: INFO: Created: latency-svc-psjv5
Apr 26 12:03:33.820: INFO: Got endpoints: latency-svc-ch92t [748.94678ms]
Apr 26 12:03:33.840: INFO: Created: latency-svc-42jxw
Apr 26 12:03:33.870: INFO: Got endpoints: latency-svc-vwlzk [748.885905ms]
Apr 26 12:03:33.891: INFO: Created: latency-svc-5cmc9
Apr 26 12:03:33.919: INFO: Got endpoints: latency-svc-nstcz [751.435684ms]
Apr 26 12:03:33.943: INFO: Created: latency-svc-x82cl
Apr 26 12:03:33.967: INFO: Got endpoints: latency-svc-chdsj [748.982756ms]
Apr 26 12:03:33.987: INFO: Created: latency-svc-z5wwj
Apr 26 12:03:34.020: INFO: Got endpoints: latency-svc-s2xj4 [747.863505ms]
Apr 26 12:03:34.042: INFO: Created: latency-svc-92rm8
Apr 26 12:03:34.074: INFO: Got endpoints: latency-svc-kznr6 [755.303749ms]
Apr 26 12:03:34.096: INFO: Created: latency-svc-77qg2
Apr 26 12:03:34.118: INFO: Got endpoints: latency-svc-n8dxh [747.654605ms]
Apr 26 12:03:34.145: INFO: Created: latency-svc-sxt82
Apr 26 12:03:34.177: INFO: Got endpoints: latency-svc-vpkrx [754.850939ms]
Apr 26 12:03:34.198: INFO: Created: latency-svc-zmctx
Apr 26 12:03:34.219: INFO: Got endpoints: latency-svc-gb97d [744.583296ms]
Apr 26 12:03:34.242: INFO: Created: latency-svc-cm75g
Apr 26 12:03:34.270: INFO: Got endpoints: latency-svc-vklr7 [749.370176ms]
Apr 26 12:03:34.289: INFO: Created: latency-svc-zhfmr
Apr 26 12:03:34.324: INFO: Got endpoints: latency-svc-mg9ff [755.590499ms]
Apr 26 12:03:34.348: INFO: Created: latency-svc-wts4s
Apr 26 12:03:34.368: INFO: Got endpoints: latency-svc-hv2hf [747.299577ms]
Apr 26 12:03:34.410: INFO: Created: latency-svc-b59vm
Apr 26 12:03:34.417: INFO: Got endpoints: latency-svc-c7pbr [746.597207ms]
Apr 26 12:03:34.435: INFO: Created: latency-svc-5jtsh
Apr 26 12:03:34.467: INFO: Got endpoints: latency-svc-l4w49 [749.508004ms]
Apr 26 12:03:34.489: INFO: Created: latency-svc-s7wln
Apr 26 12:03:34.518: INFO: Got endpoints: latency-svc-psjv5 [750.919967ms]
Apr 26 12:03:34.542: INFO: Created: latency-svc-zzbz6
Apr 26 12:03:34.567: INFO: Got endpoints: latency-svc-42jxw [747.166457ms]
Apr 26 12:03:34.587: INFO: Created: latency-svc-crmtm
Apr 26 12:03:34.621: INFO: Got endpoints: latency-svc-5cmc9 [751.16686ms]
Apr 26 12:03:34.643: INFO: Created: latency-svc-dd5p6
Apr 26 12:03:34.668: INFO: Got endpoints: latency-svc-x82cl [748.293744ms]
Apr 26 12:03:34.703: INFO: Created: latency-svc-srgbc
Apr 26 12:03:34.757: INFO: Got endpoints: latency-svc-z5wwj [790.364894ms]
Apr 26 12:03:34.773: INFO: Got endpoints: latency-svc-92rm8 [753.623955ms]
Apr 26 12:03:34.817: INFO: Created: latency-svc-f6r9l
Apr 26 12:03:34.827: INFO: Got endpoints: latency-svc-77qg2 [752.974935ms]
Apr 26 12:03:34.904: INFO: Got endpoints: latency-svc-sxt82 [785.811821ms]
Apr 26 12:03:34.914: INFO: Created: latency-svc-6dj5p
Apr 26 12:03:34.933: INFO: Got endpoints: latency-svc-zmctx [756.623387ms]
Apr 26 12:03:34.963: INFO: Created: latency-svc-fqzmc
Apr 26 12:03:34.990: INFO: Got endpoints: latency-svc-cm75g [770.853906ms]
Apr 26 12:03:35.076: INFO: Got endpoints: latency-svc-zhfmr [806.519564ms]
Apr 26 12:03:35.079: INFO: Got endpoints: latency-svc-wts4s [754.072708ms]
Apr 26 12:03:35.081: INFO: Created: latency-svc-sqqkw
Apr 26 12:03:35.107: INFO: Created: latency-svc-m9pbn
Apr 26 12:03:35.139: INFO: Created: latency-svc-gzcps
Apr 26 12:03:35.141: INFO: Got endpoints: latency-svc-b59vm [772.349345ms]
Apr 26 12:03:35.232: INFO: Got endpoints: latency-svc-5jtsh [815.830351ms]
Apr 26 12:03:35.233: INFO: Created: latency-svc-gpjzn
Apr 26 12:03:35.238: INFO: Got endpoints: latency-svc-s7wln [770.612283ms]
Apr 26 12:03:35.249: INFO: Created: latency-svc-dpckt
Apr 26 12:03:35.269: INFO: Created: latency-svc-mlg5k
Apr 26 12:03:35.277: INFO: Got endpoints: latency-svc-zzbz6 [758.804084ms]
Apr 26 12:03:35.280: INFO: Created: latency-svc-lx7n6
Apr 26 12:03:35.296: INFO: Created: latency-svc-vfzzh
Apr 26 12:03:35.312: INFO: Created: latency-svc-xr559
Apr 26 12:03:35.321: INFO: Got endpoints: latency-svc-crmtm [754.51072ms]
Apr 26 12:03:35.345: INFO: Created: latency-svc-wr2qp
Apr 26 12:03:35.367: INFO: Got endpoints: latency-svc-dd5p6 [746.148895ms]
Apr 26 12:03:35.390: INFO: Created: latency-svc-m9dv4
Apr 26 12:03:35.419: INFO: Got endpoints: latency-svc-srgbc [751.258601ms]
Apr 26 12:03:35.463: INFO: Created: latency-svc-25mdg
Apr 26 12:03:35.467: INFO: Got endpoints: latency-svc-f6r9l [709.506693ms]
Apr 26 12:03:35.489: INFO: Created: latency-svc-dww8l
Apr 26 12:03:35.518: INFO: Got endpoints: latency-svc-6dj5p [744.45836ms]
Apr 26 12:03:35.537: INFO: Created: latency-svc-6hmhp
Apr 26 12:03:35.569: INFO: Got endpoints: latency-svc-fqzmc [741.150758ms]
Apr 26 12:03:35.591: INFO: Created: latency-svc-ftzbt
Apr 26 12:03:35.620: INFO: Got endpoints: latency-svc-sqqkw [715.536399ms]
Apr 26 12:03:35.640: INFO: Created: latency-svc-ccdwg
Apr 26 12:03:35.677: INFO: Got endpoints: latency-svc-m9pbn [743.232477ms]
Apr 26 12:03:35.697: INFO: Created: latency-svc-v7rf2
Apr 26 12:03:35.718: INFO: Got endpoints: latency-svc-gzcps [727.489811ms]
Apr 26 12:03:35.746: INFO: Created: latency-svc-z7t5s
Apr 26 12:03:35.770: INFO: Got endpoints: latency-svc-gpjzn [693.351542ms]
Apr 26 12:03:35.790: INFO: Created: latency-svc-7l9dr
Apr 26 12:03:35.821: INFO: Got endpoints: latency-svc-dpckt [742.2069ms]
Apr 26 12:03:35.844: INFO: Created: latency-svc-hlcsd
Apr 26 12:03:35.870: INFO: Got endpoints: latency-svc-mlg5k [729.365874ms]
Apr 26 12:03:35.893: INFO: Created: latency-svc-sskq2
Apr 26 12:03:35.918: INFO: Got endpoints: latency-svc-lx7n6 [685.371073ms]
Apr 26 12:03:35.941: INFO: Created: latency-svc-kj646
Apr 26 12:03:35.970: INFO: Got endpoints: latency-svc-vfzzh [732.56336ms]
Apr 26 12:03:35.989: INFO: Created: latency-svc-q6ggb
Apr 26 12:03:36.021: INFO: Got endpoints: latency-svc-xr559 [744.016723ms]
Apr 26 12:03:36.044: INFO: Created: latency-svc-xfbrd
Apr 26 12:03:36.072: INFO: Got endpoints: latency-svc-wr2qp [750.094197ms]
Apr 26 12:03:36.090: INFO: Created: latency-svc-pw4q2
Apr 26 12:03:36.117: INFO: Got endpoints: latency-svc-m9dv4 [749.778614ms]
Apr 26 12:03:36.141: INFO: Created: latency-svc-42w8j
Apr 26 12:03:36.169: INFO: Got endpoints: latency-svc-25mdg [749.468624ms]
Apr 26 12:03:36.191: INFO: Created: latency-svc-szwfb
Apr 26 12:03:36.217: INFO: Got endpoints: latency-svc-dww8l [750.02654ms]
Apr 26 12:03:36.239: INFO: Created: latency-svc-schb7
Apr 26 12:03:36.269: INFO: Got endpoints: latency-svc-6hmhp [750.748516ms]
Apr 26 12:03:36.295: INFO: Created: latency-svc-jccgx
Apr 26 12:03:36.323: INFO: Got endpoints: latency-svc-ftzbt [754.623885ms]
Apr 26 12:03:36.353: INFO: Created: latency-svc-n5pq4
Apr 26 12:03:36.367: INFO: Got endpoints: latency-svc-ccdwg [747.480798ms]
Apr 26 12:03:36.385: INFO: Created: latency-svc-n9fck
Apr 26 12:03:36.416: INFO: Got endpoints: latency-svc-v7rf2 [739.832793ms]
Apr 26 12:03:36.441: INFO: Created: latency-svc-wxvfz
Apr 26 12:03:36.469: INFO: Got endpoints: latency-svc-z7t5s [750.853543ms]
Apr 26 12:03:36.489: INFO: Created: latency-svc-pnzx6
Apr 26 12:03:36.522: INFO: Got endpoints: latency-svc-7l9dr [752.801351ms]
Apr 26 12:03:36.559: INFO: Created: latency-svc-5hbkf
Apr 26 12:03:36.572: INFO: Got endpoints: latency-svc-hlcsd [750.703882ms]
Apr 26 12:03:36.602: INFO: Created: latency-svc-hl4f4
Apr 26 12:03:36.618: INFO: Got endpoints: latency-svc-sskq2 [747.716351ms]
Apr 26 12:03:36.642: INFO: Created: latency-svc-nzc68
Apr 26 12:03:36.676: INFO: Got endpoints: latency-svc-kj646 [758.13549ms]
Apr 26 12:03:36.694: INFO: Created: latency-svc-fjbj8
Apr 26 12:03:36.718: INFO: Got endpoints: latency-svc-q6ggb [747.711162ms]
Apr 26 12:03:36.741: INFO: Created: latency-svc-lcjcp
Apr 26 12:03:36.769: INFO: Got endpoints: latency-svc-xfbrd [748.178297ms]
Apr 26 12:03:36.789: INFO: Created: latency-svc-w7fgv
Apr 26 12:03:36.822: INFO: Got endpoints: latency-svc-pw4q2 [750.357201ms]
Apr 26 12:03:36.844: INFO: Created: latency-svc-zhlzz
Apr 26 12:03:36.918: INFO: Got endpoints: latency-svc-42w8j [800.812956ms]
Apr 26 12:03:36.918: INFO: Got endpoints: latency-svc-szwfb [749.38359ms]
Apr 26 12:03:36.952: INFO: Created: latency-svc-dpp8s
Apr 26 12:03:36.980: INFO: Got endpoints: latency-svc-schb7 [763.13478ms]
Apr 26 12:03:37.018: INFO: Created: latency-svc-nq75v
Apr 26 12:03:37.034: INFO: Got endpoints: latency-svc-jccgx [765.506815ms]
Apr 26 12:03:37.044: INFO: Created: latency-svc-24vtn
Apr 26 12:03:37.057: INFO: Created: latency-svc-vzxnl
Apr 26 12:03:37.067: INFO: Got endpoints: latency-svc-n5pq4 [743.889472ms]
Apr 26 12:03:37.095: INFO: Created: latency-svc-nzqjh
Apr 26 12:03:37.121: INFO: Got endpoints: latency-svc-n9fck [753.865609ms]
Apr 26 12:03:37.147: INFO: Created: latency-svc-75dts
Apr 26 12:03:37.169: INFO: Got endpoints: latency-svc-wxvfz [752.852387ms]
Apr 26 12:03:37.191: INFO: Created: latency-svc-cdnkl
Apr 26 12:03:37.218: INFO: Got endpoints: latency-svc-pnzx6 [749.209614ms]
Apr 26 12:03:37.242: INFO: Created: latency-svc-6gvvl
Apr 26 12:03:37.271: INFO: Got endpoints: latency-svc-5hbkf [748.380978ms]
Apr 26 12:03:37.294: INFO: Created: latency-svc-48zp4
Apr 26 12:03:37.322: INFO: Got endpoints: latency-svc-hl4f4 [750.456597ms]
Apr 26 12:03:37.345: INFO: Created: latency-svc-vzpnf
Apr 26 12:03:37.367: INFO: Got endpoints: latency-svc-nzc68 [749.405895ms]
Apr 26 12:03:37.390: INFO: Created: latency-svc-fqqk5
Apr 26 12:03:37.418: INFO: Got endpoints: latency-svc-fjbj8 [741.58815ms]
Apr 26 12:03:37.443: INFO: Created: latency-svc-2twph
Apr 26 12:03:37.469: INFO: Got endpoints: latency-svc-lcjcp [750.882287ms]
Apr 26 12:03:37.490: INFO: Created: latency-svc-2k5fg
Apr 26 12:03:37.517: INFO: Got endpoints: latency-svc-w7fgv [748.05619ms]
Apr 26 12:03:37.539: INFO: Created: latency-svc-s4v27
Apr 26 12:03:37.569: INFO: Got endpoints: latency-svc-zhlzz [746.891152ms]
Apr 26 12:03:37.588: INFO: Created: latency-svc-l9mgt
Apr 26 12:03:37.618: INFO: Got endpoints: latency-svc-dpp8s [700.402067ms]
Apr 26 12:03:37.639: INFO: Created: latency-svc-7z27f
Apr 26 12:03:37.666: INFO: Got endpoints: latency-svc-nq75v [748.107236ms]
Apr 26 12:03:37.690: INFO: Created: latency-svc-49djq
Apr 26 12:03:37.719: INFO: Got endpoints: latency-svc-24vtn [739.05322ms]
Apr 26 12:03:37.737: INFO: Created: latency-svc-6tlzq
Apr 26 12:03:37.768: INFO: Got endpoints: latency-svc-vzxnl [732.976768ms]
Apr 26 12:03:37.794: INFO: Created: latency-svc-wz69t
Apr 26 12:03:37.816: INFO: Got endpoints: latency-svc-nzqjh [749.046218ms]
Apr 26 12:03:37.837: INFO: Created: latency-svc-bb2v2
Apr 26 12:03:37.871: INFO: Got endpoints: latency-svc-75dts [750.063128ms]
Apr 26 12:03:37.901: INFO: Created: latency-svc-cf5pm
Apr 26 12:03:37.921: INFO: Got endpoints: latency-svc-cdnkl [751.77286ms]
Apr 26 12:03:37.945: INFO: Created: latency-svc-vwfsw
Apr 26 12:03:37.968: INFO: Got endpoints: latency-svc-6gvvl [749.665622ms]
Apr 26 12:03:37.991: INFO: Created: latency-svc-tgk9z
Apr 26 12:03:38.020: INFO: Got endpoints: latency-svc-48zp4 [749.136651ms]
Apr 26 12:03:38.042: INFO: Created: latency-svc-5s5q2
Apr 26 12:03:38.068: INFO: Got endpoints: latency-svc-vzpnf [746.050783ms]
Apr 26 12:03:38.098: INFO: Created: latency-svc-k6pnc
Apr 26 12:03:38.117: INFO: Got endpoints: latency-svc-fqqk5 [749.209265ms]
Apr 26 12:03:38.140: INFO: Created: latency-svc-hx54k
Apr 26 12:03:38.170: INFO: Got endpoints: latency-svc-2twph [751.63953ms]
Apr 26 12:03:38.192: INFO: Created: latency-svc-nb2vp
Apr 26 12:03:38.219: INFO: Got endpoints: latency-svc-2k5fg [749.72303ms]
Apr 26 12:03:38.241: INFO: Created: latency-svc-8l5zw
Apr 26 12:03:38.272: INFO: Got endpoints: latency-svc-s4v27 [754.675012ms]
Apr 26 12:03:38.296: INFO: Created: latency-svc-xr2z4
Apr 26 12:03:38.317: INFO: Got endpoints: latency-svc-l9mgt [748.335645ms]
Apr 26 12:03:38.338: INFO: Created: latency-svc-bwqc5
Apr 26 12:03:38.368: INFO: Got endpoints: latency-svc-7z27f [749.484473ms]
Apr 26 12:03:38.392: INFO: Created: latency-svc-xpbl8
Apr 26 12:03:38.418: INFO: Got endpoints: latency-svc-49djq [751.470994ms]
Apr 26 12:03:38.439: INFO: Created: latency-svc-zq6r4
Apr 26 12:03:38.469: INFO: Got endpoints: latency-svc-6tlzq [750.077928ms]
Apr 26 12:03:38.490: INFO: Created: latency-svc-cx7kc
Apr 26 12:03:38.518: INFO: Got endpoints: latency-svc-wz69t [750.765368ms]
Apr 26 12:03:38.543: INFO: Created: latency-svc-djq4k
Apr 26 12:03:38.568: INFO: Got endpoints: latency-svc-bb2v2 [751.117432ms]
Apr 26 12:03:38.589: INFO: Created: latency-svc-5nrsm
Apr 26 12:03:38.618: INFO: Got endpoints: latency-svc-cf5pm [746.046957ms]
Apr 26 12:03:38.653: INFO: Created: latency-svc-dkbmt
Apr 26 12:03:38.668: INFO: Got endpoints: latency-svc-vwfsw [746.625995ms]
Apr 26 12:03:38.691: INFO: Created: latency-svc-629th
Apr 26 12:03:38.718: INFO: Got endpoints: latency-svc-tgk9z [750.325202ms]
Apr 26 12:03:38.742: INFO: Created: latency-svc-gcpwl
Apr 26 12:03:38.768: INFO: Got endpoints: latency-svc-5s5q2 [748.026997ms]
Apr 26 12:03:38.789: INFO: Created: latency-svc-sgsfz
Apr 26 12:03:38.821: INFO: Got endpoints: latency-svc-k6pnc [752.988554ms]
Apr 26 12:03:38.844: INFO: Created: latency-svc-rr9gz
Apr 26 12:03:38.873: INFO: Got endpoints: latency-svc-hx54k [756.087676ms]
Apr 26 12:03:38.893: INFO: Created: latency-svc-nnxxq
Apr 26 12:03:38.922: INFO: Got endpoints: latency-svc-nb2vp [751.902074ms]
Apr 26 12:03:38.942: INFO: Created: latency-svc-5f88p
Apr 26 12:03:38.982: INFO: Got endpoints: latency-svc-8l5zw [762.623943ms]
Apr 26 12:03:39.007: INFO: Created: latency-svc-bwdjd
Apr 26 12:03:39.017: INFO: Got endpoints: latency-svc-xr2z4 [744.341726ms]
Apr 26 12:03:39.041: INFO: Created: latency-svc-z2v4n
Apr 26 12:03:39.069: INFO: Got endpoints: latency-svc-bwqc5 [751.262603ms]
Apr 26 12:03:39.091: INFO: Created: latency-svc-dnjbx
Apr 26 12:03:39.117: INFO: Got endpoints: latency-svc-xpbl8 [748.839191ms]
Apr 26 12:03:39.136: INFO: Created: latency-svc-l8969
Apr 26 12:03:39.167: INFO: Got endpoints: latency-svc-zq6r4 [749.674842ms]
Apr 26 12:03:39.199: INFO: Created: latency-svc-pfkkx
Apr 26 12:03:39.219: INFO: Got endpoints: latency-svc-cx7kc [749.349951ms]
Apr 26 12:03:39.238: INFO: Created: latency-svc-dcbgs
Apr 26 12:03:39.268: INFO: Got endpoints: latency-svc-djq4k [749.71114ms]
Apr 26 12:03:39.289: INFO: Created: latency-svc-hv56j
Apr 26 12:03:39.318: INFO: Got endpoints: latency-svc-5nrsm [750.100492ms]
Apr 26 12:03:39.337: INFO: Created: latency-svc-pbjpx
Apr 26 12:03:39.369: INFO: Got endpoints: latency-svc-dkbmt [750.690169ms]
Apr 26 12:03:39.421: INFO: Got endpoints: latency-svc-629th [753.231391ms]
Apr 26 12:03:39.469: INFO: Got endpoints: latency-svc-gcpwl [750.467791ms]
Apr 26 12:03:39.522: INFO: Got endpoints: latency-svc-sgsfz [753.266318ms]
Apr 26 12:03:39.573: INFO: Got endpoints: latency-svc-rr9gz [751.608766ms]
Apr 26 12:03:39.617: INFO: Got endpoints: latency-svc-nnxxq [744.365431ms]
Apr 26 12:03:39.669: INFO: Got endpoints: latency-svc-5f88p [747.025146ms]
Apr 26 12:03:39.722: INFO: Got endpoints: latency-svc-bwdjd [740.467849ms]
Apr 26 12:03:39.769: INFO: Got endpoints: latency-svc-z2v4n [752.004519ms]
Apr 26 12:03:39.818: INFO: Got endpoints: latency-svc-dnjbx [748.750267ms]
Apr 26 12:03:39.869: INFO: Got endpoints: latency-svc-l8969 [751.756142ms]
Apr 26 12:03:39.918: INFO: Got endpoints: latency-svc-pfkkx [750.265001ms]
Apr 26 12:03:39.972: INFO: Got endpoints: latency-svc-dcbgs [753.319327ms]
Apr 26 12:03:40.020: INFO: Got endpoints: latency-svc-hv56j [752.096802ms]
Apr 26 12:03:40.070: INFO: Got endpoints: latency-svc-pbjpx [752.336251ms]
Apr 26 12:03:40.070: INFO: Latencies: [34.852449ms 52.157933ms 77.631688ms 87.800867ms 105.297448ms 119.036103ms 133.316103ms 150.494588ms 171.835009ms 198.045347ms 207.104713ms 215.150735ms 227.057387ms 227.826122ms 230.85984ms 232.240855ms 237.519237ms 237.806398ms 237.866931ms 238.475233ms 239.673595ms 241.438538ms 241.82173ms 243.361489ms 243.389783ms 244.814812ms 246.583652ms 249.291128ms 249.484682ms 251.170969ms 251.871284ms 251.924042ms 252.640878ms 254.681702ms 254.753467ms 257.655347ms 257.664063ms 260.635544ms 262.05466ms 263.199332ms 263.40745ms 268.7158ms 269.625971ms 273.472034ms 285.783818ms 305.855817ms 328.678523ms 357.52923ms 448.383534ms 464.816136ms 495.494155ms 531.726016ms 567.924192ms 598.498028ms 645.146191ms 657.324416ms 671.584879ms 685.371073ms 693.351542ms 700.402067ms 709.506693ms 711.929063ms 715.114405ms 715.536399ms 727.489811ms 729.365874ms 732.56336ms 732.976768ms 737.35737ms 739.05322ms 739.832793ms 740.467849ms 741.150758ms 741.314616ms 741.58815ms 742.2069ms 743.232477ms 743.688253ms 743.889472ms 744.016723ms 744.302215ms 744.341726ms 744.365431ms 744.45836ms 744.583296ms 744.951265ms 746.046957ms 746.050783ms 746.148895ms 746.379257ms 746.597207ms 746.625995ms 746.891152ms 747.025146ms 747.166457ms 747.299577ms 747.480798ms 747.654605ms 747.711162ms 747.716351ms 747.863505ms 748.026997ms 748.05619ms 748.107236ms 748.178297ms 748.293744ms 748.335645ms 748.380978ms 748.750267ms 748.839191ms 748.885905ms 748.94678ms 748.982756ms 749.046218ms 749.060152ms 749.136651ms 749.209265ms 749.209614ms 749.349951ms 749.370176ms 749.38359ms 749.405895ms 749.468624ms 749.484473ms 749.508004ms 749.665622ms 749.674842ms 749.678735ms 749.71114ms 749.72303ms 749.778614ms 750.02654ms 750.063128ms 750.077928ms 750.094197ms 750.100492ms 750.209261ms 750.265001ms 750.325202ms 750.357201ms 750.456597ms 750.467791ms 750.615684ms 750.690169ms 750.703882ms 750.748516ms 750.765368ms 750.853543ms 750.873528ms 750.882287ms 750.919967ms 751.117432ms 751.16686ms 751.258601ms 751.262603ms 751.435684ms 751.470994ms 751.472825ms 751.608766ms 751.63953ms 751.756142ms 751.77286ms 751.902074ms 752.004519ms 752.096802ms 752.336251ms 752.801351ms 752.852387ms 752.974935ms 752.988554ms 753.231391ms 753.266318ms 753.319327ms 753.331845ms 753.623955ms 753.865609ms 754.072708ms 754.51072ms 754.623885ms 754.675012ms 754.850939ms 755.086202ms 755.303749ms 755.590499ms 756.087676ms 756.623387ms 756.824334ms 758.13549ms 758.804084ms 762.623943ms 763.13478ms 765.506815ms 770.612283ms 770.853906ms 772.349345ms 785.811821ms 790.364894ms 800.812956ms 806.519564ms 815.830351ms]
Apr 26 12:03:40.070: INFO: 50 %ile: 747.863505ms
Apr 26 12:03:40.070: INFO: 90 %ile: 754.850939ms
Apr 26 12:03:40.070: INFO: 99 %ile: 806.519564ms
Apr 26 12:03:40.070: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  test/e2e/framework/framework.go:187
Apr 26 12:03:40.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-4856" for this suite. 04/26/24 12:03:40.087
{"msg":"PASSED [sig-network] Service endpoints latency should not be very high  [Conformance]","completed":276,"skipped":5100,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.793 seconds]
[sig-network] Service endpoints latency
test/e2e/network/common/framework.go:23
  should not be very high  [Conformance]
  test/e2e/network/service_latency.go:59

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:03:29.3
    Apr 26 12:03:29.301: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename svc-latency 04/26/24 12:03:29.301
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:03:29.317
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:03:29.322
    [It] should not be very high  [Conformance]
      test/e2e/network/service_latency.go:59
    Apr 26 12:03:29.328: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: creating replication controller svc-latency-rc in namespace svc-latency-4856 04/26/24 12:03:29.329
    I0426 12:03:29.336823      23 runners.go:193] Created replication controller with name: svc-latency-rc, namespace: svc-latency-4856, replica count: 1
    I0426 12:03:30.387960      23 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    I0426 12:03:31.388153      23 runners.go:193] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
    Apr 26 12:03:31.513: INFO: Created: latency-svc-4mgdk
    Apr 26 12:03:31.517: INFO: Got endpoints: latency-svc-4mgdk [29.488834ms]
    Apr 26 12:03:31.541: INFO: Created: latency-svc-vcskt
    Apr 26 12:03:31.553: INFO: Got endpoints: latency-svc-vcskt [34.852449ms]
    Apr 26 12:03:31.559: INFO: Created: latency-svc-fn8vt
    Apr 26 12:03:31.570: INFO: Got endpoints: latency-svc-fn8vt [52.157933ms]
    Apr 26 12:03:31.590: INFO: Created: latency-svc-nq4bl
    Apr 26 12:03:31.595: INFO: Got endpoints: latency-svc-nq4bl [77.631688ms]
    Apr 26 12:03:31.597: INFO: Created: latency-svc-tl2qz
    Apr 26 12:03:31.606: INFO: Got endpoints: latency-svc-tl2qz [87.800867ms]
    Apr 26 12:03:31.613: INFO: Created: latency-svc-l5t9z
    Apr 26 12:03:31.623: INFO: Got endpoints: latency-svc-l5t9z [105.297448ms]
    Apr 26 12:03:31.628: INFO: Created: latency-svc-9jt58
    Apr 26 12:03:31.637: INFO: Got endpoints: latency-svc-9jt58 [119.036103ms]
    Apr 26 12:03:31.648: INFO: Created: latency-svc-wlhtw
    Apr 26 12:03:31.651: INFO: Got endpoints: latency-svc-wlhtw [133.316103ms]
    Apr 26 12:03:31.664: INFO: Created: latency-svc-w9twl
    Apr 26 12:03:31.668: INFO: Got endpoints: latency-svc-w9twl [150.494588ms]
    Apr 26 12:03:31.682: INFO: Created: latency-svc-x4h7w
    Apr 26 12:03:31.690: INFO: Got endpoints: latency-svc-x4h7w [171.835009ms]
    Apr 26 12:03:31.696: INFO: Created: latency-svc-mbknr
    Apr 26 12:03:31.716: INFO: Created: latency-svc-hn8sm
    Apr 26 12:03:31.716: INFO: Got endpoints: latency-svc-mbknr [198.045347ms]
    Apr 26 12:03:31.724: INFO: Created: latency-svc-rxghq
    Apr 26 12:03:31.725: INFO: Got endpoints: latency-svc-hn8sm [207.104713ms]
    Apr 26 12:03:31.733: INFO: Got endpoints: latency-svc-rxghq [215.150735ms]
    Apr 26 12:03:31.737: INFO: Created: latency-svc-p6dml
    Apr 26 12:03:31.745: INFO: Got endpoints: latency-svc-p6dml [227.057387ms]
    Apr 26 12:03:31.761: INFO: Created: latency-svc-57gzz
    Apr 26 12:03:31.779: INFO: Got endpoints: latency-svc-57gzz [260.635544ms]
    Apr 26 12:03:31.787: INFO: Created: latency-svc-4hcff
    Apr 26 12:03:31.804: INFO: Got endpoints: latency-svc-4hcff [285.783818ms]
    Apr 26 12:03:31.807: INFO: Created: latency-svc-w4jt8
    Apr 26 12:03:31.822: INFO: Got endpoints: latency-svc-w4jt8 [269.625971ms]
    Apr 26 12:03:31.823: INFO: Created: latency-svc-bzjxn
    Apr 26 12:03:31.840: INFO: Created: latency-svc-57fwq
    Apr 26 12:03:31.843: INFO: Got endpoints: latency-svc-bzjxn [273.472034ms]
    Apr 26 12:03:31.850: INFO: Got endpoints: latency-svc-57fwq [254.753467ms]
    Apr 26 12:03:31.852: INFO: Created: latency-svc-h44mq
    Apr 26 12:03:31.860: INFO: Got endpoints: latency-svc-h44mq [254.681702ms]
    Apr 26 12:03:31.864: INFO: Created: latency-svc-fbx57
    Apr 26 12:03:31.874: INFO: Got endpoints: latency-svc-fbx57 [251.170969ms]
    Apr 26 12:03:31.891: INFO: Created: latency-svc-5hssz
    Apr 26 12:03:31.899: INFO: Got endpoints: latency-svc-5hssz [262.05466ms]
    Apr 26 12:03:31.900: INFO: Created: latency-svc-85m94
    Apr 26 12:03:31.915: INFO: Got endpoints: latency-svc-85m94 [263.40745ms]
    Apr 26 12:03:31.923: INFO: Created: latency-svc-28kn6
    Apr 26 12:03:31.926: INFO: Got endpoints: latency-svc-28kn6 [257.664063ms]
    Apr 26 12:03:31.930: INFO: Created: latency-svc-hzvgz
    Apr 26 12:03:31.943: INFO: Got endpoints: latency-svc-hzvgz [252.640878ms]
    Apr 26 12:03:31.947: INFO: Created: latency-svc-rg6vx
    Apr 26 12:03:31.962: INFO: Created: latency-svc-9drq9
    Apr 26 12:03:31.963: INFO: Got endpoints: latency-svc-rg6vx [246.583652ms]
    Apr 26 12:03:31.977: INFO: Got endpoints: latency-svc-9drq9 [251.924042ms]
    Apr 26 12:03:31.986: INFO: Created: latency-svc-scnx2
    Apr 26 12:03:31.991: INFO: Got endpoints: latency-svc-scnx2 [257.655347ms]
    Apr 26 12:03:31.998: INFO: Created: latency-svc-8r86d
    Apr 26 12:03:32.014: INFO: Got endpoints: latency-svc-8r86d [268.7158ms]
    Apr 26 12:03:32.017: INFO: Created: latency-svc-h8ts2
    Apr 26 12:03:32.028: INFO: Got endpoints: latency-svc-h8ts2 [249.484682ms]
    Apr 26 12:03:32.032: INFO: Created: latency-svc-xmfxb
    Apr 26 12:03:32.042: INFO: Got endpoints: latency-svc-xmfxb [237.866931ms]
    Apr 26 12:03:32.049: INFO: Created: latency-svc-z8fnl
    Apr 26 12:03:32.061: INFO: Got endpoints: latency-svc-z8fnl [238.475233ms]
    Apr 26 12:03:32.067: INFO: Created: latency-svc-9wqwx
    Apr 26 12:03:32.071: INFO: Got endpoints: latency-svc-9wqwx [227.826122ms]
    Apr 26 12:03:32.082: INFO: Created: latency-svc-8j6rg
    Apr 26 12:03:32.088: INFO: Got endpoints: latency-svc-8j6rg [237.806398ms]
    Apr 26 12:03:32.104: INFO: Created: latency-svc-lqzxk
    Apr 26 12:03:32.110: INFO: Got endpoints: latency-svc-lqzxk [249.291128ms]
    Apr 26 12:03:32.119: INFO: Created: latency-svc-kdctq
    Apr 26 12:03:32.126: INFO: Got endpoints: latency-svc-kdctq [251.871284ms]
    Apr 26 12:03:32.150: INFO: Created: latency-svc-2x5pg
    Apr 26 12:03:32.157: INFO: Got endpoints: latency-svc-2x5pg [241.82173ms]
    Apr 26 12:03:32.169: INFO: Created: latency-svc-d9slg
    Apr 26 12:03:32.171: INFO: Got endpoints: latency-svc-d9slg [244.814812ms]
    Apr 26 12:03:32.177: INFO: Created: latency-svc-blk7v
    Apr 26 12:03:32.186: INFO: Got endpoints: latency-svc-blk7v [243.389783ms]
    Apr 26 12:03:32.190: INFO: Created: latency-svc-rcfd4
    Apr 26 12:03:32.202: INFO: Got endpoints: latency-svc-rcfd4 [239.673595ms]
    Apr 26 12:03:32.212: INFO: Created: latency-svc-4f2nf
    Apr 26 12:03:32.219: INFO: Got endpoints: latency-svc-4f2nf [241.438538ms]
    Apr 26 12:03:32.225: INFO: Created: latency-svc-bvlxw
    Apr 26 12:03:32.234: INFO: Got endpoints: latency-svc-bvlxw [243.361489ms]
    Apr 26 12:03:32.240: INFO: Created: latency-svc-vcnr2
    Apr 26 12:03:32.245: INFO: Got endpoints: latency-svc-vcnr2 [230.85984ms]
    Apr 26 12:03:32.251: INFO: Created: latency-svc-5f6z5
    Apr 26 12:03:32.261: INFO: Got endpoints: latency-svc-5f6z5 [232.240855ms]
    Apr 26 12:03:32.268: INFO: Created: latency-svc-kc9vm
    Apr 26 12:03:32.279: INFO: Got endpoints: latency-svc-kc9vm [237.519237ms]
    Apr 26 12:03:32.290: INFO: Created: latency-svc-zwmfd
    Apr 26 12:03:32.309: INFO: Created: latency-svc-9vb5t
    Apr 26 12:03:32.324: INFO: Got endpoints: latency-svc-zwmfd [263.199332ms]
    Apr 26 12:03:32.327: INFO: Created: latency-svc-dgxsm
    Apr 26 12:03:32.340: INFO: Created: latency-svc-4z4b2
    Apr 26 12:03:32.341: INFO: Created: latency-svc-24fj5
    Apr 26 12:03:32.351: INFO: Created: latency-svc-5n9zp
    Apr 26 12:03:32.368: INFO: Created: latency-svc-ssb6d
    Apr 26 12:03:32.377: INFO: Got endpoints: latency-svc-9vb5t [305.855817ms]
    Apr 26 12:03:32.388: INFO: Created: latency-svc-5jwgs
    Apr 26 12:03:32.407: INFO: Created: latency-svc-v4hq9
    Apr 26 12:03:32.417: INFO: Got endpoints: latency-svc-dgxsm [328.678523ms]
    Apr 26 12:03:32.421: INFO: Created: latency-svc-4rphg
    Apr 26 12:03:32.439: INFO: Created: latency-svc-8k66n
    Apr 26 12:03:32.461: INFO: Created: latency-svc-vnqnv
    Apr 26 12:03:32.467: INFO: Got endpoints: latency-svc-24fj5 [357.52923ms]
    Apr 26 12:03:32.468: INFO: Created: latency-svc-jhfvg
    Apr 26 12:03:32.486: INFO: Created: latency-svc-xdjqj
    Apr 26 12:03:32.508: INFO: Created: latency-svc-ljwrz
    Apr 26 12:03:32.517: INFO: Created: latency-svc-tht54
    Apr 26 12:03:32.557: INFO: Got endpoints: latency-svc-4z4b2 [657.324416ms]
    Apr 26 12:03:32.566: INFO: Created: latency-svc-79lnc
    Apr 26 12:03:32.575: INFO: Got endpoints: latency-svc-5n9zp [448.383534ms]
    Apr 26 12:03:32.583: INFO: Created: latency-svc-r5bc8
    Apr 26 12:03:32.602: INFO: Created: latency-svc-cfhkr
    Apr 26 12:03:32.611: INFO: Created: latency-svc-m4txl
    Apr 26 12:03:32.622: INFO: Got endpoints: latency-svc-ssb6d [464.816136ms]
    Apr 26 12:03:32.628: INFO: Created: latency-svc-9bwmf
    Apr 26 12:03:32.652: INFO: Created: latency-svc-26skx
    Apr 26 12:03:32.666: INFO: Got endpoints: latency-svc-5jwgs [495.494155ms]
    Apr 26 12:03:32.688: INFO: Created: latency-svc-wxcdn
    Apr 26 12:03:32.718: INFO: Got endpoints: latency-svc-v4hq9 [531.726016ms]
    Apr 26 12:03:32.742: INFO: Created: latency-svc-mqgnm
    Apr 26 12:03:32.770: INFO: Got endpoints: latency-svc-4rphg [567.924192ms]
    Apr 26 12:03:32.790: INFO: Created: latency-svc-5bhvv
    Apr 26 12:03:32.817: INFO: Got endpoints: latency-svc-8k66n [598.498028ms]
    Apr 26 12:03:32.841: INFO: Created: latency-svc-csqn5
    Apr 26 12:03:32.879: INFO: Got endpoints: latency-svc-vnqnv [645.146191ms]
    Apr 26 12:03:32.899: INFO: Created: latency-svc-c28dr
    Apr 26 12:03:32.916: INFO: Got endpoints: latency-svc-jhfvg [671.584879ms]
    Apr 26 12:03:32.941: INFO: Created: latency-svc-jhrxw
    Apr 26 12:03:32.972: INFO: Got endpoints: latency-svc-xdjqj [711.929063ms]
    Apr 26 12:03:32.995: INFO: Created: latency-svc-vzjwn
    Apr 26 12:03:33.017: INFO: Got endpoints: latency-svc-ljwrz [737.35737ms]
    Apr 26 12:03:33.045: INFO: Created: latency-svc-trglh
    Apr 26 12:03:33.071: INFO: Got endpoints: latency-svc-tht54 [746.379257ms]
    Apr 26 12:03:33.102: INFO: Created: latency-svc-ch92t
    Apr 26 12:03:33.121: INFO: Got endpoints: latency-svc-79lnc [743.688253ms]
    Apr 26 12:03:33.143: INFO: Created: latency-svc-vwlzk
    Apr 26 12:03:33.168: INFO: Got endpoints: latency-svc-r5bc8 [750.873528ms]
    Apr 26 12:03:33.191: INFO: Created: latency-svc-nstcz
    Apr 26 12:03:33.218: INFO: Got endpoints: latency-svc-cfhkr [750.615684ms]
    Apr 26 12:03:33.244: INFO: Created: latency-svc-chdsj
    Apr 26 12:03:33.272: INFO: Got endpoints: latency-svc-m4txl [715.114405ms]
    Apr 26 12:03:33.293: INFO: Created: latency-svc-s2xj4
    Apr 26 12:03:33.319: INFO: Got endpoints: latency-svc-9bwmf [744.302215ms]
    Apr 26 12:03:33.339: INFO: Created: latency-svc-kznr6
    Apr 26 12:03:33.371: INFO: Got endpoints: latency-svc-26skx [749.060152ms]
    Apr 26 12:03:33.400: INFO: Created: latency-svc-n8dxh
    Apr 26 12:03:33.422: INFO: Got endpoints: latency-svc-wxcdn [755.086202ms]
    Apr 26 12:03:33.443: INFO: Created: latency-svc-vpkrx
    Apr 26 12:03:33.475: INFO: Got endpoints: latency-svc-mqgnm [756.824334ms]
    Apr 26 12:03:33.499: INFO: Created: latency-svc-gb97d
    Apr 26 12:03:33.520: INFO: Got endpoints: latency-svc-5bhvv [749.678735ms]
    Apr 26 12:03:33.539: INFO: Created: latency-svc-vklr7
    Apr 26 12:03:33.569: INFO: Got endpoints: latency-svc-csqn5 [751.472825ms]
    Apr 26 12:03:33.594: INFO: Created: latency-svc-mg9ff
    Apr 26 12:03:33.621: INFO: Got endpoints: latency-svc-c28dr [741.314616ms]
    Apr 26 12:03:33.641: INFO: Created: latency-svc-hv2hf
    Apr 26 12:03:33.670: INFO: Got endpoints: latency-svc-jhrxw [753.331845ms]
    Apr 26 12:03:33.691: INFO: Created: latency-svc-c7pbr
    Apr 26 12:03:33.718: INFO: Got endpoints: latency-svc-vzjwn [744.951265ms]
    Apr 26 12:03:33.738: INFO: Created: latency-svc-l4w49
    Apr 26 12:03:33.767: INFO: Got endpoints: latency-svc-trglh [750.209261ms]
    Apr 26 12:03:33.790: INFO: Created: latency-svc-psjv5
    Apr 26 12:03:33.820: INFO: Got endpoints: latency-svc-ch92t [748.94678ms]
    Apr 26 12:03:33.840: INFO: Created: latency-svc-42jxw
    Apr 26 12:03:33.870: INFO: Got endpoints: latency-svc-vwlzk [748.885905ms]
    Apr 26 12:03:33.891: INFO: Created: latency-svc-5cmc9
    Apr 26 12:03:33.919: INFO: Got endpoints: latency-svc-nstcz [751.435684ms]
    Apr 26 12:03:33.943: INFO: Created: latency-svc-x82cl
    Apr 26 12:03:33.967: INFO: Got endpoints: latency-svc-chdsj [748.982756ms]
    Apr 26 12:03:33.987: INFO: Created: latency-svc-z5wwj
    Apr 26 12:03:34.020: INFO: Got endpoints: latency-svc-s2xj4 [747.863505ms]
    Apr 26 12:03:34.042: INFO: Created: latency-svc-92rm8
    Apr 26 12:03:34.074: INFO: Got endpoints: latency-svc-kznr6 [755.303749ms]
    Apr 26 12:03:34.096: INFO: Created: latency-svc-77qg2
    Apr 26 12:03:34.118: INFO: Got endpoints: latency-svc-n8dxh [747.654605ms]
    Apr 26 12:03:34.145: INFO: Created: latency-svc-sxt82
    Apr 26 12:03:34.177: INFO: Got endpoints: latency-svc-vpkrx [754.850939ms]
    Apr 26 12:03:34.198: INFO: Created: latency-svc-zmctx
    Apr 26 12:03:34.219: INFO: Got endpoints: latency-svc-gb97d [744.583296ms]
    Apr 26 12:03:34.242: INFO: Created: latency-svc-cm75g
    Apr 26 12:03:34.270: INFO: Got endpoints: latency-svc-vklr7 [749.370176ms]
    Apr 26 12:03:34.289: INFO: Created: latency-svc-zhfmr
    Apr 26 12:03:34.324: INFO: Got endpoints: latency-svc-mg9ff [755.590499ms]
    Apr 26 12:03:34.348: INFO: Created: latency-svc-wts4s
    Apr 26 12:03:34.368: INFO: Got endpoints: latency-svc-hv2hf [747.299577ms]
    Apr 26 12:03:34.410: INFO: Created: latency-svc-b59vm
    Apr 26 12:03:34.417: INFO: Got endpoints: latency-svc-c7pbr [746.597207ms]
    Apr 26 12:03:34.435: INFO: Created: latency-svc-5jtsh
    Apr 26 12:03:34.467: INFO: Got endpoints: latency-svc-l4w49 [749.508004ms]
    Apr 26 12:03:34.489: INFO: Created: latency-svc-s7wln
    Apr 26 12:03:34.518: INFO: Got endpoints: latency-svc-psjv5 [750.919967ms]
    Apr 26 12:03:34.542: INFO: Created: latency-svc-zzbz6
    Apr 26 12:03:34.567: INFO: Got endpoints: latency-svc-42jxw [747.166457ms]
    Apr 26 12:03:34.587: INFO: Created: latency-svc-crmtm
    Apr 26 12:03:34.621: INFO: Got endpoints: latency-svc-5cmc9 [751.16686ms]
    Apr 26 12:03:34.643: INFO: Created: latency-svc-dd5p6
    Apr 26 12:03:34.668: INFO: Got endpoints: latency-svc-x82cl [748.293744ms]
    Apr 26 12:03:34.703: INFO: Created: latency-svc-srgbc
    Apr 26 12:03:34.757: INFO: Got endpoints: latency-svc-z5wwj [790.364894ms]
    Apr 26 12:03:34.773: INFO: Got endpoints: latency-svc-92rm8 [753.623955ms]
    Apr 26 12:03:34.817: INFO: Created: latency-svc-f6r9l
    Apr 26 12:03:34.827: INFO: Got endpoints: latency-svc-77qg2 [752.974935ms]
    Apr 26 12:03:34.904: INFO: Got endpoints: latency-svc-sxt82 [785.811821ms]
    Apr 26 12:03:34.914: INFO: Created: latency-svc-6dj5p
    Apr 26 12:03:34.933: INFO: Got endpoints: latency-svc-zmctx [756.623387ms]
    Apr 26 12:03:34.963: INFO: Created: latency-svc-fqzmc
    Apr 26 12:03:34.990: INFO: Got endpoints: latency-svc-cm75g [770.853906ms]
    Apr 26 12:03:35.076: INFO: Got endpoints: latency-svc-zhfmr [806.519564ms]
    Apr 26 12:03:35.079: INFO: Got endpoints: latency-svc-wts4s [754.072708ms]
    Apr 26 12:03:35.081: INFO: Created: latency-svc-sqqkw
    Apr 26 12:03:35.107: INFO: Created: latency-svc-m9pbn
    Apr 26 12:03:35.139: INFO: Created: latency-svc-gzcps
    Apr 26 12:03:35.141: INFO: Got endpoints: latency-svc-b59vm [772.349345ms]
    Apr 26 12:03:35.232: INFO: Got endpoints: latency-svc-5jtsh [815.830351ms]
    Apr 26 12:03:35.233: INFO: Created: latency-svc-gpjzn
    Apr 26 12:03:35.238: INFO: Got endpoints: latency-svc-s7wln [770.612283ms]
    Apr 26 12:03:35.249: INFO: Created: latency-svc-dpckt
    Apr 26 12:03:35.269: INFO: Created: latency-svc-mlg5k
    Apr 26 12:03:35.277: INFO: Got endpoints: latency-svc-zzbz6 [758.804084ms]
    Apr 26 12:03:35.280: INFO: Created: latency-svc-lx7n6
    Apr 26 12:03:35.296: INFO: Created: latency-svc-vfzzh
    Apr 26 12:03:35.312: INFO: Created: latency-svc-xr559
    Apr 26 12:03:35.321: INFO: Got endpoints: latency-svc-crmtm [754.51072ms]
    Apr 26 12:03:35.345: INFO: Created: latency-svc-wr2qp
    Apr 26 12:03:35.367: INFO: Got endpoints: latency-svc-dd5p6 [746.148895ms]
    Apr 26 12:03:35.390: INFO: Created: latency-svc-m9dv4
    Apr 26 12:03:35.419: INFO: Got endpoints: latency-svc-srgbc [751.258601ms]
    Apr 26 12:03:35.463: INFO: Created: latency-svc-25mdg
    Apr 26 12:03:35.467: INFO: Got endpoints: latency-svc-f6r9l [709.506693ms]
    Apr 26 12:03:35.489: INFO: Created: latency-svc-dww8l
    Apr 26 12:03:35.518: INFO: Got endpoints: latency-svc-6dj5p [744.45836ms]
    Apr 26 12:03:35.537: INFO: Created: latency-svc-6hmhp
    Apr 26 12:03:35.569: INFO: Got endpoints: latency-svc-fqzmc [741.150758ms]
    Apr 26 12:03:35.591: INFO: Created: latency-svc-ftzbt
    Apr 26 12:03:35.620: INFO: Got endpoints: latency-svc-sqqkw [715.536399ms]
    Apr 26 12:03:35.640: INFO: Created: latency-svc-ccdwg
    Apr 26 12:03:35.677: INFO: Got endpoints: latency-svc-m9pbn [743.232477ms]
    Apr 26 12:03:35.697: INFO: Created: latency-svc-v7rf2
    Apr 26 12:03:35.718: INFO: Got endpoints: latency-svc-gzcps [727.489811ms]
    Apr 26 12:03:35.746: INFO: Created: latency-svc-z7t5s
    Apr 26 12:03:35.770: INFO: Got endpoints: latency-svc-gpjzn [693.351542ms]
    Apr 26 12:03:35.790: INFO: Created: latency-svc-7l9dr
    Apr 26 12:03:35.821: INFO: Got endpoints: latency-svc-dpckt [742.2069ms]
    Apr 26 12:03:35.844: INFO: Created: latency-svc-hlcsd
    Apr 26 12:03:35.870: INFO: Got endpoints: latency-svc-mlg5k [729.365874ms]
    Apr 26 12:03:35.893: INFO: Created: latency-svc-sskq2
    Apr 26 12:03:35.918: INFO: Got endpoints: latency-svc-lx7n6 [685.371073ms]
    Apr 26 12:03:35.941: INFO: Created: latency-svc-kj646
    Apr 26 12:03:35.970: INFO: Got endpoints: latency-svc-vfzzh [732.56336ms]
    Apr 26 12:03:35.989: INFO: Created: latency-svc-q6ggb
    Apr 26 12:03:36.021: INFO: Got endpoints: latency-svc-xr559 [744.016723ms]
    Apr 26 12:03:36.044: INFO: Created: latency-svc-xfbrd
    Apr 26 12:03:36.072: INFO: Got endpoints: latency-svc-wr2qp [750.094197ms]
    Apr 26 12:03:36.090: INFO: Created: latency-svc-pw4q2
    Apr 26 12:03:36.117: INFO: Got endpoints: latency-svc-m9dv4 [749.778614ms]
    Apr 26 12:03:36.141: INFO: Created: latency-svc-42w8j
    Apr 26 12:03:36.169: INFO: Got endpoints: latency-svc-25mdg [749.468624ms]
    Apr 26 12:03:36.191: INFO: Created: latency-svc-szwfb
    Apr 26 12:03:36.217: INFO: Got endpoints: latency-svc-dww8l [750.02654ms]
    Apr 26 12:03:36.239: INFO: Created: latency-svc-schb7
    Apr 26 12:03:36.269: INFO: Got endpoints: latency-svc-6hmhp [750.748516ms]
    Apr 26 12:03:36.295: INFO: Created: latency-svc-jccgx
    Apr 26 12:03:36.323: INFO: Got endpoints: latency-svc-ftzbt [754.623885ms]
    Apr 26 12:03:36.353: INFO: Created: latency-svc-n5pq4
    Apr 26 12:03:36.367: INFO: Got endpoints: latency-svc-ccdwg [747.480798ms]
    Apr 26 12:03:36.385: INFO: Created: latency-svc-n9fck
    Apr 26 12:03:36.416: INFO: Got endpoints: latency-svc-v7rf2 [739.832793ms]
    Apr 26 12:03:36.441: INFO: Created: latency-svc-wxvfz
    Apr 26 12:03:36.469: INFO: Got endpoints: latency-svc-z7t5s [750.853543ms]
    Apr 26 12:03:36.489: INFO: Created: latency-svc-pnzx6
    Apr 26 12:03:36.522: INFO: Got endpoints: latency-svc-7l9dr [752.801351ms]
    Apr 26 12:03:36.559: INFO: Created: latency-svc-5hbkf
    Apr 26 12:03:36.572: INFO: Got endpoints: latency-svc-hlcsd [750.703882ms]
    Apr 26 12:03:36.602: INFO: Created: latency-svc-hl4f4
    Apr 26 12:03:36.618: INFO: Got endpoints: latency-svc-sskq2 [747.716351ms]
    Apr 26 12:03:36.642: INFO: Created: latency-svc-nzc68
    Apr 26 12:03:36.676: INFO: Got endpoints: latency-svc-kj646 [758.13549ms]
    Apr 26 12:03:36.694: INFO: Created: latency-svc-fjbj8
    Apr 26 12:03:36.718: INFO: Got endpoints: latency-svc-q6ggb [747.711162ms]
    Apr 26 12:03:36.741: INFO: Created: latency-svc-lcjcp
    Apr 26 12:03:36.769: INFO: Got endpoints: latency-svc-xfbrd [748.178297ms]
    Apr 26 12:03:36.789: INFO: Created: latency-svc-w7fgv
    Apr 26 12:03:36.822: INFO: Got endpoints: latency-svc-pw4q2 [750.357201ms]
    Apr 26 12:03:36.844: INFO: Created: latency-svc-zhlzz
    Apr 26 12:03:36.918: INFO: Got endpoints: latency-svc-42w8j [800.812956ms]
    Apr 26 12:03:36.918: INFO: Got endpoints: latency-svc-szwfb [749.38359ms]
    Apr 26 12:03:36.952: INFO: Created: latency-svc-dpp8s
    Apr 26 12:03:36.980: INFO: Got endpoints: latency-svc-schb7 [763.13478ms]
    Apr 26 12:03:37.018: INFO: Created: latency-svc-nq75v
    Apr 26 12:03:37.034: INFO: Got endpoints: latency-svc-jccgx [765.506815ms]
    Apr 26 12:03:37.044: INFO: Created: latency-svc-24vtn
    Apr 26 12:03:37.057: INFO: Created: latency-svc-vzxnl
    Apr 26 12:03:37.067: INFO: Got endpoints: latency-svc-n5pq4 [743.889472ms]
    Apr 26 12:03:37.095: INFO: Created: latency-svc-nzqjh
    Apr 26 12:03:37.121: INFO: Got endpoints: latency-svc-n9fck [753.865609ms]
    Apr 26 12:03:37.147: INFO: Created: latency-svc-75dts
    Apr 26 12:03:37.169: INFO: Got endpoints: latency-svc-wxvfz [752.852387ms]
    Apr 26 12:03:37.191: INFO: Created: latency-svc-cdnkl
    Apr 26 12:03:37.218: INFO: Got endpoints: latency-svc-pnzx6 [749.209614ms]
    Apr 26 12:03:37.242: INFO: Created: latency-svc-6gvvl
    Apr 26 12:03:37.271: INFO: Got endpoints: latency-svc-5hbkf [748.380978ms]
    Apr 26 12:03:37.294: INFO: Created: latency-svc-48zp4
    Apr 26 12:03:37.322: INFO: Got endpoints: latency-svc-hl4f4 [750.456597ms]
    Apr 26 12:03:37.345: INFO: Created: latency-svc-vzpnf
    Apr 26 12:03:37.367: INFO: Got endpoints: latency-svc-nzc68 [749.405895ms]
    Apr 26 12:03:37.390: INFO: Created: latency-svc-fqqk5
    Apr 26 12:03:37.418: INFO: Got endpoints: latency-svc-fjbj8 [741.58815ms]
    Apr 26 12:03:37.443: INFO: Created: latency-svc-2twph
    Apr 26 12:03:37.469: INFO: Got endpoints: latency-svc-lcjcp [750.882287ms]
    Apr 26 12:03:37.490: INFO: Created: latency-svc-2k5fg
    Apr 26 12:03:37.517: INFO: Got endpoints: latency-svc-w7fgv [748.05619ms]
    Apr 26 12:03:37.539: INFO: Created: latency-svc-s4v27
    Apr 26 12:03:37.569: INFO: Got endpoints: latency-svc-zhlzz [746.891152ms]
    Apr 26 12:03:37.588: INFO: Created: latency-svc-l9mgt
    Apr 26 12:03:37.618: INFO: Got endpoints: latency-svc-dpp8s [700.402067ms]
    Apr 26 12:03:37.639: INFO: Created: latency-svc-7z27f
    Apr 26 12:03:37.666: INFO: Got endpoints: latency-svc-nq75v [748.107236ms]
    Apr 26 12:03:37.690: INFO: Created: latency-svc-49djq
    Apr 26 12:03:37.719: INFO: Got endpoints: latency-svc-24vtn [739.05322ms]
    Apr 26 12:03:37.737: INFO: Created: latency-svc-6tlzq
    Apr 26 12:03:37.768: INFO: Got endpoints: latency-svc-vzxnl [732.976768ms]
    Apr 26 12:03:37.794: INFO: Created: latency-svc-wz69t
    Apr 26 12:03:37.816: INFO: Got endpoints: latency-svc-nzqjh [749.046218ms]
    Apr 26 12:03:37.837: INFO: Created: latency-svc-bb2v2
    Apr 26 12:03:37.871: INFO: Got endpoints: latency-svc-75dts [750.063128ms]
    Apr 26 12:03:37.901: INFO: Created: latency-svc-cf5pm
    Apr 26 12:03:37.921: INFO: Got endpoints: latency-svc-cdnkl [751.77286ms]
    Apr 26 12:03:37.945: INFO: Created: latency-svc-vwfsw
    Apr 26 12:03:37.968: INFO: Got endpoints: latency-svc-6gvvl [749.665622ms]
    Apr 26 12:03:37.991: INFO: Created: latency-svc-tgk9z
    Apr 26 12:03:38.020: INFO: Got endpoints: latency-svc-48zp4 [749.136651ms]
    Apr 26 12:03:38.042: INFO: Created: latency-svc-5s5q2
    Apr 26 12:03:38.068: INFO: Got endpoints: latency-svc-vzpnf [746.050783ms]
    Apr 26 12:03:38.098: INFO: Created: latency-svc-k6pnc
    Apr 26 12:03:38.117: INFO: Got endpoints: latency-svc-fqqk5 [749.209265ms]
    Apr 26 12:03:38.140: INFO: Created: latency-svc-hx54k
    Apr 26 12:03:38.170: INFO: Got endpoints: latency-svc-2twph [751.63953ms]
    Apr 26 12:03:38.192: INFO: Created: latency-svc-nb2vp
    Apr 26 12:03:38.219: INFO: Got endpoints: latency-svc-2k5fg [749.72303ms]
    Apr 26 12:03:38.241: INFO: Created: latency-svc-8l5zw
    Apr 26 12:03:38.272: INFO: Got endpoints: latency-svc-s4v27 [754.675012ms]
    Apr 26 12:03:38.296: INFO: Created: latency-svc-xr2z4
    Apr 26 12:03:38.317: INFO: Got endpoints: latency-svc-l9mgt [748.335645ms]
    Apr 26 12:03:38.338: INFO: Created: latency-svc-bwqc5
    Apr 26 12:03:38.368: INFO: Got endpoints: latency-svc-7z27f [749.484473ms]
    Apr 26 12:03:38.392: INFO: Created: latency-svc-xpbl8
    Apr 26 12:03:38.418: INFO: Got endpoints: latency-svc-49djq [751.470994ms]
    Apr 26 12:03:38.439: INFO: Created: latency-svc-zq6r4
    Apr 26 12:03:38.469: INFO: Got endpoints: latency-svc-6tlzq [750.077928ms]
    Apr 26 12:03:38.490: INFO: Created: latency-svc-cx7kc
    Apr 26 12:03:38.518: INFO: Got endpoints: latency-svc-wz69t [750.765368ms]
    Apr 26 12:03:38.543: INFO: Created: latency-svc-djq4k
    Apr 26 12:03:38.568: INFO: Got endpoints: latency-svc-bb2v2 [751.117432ms]
    Apr 26 12:03:38.589: INFO: Created: latency-svc-5nrsm
    Apr 26 12:03:38.618: INFO: Got endpoints: latency-svc-cf5pm [746.046957ms]
    Apr 26 12:03:38.653: INFO: Created: latency-svc-dkbmt
    Apr 26 12:03:38.668: INFO: Got endpoints: latency-svc-vwfsw [746.625995ms]
    Apr 26 12:03:38.691: INFO: Created: latency-svc-629th
    Apr 26 12:03:38.718: INFO: Got endpoints: latency-svc-tgk9z [750.325202ms]
    Apr 26 12:03:38.742: INFO: Created: latency-svc-gcpwl
    Apr 26 12:03:38.768: INFO: Got endpoints: latency-svc-5s5q2 [748.026997ms]
    Apr 26 12:03:38.789: INFO: Created: latency-svc-sgsfz
    Apr 26 12:03:38.821: INFO: Got endpoints: latency-svc-k6pnc [752.988554ms]
    Apr 26 12:03:38.844: INFO: Created: latency-svc-rr9gz
    Apr 26 12:03:38.873: INFO: Got endpoints: latency-svc-hx54k [756.087676ms]
    Apr 26 12:03:38.893: INFO: Created: latency-svc-nnxxq
    Apr 26 12:03:38.922: INFO: Got endpoints: latency-svc-nb2vp [751.902074ms]
    Apr 26 12:03:38.942: INFO: Created: latency-svc-5f88p
    Apr 26 12:03:38.982: INFO: Got endpoints: latency-svc-8l5zw [762.623943ms]
    Apr 26 12:03:39.007: INFO: Created: latency-svc-bwdjd
    Apr 26 12:03:39.017: INFO: Got endpoints: latency-svc-xr2z4 [744.341726ms]
    Apr 26 12:03:39.041: INFO: Created: latency-svc-z2v4n
    Apr 26 12:03:39.069: INFO: Got endpoints: latency-svc-bwqc5 [751.262603ms]
    Apr 26 12:03:39.091: INFO: Created: latency-svc-dnjbx
    Apr 26 12:03:39.117: INFO: Got endpoints: latency-svc-xpbl8 [748.839191ms]
    Apr 26 12:03:39.136: INFO: Created: latency-svc-l8969
    Apr 26 12:03:39.167: INFO: Got endpoints: latency-svc-zq6r4 [749.674842ms]
    Apr 26 12:03:39.199: INFO: Created: latency-svc-pfkkx
    Apr 26 12:03:39.219: INFO: Got endpoints: latency-svc-cx7kc [749.349951ms]
    Apr 26 12:03:39.238: INFO: Created: latency-svc-dcbgs
    Apr 26 12:03:39.268: INFO: Got endpoints: latency-svc-djq4k [749.71114ms]
    Apr 26 12:03:39.289: INFO: Created: latency-svc-hv56j
    Apr 26 12:03:39.318: INFO: Got endpoints: latency-svc-5nrsm [750.100492ms]
    Apr 26 12:03:39.337: INFO: Created: latency-svc-pbjpx
    Apr 26 12:03:39.369: INFO: Got endpoints: latency-svc-dkbmt [750.690169ms]
    Apr 26 12:03:39.421: INFO: Got endpoints: latency-svc-629th [753.231391ms]
    Apr 26 12:03:39.469: INFO: Got endpoints: latency-svc-gcpwl [750.467791ms]
    Apr 26 12:03:39.522: INFO: Got endpoints: latency-svc-sgsfz [753.266318ms]
    Apr 26 12:03:39.573: INFO: Got endpoints: latency-svc-rr9gz [751.608766ms]
    Apr 26 12:03:39.617: INFO: Got endpoints: latency-svc-nnxxq [744.365431ms]
    Apr 26 12:03:39.669: INFO: Got endpoints: latency-svc-5f88p [747.025146ms]
    Apr 26 12:03:39.722: INFO: Got endpoints: latency-svc-bwdjd [740.467849ms]
    Apr 26 12:03:39.769: INFO: Got endpoints: latency-svc-z2v4n [752.004519ms]
    Apr 26 12:03:39.818: INFO: Got endpoints: latency-svc-dnjbx [748.750267ms]
    Apr 26 12:03:39.869: INFO: Got endpoints: latency-svc-l8969 [751.756142ms]
    Apr 26 12:03:39.918: INFO: Got endpoints: latency-svc-pfkkx [750.265001ms]
    Apr 26 12:03:39.972: INFO: Got endpoints: latency-svc-dcbgs [753.319327ms]
    Apr 26 12:03:40.020: INFO: Got endpoints: latency-svc-hv56j [752.096802ms]
    Apr 26 12:03:40.070: INFO: Got endpoints: latency-svc-pbjpx [752.336251ms]
    Apr 26 12:03:40.070: INFO: Latencies: [34.852449ms 52.157933ms 77.631688ms 87.800867ms 105.297448ms 119.036103ms 133.316103ms 150.494588ms 171.835009ms 198.045347ms 207.104713ms 215.150735ms 227.057387ms 227.826122ms 230.85984ms 232.240855ms 237.519237ms 237.806398ms 237.866931ms 238.475233ms 239.673595ms 241.438538ms 241.82173ms 243.361489ms 243.389783ms 244.814812ms 246.583652ms 249.291128ms 249.484682ms 251.170969ms 251.871284ms 251.924042ms 252.640878ms 254.681702ms 254.753467ms 257.655347ms 257.664063ms 260.635544ms 262.05466ms 263.199332ms 263.40745ms 268.7158ms 269.625971ms 273.472034ms 285.783818ms 305.855817ms 328.678523ms 357.52923ms 448.383534ms 464.816136ms 495.494155ms 531.726016ms 567.924192ms 598.498028ms 645.146191ms 657.324416ms 671.584879ms 685.371073ms 693.351542ms 700.402067ms 709.506693ms 711.929063ms 715.114405ms 715.536399ms 727.489811ms 729.365874ms 732.56336ms 732.976768ms 737.35737ms 739.05322ms 739.832793ms 740.467849ms 741.150758ms 741.314616ms 741.58815ms 742.2069ms 743.232477ms 743.688253ms 743.889472ms 744.016723ms 744.302215ms 744.341726ms 744.365431ms 744.45836ms 744.583296ms 744.951265ms 746.046957ms 746.050783ms 746.148895ms 746.379257ms 746.597207ms 746.625995ms 746.891152ms 747.025146ms 747.166457ms 747.299577ms 747.480798ms 747.654605ms 747.711162ms 747.716351ms 747.863505ms 748.026997ms 748.05619ms 748.107236ms 748.178297ms 748.293744ms 748.335645ms 748.380978ms 748.750267ms 748.839191ms 748.885905ms 748.94678ms 748.982756ms 749.046218ms 749.060152ms 749.136651ms 749.209265ms 749.209614ms 749.349951ms 749.370176ms 749.38359ms 749.405895ms 749.468624ms 749.484473ms 749.508004ms 749.665622ms 749.674842ms 749.678735ms 749.71114ms 749.72303ms 749.778614ms 750.02654ms 750.063128ms 750.077928ms 750.094197ms 750.100492ms 750.209261ms 750.265001ms 750.325202ms 750.357201ms 750.456597ms 750.467791ms 750.615684ms 750.690169ms 750.703882ms 750.748516ms 750.765368ms 750.853543ms 750.873528ms 750.882287ms 750.919967ms 751.117432ms 751.16686ms 751.258601ms 751.262603ms 751.435684ms 751.470994ms 751.472825ms 751.608766ms 751.63953ms 751.756142ms 751.77286ms 751.902074ms 752.004519ms 752.096802ms 752.336251ms 752.801351ms 752.852387ms 752.974935ms 752.988554ms 753.231391ms 753.266318ms 753.319327ms 753.331845ms 753.623955ms 753.865609ms 754.072708ms 754.51072ms 754.623885ms 754.675012ms 754.850939ms 755.086202ms 755.303749ms 755.590499ms 756.087676ms 756.623387ms 756.824334ms 758.13549ms 758.804084ms 762.623943ms 763.13478ms 765.506815ms 770.612283ms 770.853906ms 772.349345ms 785.811821ms 790.364894ms 800.812956ms 806.519564ms 815.830351ms]
    Apr 26 12:03:40.070: INFO: 50 %ile: 747.863505ms
    Apr 26 12:03:40.070: INFO: 90 %ile: 754.850939ms
    Apr 26 12:03:40.070: INFO: 99 %ile: 806.519564ms
    Apr 26 12:03:40.070: INFO: Total sample count: 200
    [AfterEach] [sig-network] Service endpoints latency
      test/e2e/framework/framework.go:187
    Apr 26 12:03:40.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svc-latency-4856" for this suite. 04/26/24 12:03:40.087
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:03:40.094
Apr 26 12:03:40.094: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 12:03:40.095
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:03:40.112
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:03:40.119
[It] works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152
Apr 26 12:03:40.125: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/26/24 12:03:42.371
Apr 26 12:03:42.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-3721 --namespace=crd-publish-openapi-3721 create -f -'
Apr 26 12:03:42.901: INFO: stderr: ""
Apr 26 12:03:42.901: INFO: stdout: "e2e-test-crd-publish-openapi-2581-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 26 12:03:42.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-3721 --namespace=crd-publish-openapi-3721 delete e2e-test-crd-publish-openapi-2581-crds test-cr'
Apr 26 12:03:42.978: INFO: stderr: ""
Apr 26 12:03:42.978: INFO: stdout: "e2e-test-crd-publish-openapi-2581-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr 26 12:03:42.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-3721 --namespace=crd-publish-openapi-3721 apply -f -'
Apr 26 12:03:43.135: INFO: stderr: ""
Apr 26 12:03:43.135: INFO: stdout: "e2e-test-crd-publish-openapi-2581-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 26 12:03:43.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-3721 --namespace=crd-publish-openapi-3721 delete e2e-test-crd-publish-openapi-2581-crds test-cr'
Apr 26 12:03:43.207: INFO: stderr: ""
Apr 26 12:03:43.207: INFO: stdout: "e2e-test-crd-publish-openapi-2581-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema 04/26/24 12:03:43.207
Apr 26 12:03:43.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-3721 explain e2e-test-crd-publish-openapi-2581-crds'
Apr 26 12:03:43.598: INFO: stderr: ""
Apr 26 12:03:43.598: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2581-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:03:45.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3721" for this suite. 04/26/24 12:03:45.911
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]","completed":277,"skipped":5103,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.827 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:152

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:03:40.094
    Apr 26 12:03:40.094: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 12:03:40.095
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:03:40.112
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:03:40.119
    [It] works for CRD without validation schema [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:152
    Apr 26 12:03:40.125: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/26/24 12:03:42.371
    Apr 26 12:03:42.371: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-3721 --namespace=crd-publish-openapi-3721 create -f -'
    Apr 26 12:03:42.901: INFO: stderr: ""
    Apr 26 12:03:42.901: INFO: stdout: "e2e-test-crd-publish-openapi-2581-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Apr 26 12:03:42.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-3721 --namespace=crd-publish-openapi-3721 delete e2e-test-crd-publish-openapi-2581-crds test-cr'
    Apr 26 12:03:42.978: INFO: stderr: ""
    Apr 26 12:03:42.978: INFO: stdout: "e2e-test-crd-publish-openapi-2581-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    Apr 26 12:03:42.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-3721 --namespace=crd-publish-openapi-3721 apply -f -'
    Apr 26 12:03:43.135: INFO: stderr: ""
    Apr 26 12:03:43.135: INFO: stdout: "e2e-test-crd-publish-openapi-2581-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
    Apr 26 12:03:43.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-3721 --namespace=crd-publish-openapi-3721 delete e2e-test-crd-publish-openapi-2581-crds test-cr'
    Apr 26 12:03:43.207: INFO: stderr: ""
    Apr 26 12:03:43.207: INFO: stdout: "e2e-test-crd-publish-openapi-2581-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR without validation schema 04/26/24 12:03:43.207
    Apr 26 12:03:43.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-3721 explain e2e-test-crd-publish-openapi-2581-crds'
    Apr 26 12:03:43.598: INFO: stderr: ""
    Apr 26 12:03:43.598: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-2581-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:03:45.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-3721" for this suite. 04/26/24 12:03:45.911
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Probing container
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:03:45.922
Apr 26 12:03:45.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-probe 04/26/24 12:03:45.923
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:03:45.943
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:03:45.951
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211
STEP: Creating pod test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9 in namespace container-probe-750 04/26/24 12:03:45.956
Apr 26 12:03:45.976: INFO: Waiting up to 5m0s for pod "test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9" in namespace "container-probe-750" to be "not pending"
Apr 26 12:03:45.999: INFO: Pod "test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.778974ms
Apr 26 12:03:48.007: INFO: Pod "test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9": Phase="Running", Reason="", readiness=true. Elapsed: 2.031047351s
Apr 26 12:03:48.007: INFO: Pod "test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9" satisfied condition "not pending"
Apr 26 12:03:48.007: INFO: Started pod test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9 in namespace container-probe-750
STEP: checking the pod's current state and verifying that restartCount is present 04/26/24 12:03:48.007
Apr 26 12:03:48.012: INFO: Initial restart count of pod test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9 is 0
STEP: deleting the pod 04/26/24 12:07:48.936
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 26 12:07:48.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-750" for this suite. 04/26/24 12:07:48.96
{"msg":"PASSED [sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]","completed":278,"skipped":5112,"failed":0}
------------------------------
â€¢ [SLOW TEST] [243.045 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:211

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:03:45.922
    Apr 26 12:03:45.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-probe 04/26/24 12:03:45.923
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:03:45.943
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:03:45.951
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:211
    STEP: Creating pod test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9 in namespace container-probe-750 04/26/24 12:03:45.956
    Apr 26 12:03:45.976: INFO: Waiting up to 5m0s for pod "test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9" in namespace "container-probe-750" to be "not pending"
    Apr 26 12:03:45.999: INFO: Pod "test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.778974ms
    Apr 26 12:03:48.007: INFO: Pod "test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9": Phase="Running", Reason="", readiness=true. Elapsed: 2.031047351s
    Apr 26 12:03:48.007: INFO: Pod "test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9" satisfied condition "not pending"
    Apr 26 12:03:48.007: INFO: Started pod test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9 in namespace container-probe-750
    STEP: checking the pod's current state and verifying that restartCount is present 04/26/24 12:03:48.007
    Apr 26 12:03:48.012: INFO: Initial restart count of pod test-webserver-824442a8-d23a-45e7-bba4-0f2f47ce3cf9 is 0
    STEP: deleting the pod 04/26/24 12:07:48.936
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 26 12:07:48.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-750" for this suite. 04/26/24 12:07:48.96
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:07:48.968
Apr 26 12:07:48.968: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 12:07:48.97
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:07:48.986
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:07:48.992
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220
STEP: Creating a pod to test downward API volume plugin 04/26/24 12:07:48.998
Apr 26 12:07:49.026: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571" in namespace "downward-api-2103" to be "Succeeded or Failed"
Apr 26 12:07:49.030: INFO: Pod "downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571": Phase="Pending", Reason="", readiness=false. Elapsed: 4.578358ms
Apr 26 12:07:51.037: INFO: Pod "downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010944444s
Apr 26 12:07:53.036: INFO: Pod "downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010351933s
STEP: Saw pod success 04/26/24 12:07:53.036
Apr 26 12:07:53.036: INFO: Pod "downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571" satisfied condition "Succeeded or Failed"
Apr 26 12:07:53.041: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571 container client-container: <nil>
STEP: delete the pod 04/26/24 12:07:53.208
Apr 26 12:07:53.242: INFO: Waiting for pod downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571 to disappear
Apr 26 12:07:53.258: INFO: Pod downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571 no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 26 12:07:53.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2103" for this suite. 04/26/24 12:07:53.269
{"msg":"PASSED [sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]","completed":279,"skipped":5129,"failed":0}
------------------------------
â€¢ [4.308 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should provide container's cpu request [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:220

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:07:48.968
    Apr 26 12:07:48.968: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 12:07:48.97
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:07:48.986
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:07:48.992
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should provide container's cpu request [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:220
    STEP: Creating a pod to test downward API volume plugin 04/26/24 12:07:48.998
    Apr 26 12:07:49.026: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571" in namespace "downward-api-2103" to be "Succeeded or Failed"
    Apr 26 12:07:49.030: INFO: Pod "downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571": Phase="Pending", Reason="", readiness=false. Elapsed: 4.578358ms
    Apr 26 12:07:51.037: INFO: Pod "downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010944444s
    Apr 26 12:07:53.036: INFO: Pod "downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010351933s
    STEP: Saw pod success 04/26/24 12:07:53.036
    Apr 26 12:07:53.036: INFO: Pod "downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571" satisfied condition "Succeeded or Failed"
    Apr 26 12:07:53.041: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571 container client-container: <nil>
    STEP: delete the pod 04/26/24 12:07:53.208
    Apr 26 12:07:53.242: INFO: Waiting for pod downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571 to disappear
    Apr 26 12:07:53.258: INFO: Pod downwardapi-volume-0e82619e-a956-4a96-b064-8ab3260e9571 no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 26 12:07:53.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-2103" for this suite. 04/26/24 12:07:53.269
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-apps] CronJob
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:07:53.277
Apr 26 12:07:53.277: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename cronjob 04/26/24 12:07:53.278
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:07:53.299
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:07:53.304
[It] should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319
STEP: Creating a cronjob 04/26/24 12:07:53.309
STEP: creating 04/26/24 12:07:53.309
STEP: getting 04/26/24 12:07:53.317
STEP: listing 04/26/24 12:07:53.332
STEP: watching 04/26/24 12:07:53.337
Apr 26 12:07:53.337: INFO: starting watch
STEP: cluster-wide listing 04/26/24 12:07:53.34
STEP: cluster-wide watching 04/26/24 12:07:53.344
Apr 26 12:07:53.344: INFO: starting watch
STEP: patching 04/26/24 12:07:53.346
STEP: updating 04/26/24 12:07:53.354
Apr 26 12:07:53.391: INFO: waiting for watch events with expected annotations
Apr 26 12:07:53.391: INFO: saw patched and updated annotations
STEP: patching /status 04/26/24 12:07:53.391
STEP: updating /status 04/26/24 12:07:53.415
STEP: get /status 04/26/24 12:07:53.426
STEP: deleting 04/26/24 12:07:53.431
STEP: deleting a collection 04/26/24 12:07:53.455
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 26 12:07:53.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9981" for this suite. 04/26/24 12:07:53.483
{"msg":"PASSED [sig-apps] CronJob should support CronJob API operations [Conformance]","completed":280,"skipped":5135,"failed":0}
------------------------------
â€¢ [0.213 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should support CronJob API operations [Conformance]
  test/e2e/apps/cronjob.go:319

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:07:53.277
    Apr 26 12:07:53.277: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename cronjob 04/26/24 12:07:53.278
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:07:53.299
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:07:53.304
    [It] should support CronJob API operations [Conformance]
      test/e2e/apps/cronjob.go:319
    STEP: Creating a cronjob 04/26/24 12:07:53.309
    STEP: creating 04/26/24 12:07:53.309
    STEP: getting 04/26/24 12:07:53.317
    STEP: listing 04/26/24 12:07:53.332
    STEP: watching 04/26/24 12:07:53.337
    Apr 26 12:07:53.337: INFO: starting watch
    STEP: cluster-wide listing 04/26/24 12:07:53.34
    STEP: cluster-wide watching 04/26/24 12:07:53.344
    Apr 26 12:07:53.344: INFO: starting watch
    STEP: patching 04/26/24 12:07:53.346
    STEP: updating 04/26/24 12:07:53.354
    Apr 26 12:07:53.391: INFO: waiting for watch events with expected annotations
    Apr 26 12:07:53.391: INFO: saw patched and updated annotations
    STEP: patching /status 04/26/24 12:07:53.391
    STEP: updating /status 04/26/24 12:07:53.415
    STEP: get /status 04/26/24 12:07:53.426
    STEP: deleting 04/26/24 12:07:53.431
    STEP: deleting a collection 04/26/24 12:07:53.455
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 26 12:07:53.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9981" for this suite. 04/26/24 12:07:53.483
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:07:53.492
Apr 26 12:07:53.492: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename svcaccounts 04/26/24 12:07:53.493
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:07:53.54
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:07:53.546
[It] should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646
STEP: creating a ServiceAccount 04/26/24 12:07:53.552
STEP: watching for the ServiceAccount to be added 04/26/24 12:07:53.563
STEP: patching the ServiceAccount 04/26/24 12:07:53.566
STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 04/26/24 12:07:53.574
STEP: deleting the ServiceAccount 04/26/24 12:07:53.601
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 26 12:07:53.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2459" for this suite. 04/26/24 12:07:53.669
{"msg":"PASSED [sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]","completed":281,"skipped":5142,"failed":0}
------------------------------
â€¢ [0.184 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should run through the lifecycle of a ServiceAccount [Conformance]
  test/e2e/auth/service_accounts.go:646

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:07:53.492
    Apr 26 12:07:53.492: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename svcaccounts 04/26/24 12:07:53.493
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:07:53.54
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:07:53.546
    [It] should run through the lifecycle of a ServiceAccount [Conformance]
      test/e2e/auth/service_accounts.go:646
    STEP: creating a ServiceAccount 04/26/24 12:07:53.552
    STEP: watching for the ServiceAccount to be added 04/26/24 12:07:53.563
    STEP: patching the ServiceAccount 04/26/24 12:07:53.566
    STEP: finding ServiceAccount in list of all ServiceAccounts (by LabelSelector) 04/26/24 12:07:53.574
    STEP: deleting the ServiceAccount 04/26/24 12:07:53.601
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 26 12:07:53.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-2459" for this suite. 04/26/24 12:07:53.669
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:07:53.677
Apr 26 12:07:53.677: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 12:07:53.678
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:07:53.69
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:07:53.699
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83
STEP: Creating a pod to test downward API volume plugin 04/26/24 12:07:53.705
Apr 26 12:07:53.716: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b" in namespace "downward-api-6024" to be "Succeeded or Failed"
Apr 26 12:07:53.799: INFO: Pod "downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b": Phase="Pending", Reason="", readiness=false. Elapsed: 82.15326ms
Apr 26 12:07:55.809: INFO: Pod "downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b": Phase="Running", Reason="", readiness=false. Elapsed: 2.092172133s
Apr 26 12:07:57.804: INFO: Pod "downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.087540298s
STEP: Saw pod success 04/26/24 12:07:57.804
Apr 26 12:07:57.804: INFO: Pod "downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b" satisfied condition "Succeeded or Failed"
Apr 26 12:07:57.809: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh pod downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b container client-container: <nil>
STEP: delete the pod 04/26/24 12:07:57.976
Apr 26 12:07:57.992: INFO: Waiting for pod downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b to disappear
Apr 26 12:07:57.996: INFO: Pod downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b no longer exists
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 26 12:07:57.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6024" for this suite. 04/26/24 12:07:58.008
{"msg":"PASSED [sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]","completed":282,"skipped":5147,"failed":0}
------------------------------
â€¢ [4.337 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:83

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:07:53.677
    Apr 26 12:07:53.677: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 12:07:53.678
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:07:53.69
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:07:53.699
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:83
    STEP: Creating a pod to test downward API volume plugin 04/26/24 12:07:53.705
    Apr 26 12:07:53.716: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b" in namespace "downward-api-6024" to be "Succeeded or Failed"
    Apr 26 12:07:53.799: INFO: Pod "downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b": Phase="Pending", Reason="", readiness=false. Elapsed: 82.15326ms
    Apr 26 12:07:55.809: INFO: Pod "downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b": Phase="Running", Reason="", readiness=false. Elapsed: 2.092172133s
    Apr 26 12:07:57.804: INFO: Pod "downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.087540298s
    STEP: Saw pod success 04/26/24 12:07:57.804
    Apr 26 12:07:57.804: INFO: Pod "downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b" satisfied condition "Succeeded or Failed"
    Apr 26 12:07:57.809: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh pod downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b container client-container: <nil>
    STEP: delete the pod 04/26/24 12:07:57.976
    Apr 26 12:07:57.992: INFO: Waiting for pod downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b to disappear
    Apr 26 12:07:57.996: INFO: Pod downwardapi-volume-1e9484af-7a19-4d54-919f-721f4c01412b no longer exists
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 26 12:07:57.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6024" for this suite. 04/26/24 12:07:58.008
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:07:58.015
Apr 26 12:07:58.015: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pod-network-test 04/26/24 12:07:58.016
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:07:58.031
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:07:58.037
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:105
STEP: Performing setup for networking test in namespace pod-network-test-3394 04/26/24 12:07:58.043
STEP: creating a selector 04/26/24 12:07:58.043
STEP: Creating the service pods in kubernetes 04/26/24 12:07:58.044
Apr 26 12:07:58.044: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 26 12:07:58.225: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3394" to be "running and ready"
Apr 26 12:07:58.242: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.299747ms
Apr 26 12:07:58.242: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:08:00.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.023664737s
Apr 26 12:08:00.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 12:08:02.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.023530084s
Apr 26 12:08:02.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 12:08:04.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.023502431s
Apr 26 12:08:04.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 12:08:06.261: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.035205959s
Apr 26 12:08:06.261: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 12:08:08.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.023159501s
Apr 26 12:08:08.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 12:08:10.251: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.025070122s
Apr 26 12:08:10.251: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 26 12:08:10.251: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 26 12:08:10.263: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3394" to be "running and ready"
Apr 26 12:08:10.275: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 11.919882ms
Apr 26 12:08:10.275: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 26 12:08:10.275: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 26 12:08:10.289: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3394" to be "running and ready"
Apr 26 12:08:10.303: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 13.176749ms
Apr 26 12:08:10.303: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 26 12:08:10.303: INFO: Pod "netserver-2" satisfied condition "running and ready"
Apr 26 12:08:10.307: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-3394" to be "running and ready"
Apr 26 12:08:10.312: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 4.806808ms
Apr 26 12:08:10.312: INFO: The phase of Pod netserver-3 is Running (Ready = true)
Apr 26 12:08:10.312: INFO: Pod "netserver-3" satisfied condition "running and ready"
Apr 26 12:08:10.316: INFO: Waiting up to 5m0s for pod "netserver-4" in namespace "pod-network-test-3394" to be "running and ready"
Apr 26 12:08:10.319: INFO: Pod "netserver-4": Phase="Running", Reason="", readiness=true. Elapsed: 3.808342ms
Apr 26 12:08:10.319: INFO: The phase of Pod netserver-4 is Running (Ready = true)
Apr 26 12:08:10.319: INFO: Pod "netserver-4" satisfied condition "running and ready"
STEP: Creating test pods 04/26/24 12:08:10.323
Apr 26 12:08:10.342: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3394" to be "running"
Apr 26 12:08:10.350: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.355036ms
Apr 26 12:08:12.357: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014381356s
Apr 26 12:08:12.357: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 26 12:08:12.361: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-3394" to be "running"
Apr 26 12:08:12.366: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.877579ms
Apr 26 12:08:12.366: INFO: Pod "host-test-container-pod" satisfied condition "running"
Apr 26 12:08:12.370: INFO: Setting MaxTries for pod polling to 55 for networking test based on endpoint count 5
Apr 26 12:08:12.370: INFO: Going to poll 100.96.4.24 on port 8083 at least 0 times, with a maximum of 55 tries before failing
Apr 26 12:08:12.374: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.4.24:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3394 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:08:12.375: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:08:12.376: INFO: ExecWithOptions: Clientset creation
Apr 26 12:08:12.376: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-3394/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.4.24%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 26 12:08:12.819: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 26 12:08:12.819: INFO: Going to poll 100.96.2.96 on port 8083 at least 0 times, with a maximum of 55 tries before failing
Apr 26 12:08:12.826: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.2.96:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3394 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:08:12.826: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:08:12.826: INFO: ExecWithOptions: Clientset creation
Apr 26 12:08:12.826: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-3394/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.2.96%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 26 12:08:13.275: INFO: Found all 1 expected endpoints: [netserver-1]
Apr 26 12:08:13.275: INFO: Going to poll 100.96.3.74 on port 8083 at least 0 times, with a maximum of 55 tries before failing
Apr 26 12:08:13.282: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.3.74:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3394 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:08:13.282: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:08:13.283: INFO: ExecWithOptions: Clientset creation
Apr 26 12:08:13.283: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-3394/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.3.74%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 26 12:08:13.790: INFO: Found all 1 expected endpoints: [netserver-2]
Apr 26 12:08:13.790: INFO: Going to poll 100.96.1.254 on port 8083 at least 0 times, with a maximum of 55 tries before failing
Apr 26 12:08:13.796: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.1.254:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3394 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:08:13.796: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:08:13.797: INFO: ExecWithOptions: Clientset creation
Apr 26 12:08:13.797: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-3394/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.1.254%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 26 12:08:14.315: INFO: Found all 1 expected endpoints: [netserver-3]
Apr 26 12:08:14.315: INFO: Going to poll 100.96.0.90 on port 8083 at least 0 times, with a maximum of 55 tries before failing
Apr 26 12:08:14.322: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.0.90:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3394 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:08:14.322: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:08:14.322: INFO: ExecWithOptions: Clientset creation
Apr 26 12:08:14.323: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-3394/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.0.90%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 26 12:08:14.753: INFO: Found all 1 expected endpoints: [netserver-4]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 26 12:08:14.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3394" for this suite. 04/26/24 12:08:14.769
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]","completed":283,"skipped":5149,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.761 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:07:58.015
    Apr 26 12:07:58.015: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pod-network-test 04/26/24 12:07:58.016
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:07:58.031
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:07:58.037
    [It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:105
    STEP: Performing setup for networking test in namespace pod-network-test-3394 04/26/24 12:07:58.043
    STEP: creating a selector 04/26/24 12:07:58.043
    STEP: Creating the service pods in kubernetes 04/26/24 12:07:58.044
    Apr 26 12:07:58.044: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 26 12:07:58.225: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-3394" to be "running and ready"
    Apr 26 12:07:58.242: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.299747ms
    Apr 26 12:07:58.242: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:08:00.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.023664737s
    Apr 26 12:08:00.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 12:08:02.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.023530084s
    Apr 26 12:08:02.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 12:08:04.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.023502431s
    Apr 26 12:08:04.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 12:08:06.261: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.035205959s
    Apr 26 12:08:06.261: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 12:08:08.249: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.023159501s
    Apr 26 12:08:08.249: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 12:08:10.251: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.025070122s
    Apr 26 12:08:10.251: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 26 12:08:10.251: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 26 12:08:10.263: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-3394" to be "running and ready"
    Apr 26 12:08:10.275: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 11.919882ms
    Apr 26 12:08:10.275: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 26 12:08:10.275: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 26 12:08:10.289: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-3394" to be "running and ready"
    Apr 26 12:08:10.303: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 13.176749ms
    Apr 26 12:08:10.303: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 26 12:08:10.303: INFO: Pod "netserver-2" satisfied condition "running and ready"
    Apr 26 12:08:10.307: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-3394" to be "running and ready"
    Apr 26 12:08:10.312: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 4.806808ms
    Apr 26 12:08:10.312: INFO: The phase of Pod netserver-3 is Running (Ready = true)
    Apr 26 12:08:10.312: INFO: Pod "netserver-3" satisfied condition "running and ready"
    Apr 26 12:08:10.316: INFO: Waiting up to 5m0s for pod "netserver-4" in namespace "pod-network-test-3394" to be "running and ready"
    Apr 26 12:08:10.319: INFO: Pod "netserver-4": Phase="Running", Reason="", readiness=true. Elapsed: 3.808342ms
    Apr 26 12:08:10.319: INFO: The phase of Pod netserver-4 is Running (Ready = true)
    Apr 26 12:08:10.319: INFO: Pod "netserver-4" satisfied condition "running and ready"
    STEP: Creating test pods 04/26/24 12:08:10.323
    Apr 26 12:08:10.342: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-3394" to be "running"
    Apr 26 12:08:10.350: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 7.355036ms
    Apr 26 12:08:12.357: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.014381356s
    Apr 26 12:08:12.357: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 26 12:08:12.361: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-3394" to be "running"
    Apr 26 12:08:12.366: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.877579ms
    Apr 26 12:08:12.366: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Apr 26 12:08:12.370: INFO: Setting MaxTries for pod polling to 55 for networking test based on endpoint count 5
    Apr 26 12:08:12.370: INFO: Going to poll 100.96.4.24 on port 8083 at least 0 times, with a maximum of 55 tries before failing
    Apr 26 12:08:12.374: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.4.24:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3394 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:08:12.375: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:08:12.376: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:08:12.376: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-3394/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.4.24%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 26 12:08:12.819: INFO: Found all 1 expected endpoints: [netserver-0]
    Apr 26 12:08:12.819: INFO: Going to poll 100.96.2.96 on port 8083 at least 0 times, with a maximum of 55 tries before failing
    Apr 26 12:08:12.826: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.2.96:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3394 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:08:12.826: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:08:12.826: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:08:12.826: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-3394/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.2.96%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 26 12:08:13.275: INFO: Found all 1 expected endpoints: [netserver-1]
    Apr 26 12:08:13.275: INFO: Going to poll 100.96.3.74 on port 8083 at least 0 times, with a maximum of 55 tries before failing
    Apr 26 12:08:13.282: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.3.74:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3394 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:08:13.282: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:08:13.283: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:08:13.283: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-3394/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.3.74%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 26 12:08:13.790: INFO: Found all 1 expected endpoints: [netserver-2]
    Apr 26 12:08:13.790: INFO: Going to poll 100.96.1.254 on port 8083 at least 0 times, with a maximum of 55 tries before failing
    Apr 26 12:08:13.796: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.1.254:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3394 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:08:13.796: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:08:13.797: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:08:13.797: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-3394/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.1.254%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 26 12:08:14.315: INFO: Found all 1 expected endpoints: [netserver-3]
    Apr 26 12:08:14.315: INFO: Going to poll 100.96.0.90 on port 8083 at least 0 times, with a maximum of 55 tries before failing
    Apr 26 12:08:14.322: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.96.0.90:8083/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3394 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:08:14.322: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:08:14.322: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:08:14.323: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-3394/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=curl+-g+-q+-s+--max-time+15+--connect-timeout+1+http%3A%2F%2F100.96.0.90%3A8083%2FhostName+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 26 12:08:14.753: INFO: Found all 1 expected endpoints: [netserver-4]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 26 12:08:14.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-3394" for this suite. 04/26/24 12:08:14.769
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-node] Secrets
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:08:14.778
Apr 26 12:08:14.778: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 12:08:14.779
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:14.798
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:14.804
[It] should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94
STEP: creating secret secrets-486/secret-test-9aa3b1aa-a267-4339-a4bb-28d5e0e3bfa5 04/26/24 12:08:14.81
STEP: Creating a pod to test consume secrets 04/26/24 12:08:14.815
Apr 26 12:08:14.833: INFO: Waiting up to 5m0s for pod "pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9" in namespace "secrets-486" to be "Succeeded or Failed"
Apr 26 12:08:14.840: INFO: Pod "pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.462098ms
Apr 26 12:08:16.850: INFO: Pod "pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016006184s
Apr 26 12:08:18.846: INFO: Pod "pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012556554s
STEP: Saw pod success 04/26/24 12:08:18.846
Apr 26 12:08:18.846: INFO: Pod "pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9" satisfied condition "Succeeded or Failed"
Apr 26 12:08:18.851: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9 container env-test: <nil>
STEP: delete the pod 04/26/24 12:08:19.006
Apr 26 12:08:19.023: INFO: Waiting for pod pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9 to disappear
Apr 26 12:08:19.028: INFO: Pod pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9 no longer exists
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 26 12:08:19.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-486" for this suite. 04/26/24 12:08:19.037
{"msg":"PASSED [sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]","completed":284,"skipped":5150,"failed":0}
------------------------------
â€¢ [4.266 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should be consumable via the environment [NodeConformance] [Conformance]
  test/e2e/common/node/secrets.go:94

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:08:14.778
    Apr 26 12:08:14.778: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 12:08:14.779
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:14.798
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:14.804
    [It] should be consumable via the environment [NodeConformance] [Conformance]
      test/e2e/common/node/secrets.go:94
    STEP: creating secret secrets-486/secret-test-9aa3b1aa-a267-4339-a4bb-28d5e0e3bfa5 04/26/24 12:08:14.81
    STEP: Creating a pod to test consume secrets 04/26/24 12:08:14.815
    Apr 26 12:08:14.833: INFO: Waiting up to 5m0s for pod "pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9" in namespace "secrets-486" to be "Succeeded or Failed"
    Apr 26 12:08:14.840: INFO: Pod "pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.462098ms
    Apr 26 12:08:16.850: INFO: Pod "pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016006184s
    Apr 26 12:08:18.846: INFO: Pod "pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012556554s
    STEP: Saw pod success 04/26/24 12:08:18.846
    Apr 26 12:08:18.846: INFO: Pod "pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9" satisfied condition "Succeeded or Failed"
    Apr 26 12:08:18.851: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9 container env-test: <nil>
    STEP: delete the pod 04/26/24 12:08:19.006
    Apr 26 12:08:19.023: INFO: Waiting for pod pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9 to disappear
    Apr 26 12:08:19.028: INFO: Pod pod-configmaps-5c42819c-9189-4831-9c84-2082490f54d9 no longer exists
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 12:08:19.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-486" for this suite. 04/26/24 12:08:19.037
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:08:19.047
Apr 26 12:08:19.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 12:08:19.048
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:19.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:19.078
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394
STEP: creating a Service 04/26/24 12:08:19.086
STEP: watching for the Service to be added 04/26/24 12:08:19.103
Apr 26 12:08:19.107: INFO: Found Service test-service-5b55p in namespace services-3342 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
Apr 26 12:08:19.107: INFO: Service test-service-5b55p created
STEP: Getting /status 04/26/24 12:08:19.107
Apr 26 12:08:19.112: INFO: Service test-service-5b55p has LoadBalancer: {[]}
STEP: patching the ServiceStatus 04/26/24 12:08:19.112
STEP: watching for the Service to be patched 04/26/24 12:08:19.117
Apr 26 12:08:19.120: INFO: observed Service test-service-5b55p in namespace services-3342 with annotations: map[] & LoadBalancer: {[]}
Apr 26 12:08:19.120: INFO: Found Service test-service-5b55p in namespace services-3342 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
Apr 26 12:08:19.120: INFO: Service test-service-5b55p has service status patched
STEP: updating the ServiceStatus 04/26/24 12:08:19.12
Apr 26 12:08:19.128: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
STEP: watching for the Service to be updated 04/26/24 12:08:19.129
Apr 26 12:08:19.131: INFO: Observed Service test-service-5b55p in namespace services-3342 with annotations: map[] & Conditions: {[]}
Apr 26 12:08:19.132: INFO: Observed event: &Service{ObjectMeta:{test-service-5b55p  services-3342  0e99e11f-4cb4-46bd-af4b-dfe0bc7e5700 43926 0 2024-04-26 12:08:19 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-04-26 12:08:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-04-26 12:08:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:100.68.105.245,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[100.68.105.245],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
Apr 26 12:08:19.132: INFO: Found Service test-service-5b55p in namespace services-3342 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
Apr 26 12:08:19.132: INFO: Service test-service-5b55p has service status updated
STEP: patching the service 04/26/24 12:08:19.132
STEP: watching for the Service to be patched 04/26/24 12:08:19.147
Apr 26 12:08:19.150: INFO: observed Service test-service-5b55p in namespace services-3342 with labels: map[test-service-static:true]
Apr 26 12:08:19.150: INFO: observed Service test-service-5b55p in namespace services-3342 with labels: map[test-service-static:true]
Apr 26 12:08:19.150: INFO: observed Service test-service-5b55p in namespace services-3342 with labels: map[test-service-static:true]
Apr 26 12:08:19.150: INFO: Found Service test-service-5b55p in namespace services-3342 with labels: map[test-service:patched test-service-static:true]
Apr 26 12:08:19.150: INFO: Service test-service-5b55p patched
STEP: deleting the service 04/26/24 12:08:19.15
STEP: watching for the Service to be deleted 04/26/24 12:08:19.171
Apr 26 12:08:19.174: INFO: Observed event: ADDED
Apr 26 12:08:19.174: INFO: Observed event: MODIFIED
Apr 26 12:08:19.174: INFO: Observed event: MODIFIED
Apr 26 12:08:19.175: INFO: Observed event: MODIFIED
Apr 26 12:08:19.175: INFO: Found Service test-service-5b55p in namespace services-3342 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
Apr 26 12:08:19.175: INFO: Service test-service-5b55p deleted
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 12:08:19.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3342" for this suite. 04/26/24 12:08:19.184
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should complete a service status lifecycle [Conformance]","completed":285,"skipped":5158,"failed":0}
------------------------------
â€¢ [0.144 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should complete a service status lifecycle [Conformance]
  test/e2e/network/service.go:3394

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:08:19.047
    Apr 26 12:08:19.047: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 12:08:19.048
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:19.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:19.078
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should complete a service status lifecycle [Conformance]
      test/e2e/network/service.go:3394
    STEP: creating a Service 04/26/24 12:08:19.086
    STEP: watching for the Service to be added 04/26/24 12:08:19.103
    Apr 26 12:08:19.107: INFO: Found Service test-service-5b55p in namespace services-3342 with labels: map[test-service-static:true] & ports [{http TCP <nil> 80 {0 80 } 0}]
    Apr 26 12:08:19.107: INFO: Service test-service-5b55p created
    STEP: Getting /status 04/26/24 12:08:19.107
    Apr 26 12:08:19.112: INFO: Service test-service-5b55p has LoadBalancer: {[]}
    STEP: patching the ServiceStatus 04/26/24 12:08:19.112
    STEP: watching for the Service to be patched 04/26/24 12:08:19.117
    Apr 26 12:08:19.120: INFO: observed Service test-service-5b55p in namespace services-3342 with annotations: map[] & LoadBalancer: {[]}
    Apr 26 12:08:19.120: INFO: Found Service test-service-5b55p in namespace services-3342 with annotations: map[patchedstatus:true] & LoadBalancer: {[{203.0.113.1  []}]}
    Apr 26 12:08:19.120: INFO: Service test-service-5b55p has service status patched
    STEP: updating the ServiceStatus 04/26/24 12:08:19.12
    Apr 26 12:08:19.128: INFO: updatedStatus.Conditions: []v1.Condition{v1.Condition{Type:"StatusUpdate", Status:"True", ObservedGeneration:0, LastTransitionTime:time.Date(1, time.January, 1, 0, 0, 0, 0, time.UTC), Reason:"E2E", Message:"Set from e2e test"}}
    STEP: watching for the Service to be updated 04/26/24 12:08:19.129
    Apr 26 12:08:19.131: INFO: Observed Service test-service-5b55p in namespace services-3342 with annotations: map[] & Conditions: {[]}
    Apr 26 12:08:19.132: INFO: Observed event: &Service{ObjectMeta:{test-service-5b55p  services-3342  0e99e11f-4cb4-46bd-af4b-dfe0bc7e5700 43926 0 2024-04-26 12:08:19 +0000 UTC <nil> <nil> map[test-service-static:true] map[patchedstatus:true] [] [] [{e2e.test Update v1 2024-04-26 12:08:19 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:test-service-static":{}}},"f:spec":{"f:internalTrafficPolicy":{},"f:ports":{".":{},"k:{\"port\":80,\"protocol\":\"TCP\"}":{".":{},"f:name":{},"f:port":{},"f:protocol":{},"f:targetPort":{}}},"f:sessionAffinity":{},"f:type":{}}} } {e2e.test Update v1 2024-04-26 12:08:19 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:patchedstatus":{}}},"f:status":{"f:loadBalancer":{"f:ingress":{}}}} status}]},Spec:ServiceSpec{Ports:[]ServicePort{ServicePort{Name:http,Protocol:TCP,Port:80,TargetPort:{0 80 },NodePort:0,AppProtocol:nil,},},Selector:map[string]string{},ClusterIP:100.68.105.245,Type:ClusterIP,ExternalIPs:[],SessionAffinity:None,LoadBalancerIP:,LoadBalancerSourceRanges:[],ExternalName:,ExternalTrafficPolicy:,HealthCheckNodePort:0,PublishNotReadyAddresses:false,SessionAffinityConfig:nil,IPFamilyPolicy:*SingleStack,ClusterIPs:[100.68.105.245],IPFamilies:[IPv4],AllocateLoadBalancerNodePorts:nil,LoadBalancerClass:nil,InternalTrafficPolicy:*Cluster,},Status:ServiceStatus{LoadBalancer:LoadBalancerStatus{Ingress:[]LoadBalancerIngress{LoadBalancerIngress{IP:203.0.113.1,Hostname:,Ports:[]PortStatus{},},},},Conditions:[]Condition{},},}
    Apr 26 12:08:19.132: INFO: Found Service test-service-5b55p in namespace services-3342 with annotations: map[patchedstatus:true] & Conditions: [{StatusUpdate True 0 0001-01-01 00:00:00 +0000 UTC E2E Set from e2e test}]
    Apr 26 12:08:19.132: INFO: Service test-service-5b55p has service status updated
    STEP: patching the service 04/26/24 12:08:19.132
    STEP: watching for the Service to be patched 04/26/24 12:08:19.147
    Apr 26 12:08:19.150: INFO: observed Service test-service-5b55p in namespace services-3342 with labels: map[test-service-static:true]
    Apr 26 12:08:19.150: INFO: observed Service test-service-5b55p in namespace services-3342 with labels: map[test-service-static:true]
    Apr 26 12:08:19.150: INFO: observed Service test-service-5b55p in namespace services-3342 with labels: map[test-service-static:true]
    Apr 26 12:08:19.150: INFO: Found Service test-service-5b55p in namespace services-3342 with labels: map[test-service:patched test-service-static:true]
    Apr 26 12:08:19.150: INFO: Service test-service-5b55p patched
    STEP: deleting the service 04/26/24 12:08:19.15
    STEP: watching for the Service to be deleted 04/26/24 12:08:19.171
    Apr 26 12:08:19.174: INFO: Observed event: ADDED
    Apr 26 12:08:19.174: INFO: Observed event: MODIFIED
    Apr 26 12:08:19.174: INFO: Observed event: MODIFIED
    Apr 26 12:08:19.175: INFO: Observed event: MODIFIED
    Apr 26 12:08:19.175: INFO: Found Service test-service-5b55p in namespace services-3342 with labels: map[test-service:patched test-service-static:true] & annotations: map[patchedstatus:true]
    Apr 26 12:08:19.175: INFO: Service test-service-5b55p deleted
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 12:08:19.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-3342" for this suite. 04/26/24 12:08:19.184
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] PreStop
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
[BeforeEach] [sig-node] PreStop
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:08:19.193
Apr 26 12:08:19.193: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename prestop 04/26/24 12:08:19.194
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:19.205
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:19.21
[BeforeEach] [sig-node] PreStop
  test/e2e/node/pre_stop.go:159
[It] should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168
STEP: Creating server pod server in namespace prestop-6910 04/26/24 12:08:19.214
STEP: Waiting for pods to come up. 04/26/24 12:08:19.232
Apr 26 12:08:19.232: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-6910" to be "running"
Apr 26 12:08:19.241: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 8.369401ms
Apr 26 12:08:21.247: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.015008303s
Apr 26 12:08:21.247: INFO: Pod "server" satisfied condition "running"
STEP: Creating tester pod tester in namespace prestop-6910 04/26/24 12:08:21.254
Apr 26 12:08:21.264: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-6910" to be "running"
Apr 26 12:08:21.268: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 3.883252ms
Apr 26 12:08:23.274: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.010357418s
Apr 26 12:08:23.274: INFO: Pod "tester" satisfied condition "running"
STEP: Deleting pre-stop pod 04/26/24 12:08:23.275
Apr 26 12:08:28.399: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod 04/26/24 12:08:28.399
[AfterEach] [sig-node] PreStop
  test/e2e/framework/framework.go:187
Apr 26 12:08:28.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6910" for this suite. 04/26/24 12:08:28.449
{"msg":"PASSED [sig-node] PreStop should call prestop when killing a pod  [Conformance]","completed":286,"skipped":5218,"failed":0}
------------------------------
â€¢ [SLOW TEST] [9.263 seconds]
[sig-node] PreStop
test/e2e/node/framework.go:23
  should call prestop when killing a pod  [Conformance]
  test/e2e/node/pre_stop.go:168

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] PreStop
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:08:19.193
    Apr 26 12:08:19.193: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename prestop 04/26/24 12:08:19.194
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:19.205
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:19.21
    [BeforeEach] [sig-node] PreStop
      test/e2e/node/pre_stop.go:159
    [It] should call prestop when killing a pod  [Conformance]
      test/e2e/node/pre_stop.go:168
    STEP: Creating server pod server in namespace prestop-6910 04/26/24 12:08:19.214
    STEP: Waiting for pods to come up. 04/26/24 12:08:19.232
    Apr 26 12:08:19.232: INFO: Waiting up to 5m0s for pod "server" in namespace "prestop-6910" to be "running"
    Apr 26 12:08:19.241: INFO: Pod "server": Phase="Pending", Reason="", readiness=false. Elapsed: 8.369401ms
    Apr 26 12:08:21.247: INFO: Pod "server": Phase="Running", Reason="", readiness=true. Elapsed: 2.015008303s
    Apr 26 12:08:21.247: INFO: Pod "server" satisfied condition "running"
    STEP: Creating tester pod tester in namespace prestop-6910 04/26/24 12:08:21.254
    Apr 26 12:08:21.264: INFO: Waiting up to 5m0s for pod "tester" in namespace "prestop-6910" to be "running"
    Apr 26 12:08:21.268: INFO: Pod "tester": Phase="Pending", Reason="", readiness=false. Elapsed: 3.883252ms
    Apr 26 12:08:23.274: INFO: Pod "tester": Phase="Running", Reason="", readiness=true. Elapsed: 2.010357418s
    Apr 26 12:08:23.274: INFO: Pod "tester" satisfied condition "running"
    STEP: Deleting pre-stop pod 04/26/24 12:08:23.275
    Apr 26 12:08:28.399: INFO: Saw: {
    	"Hostname": "server",
    	"Sent": null,
    	"Received": {
    		"prestop": 1
    	},
    	"Errors": null,
    	"Log": [
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
    		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
    	],
    	"StillContactingPeers": true
    }
    STEP: Deleting the server pod 04/26/24 12:08:28.399
    [AfterEach] [sig-node] PreStop
      test/e2e/framework/framework.go:187
    Apr 26 12:08:28.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "prestop-6910" for this suite. 04/26/24 12:08:28.449
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
[BeforeEach] [sig-node] Downward API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:08:28.463
Apr 26 12:08:28.463: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 12:08:28.464
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:28.481
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:28.487
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165
STEP: Creating a pod to test downward api env vars 04/26/24 12:08:28.492
Apr 26 12:08:28.505: INFO: Waiting up to 5m0s for pod "downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5" in namespace "downward-api-6150" to be "Succeeded or Failed"
Apr 26 12:08:28.520: INFO: Pod "downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.297066ms
Apr 26 12:08:30.527: INFO: Pod "downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021722013s
Apr 26 12:08:32.526: INFO: Pod "downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02076183s
STEP: Saw pod success 04/26/24 12:08:32.526
Apr 26 12:08:32.526: INFO: Pod "downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5" satisfied condition "Succeeded or Failed"
Apr 26 12:08:32.533: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh pod downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5 container dapi-container: <nil>
STEP: delete the pod 04/26/24 12:08:32.552
Apr 26 12:08:32.566: INFO: Waiting for pod downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5 to disappear
Apr 26 12:08:32.571: INFO: Pod downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5 no longer exists
[AfterEach] [sig-node] Downward API
  test/e2e/framework/framework.go:187
Apr 26 12:08:32.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6150" for this suite. 04/26/24 12:08:32.583
{"msg":"PASSED [sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]","completed":287,"skipped":5248,"failed":0}
------------------------------
â€¢ [4.128 seconds]
[sig-node] Downward API
test/e2e/common/node/framework.go:23
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  test/e2e/common/node/downwardapi.go:165

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Downward API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:08:28.463
    Apr 26 12:08:28.463: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 12:08:28.464
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:28.481
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:28.487
    [It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
      test/e2e/common/node/downwardapi.go:165
    STEP: Creating a pod to test downward api env vars 04/26/24 12:08:28.492
    Apr 26 12:08:28.505: INFO: Waiting up to 5m0s for pod "downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5" in namespace "downward-api-6150" to be "Succeeded or Failed"
    Apr 26 12:08:28.520: INFO: Pod "downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.297066ms
    Apr 26 12:08:30.527: INFO: Pod "downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021722013s
    Apr 26 12:08:32.526: INFO: Pod "downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.02076183s
    STEP: Saw pod success 04/26/24 12:08:32.526
    Apr 26 12:08:32.526: INFO: Pod "downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5" satisfied condition "Succeeded or Failed"
    Apr 26 12:08:32.533: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh pod downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5 container dapi-container: <nil>
    STEP: delete the pod 04/26/24 12:08:32.552
    Apr 26 12:08:32.566: INFO: Waiting for pod downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5 to disappear
    Apr 26 12:08:32.571: INFO: Pod downward-api-b75c8f67-5e37-4df7-805a-9cad8f903fb5 no longer exists
    [AfterEach] [sig-node] Downward API
      test/e2e/framework/framework.go:187
    Apr 26 12:08:32.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-6150" for this suite. 04/26/24 12:08:32.583
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Ingress API
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
[BeforeEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:08:32.592
Apr 26 12:08:32.592: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename ingress 04/26/24 12:08:32.593
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:32.607
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:32.613
[It] should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552
STEP: getting /apis 04/26/24 12:08:32.618
STEP: getting /apis/networking.k8s.io 04/26/24 12:08:32.622
STEP: getting /apis/networking.k8s.iov1 04/26/24 12:08:32.624
STEP: creating 04/26/24 12:08:32.627
STEP: getting 04/26/24 12:08:32.645
STEP: listing 04/26/24 12:08:32.652
STEP: watching 04/26/24 12:08:32.658
Apr 26 12:08:32.658: INFO: starting watch
STEP: cluster-wide listing 04/26/24 12:08:32.661
STEP: cluster-wide watching 04/26/24 12:08:32.666
Apr 26 12:08:32.666: INFO: starting watch
STEP: patching 04/26/24 12:08:32.669
STEP: updating 04/26/24 12:08:32.677
Apr 26 12:08:32.688: INFO: waiting for watch events with expected annotations
Apr 26 12:08:32.688: INFO: saw patched and updated annotations
STEP: patching /status 04/26/24 12:08:32.688
STEP: updating /status 04/26/24 12:08:32.693
STEP: get /status 04/26/24 12:08:32.704
STEP: deleting 04/26/24 12:08:32.709
STEP: deleting a collection 04/26/24 12:08:32.724
[AfterEach] [sig-network] Ingress API
  test/e2e/framework/framework.go:187
Apr 26 12:08:32.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingress-1424" for this suite. 04/26/24 12:08:32.753
{"msg":"PASSED [sig-network] Ingress API should support creating Ingress API operations [Conformance]","completed":288,"skipped":5251,"failed":0}
------------------------------
â€¢ [0.167 seconds]
[sig-network] Ingress API
test/e2e/network/common/framework.go:23
  should support creating Ingress API operations [Conformance]
  test/e2e/network/ingress.go:552

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:08:32.592
    Apr 26 12:08:32.592: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename ingress 04/26/24 12:08:32.593
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:32.607
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:32.613
    [It] should support creating Ingress API operations [Conformance]
      test/e2e/network/ingress.go:552
    STEP: getting /apis 04/26/24 12:08:32.618
    STEP: getting /apis/networking.k8s.io 04/26/24 12:08:32.622
    STEP: getting /apis/networking.k8s.iov1 04/26/24 12:08:32.624
    STEP: creating 04/26/24 12:08:32.627
    STEP: getting 04/26/24 12:08:32.645
    STEP: listing 04/26/24 12:08:32.652
    STEP: watching 04/26/24 12:08:32.658
    Apr 26 12:08:32.658: INFO: starting watch
    STEP: cluster-wide listing 04/26/24 12:08:32.661
    STEP: cluster-wide watching 04/26/24 12:08:32.666
    Apr 26 12:08:32.666: INFO: starting watch
    STEP: patching 04/26/24 12:08:32.669
    STEP: updating 04/26/24 12:08:32.677
    Apr 26 12:08:32.688: INFO: waiting for watch events with expected annotations
    Apr 26 12:08:32.688: INFO: saw patched and updated annotations
    STEP: patching /status 04/26/24 12:08:32.688
    STEP: updating /status 04/26/24 12:08:32.693
    STEP: get /status 04/26/24 12:08:32.704
    STEP: deleting 04/26/24 12:08:32.709
    STEP: deleting a collection 04/26/24 12:08:32.724
    [AfterEach] [sig-network] Ingress API
      test/e2e/framework/framework.go:187
    Apr 26 12:08:32.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingress-1424" for this suite. 04/26/24 12:08:32.753
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-node] Security Context
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:08:32.76
Apr 26 12:08:32.760: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename security-context 04/26/24 12:08:32.762
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:32.778
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:32.783
[It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132
STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/26/24 12:08:32.789
Apr 26 12:08:32.803: INFO: Waiting up to 5m0s for pod "security-context-7437bb22-9092-4f64-bf1b-250606e64458" in namespace "security-context-7749" to be "Succeeded or Failed"
Apr 26 12:08:32.811: INFO: Pod "security-context-7437bb22-9092-4f64-bf1b-250606e64458": Phase="Pending", Reason="", readiness=false. Elapsed: 7.404762ms
Apr 26 12:08:34.820: INFO: Pod "security-context-7437bb22-9092-4f64-bf1b-250606e64458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016708557s
Apr 26 12:08:36.831: INFO: Pod "security-context-7437bb22-9092-4f64-bf1b-250606e64458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027976929s
STEP: Saw pod success 04/26/24 12:08:36.831
Apr 26 12:08:36.831: INFO: Pod "security-context-7437bb22-9092-4f64-bf1b-250606e64458" satisfied condition "Succeeded or Failed"
Apr 26 12:08:36.851: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod security-context-7437bb22-9092-4f64-bf1b-250606e64458 container test-container: <nil>
STEP: delete the pod 04/26/24 12:08:36.951
Apr 26 12:08:36.967: INFO: Waiting for pod security-context-7437bb22-9092-4f64-bf1b-250606e64458 to disappear
Apr 26 12:08:36.974: INFO: Pod security-context-7437bb22-9092-4f64-bf1b-250606e64458 no longer exists
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 26 12:08:36.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-7749" for this suite. 04/26/24 12:08:36.985
{"msg":"PASSED [sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]","completed":289,"skipped":5258,"failed":0}
------------------------------
â€¢ [4.232 seconds]
[sig-node] Security Context
test/e2e/node/framework.go:23
  should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
  test/e2e/node/security_context.go:132

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:08:32.76
    Apr 26 12:08:32.760: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename security-context 04/26/24 12:08:32.762
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:32.778
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:32.783
    [It] should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]
      test/e2e/node/security_context.go:132
    STEP: Creating a pod to test pod.Spec.SecurityContext.RunAsUser 04/26/24 12:08:32.789
    Apr 26 12:08:32.803: INFO: Waiting up to 5m0s for pod "security-context-7437bb22-9092-4f64-bf1b-250606e64458" in namespace "security-context-7749" to be "Succeeded or Failed"
    Apr 26 12:08:32.811: INFO: Pod "security-context-7437bb22-9092-4f64-bf1b-250606e64458": Phase="Pending", Reason="", readiness=false. Elapsed: 7.404762ms
    Apr 26 12:08:34.820: INFO: Pod "security-context-7437bb22-9092-4f64-bf1b-250606e64458": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016708557s
    Apr 26 12:08:36.831: INFO: Pod "security-context-7437bb22-9092-4f64-bf1b-250606e64458": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027976929s
    STEP: Saw pod success 04/26/24 12:08:36.831
    Apr 26 12:08:36.831: INFO: Pod "security-context-7437bb22-9092-4f64-bf1b-250606e64458" satisfied condition "Succeeded or Failed"
    Apr 26 12:08:36.851: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod security-context-7437bb22-9092-4f64-bf1b-250606e64458 container test-container: <nil>
    STEP: delete the pod 04/26/24 12:08:36.951
    Apr 26 12:08:36.967: INFO: Waiting for pod security-context-7437bb22-9092-4f64-bf1b-250606e64458 to disappear
    Apr 26 12:08:36.974: INFO: Pod security-context-7437bb22-9092-4f64-bf1b-250606e64458 no longer exists
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 26 12:08:36.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-7749" for this suite. 04/26/24 12:08:36.985
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:08:36.998
Apr 26 12:08:36.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir-wrapper 04/26/24 12:08:36.999
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:37.014
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:37.021
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189
STEP: Creating 50 configmaps 04/26/24 12:08:37.026
STEP: Creating RC which spawns configmap-volume pods 04/26/24 12:08:37.287
Apr 26 12:08:37.366: INFO: Pod name wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b: Found 1 pods out of 5
Apr 26 12:08:42.388: INFO: Pod name wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/26/24 12:08:42.388
Apr 26 12:08:42.388: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-4gwx9" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:42.395: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-4gwx9": Phase="Running", Reason="", readiness=true. Elapsed: 6.013656ms
Apr 26 12:08:42.395: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-4gwx9" satisfied condition "running"
Apr 26 12:08:42.395: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-fpzt6" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:42.403: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-fpzt6": Phase="Running", Reason="", readiness=true. Elapsed: 8.079043ms
Apr 26 12:08:42.403: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-fpzt6" satisfied condition "running"
Apr 26 12:08:42.403: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-gt95l" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:42.410: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-gt95l": Phase="Running", Reason="", readiness=true. Elapsed: 7.079555ms
Apr 26 12:08:42.410: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-gt95l" satisfied condition "running"
Apr 26 12:08:42.410: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-j6h9c" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:42.417: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-j6h9c": Phase="Running", Reason="", readiness=true. Elapsed: 6.989508ms
Apr 26 12:08:42.418: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-j6h9c" satisfied condition "running"
Apr 26 12:08:42.418: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-tm5mn" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:42.425: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-tm5mn": Phase="Running", Reason="", readiness=true. Elapsed: 7.03942ms
Apr 26 12:08:42.425: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-tm5mn" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b in namespace emptydir-wrapper-7413, will wait for the garbage collector to delete the pods 04/26/24 12:08:42.425
Apr 26 12:08:42.492: INFO: Deleting ReplicationController wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b took: 10.30919ms
Apr 26 12:08:42.693: INFO: Terminating ReplicationController wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b pods took: 200.471592ms
STEP: Creating RC which spawns configmap-volume pods 04/26/24 12:08:44.007
Apr 26 12:08:44.022: INFO: Pod name wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f: Found 0 pods out of 5
Apr 26 12:08:49.041: INFO: Pod name wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/26/24 12:08:49.041
Apr 26 12:08:49.041: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-577gb" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:49.047: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-577gb": Phase="Running", Reason="", readiness=true. Elapsed: 5.841162ms
Apr 26 12:08:49.047: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-577gb" satisfied condition "running"
Apr 26 12:08:49.047: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-5fxxk" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:49.054: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-5fxxk": Phase="Running", Reason="", readiness=true. Elapsed: 7.183802ms
Apr 26 12:08:49.054: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-5fxxk" satisfied condition "running"
Apr 26 12:08:49.055: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-jkvph" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:49.061: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-jkvph": Phase="Running", Reason="", readiness=true. Elapsed: 6.651136ms
Apr 26 12:08:49.061: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-jkvph" satisfied condition "running"
Apr 26 12:08:49.062: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-prmlv" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:49.069: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-prmlv": Phase="Running", Reason="", readiness=true. Elapsed: 7.175015ms
Apr 26 12:08:49.069: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-prmlv" satisfied condition "running"
Apr 26 12:08:49.069: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-w9htl" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:49.075: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-w9htl": Phase="Running", Reason="", readiness=true. Elapsed: 5.867622ms
Apr 26 12:08:49.075: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-w9htl" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f in namespace emptydir-wrapper-7413, will wait for the garbage collector to delete the pods 04/26/24 12:08:49.075
Apr 26 12:08:49.143: INFO: Deleting ReplicationController wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f took: 10.096243ms
Apr 26 12:08:49.244: INFO: Terminating ReplicationController wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f pods took: 101.167269ms
STEP: Creating RC which spawns configmap-volume pods 04/26/24 12:08:50.862
Apr 26 12:08:50.881: INFO: Pod name wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242: Found 0 pods out of 5
Apr 26 12:08:55.903: INFO: Pod name wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242: Found 5 pods out of 5
STEP: Ensuring each pod is running 04/26/24 12:08:55.903
Apr 26 12:08:55.903: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-cx26n" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:55.910: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-cx26n": Phase="Running", Reason="", readiness=true. Elapsed: 6.941931ms
Apr 26 12:08:55.910: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-cx26n" satisfied condition "running"
Apr 26 12:08:55.910: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-frgj8" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:55.917: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-frgj8": Phase="Running", Reason="", readiness=true. Elapsed: 6.502229ms
Apr 26 12:08:55.917: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-frgj8" satisfied condition "running"
Apr 26 12:08:55.917: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-jt45f" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:55.923: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-jt45f": Phase="Running", Reason="", readiness=true. Elapsed: 5.692646ms
Apr 26 12:08:55.923: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-jt45f" satisfied condition "running"
Apr 26 12:08:55.923: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-lsz9k" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:55.930: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-lsz9k": Phase="Running", Reason="", readiness=true. Elapsed: 6.956688ms
Apr 26 12:08:55.930: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-lsz9k" satisfied condition "running"
Apr 26 12:08:55.930: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-zgmhx" in namespace "emptydir-wrapper-7413" to be "running"
Apr 26 12:08:55.936: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-zgmhx": Phase="Running", Reason="", readiness=true. Elapsed: 5.972128ms
Apr 26 12:08:55.936: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-zgmhx" satisfied condition "running"
STEP: deleting ReplicationController wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242 in namespace emptydir-wrapper-7413, will wait for the garbage collector to delete the pods 04/26/24 12:08:55.936
Apr 26 12:08:56.003: INFO: Deleting ReplicationController wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242 took: 8.369057ms
Apr 26 12:08:56.105: INFO: Terminating ReplicationController wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242 pods took: 101.133668ms
STEP: Cleaning up the configMaps 04/26/24 12:08:57.005
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  test/e2e/framework/framework.go:187
Apr 26 12:08:57.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7413" for this suite. 04/26/24 12:08:57.31
{"msg":"PASSED [sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]","completed":290,"skipped":5283,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.318 seconds]
[sig-storage] EmptyDir wrapper volumes
test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  test/e2e/storage/empty_dir_wrapper.go:189

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:08:36.998
    Apr 26 12:08:36.999: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir-wrapper 04/26/24 12:08:36.999
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:37.014
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:37.021
    [It] should not cause race condition when used for configmaps [Serial] [Conformance]
      test/e2e/storage/empty_dir_wrapper.go:189
    STEP: Creating 50 configmaps 04/26/24 12:08:37.026
    STEP: Creating RC which spawns configmap-volume pods 04/26/24 12:08:37.287
    Apr 26 12:08:37.366: INFO: Pod name wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b: Found 1 pods out of 5
    Apr 26 12:08:42.388: INFO: Pod name wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/26/24 12:08:42.388
    Apr 26 12:08:42.388: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-4gwx9" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:42.395: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-4gwx9": Phase="Running", Reason="", readiness=true. Elapsed: 6.013656ms
    Apr 26 12:08:42.395: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-4gwx9" satisfied condition "running"
    Apr 26 12:08:42.395: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-fpzt6" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:42.403: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-fpzt6": Phase="Running", Reason="", readiness=true. Elapsed: 8.079043ms
    Apr 26 12:08:42.403: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-fpzt6" satisfied condition "running"
    Apr 26 12:08:42.403: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-gt95l" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:42.410: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-gt95l": Phase="Running", Reason="", readiness=true. Elapsed: 7.079555ms
    Apr 26 12:08:42.410: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-gt95l" satisfied condition "running"
    Apr 26 12:08:42.410: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-j6h9c" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:42.417: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-j6h9c": Phase="Running", Reason="", readiness=true. Elapsed: 6.989508ms
    Apr 26 12:08:42.418: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-j6h9c" satisfied condition "running"
    Apr 26 12:08:42.418: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-tm5mn" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:42.425: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-tm5mn": Phase="Running", Reason="", readiness=true. Elapsed: 7.03942ms
    Apr 26 12:08:42.425: INFO: Pod "wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b-tm5mn" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b in namespace emptydir-wrapper-7413, will wait for the garbage collector to delete the pods 04/26/24 12:08:42.425
    Apr 26 12:08:42.492: INFO: Deleting ReplicationController wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b took: 10.30919ms
    Apr 26 12:08:42.693: INFO: Terminating ReplicationController wrapped-volume-race-220a5cd5-af05-4bd0-a8ae-c7dfd8a2114b pods took: 200.471592ms
    STEP: Creating RC which spawns configmap-volume pods 04/26/24 12:08:44.007
    Apr 26 12:08:44.022: INFO: Pod name wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f: Found 0 pods out of 5
    Apr 26 12:08:49.041: INFO: Pod name wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/26/24 12:08:49.041
    Apr 26 12:08:49.041: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-577gb" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:49.047: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-577gb": Phase="Running", Reason="", readiness=true. Elapsed: 5.841162ms
    Apr 26 12:08:49.047: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-577gb" satisfied condition "running"
    Apr 26 12:08:49.047: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-5fxxk" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:49.054: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-5fxxk": Phase="Running", Reason="", readiness=true. Elapsed: 7.183802ms
    Apr 26 12:08:49.054: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-5fxxk" satisfied condition "running"
    Apr 26 12:08:49.055: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-jkvph" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:49.061: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-jkvph": Phase="Running", Reason="", readiness=true. Elapsed: 6.651136ms
    Apr 26 12:08:49.061: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-jkvph" satisfied condition "running"
    Apr 26 12:08:49.062: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-prmlv" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:49.069: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-prmlv": Phase="Running", Reason="", readiness=true. Elapsed: 7.175015ms
    Apr 26 12:08:49.069: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-prmlv" satisfied condition "running"
    Apr 26 12:08:49.069: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-w9htl" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:49.075: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-w9htl": Phase="Running", Reason="", readiness=true. Elapsed: 5.867622ms
    Apr 26 12:08:49.075: INFO: Pod "wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f-w9htl" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f in namespace emptydir-wrapper-7413, will wait for the garbage collector to delete the pods 04/26/24 12:08:49.075
    Apr 26 12:08:49.143: INFO: Deleting ReplicationController wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f took: 10.096243ms
    Apr 26 12:08:49.244: INFO: Terminating ReplicationController wrapped-volume-race-57c9753b-cc37-43ae-9322-a8dfd428fe1f pods took: 101.167269ms
    STEP: Creating RC which spawns configmap-volume pods 04/26/24 12:08:50.862
    Apr 26 12:08:50.881: INFO: Pod name wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242: Found 0 pods out of 5
    Apr 26 12:08:55.903: INFO: Pod name wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242: Found 5 pods out of 5
    STEP: Ensuring each pod is running 04/26/24 12:08:55.903
    Apr 26 12:08:55.903: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-cx26n" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:55.910: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-cx26n": Phase="Running", Reason="", readiness=true. Elapsed: 6.941931ms
    Apr 26 12:08:55.910: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-cx26n" satisfied condition "running"
    Apr 26 12:08:55.910: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-frgj8" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:55.917: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-frgj8": Phase="Running", Reason="", readiness=true. Elapsed: 6.502229ms
    Apr 26 12:08:55.917: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-frgj8" satisfied condition "running"
    Apr 26 12:08:55.917: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-jt45f" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:55.923: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-jt45f": Phase="Running", Reason="", readiness=true. Elapsed: 5.692646ms
    Apr 26 12:08:55.923: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-jt45f" satisfied condition "running"
    Apr 26 12:08:55.923: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-lsz9k" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:55.930: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-lsz9k": Phase="Running", Reason="", readiness=true. Elapsed: 6.956688ms
    Apr 26 12:08:55.930: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-lsz9k" satisfied condition "running"
    Apr 26 12:08:55.930: INFO: Waiting up to 5m0s for pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-zgmhx" in namespace "emptydir-wrapper-7413" to be "running"
    Apr 26 12:08:55.936: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-zgmhx": Phase="Running", Reason="", readiness=true. Elapsed: 5.972128ms
    Apr 26 12:08:55.936: INFO: Pod "wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242-zgmhx" satisfied condition "running"
    STEP: deleting ReplicationController wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242 in namespace emptydir-wrapper-7413, will wait for the garbage collector to delete the pods 04/26/24 12:08:55.936
    Apr 26 12:08:56.003: INFO: Deleting ReplicationController wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242 took: 8.369057ms
    Apr 26 12:08:56.105: INFO: Terminating ReplicationController wrapped-volume-race-38091db3-7454-4e77-b5d1-89cd30c01242 pods took: 101.133668ms
    STEP: Cleaning up the configMaps 04/26/24 12:08:57.005
    [AfterEach] [sig-storage] EmptyDir wrapper volumes
      test/e2e/framework/framework.go:187
    Apr 26 12:08:57.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-wrapper-7413" for this suite. 04/26/24 12:08:57.31
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSS
------------------------------
[sig-instrumentation] Events
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
[BeforeEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:08:57.318
Apr 26 12:08:57.318: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename events 04/26/24 12:08:57.319
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:57.335
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:57.34
[It] should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175
STEP: Create set of events 04/26/24 12:08:57.345
Apr 26 12:08:57.351: INFO: created test-event-1
Apr 26 12:08:57.357: INFO: created test-event-2
Apr 26 12:08:57.361: INFO: created test-event-3
STEP: get a list of Events with a label in the current namespace 04/26/24 12:08:57.361
STEP: delete collection of events 04/26/24 12:08:57.365
Apr 26 12:08:57.366: INFO: requesting DeleteCollection of events
STEP: check that the list of events matches the requested quantity 04/26/24 12:08:57.385
Apr 26 12:08:57.385: INFO: requesting list of events to confirm quantity
[AfterEach] [sig-instrumentation] Events
  test/e2e/framework/framework.go:187
Apr 26 12:08:57.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-7279" for this suite. 04/26/24 12:08:57.405
{"msg":"PASSED [sig-instrumentation] Events should delete a collection of events [Conformance]","completed":291,"skipped":5292,"failed":0}
------------------------------
â€¢ [0.094 seconds]
[sig-instrumentation] Events
test/e2e/instrumentation/common/framework.go:23
  should delete a collection of events [Conformance]
  test/e2e/instrumentation/core_events.go:175

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:08:57.318
    Apr 26 12:08:57.318: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename events 04/26/24 12:08:57.319
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:57.335
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:57.34
    [It] should delete a collection of events [Conformance]
      test/e2e/instrumentation/core_events.go:175
    STEP: Create set of events 04/26/24 12:08:57.345
    Apr 26 12:08:57.351: INFO: created test-event-1
    Apr 26 12:08:57.357: INFO: created test-event-2
    Apr 26 12:08:57.361: INFO: created test-event-3
    STEP: get a list of Events with a label in the current namespace 04/26/24 12:08:57.361
    STEP: delete collection of events 04/26/24 12:08:57.365
    Apr 26 12:08:57.366: INFO: requesting DeleteCollection of events
    STEP: check that the list of events matches the requested quantity 04/26/24 12:08:57.385
    Apr 26 12:08:57.385: INFO: requesting list of events to confirm quantity
    [AfterEach] [sig-instrumentation] Events
      test/e2e/framework/framework.go:187
    Apr 26 12:08:57.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "events-7279" for this suite. 04/26/24 12:08:57.405
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:08:57.413
Apr 26 12:08:57.413: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 12:08:57.414
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:57.431
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:57.436
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 12:08:57.454
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 12:08:57.658
STEP: Deploying the webhook pod 04/26/24 12:08:57.664
STEP: Wait for the deployment to be ready 04/26/24 12:08:57.677
Apr 26 12:08:57.689: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 12:08:59.704
STEP: Verifying the service has paired with the endpoint 04/26/24 12:08:59.726
Apr 26 12:09:00.727: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208
STEP: Registering the webhook via the AdmissionRegistration API 04/26/24 12:09:00.733
STEP: create a pod 04/26/24 12:09:00.818
Apr 26 12:09:00.841: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-1642" to be "running"
Apr 26 12:09:00.846: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.461818ms
Apr 26 12:09:02.851: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009077629s
Apr 26 12:09:02.851: INFO: Pod "to-be-attached-pod" satisfied condition "running"
STEP: 'kubectl attach' the pod, should be denied by the webhook 04/26/24 12:09:02.851
Apr 26 12:09:02.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=webhook-1642 attach --namespace=webhook-1642 to-be-attached-pod -i -c=container1'
Apr 26 12:09:03.066: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:09:03.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1642" for this suite. 04/26/24 12:09:03.083
STEP: Destroying namespace "webhook-1642-markers" for this suite. 04/26/24 12:09:03.095
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]","completed":292,"skipped":5292,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.773 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  test/e2e/apimachinery/webhook.go:208

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:08:57.413
    Apr 26 12:08:57.413: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 12:08:57.414
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:08:57.431
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:08:57.436
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 12:08:57.454
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 12:08:57.658
    STEP: Deploying the webhook pod 04/26/24 12:08:57.664
    STEP: Wait for the deployment to be ready 04/26/24 12:08:57.677
    Apr 26 12:08:57.689: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 12:08:59.704
    STEP: Verifying the service has paired with the endpoint 04/26/24 12:08:59.726
    Apr 26 12:09:00.727: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should be able to deny attaching pod [Conformance]
      test/e2e/apimachinery/webhook.go:208
    STEP: Registering the webhook via the AdmissionRegistration API 04/26/24 12:09:00.733
    STEP: create a pod 04/26/24 12:09:00.818
    Apr 26 12:09:00.841: INFO: Waiting up to 5m0s for pod "to-be-attached-pod" in namespace "webhook-1642" to be "running"
    Apr 26 12:09:00.846: INFO: Pod "to-be-attached-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 4.461818ms
    Apr 26 12:09:02.851: INFO: Pod "to-be-attached-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.009077629s
    Apr 26 12:09:02.851: INFO: Pod "to-be-attached-pod" satisfied condition "running"
    STEP: 'kubectl attach' the pod, should be denied by the webhook 04/26/24 12:09:02.851
    Apr 26 12:09:02.852: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=webhook-1642 attach --namespace=webhook-1642 to-be-attached-pod -i -c=container1'
    Apr 26 12:09:03.066: INFO: rc: 1
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:09:03.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-1642" for this suite. 04/26/24 12:09:03.083
    STEP: Destroying namespace "webhook-1642-markers" for this suite. 04/26/24 12:09:03.095
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-node] RuntimeClass
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:09:03.187
Apr 26 12:09:03.187: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename runtimeclass 04/26/24 12:09:03.188
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:03.241
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:03.246
[It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104
Apr 26 12:09:03.303: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7414 to be scheduled
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 26 12:09:03.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-7414" for this suite. 04/26/24 12:09:03.387
{"msg":"PASSED [sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]","completed":293,"skipped":5294,"failed":0}
------------------------------
â€¢ [0.229 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:104

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:09:03.187
    Apr 26 12:09:03.187: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename runtimeclass 04/26/24 12:09:03.188
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:03.241
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:03.246
    [It] should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:104
    Apr 26 12:09:03.303: INFO: Waiting up to 1m20s for at least 1 pods in namespace runtimeclass-7414 to be scheduled
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 26 12:09:03.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-7414" for this suite. 04/26/24 12:09:03.387
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:09:03.419
Apr 26 12:09:03.419: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename replication-controller 04/26/24 12:09:03.42
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:03.498
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:03.504
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100
STEP: Given a ReplicationController is created 04/26/24 12:09:03.508
STEP: When the matched label of one of its pods change 04/26/24 12:09:03.516
Apr 26 12:09:03.540: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 26 12:09:08.549: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released 04/26/24 12:09:08.561
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 26 12:09:09.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5924" for this suite. 04/26/24 12:09:09.584
{"msg":"PASSED [sig-apps] ReplicationController should release no longer matching pods [Conformance]","completed":294,"skipped":5351,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.172 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  test/e2e/apps/rc.go:100

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:09:03.419
    Apr 26 12:09:03.419: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename replication-controller 04/26/24 12:09:03.42
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:03.498
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:03.504
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should release no longer matching pods [Conformance]
      test/e2e/apps/rc.go:100
    STEP: Given a ReplicationController is created 04/26/24 12:09:03.508
    STEP: When the matched label of one of its pods change 04/26/24 12:09:03.516
    Apr 26 12:09:03.540: INFO: Pod name pod-release: Found 0 pods out of 1
    Apr 26 12:09:08.549: INFO: Pod name pod-release: Found 1 pods out of 1
    STEP: Then the pod is released 04/26/24 12:09:08.561
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 26 12:09:09.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-5924" for this suite. 04/26/24 12:09:09.584
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:09:09.591
Apr 26 12:09:09.591: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 12:09:09.593
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:09.608
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:09.613
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186
STEP: Creating a pod to test emptydir 0777 on node default medium 04/26/24 12:09:09.618
Apr 26 12:09:09.654: INFO: Waiting up to 5m0s for pod "pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b" in namespace "emptydir-2087" to be "Succeeded or Failed"
Apr 26 12:09:09.659: INFO: Pod "pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.394572ms
Apr 26 12:09:11.667: INFO: Pod "pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012909767s
Apr 26 12:09:13.665: INFO: Pod "pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010741065s
STEP: Saw pod success 04/26/24 12:09:13.665
Apr 26 12:09:13.665: INFO: Pod "pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b" satisfied condition "Succeeded or Failed"
Apr 26 12:09:13.670: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b container test-container: <nil>
STEP: delete the pod 04/26/24 12:09:13.706
Apr 26 12:09:13.721: INFO: Waiting for pod pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b to disappear
Apr 26 12:09:13.724: INFO: Pod pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 12:09:13.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2087" for this suite. 04/26/24 12:09:13.733
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":295,"skipped":5359,"failed":0}
------------------------------
â€¢ [4.148 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:186

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:09:09.591
    Apr 26 12:09:09.591: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 12:09:09.593
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:09.608
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:09.613
    [It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:186
    STEP: Creating a pod to test emptydir 0777 on node default medium 04/26/24 12:09:09.618
    Apr 26 12:09:09.654: INFO: Waiting up to 5m0s for pod "pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b" in namespace "emptydir-2087" to be "Succeeded or Failed"
    Apr 26 12:09:09.659: INFO: Pod "pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.394572ms
    Apr 26 12:09:11.667: INFO: Pod "pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.012909767s
    Apr 26 12:09:13.665: INFO: Pod "pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010741065s
    STEP: Saw pod success 04/26/24 12:09:13.665
    Apr 26 12:09:13.665: INFO: Pod "pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b" satisfied condition "Succeeded or Failed"
    Apr 26 12:09:13.670: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b container test-container: <nil>
    STEP: delete the pod 04/26/24 12:09:13.706
    Apr 26 12:09:13.721: INFO: Waiting for pod pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b to disappear
    Apr 26 12:09:13.724: INFO: Pod pod-690971cf-8cd7-44d3-9f82-1ba8b6545d5b no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 12:09:13.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2087" for this suite. 04/26/24 12:09:13.733
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:09:13.739
Apr 26 12:09:13.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename statefulset 04/26/24 12:09:13.74
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:13.756
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:13.764
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-6682 04/26/24 12:09:13.769
[It] Should recreate evicted statefulset [Conformance]
  test/e2e/apps/statefulset.go:737
STEP: Looking for a node to schedule stateful set and pod 04/26/24 12:09:13.775
STEP: Creating pod with conflicting port in namespace statefulset-6682 04/26/24 12:09:13.787
STEP: Waiting until pod test-pod will start running in namespace statefulset-6682 04/26/24 12:09:13.796
Apr 26 12:09:13.796: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-6682" to be "running"
Apr 26 12:09:13.802: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.181453ms
Apr 26 12:09:15.809: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012442735s
Apr 26 12:09:15.809: INFO: Pod "test-pod" satisfied condition "running"
STEP: Creating statefulset with conflicting port in namespace statefulset-6682 04/26/24 12:09:15.809
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6682 04/26/24 12:09:15.815
Apr 26 12:09:15.833: INFO: Observed stateful pod in namespace: statefulset-6682, name: ss-0, uid: c102188e-719e-4bf1-921b-6db768735b83, status phase: Pending. Waiting for statefulset controller to delete.
Apr 26 12:09:15.849: INFO: Observed stateful pod in namespace: statefulset-6682, name: ss-0, uid: c102188e-719e-4bf1-921b-6db768735b83, status phase: Failed. Waiting for statefulset controller to delete.
Apr 26 12:09:15.857: INFO: Observed stateful pod in namespace: statefulset-6682, name: ss-0, uid: c102188e-719e-4bf1-921b-6db768735b83, status phase: Failed. Waiting for statefulset controller to delete.
Apr 26 12:09:15.859: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6682
STEP: Removing pod with conflicting port in namespace statefulset-6682 04/26/24 12:09:15.859
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6682 and will be in running state 04/26/24 12:09:15.876
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 26 12:09:17.898: INFO: Deleting all statefulset in ns statefulset-6682
Apr 26 12:09:17.902: INFO: Scaling statefulset ss to 0
Apr 26 12:09:27.936: INFO: Waiting for statefulset status.replicas updated to 0
Apr 26 12:09:27.940: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 26 12:09:27.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6682" for this suite. 04/26/24 12:09:27.967
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]","completed":296,"skipped":5381,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.234 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    Should recreate evicted statefulset [Conformance]
    test/e2e/apps/statefulset.go:737

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:09:13.739
    Apr 26 12:09:13.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename statefulset 04/26/24 12:09:13.74
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:13.756
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:13.764
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-6682 04/26/24 12:09:13.769
    [It] Should recreate evicted statefulset [Conformance]
      test/e2e/apps/statefulset.go:737
    STEP: Looking for a node to schedule stateful set and pod 04/26/24 12:09:13.775
    STEP: Creating pod with conflicting port in namespace statefulset-6682 04/26/24 12:09:13.787
    STEP: Waiting until pod test-pod will start running in namespace statefulset-6682 04/26/24 12:09:13.796
    Apr 26 12:09:13.796: INFO: Waiting up to 5m0s for pod "test-pod" in namespace "statefulset-6682" to be "running"
    Apr 26 12:09:13.802: INFO: Pod "test-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 5.181453ms
    Apr 26 12:09:15.809: INFO: Pod "test-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.012442735s
    Apr 26 12:09:15.809: INFO: Pod "test-pod" satisfied condition "running"
    STEP: Creating statefulset with conflicting port in namespace statefulset-6682 04/26/24 12:09:15.809
    STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6682 04/26/24 12:09:15.815
    Apr 26 12:09:15.833: INFO: Observed stateful pod in namespace: statefulset-6682, name: ss-0, uid: c102188e-719e-4bf1-921b-6db768735b83, status phase: Pending. Waiting for statefulset controller to delete.
    Apr 26 12:09:15.849: INFO: Observed stateful pod in namespace: statefulset-6682, name: ss-0, uid: c102188e-719e-4bf1-921b-6db768735b83, status phase: Failed. Waiting for statefulset controller to delete.
    Apr 26 12:09:15.857: INFO: Observed stateful pod in namespace: statefulset-6682, name: ss-0, uid: c102188e-719e-4bf1-921b-6db768735b83, status phase: Failed. Waiting for statefulset controller to delete.
    Apr 26 12:09:15.859: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6682
    STEP: Removing pod with conflicting port in namespace statefulset-6682 04/26/24 12:09:15.859
    STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6682 and will be in running state 04/26/24 12:09:15.876
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 26 12:09:17.898: INFO: Deleting all statefulset in ns statefulset-6682
    Apr 26 12:09:17.902: INFO: Scaling statefulset ss to 0
    Apr 26 12:09:27.936: INFO: Waiting for statefulset status.replicas updated to 0
    Apr 26 12:09:27.940: INFO: Deleting statefulset ss
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 26 12:09:27.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-6682" for this suite. 04/26/24 12:09:27.967
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:09:27.976
Apr 26 12:09:27.976: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename downward-api 04/26/24 12:09:27.978
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:27.992
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:27.997
[BeforeEach] [sig-storage] Downward API volume
  test/e2e/common/storage/downwardapi_volume.go:43
[It] should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129
STEP: Creating the pod 04/26/24 12:09:28.002
Apr 26 12:09:28.012: INFO: Waiting up to 5m0s for pod "labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6" in namespace "downward-api-4489" to be "running and ready"
Apr 26 12:09:28.023: INFO: Pod "labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.64242ms
Apr 26 12:09:28.023: INFO: The phase of Pod labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:09:30.031: INFO: Pod "labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6": Phase="Running", Reason="", readiness=true. Elapsed: 2.018912821s
Apr 26 12:09:30.031: INFO: The phase of Pod labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6 is Running (Ready = true)
Apr 26 12:09:30.031: INFO: Pod "labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6" satisfied condition "running and ready"
Apr 26 12:09:30.567: INFO: Successfully updated pod "labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6"
[AfterEach] [sig-storage] Downward API volume
  test/e2e/framework/framework.go:187
Apr 26 12:09:32.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4489" for this suite. 04/26/24 12:09:32.651
{"msg":"PASSED [sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]","completed":297,"skipped":5414,"failed":0}
------------------------------
â€¢ [4.683 seconds]
[sig-storage] Downward API volume
test/e2e/common/storage/framework.go:23
  should update labels on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/downwardapi_volume.go:129

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:09:27.976
    Apr 26 12:09:27.976: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename downward-api 04/26/24 12:09:27.978
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:27.992
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:27.997
    [BeforeEach] [sig-storage] Downward API volume
      test/e2e/common/storage/downwardapi_volume.go:43
    [It] should update labels on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/downwardapi_volume.go:129
    STEP: Creating the pod 04/26/24 12:09:28.002
    Apr 26 12:09:28.012: INFO: Waiting up to 5m0s for pod "labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6" in namespace "downward-api-4489" to be "running and ready"
    Apr 26 12:09:28.023: INFO: Pod "labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.64242ms
    Apr 26 12:09:28.023: INFO: The phase of Pod labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:09:30.031: INFO: Pod "labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6": Phase="Running", Reason="", readiness=true. Elapsed: 2.018912821s
    Apr 26 12:09:30.031: INFO: The phase of Pod labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6 is Running (Ready = true)
    Apr 26 12:09:30.031: INFO: Pod "labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6" satisfied condition "running and ready"
    Apr 26 12:09:30.567: INFO: Successfully updated pod "labelsupdate2699c0a4-531b-4558-9e4d-1817f6f680b6"
    [AfterEach] [sig-storage] Downward API volume
      test/e2e/framework/framework.go:187
    Apr 26 12:09:32.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "downward-api-4489" for this suite. 04/26/24 12:09:32.651
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:09:32.66
Apr 26 12:09:32.660: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 12:09:32.661
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:32.675
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:32.682
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 12:09:32.703
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 12:09:32.899
STEP: Deploying the webhook pod 04/26/24 12:09:32.906
STEP: Wait for the deployment to be ready 04/26/24 12:09:32.924
Apr 26 12:09:32.966: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 12:09:34.982
STEP: Verifying the service has paired with the endpoint 04/26/24 12:09:35.006
Apr 26 12:09:36.007: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290
Apr 26 12:09:36.012: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7753-crds.webhook.example.com via the AdmissionRegistration API 04/26/24 12:09:36.527
STEP: Creating a custom resource that should be mutated by the webhook 04/26/24 12:09:36.657
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:09:39.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8054" for this suite. 04/26/24 12:09:39.478
STEP: Destroying namespace "webhook-8054-markers" for this suite. 04/26/24 12:09:39.484
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]","completed":298,"skipped":5417,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.893 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  test/e2e/apimachinery/webhook.go:290

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:09:32.66
    Apr 26 12:09:32.660: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 12:09:32.661
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:32.675
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:32.682
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 12:09:32.703
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 12:09:32.899
    STEP: Deploying the webhook pod 04/26/24 12:09:32.906
    STEP: Wait for the deployment to be ready 04/26/24 12:09:32.924
    Apr 26 12:09:32.966: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 12:09:34.982
    STEP: Verifying the service has paired with the endpoint 04/26/24 12:09:35.006
    Apr 26 12:09:36.007: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] should mutate custom resource [Conformance]
      test/e2e/apimachinery/webhook.go:290
    Apr 26 12:09:36.012: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7753-crds.webhook.example.com via the AdmissionRegistration API 04/26/24 12:09:36.527
    STEP: Creating a custom resource that should be mutated by the webhook 04/26/24 12:09:36.657
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:09:39.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8054" for this suite. 04/26/24 12:09:39.478
    STEP: Destroying namespace "webhook-8054-markers" for this suite. 04/26/24 12:09:39.484
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:09:39.554
Apr 26 12:09:39.554: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 12:09:39.555
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:39.58
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:39.585
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67
STEP: Creating secret with name secret-test-f90ce658-5d80-4d8e-a28a-06b1ba356d0d 04/26/24 12:09:39.59
STEP: Creating a pod to test consume secrets 04/26/24 12:09:39.604
Apr 26 12:09:39.623: INFO: Waiting up to 5m0s for pod "pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23" in namespace "secrets-6131" to be "Succeeded or Failed"
Apr 26 12:09:39.637: INFO: Pod "pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23": Phase="Pending", Reason="", readiness=false. Elapsed: 13.610069ms
Apr 26 12:09:41.643: INFO: Pod "pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019777502s
Apr 26 12:09:43.643: INFO: Pod "pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01956537s
STEP: Saw pod success 04/26/24 12:09:43.643
Apr 26 12:09:43.643: INFO: Pod "pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23" satisfied condition "Succeeded or Failed"
Apr 26 12:09:43.647: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23 container secret-volume-test: <nil>
STEP: delete the pod 04/26/24 12:09:43.662
Apr 26 12:09:43.675: INFO: Waiting for pod pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23 to disappear
Apr 26 12:09:43.679: INFO: Pod pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 26 12:09:43.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6131" for this suite. 04/26/24 12:09:43.689
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]","completed":299,"skipped":5439,"failed":0}
------------------------------
â€¢ [4.141 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:67

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:09:39.554
    Apr 26 12:09:39.554: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 12:09:39.555
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:39.58
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:39.585
    [It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:67
    STEP: Creating secret with name secret-test-f90ce658-5d80-4d8e-a28a-06b1ba356d0d 04/26/24 12:09:39.59
    STEP: Creating a pod to test consume secrets 04/26/24 12:09:39.604
    Apr 26 12:09:39.623: INFO: Waiting up to 5m0s for pod "pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23" in namespace "secrets-6131" to be "Succeeded or Failed"
    Apr 26 12:09:39.637: INFO: Pod "pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23": Phase="Pending", Reason="", readiness=false. Elapsed: 13.610069ms
    Apr 26 12:09:41.643: INFO: Pod "pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019777502s
    Apr 26 12:09:43.643: INFO: Pod "pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01956537s
    STEP: Saw pod success 04/26/24 12:09:43.643
    Apr 26 12:09:43.643: INFO: Pod "pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23" satisfied condition "Succeeded or Failed"
    Apr 26 12:09:43.647: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23 container secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 12:09:43.662
    Apr 26 12:09:43.675: INFO: Waiting for pod pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23 to disappear
    Apr 26 12:09:43.679: INFO: Pod pod-secrets-55e80c34-8084-4687-8191-4b8d8706af23 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 12:09:43.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-6131" for this suite. 04/26/24 12:09:43.689
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[BeforeEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:09:43.696
Apr 26 12:09:43.696: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 12:09:43.698
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:43.712
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:43.717
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503
[AfterEach] [sig-storage] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 12:09:43.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-479" for this suite. 04/26/24 12:09:43.779
{"msg":"PASSED [sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]","completed":300,"skipped":5442,"failed":0}
------------------------------
â€¢ [0.093 seconds]
[sig-storage] ConfigMap
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/configmap_volume.go:503

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:09:43.696
    Apr 26 12:09:43.696: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 12:09:43.698
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:43.712
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:43.717
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/configmap_volume.go:503
    [AfterEach] [sig-storage] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 12:09:43.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-479" for this suite. 04/26/24 12:09:43.779
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
[BeforeEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:09:43.793
Apr 26 12:09:43.793: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename deployment 04/26/24 12:09:43.795
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:43.815
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:43.82
[BeforeEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:91
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105
Apr 26 12:09:43.825: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 26 12:09:43.834: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 26 12:09:48.840: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running 04/26/24 12:09:48.84
Apr 26 12:09:48.841: INFO: Creating deployment "test-rolling-update-deployment"
Apr 26 12:09:48.846: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 26 12:09:48.856: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 26 12:09:50.868: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 26 12:09:50.872: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  test/e2e/apps/deployment.go:84
Apr 26 12:09:50.885: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7791  71348387-5853-4ad8-ab5e-ece7c31afa4e 45039 1 2024-04-26 12:09:48 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2024-04-26 12:09:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:09:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003df4a68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2024-04-26 12:09:48 +0000 UTC,LastTransitionTime:2024-04-26 12:09:48 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2024-04-26 12:09:49 +0000 UTC,LastTransitionTime:2024-04-26 12:09:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 26 12:09:50.890: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-7791  8d139af5-49fb-45f7-b4eb-016879faadf4 45031 1 2024-04-26 12:09:48 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 71348387-5853-4ad8-ab5e-ece7c31afa4e 0xc0046f4e77 0xc0046f4e78}] [] [{kube-controller-manager Update apps/v1 2024-04-26 12:09:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"71348387-5853-4ad8-ab5e-ece7c31afa4e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:09:49 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0046f4f28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 26 12:09:50.890: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 26 12:09:50.890: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7791  8c924129-b29b-470c-a61b-f2b5f6deeb5c 45038 2 2024-04-26 12:09:43 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 71348387-5853-4ad8-ab5e-ece7c31afa4e 0xc0046f4d47 0xc0046f4d48}] [] [{e2e.test Update apps/v1 2024-04-26 12:09:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:09:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"71348387-5853-4ad8-ab5e-ece7c31afa4e\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:09:49 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0046f4e08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 26 12:09:50.894: INFO: Pod "test-rolling-update-deployment-78f575d8ff-k6b4k" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-k6b4k test-rolling-update-deployment-78f575d8ff- deployment-7791  835d8c9d-7deb-4be3-9d53-54b914477446 45030 0 2024-04-26 12:09:48 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:f34a228208af0e7d207e62879d0eaa8da8b731cba9a9fe5111376c0ac14afceb cni.projectcalico.org/podIP:100.96.1.14/32 cni.projectcalico.org/podIPs:100.96.1.14/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 8d139af5-49fb-45f7-b4eb-016879faadf4 0xc0046f53a7 0xc0046f53a8}] [] [{kube-controller-manager Update v1 2024-04-26 12:09:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d139af5-49fb-45f7-b4eb-016879faadf4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 12:09:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 12:09:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.14\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dnqff,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dnqff,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:09:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:09:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:09:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:09:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.14,StartTime:2024-04-26 12:09:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 12:09:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://4c322447a47137dbcddd7f64e20b792a6bf1aa97aff31cbc151ac86259a0061d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.14,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  test/e2e/framework/framework.go:187
Apr 26 12:09:50.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7791" for this suite. 04/26/24 12:09:50.907
{"msg":"PASSED [sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]","completed":301,"skipped":5459,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.121 seconds]
[sig-apps] Deployment
test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  test/e2e/apps/deployment.go:105

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:09:43.793
    Apr 26 12:09:43.793: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename deployment 04/26/24 12:09:43.795
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:43.815
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:43.82
    [BeforeEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:91
    [It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
      test/e2e/apps/deployment.go:105
    Apr 26 12:09:43.825: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
    Apr 26 12:09:43.834: INFO: Pod name sample-pod: Found 0 pods out of 1
    Apr 26 12:09:48.840: INFO: Pod name sample-pod: Found 1 pods out of 1
    STEP: ensuring each pod is running 04/26/24 12:09:48.84
    Apr 26 12:09:48.841: INFO: Creating deployment "test-rolling-update-deployment"
    Apr 26 12:09:48.846: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
    Apr 26 12:09:48.856: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
    Apr 26 12:09:50.868: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
    Apr 26 12:09:50.872: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
    [AfterEach] [sig-apps] Deployment
      test/e2e/apps/deployment.go:84
    Apr 26 12:09:50.885: INFO: Deployment "test-rolling-update-deployment":
    &Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7791  71348387-5853-4ad8-ab5e-ece7c31afa4e 45039 1 2024-04-26 12:09:48 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] [] [{e2e.test Update apps/v1 2024-04-26 12:09:48 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:progressDeadlineSeconds":{},"f:replicas":{},"f:revisionHistoryLimit":{},"f:selector":{},"f:strategy":{"f:rollingUpdate":{".":{},"f:maxSurge":{},"f:maxUnavailable":{}},"f:type":{}},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:09:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}}},"f:status":{"f:availableReplicas":{},"f:conditions":{".":{},"k:{\"type\":\"Available\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Progressing\"}":{".":{},"f:lastTransitionTime":{},"f:lastUpdateTime":{},"f:message":{},"f:reason":{},"f:status":{},"f:type":{}}},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{},"f:updatedReplicas":{}}} status}]},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc003df4a68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2024-04-26 12:09:48 +0000 UTC,LastTransitionTime:2024-04-26 12:09:48 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-78f575d8ff" has successfully progressed.,LastUpdateTime:2024-04-26 12:09:49 +0000 UTC,LastTransitionTime:2024-04-26 12:09:48 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

    Apr 26 12:09:50.890: INFO: New ReplicaSet "test-rolling-update-deployment-78f575d8ff" of Deployment "test-rolling-update-deployment":
    &ReplicaSet{ObjectMeta:{test-rolling-update-deployment-78f575d8ff  deployment-7791  8d139af5-49fb-45f7-b4eb-016879faadf4 45031 1 2024-04-26 12:09:48 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 71348387-5853-4ad8-ab5e-ece7c31afa4e 0xc0046f4e77 0xc0046f4e78}] [] [{kube-controller-manager Update apps/v1 2024-04-26 12:09:48 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"71348387-5853-4ad8-ab5e-ece7c31afa4e\"}":{}}},"f:spec":{"f:replicas":{},"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:09:49 +0000 UTC FieldsV1 {"f:status":{"f:availableReplicas":{},"f:fullyLabeledReplicas":{},"f:observedGeneration":{},"f:readyReplicas":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 78f575d8ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[] [] [] []} {[] [] [{agnhost registry.k8s.io/e2e-test-images/agnhost:2.40 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,} false false false}] [] Always 0xc0046f4f28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
    Apr 26 12:09:50.890: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
    Apr 26 12:09:50.890: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7791  8c924129-b29b-470c-a61b-f2b5f6deeb5c 45038 2 2024-04-26 12:09:43 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 71348387-5853-4ad8-ab5e-ece7c31afa4e 0xc0046f4d47 0xc0046f4d48}] [] [{e2e.test Update apps/v1 2024-04-26 12:09:43 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:deployment.kubernetes.io/revision":{}},"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:selector":{},"f:template":{"f:metadata":{"f:labels":{".":{},"f:name":{},"f:pod":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"httpd\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:09:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{"f:deployment.kubernetes.io/desired-replicas":{},"f:deployment.kubernetes.io/max-replicas":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"71348387-5853-4ad8-ab5e-ece7c31afa4e\"}":{}}},"f:spec":{"f:replicas":{}}} } {kube-controller-manager Update apps/v1 2024-04-26 12:09:49 +0000 UTC FieldsV1 {"f:status":{"f:observedGeneration":{},"f:replicas":{}}} status}]},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] [] []} {[] [] [{httpd registry.k8s.io/e2e-test-images/httpd:2.4.38-2 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0046f4e08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] [] <nil> nil <nil>}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
    Apr 26 12:09:50.894: INFO: Pod "test-rolling-update-deployment-78f575d8ff-k6b4k" is available:
    &Pod{ObjectMeta:{test-rolling-update-deployment-78f575d8ff-k6b4k test-rolling-update-deployment-78f575d8ff- deployment-7791  835d8c9d-7deb-4be3-9d53-54b914477446 45030 0 2024-04-26 12:09:48 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:78f575d8ff] map[cni.projectcalico.org/containerID:f34a228208af0e7d207e62879d0eaa8da8b731cba9a9fe5111376c0ac14afceb cni.projectcalico.org/podIP:100.96.1.14/32 cni.projectcalico.org/podIPs:100.96.1.14/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-78f575d8ff 8d139af5-49fb-45f7-b4eb-016879faadf4 0xc0046f53a7 0xc0046f53a8}] [] [{kube-controller-manager Update v1 2024-04-26 12:09:48 +0000 UTC FieldsV1 {"f:metadata":{"f:generateName":{},"f:labels":{".":{},"f:name":{},"f:pod-template-hash":{}},"f:ownerReferences":{".":{},"k:{\"uid\":\"8d139af5-49fb-45f7-b4eb-016879faadf4\"}":{}}},"f:spec":{"f:containers":{"k:{\"name\":\"agnhost\"}":{".":{},"f:image":{},"f:imagePullPolicy":{},"f:name":{},"f:resources":{},"f:securityContext":{},"f:terminationMessagePath":{},"f:terminationMessagePolicy":{}}},"f:dnsPolicy":{},"f:enableServiceLinks":{},"f:restartPolicy":{},"f:schedulerName":{},"f:securityContext":{},"f:terminationGracePeriodSeconds":{}}} } {calico Update v1 2024-04-26 12:09:49 +0000 UTC FieldsV1 {"f:metadata":{"f:annotations":{".":{},"f:cni.projectcalico.org/containerID":{},"f:cni.projectcalico.org/podIP":{},"f:cni.projectcalico.org/podIPs":{}}}} status} {kubelet Update v1 2024-04-26 12:09:49 +0000 UTC FieldsV1 {"f:status":{"f:conditions":{"k:{\"type\":\"ContainersReady\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Initialized\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}},"k:{\"type\":\"Ready\"}":{".":{},"f:lastProbeTime":{},"f:lastTransitionTime":{},"f:status":{},"f:type":{}}},"f:containerStatuses":{},"f:hostIP":{},"f:phase":{},"f:podIP":{},"f:podIPs":{".":{},"k:{\"ip\":\"100.96.1.14\"}":{".":{},"f:ip":{}}},"f:startTime":{}}} status}]},Spec:PodSpec{Volumes:[]Volume{Volume{Name:kube-api-access-dnqff,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:nil,NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:&ProjectedVolumeSource{Sources:[]VolumeProjection{VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:nil,ServiceAccountToken:&ServiceAccountTokenProjection{Audience:,ExpirationSeconds:*3607,Path:token,},},VolumeProjection{Secret:nil,DownwardAPI:nil,ConfigMap:&ConfigMapProjection{LocalObjectReference:LocalObjectReference{Name:kube-root-ca.crt,},Items:[]KeyToPath{KeyToPath{Key:ca.crt,Path:ca.crt,Mode:nil,},},Optional:nil,},ServiceAccountToken:nil,},VolumeProjection{Secret:nil,DownwardAPI:&DownwardAPIProjection{Items:[]DownwardAPIVolumeFile{DownwardAPIVolumeFile{Path:namespace,FieldRef:&ObjectFieldSelector{APIVersion:v1,FieldPath:metadata.namespace,},ResourceFieldRef:nil,Mode:nil,},},},ConfigMap:nil,ServiceAccountToken:nil,},},DefaultMode:*420,},StorageOS:nil,CSI:nil,Ephemeral:nil,},},},Containers:[]Container{Container{Name:agnhost,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{EnvVar{Name:KUBERNETES_SERVICE_HOST,Value:api.conf-125.thomas.internal.emk.fuga.cloud,ValueFrom:nil,},},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:kube-api-access-dnqff,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,SeccompProfile:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,FSGroupChangePolicy:nil,SeccompProfile:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:*PreemptLowerPriority,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},SetHostnameAsFQDN:nil,OS:nil,HostUsers:nil,},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:09:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:09:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:09:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2024-04-26 12:09:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.248,PodIP:100.96.1.14,StartTime:2024-04-26 12:09:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:agnhost,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2024-04-26 12:09:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:registry.k8s.io/e2e-test-images/agnhost:2.40,ImageID:registry.k8s.io/e2e-test-images/agnhost@sha256:af7e3857d87770ddb40f5ea4f89b5a2709504ab1ee31f9ea4ab5823c045f2146,ContainerID:containerd://4c322447a47137dbcddd7f64e20b792a6bf1aa97aff31cbc151ac86259a0061d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.96.1.14,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
    [AfterEach] [sig-apps] Deployment
      test/e2e/framework/framework.go:187
    Apr 26 12:09:50.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "deployment-7791" for this suite. 04/26/24 12:09:50.907
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:09:50.918
Apr 26 12:09:50.918: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename cronjob 04/26/24 12:09:50.919
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:50.937
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:50.943
[It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124
STEP: Creating a ForbidConcurrent cronjob 04/26/24 12:09:50.948
STEP: Ensuring a job is scheduled 04/26/24 12:09:50.953
STEP: Ensuring exactly one is scheduled 04/26/24 12:10:00.962
STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/26/24 12:10:00.968
STEP: Ensuring no more jobs are scheduled 04/26/24 12:10:00.973
STEP: Removing cronjob 04/26/24 12:15:00.986
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 26 12:15:00.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-365" for this suite. 04/26/24 12:15:01.003
{"msg":"PASSED [sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]","completed":302,"skipped":5546,"failed":0}
------------------------------
â€¢ [SLOW TEST] [310.094 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
  test/e2e/apps/cronjob.go:124

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:09:50.918
    Apr 26 12:09:50.918: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename cronjob 04/26/24 12:09:50.919
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:09:50.937
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:09:50.943
    [It] should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]
      test/e2e/apps/cronjob.go:124
    STEP: Creating a ForbidConcurrent cronjob 04/26/24 12:09:50.948
    STEP: Ensuring a job is scheduled 04/26/24 12:09:50.953
    STEP: Ensuring exactly one is scheduled 04/26/24 12:10:00.962
    STEP: Ensuring exactly one running job exists by listing jobs explicitly 04/26/24 12:10:00.968
    STEP: Ensuring no more jobs are scheduled 04/26/24 12:10:00.973
    STEP: Removing cronjob 04/26/24 12:15:00.986
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 26 12:15:00.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-365" for this suite. 04/26/24 12:15:01.003
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch
  watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:15:01.021
Apr 26 12:15:01.021: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename crd-watch 04/26/24 12:15:01.023
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:15:01.066
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:15:01.073
[It] watch on custom resource definition objects [Conformance]
  test/e2e/apimachinery/crd_watch.go:51
Apr 26 12:15:01.079: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Creating first CR  04/26/24 12:15:03.64
Apr 26 12:15:03.645: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-26T12:15:03Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-26T12:15:03Z]] name:name1 resourceVersion:46290 uid:f5ee1bc4-b4a6-47d5-ad15-af007378ac43] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR 04/26/24 12:15:13.646
Apr 26 12:15:13.660: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-26T12:15:13Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-26T12:15:13Z]] name:name2 resourceVersion:46335 uid:02011836-7e9c-47c1-9eb8-cfe31de9120a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR 04/26/24 12:15:23.66
Apr 26 12:15:23.670: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-26T12:15:03Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-26T12:15:23Z]] name:name1 resourceVersion:46373 uid:f5ee1bc4-b4a6-47d5-ad15-af007378ac43] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR 04/26/24 12:15:33.67
Apr 26 12:15:33.681: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-26T12:15:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-26T12:15:33Z]] name:name2 resourceVersion:46413 uid:02011836-7e9c-47c1-9eb8-cfe31de9120a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR 04/26/24 12:15:43.682
Apr 26 12:15:43.692: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-26T12:15:03Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-26T12:15:23Z]] name:name1 resourceVersion:46452 uid:f5ee1bc4-b4a6-47d5-ad15-af007378ac43] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR 04/26/24 12:15:53.693
Apr 26 12:15:53.702: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-26T12:15:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-26T12:15:33Z]] name:name2 resourceVersion:46493 uid:02011836-7e9c-47c1-9eb8-cfe31de9120a] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:16:04.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-403" for this suite. 04/26/24 12:16:04.247
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]","completed":303,"skipped":5602,"failed":0}
------------------------------
â€¢ [SLOW TEST] [63.232 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  test/e2e/apimachinery/crd_watch.go:44
    watch on custom resource definition objects [Conformance]
    test/e2e/apimachinery/crd_watch.go:51

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:15:01.021
    Apr 26 12:15:01.021: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename crd-watch 04/26/24 12:15:01.023
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:15:01.066
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:15:01.073
    [It] watch on custom resource definition objects [Conformance]
      test/e2e/apimachinery/crd_watch.go:51
    Apr 26 12:15:01.079: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Creating first CR  04/26/24 12:15:03.64
    Apr 26 12:15:03.645: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-26T12:15:03Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-26T12:15:03Z]] name:name1 resourceVersion:46290 uid:f5ee1bc4-b4a6-47d5-ad15-af007378ac43] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Creating second CR 04/26/24 12:15:13.646
    Apr 26 12:15:13.660: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-26T12:15:13Z generation:1 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-26T12:15:13Z]] name:name2 resourceVersion:46335 uid:02011836-7e9c-47c1-9eb8-cfe31de9120a] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying first CR 04/26/24 12:15:23.66
    Apr 26 12:15:23.670: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-26T12:15:03Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-26T12:15:23Z]] name:name1 resourceVersion:46373 uid:f5ee1bc4-b4a6-47d5-ad15-af007378ac43] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Modifying second CR 04/26/24 12:15:33.67
    Apr 26 12:15:33.681: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-26T12:15:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-26T12:15:33Z]] name:name2 resourceVersion:46413 uid:02011836-7e9c-47c1-9eb8-cfe31de9120a] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting first CR 04/26/24 12:15:43.682
    Apr 26 12:15:43.692: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-26T12:15:03Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-26T12:15:23Z]] name:name1 resourceVersion:46452 uid:f5ee1bc4-b4a6-47d5-ad15-af007378ac43] num:map[num1:9223372036854775807 num2:1000000]]}
    STEP: Deleting second CR 04/26/24 12:15:53.693
    Apr 26 12:15:53.702: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2024-04-26T12:15:13Z generation:2 managedFields:[map[apiVersion:mygroup.example.com/v1beta1 fieldsType:FieldsV1 fieldsV1:map[f:content:map[.:map[] f:key:map[]] f:dummy:map[] f:num:map[.:map[] f:num1:map[] f:num2:map[]]] manager:e2e.test operation:Update time:2024-04-26T12:15:33Z]] name:name2 resourceVersion:46493 uid:02011836-7e9c-47c1-9eb8-cfe31de9120a] num:map[num1:9223372036854775807 num2:1000000]]}
    [AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:16:04.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-watch-403" for this suite. 04/26/24 12:16:04.247
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
[BeforeEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:16:04.257
Apr 26 12:16:04.257: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename svcaccounts 04/26/24 12:16:04.258
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:04.275
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:04.282
[It] should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272
STEP: Creating a pod to test service account token:  04/26/24 12:16:04.287
Apr 26 12:16:04.310: INFO: Waiting up to 5m0s for pod "test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57" in namespace "svcaccounts-9357" to be "Succeeded or Failed"
Apr 26 12:16:04.315: INFO: Pod "test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57": Phase="Pending", Reason="", readiness=false. Elapsed: 5.158162ms
Apr 26 12:16:06.323: INFO: Pod "test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01325911s
Apr 26 12:16:08.321: INFO: Pod "test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011469318s
STEP: Saw pod success 04/26/24 12:16:08.321
Apr 26 12:16:08.321: INFO: Pod "test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57" satisfied condition "Succeeded or Failed"
Apr 26 12:16:08.327: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57 container agnhost-container: <nil>
STEP: delete the pod 04/26/24 12:16:08.456
Apr 26 12:16:08.471: INFO: Waiting for pod test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57 to disappear
Apr 26 12:16:08.476: INFO: Pod test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57 no longer exists
[AfterEach] [sig-auth] ServiceAccounts
  test/e2e/framework/framework.go:187
Apr 26 12:16:08.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9357" for this suite. 04/26/24 12:16:08.487
{"msg":"PASSED [sig-auth] ServiceAccounts should mount projected service account token [Conformance]","completed":304,"skipped":5620,"failed":0}
------------------------------
â€¢ [4.238 seconds]
[sig-auth] ServiceAccounts
test/e2e/auth/framework.go:23
  should mount projected service account token [Conformance]
  test/e2e/auth/service_accounts.go:272

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:16:04.257
    Apr 26 12:16:04.257: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename svcaccounts 04/26/24 12:16:04.258
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:04.275
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:04.282
    [It] should mount projected service account token [Conformance]
      test/e2e/auth/service_accounts.go:272
    STEP: Creating a pod to test service account token:  04/26/24 12:16:04.287
    Apr 26 12:16:04.310: INFO: Waiting up to 5m0s for pod "test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57" in namespace "svcaccounts-9357" to be "Succeeded or Failed"
    Apr 26 12:16:04.315: INFO: Pod "test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57": Phase="Pending", Reason="", readiness=false. Elapsed: 5.158162ms
    Apr 26 12:16:06.323: INFO: Pod "test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01325911s
    Apr 26 12:16:08.321: INFO: Pod "test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011469318s
    STEP: Saw pod success 04/26/24 12:16:08.321
    Apr 26 12:16:08.321: INFO: Pod "test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57" satisfied condition "Succeeded or Failed"
    Apr 26 12:16:08.327: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57 container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 12:16:08.456
    Apr 26 12:16:08.471: INFO: Waiting for pod test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57 to disappear
    Apr 26 12:16:08.476: INFO: Pod test-pod-6b5697b1-2dbf-4e1f-9ceb-94c1659f7f57 no longer exists
    [AfterEach] [sig-auth] ServiceAccounts
      test/e2e/framework/framework.go:187
    Apr 26 12:16:08.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "svcaccounts-9357" for this suite. 04/26/24 12:16:08.487
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application
  should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:16:08.502
Apr 26 12:16:08.502: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 12:16:08.503
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:08.517
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:08.524
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should create and stop a working application  [Conformance]
  test/e2e/kubectl/kubectl.go:392
STEP: creating all guestbook components 04/26/24 12:16:08.529
Apr 26 12:16:08.529: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-replica
  labels:
    app: agnhost
    role: replica
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: agnhost
    role: replica
    tier: backend

Apr 26 12:16:08.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 create -f -'
Apr 26 12:16:09.207: INFO: stderr: ""
Apr 26 12:16:09.207: INFO: stdout: "service/agnhost-replica created\n"
Apr 26 12:16:09.207: INFO: apiVersion: v1
kind: Service
metadata:
  name: agnhost-primary
  labels:
    app: agnhost
    role: primary
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: agnhost
    role: primary
    tier: backend

Apr 26 12:16:09.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 create -f -'
Apr 26 12:16:09.833: INFO: stderr: ""
Apr 26 12:16:09.833: INFO: stdout: "service/agnhost-primary created\n"
Apr 26 12:16:09.833: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 26 12:16:09.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 create -f -'
Apr 26 12:16:09.986: INFO: stderr: ""
Apr 26 12:16:09.986: INFO: stdout: "service/frontend created\n"
Apr 26 12:16:09.986: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: guestbook-frontend
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--backend-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 80

Apr 26 12:16:09.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 create -f -'
Apr 26 12:16:10.128: INFO: stderr: ""
Apr 26 12:16:10.128: INFO: stdout: "deployment.apps/frontend created\n"
Apr 26 12:16:10.128: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-primary
spec:
  replicas: 1
  selector:
    matchLabels:
      app: agnhost
      role: primary
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      containers:
      - name: primary
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 26 12:16:10.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 create -f -'
Apr 26 12:16:10.307: INFO: stderr: ""
Apr 26 12:16:10.307: INFO: stdout: "deployment.apps/agnhost-primary created\n"
Apr 26 12:16:10.307: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: agnhost-replica
spec:
  replicas: 2
  selector:
    matchLabels:
      app: agnhost
      role: replica
      tier: backend
  template:
    metadata:
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      containers:
      - name: replica
        image: registry.k8s.io/e2e-test-images/agnhost:2.40
        args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 26 12:16:10.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 create -f -'
Apr 26 12:16:10.469: INFO: stderr: ""
Apr 26 12:16:10.469: INFO: stdout: "deployment.apps/agnhost-replica created\n"
STEP: validating guestbook app 04/26/24 12:16:10.469
Apr 26 12:16:10.469: INFO: Waiting for all frontend pods to be Running.
Apr 26 12:16:15.521: INFO: Waiting for frontend to serve content.
Apr 26 12:16:15.629: INFO: Trying to add a new entry to the guestbook.
Apr 26 12:16:15.769: INFO: Verifying that added entry can be retrieved.
Apr 26 12:16:15.820: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
STEP: using delete to clean up resources 04/26/24 12:16:20.933
Apr 26 12:16:20.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 delete --grace-period=0 --force -f -'
Apr 26 12:16:21.014: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 26 12:16:21.014: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
STEP: using delete to clean up resources 04/26/24 12:16:21.014
Apr 26 12:16:21.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 delete --grace-period=0 --force -f -'
Apr 26 12:16:21.085: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 26 12:16:21.085: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 04/26/24 12:16:21.085
Apr 26 12:16:21.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 delete --grace-period=0 --force -f -'
Apr 26 12:16:21.186: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 26 12:16:21.186: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources 04/26/24 12:16:21.186
Apr 26 12:16:21.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 delete --grace-period=0 --force -f -'
Apr 26 12:16:21.248: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 26 12:16:21.248: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources 04/26/24 12:16:21.248
Apr 26 12:16:21.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 delete --grace-period=0 --force -f -'
Apr 26 12:16:21.324: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 26 12:16:21.324: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
STEP: using delete to clean up resources 04/26/24 12:16:21.324
Apr 26 12:16:21.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 delete --grace-period=0 --force -f -'
Apr 26 12:16:21.405: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 26 12:16:21.405: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 12:16:21.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7494" for this suite. 04/26/24 12:16:21.423
{"msg":"PASSED [sig-cli] Kubectl client Guestbook application should create and stop a working application  [Conformance]","completed":305,"skipped":5646,"failed":0}
------------------------------
â€¢ [SLOW TEST] [12.941 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Guestbook application
  test/e2e/kubectl/kubectl.go:367
    should create and stop a working application  [Conformance]
    test/e2e/kubectl/kubectl.go:392

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:16:08.502
    Apr 26 12:16:08.502: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 12:16:08.503
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:08.517
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:08.524
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should create and stop a working application  [Conformance]
      test/e2e/kubectl/kubectl.go:392
    STEP: creating all guestbook components 04/26/24 12:16:08.529
    Apr 26 12:16:08.529: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-replica
      labels:
        app: agnhost
        role: replica
        tier: backend
    spec:
      ports:
      - port: 6379
      selector:
        app: agnhost
        role: replica
        tier: backend

    Apr 26 12:16:08.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 create -f -'
    Apr 26 12:16:09.207: INFO: stderr: ""
    Apr 26 12:16:09.207: INFO: stdout: "service/agnhost-replica created\n"
    Apr 26 12:16:09.207: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: agnhost-primary
      labels:
        app: agnhost
        role: primary
        tier: backend
    spec:
      ports:
      - port: 6379
        targetPort: 6379
      selector:
        app: agnhost
        role: primary
        tier: backend

    Apr 26 12:16:09.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 create -f -'
    Apr 26 12:16:09.833: INFO: stderr: ""
    Apr 26 12:16:09.833: INFO: stdout: "service/agnhost-primary created\n"
    Apr 26 12:16:09.833: INFO: apiVersion: v1
    kind: Service
    metadata:
      name: frontend
      labels:
        app: guestbook
        tier: frontend
    spec:
      # if your cluster supports it, uncomment the following to automatically create
      # an external load-balanced IP for the frontend service.
      # type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: guestbook
        tier: frontend

    Apr 26 12:16:09.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 create -f -'
    Apr 26 12:16:09.986: INFO: stderr: ""
    Apr 26 12:16:09.986: INFO: stdout: "service/frontend created\n"
    Apr 26 12:16:09.986: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: frontend
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: guestbook
          tier: frontend
      template:
        metadata:
          labels:
            app: guestbook
            tier: frontend
        spec:
          containers:
          - name: guestbook-frontend
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--backend-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 80

    Apr 26 12:16:09.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 create -f -'
    Apr 26 12:16:10.128: INFO: stderr: ""
    Apr 26 12:16:10.128: INFO: stdout: "deployment.apps/frontend created\n"
    Apr 26 12:16:10.128: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-primary
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: agnhost
          role: primary
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: primary
            tier: backend
        spec:
          containers:
          - name: primary
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Apr 26 12:16:10.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 create -f -'
    Apr 26 12:16:10.307: INFO: stderr: ""
    Apr 26 12:16:10.307: INFO: stdout: "deployment.apps/agnhost-primary created\n"
    Apr 26 12:16:10.307: INFO: apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: agnhost-replica
    spec:
      replicas: 2
      selector:
        matchLabels:
          app: agnhost
          role: replica
          tier: backend
      template:
        metadata:
          labels:
            app: agnhost
            role: replica
            tier: backend
        spec:
          containers:
          - name: replica
            image: registry.k8s.io/e2e-test-images/agnhost:2.40
            args: [ "guestbook", "--replicaof", "agnhost-primary", "--http-port", "6379" ]
            resources:
              requests:
                cpu: 100m
                memory: 100Mi
            ports:
            - containerPort: 6379

    Apr 26 12:16:10.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 create -f -'
    Apr 26 12:16:10.469: INFO: stderr: ""
    Apr 26 12:16:10.469: INFO: stdout: "deployment.apps/agnhost-replica created\n"
    STEP: validating guestbook app 04/26/24 12:16:10.469
    Apr 26 12:16:10.469: INFO: Waiting for all frontend pods to be Running.
    Apr 26 12:16:15.521: INFO: Waiting for frontend to serve content.
    Apr 26 12:16:15.629: INFO: Trying to add a new entry to the guestbook.
    Apr 26 12:16:15.769: INFO: Verifying that added entry can be retrieved.
    Apr 26 12:16:15.820: INFO: Failed to get response from guestbook. err: <nil>, response: {"data":""}
    STEP: using delete to clean up resources 04/26/24 12:16:20.933
    Apr 26 12:16:20.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 delete --grace-period=0 --force -f -'
    Apr 26 12:16:21.014: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 26 12:16:21.014: INFO: stdout: "service \"agnhost-replica\" force deleted\n"
    STEP: using delete to clean up resources 04/26/24 12:16:21.014
    Apr 26 12:16:21.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 delete --grace-period=0 --force -f -'
    Apr 26 12:16:21.085: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 26 12:16:21.085: INFO: stdout: "service \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 04/26/24 12:16:21.085
    Apr 26 12:16:21.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 delete --grace-period=0 --force -f -'
    Apr 26 12:16:21.186: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 26 12:16:21.186: INFO: stdout: "service \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 04/26/24 12:16:21.186
    Apr 26 12:16:21.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 delete --grace-period=0 --force -f -'
    Apr 26 12:16:21.248: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 26 12:16:21.248: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
    STEP: using delete to clean up resources 04/26/24 12:16:21.248
    Apr 26 12:16:21.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 delete --grace-period=0 --force -f -'
    Apr 26 12:16:21.324: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 26 12:16:21.324: INFO: stdout: "deployment.apps \"agnhost-primary\" force deleted\n"
    STEP: using delete to clean up resources 04/26/24 12:16:21.324
    Apr 26 12:16:21.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7494 delete --grace-period=0 --force -f -'
    Apr 26 12:16:21.405: INFO: stderr: "Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
    Apr 26 12:16:21.405: INFO: stdout: "deployment.apps \"agnhost-replica\" force deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 12:16:21.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7494" for this suite. 04/26/24 12:16:21.423
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:16:21.444
Apr 26 12:16:21.444: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 12:16:21.445
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:21.478
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:21.485
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185
STEP: fetching services 04/26/24 12:16:21.491
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 12:16:21.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7490" for this suite. 04/26/24 12:16:21.508
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should find a service from listing all namespaces [Conformance]","completed":306,"skipped":5659,"failed":0}
------------------------------
â€¢ [0.072 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should find a service from listing all namespaces [Conformance]
  test/e2e/network/service.go:3185

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:16:21.444
    Apr 26 12:16:21.444: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 12:16:21.445
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:21.478
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:21.485
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should find a service from listing all namespaces [Conformance]
      test/e2e/network/service.go:3185
    STEP: fetching services 04/26/24 12:16:21.491
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 12:16:21.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-7490" for this suite. 04/26/24 12:16:21.508
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:16:21.516
Apr 26 12:16:21.516: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 12:16:21.517
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:21.534
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:21.539
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46
STEP: Creating secret with name secret-test-7fe9aa6b-7e44-4b54-93c1-9729254a902e 04/26/24 12:16:21.544
STEP: Creating a pod to test consume secrets 04/26/24 12:16:21.549
Apr 26 12:16:21.575: INFO: Waiting up to 5m0s for pod "pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020" in namespace "secrets-1251" to be "Succeeded or Failed"
Apr 26 12:16:21.586: INFO: Pod "pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020": Phase="Pending", Reason="", readiness=false. Elapsed: 9.975279ms
Apr 26 12:16:23.592: INFO: Pod "pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016738634s
Apr 26 12:16:25.593: INFO: Pod "pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017255182s
STEP: Saw pod success 04/26/24 12:16:25.593
Apr 26 12:16:25.593: INFO: Pod "pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020" satisfied condition "Succeeded or Failed"
Apr 26 12:16:25.599: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020 container secret-volume-test: <nil>
STEP: delete the pod 04/26/24 12:16:25.761
Apr 26 12:16:25.774: INFO: Waiting for pod pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020 to disappear
Apr 26 12:16:25.801: INFO: Pod pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020 no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 26 12:16:25.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1251" for this suite. 04/26/24 12:16:25.814
{"msg":"PASSED [sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]","completed":307,"skipped":5669,"failed":0}
------------------------------
â€¢ [4.307 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:16:21.516
    Apr 26 12:16:21.516: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 12:16:21.517
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:21.534
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:21.539
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:46
    STEP: Creating secret with name secret-test-7fe9aa6b-7e44-4b54-93c1-9729254a902e 04/26/24 12:16:21.544
    STEP: Creating a pod to test consume secrets 04/26/24 12:16:21.549
    Apr 26 12:16:21.575: INFO: Waiting up to 5m0s for pod "pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020" in namespace "secrets-1251" to be "Succeeded or Failed"
    Apr 26 12:16:21.586: INFO: Pod "pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020": Phase="Pending", Reason="", readiness=false. Elapsed: 9.975279ms
    Apr 26 12:16:23.592: INFO: Pod "pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016738634s
    Apr 26 12:16:25.593: INFO: Pod "pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017255182s
    STEP: Saw pod success 04/26/24 12:16:25.593
    Apr 26 12:16:25.593: INFO: Pod "pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020" satisfied condition "Succeeded or Failed"
    Apr 26 12:16:25.599: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020 container secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 12:16:25.761
    Apr 26 12:16:25.774: INFO: Waiting for pod pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020 to disappear
    Apr 26 12:16:25.801: INFO: Pod pod-secrets-1d10bd5d-bfa5-4992-99a3-401ad8198020 no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 12:16:25.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-1251" for this suite. 04/26/24 12:16:25.814
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial]
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:16:25.824
Apr 26 12:16:25.824: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename daemonsets 04/26/24 12:16:25.825
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:25.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:25.844
[BeforeEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:145
[It] should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431
Apr 26 12:16:25.959: INFO: Create a RollingUpdate DaemonSet
Apr 26 12:16:25.978: INFO: Check that daemon pods launch on every node of the cluster
Apr 26 12:16:26.061: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 12:16:26.061: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 12:16:27.087: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 12:16:27.087: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
Apr 26 12:16:28.085: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
Apr 26 12:16:28.086: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
Apr 26 12:16:28.086: INFO: Update the DaemonSet to trigger a rollout
Apr 26 12:16:28.100: INFO: Updating DaemonSet daemon-set
Apr 26 12:16:31.137: INFO: Roll back the DaemonSet before rollout is complete
Apr 26 12:16:31.147: INFO: Updating DaemonSet daemon-set
Apr 26 12:16:31.147: INFO: Make sure DaemonSet rollback is complete
Apr 26 12:16:31.153: INFO: Wrong image for pod: daemon-set-6cwhn. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
Apr 26 12:16:31.153: INFO: Pod daemon-set-6cwhn is not available
Apr 26 12:16:34.173: INFO: Pod daemon-set-vh67g is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/apps/daemon_set.go:110
STEP: Deleting DaemonSet "daemon-set" 04/26/24 12:16:34.202
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-628, will wait for the garbage collector to delete the pods 04/26/24 12:16:34.202
Apr 26 12:16:34.265: INFO: Deleting DaemonSet.extensions daemon-set took: 8.354312ms
Apr 26 12:16:34.366: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.811329ms
Apr 26 12:16:35.779: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
Apr 26 12:16:35.779: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
Apr 26 12:16:35.791: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"46949"},"items":null}

Apr 26 12:16:35.799: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"46949"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  test/e2e/framework/framework.go:187
Apr 26 12:16:35.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-628" for this suite. 04/26/24 12:16:35.855
{"msg":"PASSED [sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]","completed":308,"skipped":5681,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.040 seconds]
[sig-apps] Daemon set [Serial]
test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  test/e2e/apps/daemon_set.go:431

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:16:25.824
    Apr 26 12:16:25.824: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename daemonsets 04/26/24 12:16:25.825
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:25.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:25.844
    [BeforeEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:145
    [It] should rollback without unnecessary restarts [Conformance]
      test/e2e/apps/daemon_set.go:431
    Apr 26 12:16:25.959: INFO: Create a RollingUpdate DaemonSet
    Apr 26 12:16:25.978: INFO: Check that daemon pods launch on every node of the cluster
    Apr 26 12:16:26.061: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 12:16:26.061: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 12:16:27.087: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 12:16:27.087: INFO: Node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh is running 0 daemon pod, expected 1
    Apr 26 12:16:28.085: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 5
    Apr 26 12:16:28.086: INFO: Number of running nodes: 5, number of available pods: 5 in daemonset daemon-set
    Apr 26 12:16:28.086: INFO: Update the DaemonSet to trigger a rollout
    Apr 26 12:16:28.100: INFO: Updating DaemonSet daemon-set
    Apr 26 12:16:31.137: INFO: Roll back the DaemonSet before rollout is complete
    Apr 26 12:16:31.147: INFO: Updating DaemonSet daemon-set
    Apr 26 12:16:31.147: INFO: Make sure DaemonSet rollback is complete
    Apr 26 12:16:31.153: INFO: Wrong image for pod: daemon-set-6cwhn. Expected: registry.k8s.io/e2e-test-images/httpd:2.4.38-2, got: foo:non-existent.
    Apr 26 12:16:31.153: INFO: Pod daemon-set-6cwhn is not available
    Apr 26 12:16:34.173: INFO: Pod daemon-set-vh67g is not available
    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/apps/daemon_set.go:110
    STEP: Deleting DaemonSet "daemon-set" 04/26/24 12:16:34.202
    STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-628, will wait for the garbage collector to delete the pods 04/26/24 12:16:34.202
    Apr 26 12:16:34.265: INFO: Deleting DaemonSet.extensions daemon-set took: 8.354312ms
    Apr 26 12:16:34.366: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.811329ms
    Apr 26 12:16:35.779: INFO: Number of nodes with available pods controlled by daemonset daemon-set: 0
    Apr 26 12:16:35.779: INFO: Number of running nodes: 0, number of available pods: 0 in daemonset daemon-set
    Apr 26 12:16:35.791: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"resourceVersion":"46949"},"items":null}

    Apr 26 12:16:35.799: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"resourceVersion":"46949"},"items":null}

    [AfterEach] [sig-apps] Daemon set [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 12:16:35.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "daemonsets-628" for this suite. 04/26/24 12:16:35.855
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:16:35.868
Apr 26 12:16:35.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename custom-resource-definition 04/26/24 12:16:35.869
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:35.887
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:35.893
[It] custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269
Apr 26 12:16:35.898: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:16:39.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3037" for this suite. 04/26/24 12:16:39.085
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works  [Conformance]","completed":309,"skipped":5705,"failed":0}
------------------------------
â€¢ [3.224 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  custom resource defaulting for requests and from storage works  [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:269

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:16:35.868
    Apr 26 12:16:35.868: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename custom-resource-definition 04/26/24 12:16:35.869
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:35.887
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:35.893
    [It] custom resource defaulting for requests and from storage works  [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:269
    Apr 26 12:16:35.898: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:16:39.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-3037" for this suite. 04/26/24 12:16:39.085
  << End Captured GinkgoWriter Output
------------------------------
SSSS
------------------------------
[sig-api-machinery] Watchers
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:16:39.093
Apr 26 12:16:39.093: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename watch 04/26/24 12:16:39.095
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:39.111
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:39.116
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257
STEP: creating a watch on configmaps with a certain label 04/26/24 12:16:39.122
STEP: creating a new configmap 04/26/24 12:16:39.125
STEP: modifying the configmap once 04/26/24 12:16:39.129
STEP: changing the label value of the configmap 04/26/24 12:16:39.137
STEP: Expecting to observe a delete notification for the watched object 04/26/24 12:16:39.146
Apr 26 12:16:39.146: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7322  904380e7-8a00-4cf9-ab8f-89acbe66e433 46987 0 2024-04-26 12:16:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-26 12:16:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 12:16:39.146: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7322  904380e7-8a00-4cf9-ab8f-89acbe66e433 46988 0 2024-04-26 12:16:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-26 12:16:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 12:16:39.146: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7322  904380e7-8a00-4cf9-ab8f-89acbe66e433 46989 0 2024-04-26 12:16:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-26 12:16:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time 04/26/24 12:16:39.146
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 04/26/24 12:16:39.154
STEP: changing the label value of the configmap back 04/26/24 12:16:49.155
STEP: modifying the configmap a third time 04/26/24 12:16:49.168
STEP: deleting the configmap 04/26/24 12:16:49.183
STEP: Expecting to observe an add notification for the watched object when the label value was restored 04/26/24 12:16:49.19
Apr 26 12:16:49.190: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7322  904380e7-8a00-4cf9-ab8f-89acbe66e433 47038 0 2024-04-26 12:16:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-26 12:16:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 12:16:49.190: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7322  904380e7-8a00-4cf9-ab8f-89acbe66e433 47039 0 2024-04-26 12:16:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-26 12:16:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 12:16:49.190: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7322  904380e7-8a00-4cf9-ab8f-89acbe66e433 47040 0 2024-04-26 12:16:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-26 12:16:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 26 12:16:49.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7322" for this suite. 04/26/24 12:16:49.202
{"msg":"PASSED [sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]","completed":310,"skipped":5709,"failed":0}
------------------------------
â€¢ [SLOW TEST] [10.115 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  test/e2e/apimachinery/watch.go:257

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:16:39.093
    Apr 26 12:16:39.093: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename watch 04/26/24 12:16:39.095
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:39.111
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:39.116
    [It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
      test/e2e/apimachinery/watch.go:257
    STEP: creating a watch on configmaps with a certain label 04/26/24 12:16:39.122
    STEP: creating a new configmap 04/26/24 12:16:39.125
    STEP: modifying the configmap once 04/26/24 12:16:39.129
    STEP: changing the label value of the configmap 04/26/24 12:16:39.137
    STEP: Expecting to observe a delete notification for the watched object 04/26/24 12:16:39.146
    Apr 26 12:16:39.146: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7322  904380e7-8a00-4cf9-ab8f-89acbe66e433 46987 0 2024-04-26 12:16:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-26 12:16:39 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 12:16:39.146: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7322  904380e7-8a00-4cf9-ab8f-89acbe66e433 46988 0 2024-04-26 12:16:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-26 12:16:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 12:16:39.146: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7322  904380e7-8a00-4cf9-ab8f-89acbe66e433 46989 0 2024-04-26 12:16:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-26 12:16:39 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time 04/26/24 12:16:39.146
    STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements 04/26/24 12:16:39.154
    STEP: changing the label value of the configmap back 04/26/24 12:16:49.155
    STEP: modifying the configmap a third time 04/26/24 12:16:49.168
    STEP: deleting the configmap 04/26/24 12:16:49.183
    STEP: Expecting to observe an add notification for the watched object when the label value was restored 04/26/24 12:16:49.19
    Apr 26 12:16:49.190: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7322  904380e7-8a00-4cf9-ab8f-89acbe66e433 47038 0 2024-04-26 12:16:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-26 12:16:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 12:16:49.190: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7322  904380e7-8a00-4cf9-ab8f-89acbe66e433 47039 0 2024-04-26 12:16:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-26 12:16:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 12:16:49.190: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7322  904380e7-8a00-4cf9-ab8f-89acbe66e433 47040 0 2024-04-26 12:16:39 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] [] [{e2e.test Update v1 2024-04-26 12:16:49 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 26 12:16:49.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-7322" for this suite. 04/26/24 12:16:49.202
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl diff
  should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:16:49.211
Apr 26 12:16:49.211: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 12:16:49.212
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:49.228
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:49.235
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if kubectl diff finds a difference for Deployments [Conformance]
  test/e2e/kubectl/kubectl.go:929
STEP: create deployment with httpd image 04/26/24 12:16:49.241
Apr 26 12:16:49.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7952 create -f -'
Apr 26 12:16:49.808: INFO: stderr: ""
Apr 26 12:16:49.808: INFO: stdout: "deployment.apps/httpd-deployment created\n"
STEP: verify diff finds difference between live and declared image 04/26/24 12:16:49.808
Apr 26 12:16:49.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7952 diff -f -'
Apr 26 12:16:49.968: INFO: rc: 1
Apr 26 12:16:49.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7952 delete -f -'
Apr 26 12:16:50.035: INFO: stderr: ""
Apr 26 12:16:50.035: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 12:16:50.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7952" for this suite. 04/26/24 12:16:50.052
{"msg":"PASSED [sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]","completed":311,"skipped":5738,"failed":0}
------------------------------
â€¢ [0.847 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl diff
  test/e2e/kubectl/kubectl.go:923
    should check if kubectl diff finds a difference for Deployments [Conformance]
    test/e2e/kubectl/kubectl.go:929

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:16:49.211
    Apr 26 12:16:49.211: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 12:16:49.212
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:49.228
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:49.235
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if kubectl diff finds a difference for Deployments [Conformance]
      test/e2e/kubectl/kubectl.go:929
    STEP: create deployment with httpd image 04/26/24 12:16:49.241
    Apr 26 12:16:49.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7952 create -f -'
    Apr 26 12:16:49.808: INFO: stderr: ""
    Apr 26 12:16:49.808: INFO: stdout: "deployment.apps/httpd-deployment created\n"
    STEP: verify diff finds difference between live and declared image 04/26/24 12:16:49.808
    Apr 26 12:16:49.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7952 diff -f -'
    Apr 26 12:16:49.968: INFO: rc: 1
    Apr 26 12:16:49.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7952 delete -f -'
    Apr 26 12:16:50.035: INFO: stderr: ""
    Apr 26 12:16:50.035: INFO: stdout: "deployment.apps \"httpd-deployment\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 12:16:50.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7952" for this suite. 04/26/24 12:16:50.052
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-storage] Projected configMap
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
[BeforeEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:16:50.058
Apr 26 12:16:50.058: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 12:16:50.059
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:50.072
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:50.077
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46
STEP: Creating configMap with name projected-configmap-test-volume-d4b68826-72aa-4c47-bbaf-96fb24277b60 04/26/24 12:16:50.082
STEP: Creating a pod to test consume configMaps 04/26/24 12:16:50.087
Apr 26 12:16:50.098: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2" in namespace "projected-1810" to be "Succeeded or Failed"
Apr 26 12:16:50.102: INFO: Pod "pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.09339ms
Apr 26 12:16:52.109: INFO: Pod "pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2": Phase="Running", Reason="", readiness=false. Elapsed: 2.011151965s
Apr 26 12:16:54.129: INFO: Pod "pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030979312s
STEP: Saw pod success 04/26/24 12:16:54.129
Apr 26 12:16:54.129: INFO: Pod "pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2" satisfied condition "Succeeded or Failed"
Apr 26 12:16:54.143: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2 container agnhost-container: <nil>
STEP: delete the pod 04/26/24 12:16:54.156
Apr 26 12:16:54.177: INFO: Waiting for pod pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2 to disappear
Apr 26 12:16:54.181: INFO: Pod pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  test/e2e/framework/framework.go:187
Apr 26 12:16:54.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1810" for this suite. 04/26/24 12:16:54.19
{"msg":"PASSED [sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]","completed":312,"skipped":5739,"failed":0}
------------------------------
â€¢ [4.139 seconds]
[sig-storage] Projected configMap
test/e2e/common/storage/framework.go:23
  should be consumable from pods in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_configmap.go:46

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:16:50.058
    Apr 26 12:16:50.058: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 12:16:50.059
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:50.072
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:50.077
    [It] should be consumable from pods in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_configmap.go:46
    STEP: Creating configMap with name projected-configmap-test-volume-d4b68826-72aa-4c47-bbaf-96fb24277b60 04/26/24 12:16:50.082
    STEP: Creating a pod to test consume configMaps 04/26/24 12:16:50.087
    Apr 26 12:16:50.098: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2" in namespace "projected-1810" to be "Succeeded or Failed"
    Apr 26 12:16:50.102: INFO: Pod "pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.09339ms
    Apr 26 12:16:52.109: INFO: Pod "pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2": Phase="Running", Reason="", readiness=false. Elapsed: 2.011151965s
    Apr 26 12:16:54.129: INFO: Pod "pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030979312s
    STEP: Saw pod success 04/26/24 12:16:54.129
    Apr 26 12:16:54.129: INFO: Pod "pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2" satisfied condition "Succeeded or Failed"
    Apr 26 12:16:54.143: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2 container agnhost-container: <nil>
    STEP: delete the pod 04/26/24 12:16:54.156
    Apr 26 12:16:54.177: INFO: Waiting for pod pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2 to disappear
    Apr 26 12:16:54.181: INFO: Pod pod-projected-configmaps-ae7ce7c5-863f-4ad7-8cc7-65d99d24bce2 no longer exists
    [AfterEach] [sig-storage] Projected configMap
      test/e2e/framework/framework.go:187
    Apr 26 12:16:54.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-1810" for this suite. 04/26/24 12:16:54.19
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:16:54.198
Apr 26 12:16:54.198: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 12:16:54.2
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:54.238
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:54.244
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146
STEP: Creating a pod to test emptydir 0777 on tmpfs 04/26/24 12:16:54.249
Apr 26 12:16:54.259: INFO: Waiting up to 5m0s for pod "pod-37264e2d-537a-4487-a57b-8529b908af56" in namespace "emptydir-5562" to be "Succeeded or Failed"
Apr 26 12:16:54.267: INFO: Pod "pod-37264e2d-537a-4487-a57b-8529b908af56": Phase="Pending", Reason="", readiness=false. Elapsed: 8.255358ms
Apr 26 12:16:56.275: INFO: Pod "pod-37264e2d-537a-4487-a57b-8529b908af56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016494061s
Apr 26 12:16:58.278: INFO: Pod "pod-37264e2d-537a-4487-a57b-8529b908af56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019264858s
STEP: Saw pod success 04/26/24 12:16:58.278
Apr 26 12:16:58.278: INFO: Pod "pod-37264e2d-537a-4487-a57b-8529b908af56" satisfied condition "Succeeded or Failed"
Apr 26 12:16:58.284: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-37264e2d-537a-4487-a57b-8529b908af56 container test-container: <nil>
STEP: delete the pod 04/26/24 12:16:58.298
Apr 26 12:16:58.338: INFO: Waiting for pod pod-37264e2d-537a-4487-a57b-8529b908af56 to disappear
Apr 26 12:16:58.374: INFO: Pod pod-37264e2d-537a-4487-a57b-8529b908af56 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 12:16:58.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5562" for this suite. 04/26/24 12:16:58.386
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]","completed":313,"skipped":5741,"failed":0}
------------------------------
â€¢ [4.195 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:146

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:16:54.198
    Apr 26 12:16:54.198: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 12:16:54.2
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:54.238
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:54.244
    [It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:146
    STEP: Creating a pod to test emptydir 0777 on tmpfs 04/26/24 12:16:54.249
    Apr 26 12:16:54.259: INFO: Waiting up to 5m0s for pod "pod-37264e2d-537a-4487-a57b-8529b908af56" in namespace "emptydir-5562" to be "Succeeded or Failed"
    Apr 26 12:16:54.267: INFO: Pod "pod-37264e2d-537a-4487-a57b-8529b908af56": Phase="Pending", Reason="", readiness=false. Elapsed: 8.255358ms
    Apr 26 12:16:56.275: INFO: Pod "pod-37264e2d-537a-4487-a57b-8529b908af56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016494061s
    Apr 26 12:16:58.278: INFO: Pod "pod-37264e2d-537a-4487-a57b-8529b908af56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019264858s
    STEP: Saw pod success 04/26/24 12:16:58.278
    Apr 26 12:16:58.278: INFO: Pod "pod-37264e2d-537a-4487-a57b-8529b908af56" satisfied condition "Succeeded or Failed"
    Apr 26 12:16:58.284: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-37264e2d-537a-4487-a57b-8529b908af56 container test-container: <nil>
    STEP: delete the pod 04/26/24 12:16:58.298
    Apr 26 12:16:58.338: INFO: Waiting for pod pod-37264e2d-537a-4487-a57b-8529b908af56 to disappear
    Apr 26 12:16:58.374: INFO: Pod pod-37264e2d-537a-4487-a57b-8529b908af56 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 12:16:58.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-5562" for this suite. 04/26/24 12:16:58.386
  << End Captured GinkgoWriter Output
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes
  should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
[BeforeEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:16:58.396
Apr 26 12:16:58.397: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename subpath 04/26/24 12:16:58.398
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:58.434
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:58.44
[BeforeEach] Atomic writer volumes
  test/e2e/storage/subpath.go:40
STEP: Setting up data 04/26/24 12:16:58.446
[It] should support subpaths with secret pod [Conformance]
  test/e2e/storage/subpath.go:60
STEP: Creating pod pod-subpath-test-secret-kmbp 04/26/24 12:16:58.469
STEP: Creating a pod to test atomic-volume-subpath 04/26/24 12:16:58.469
Apr 26 12:16:58.484: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-kmbp" in namespace "subpath-2026" to be "Succeeded or Failed"
Apr 26 12:16:58.506: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Pending", Reason="", readiness=false. Elapsed: 22.466967ms
Apr 26 12:17:00.517: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 2.032870625s
Apr 26 12:17:02.514: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 4.030001949s
Apr 26 12:17:04.512: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 6.028150167s
Apr 26 12:17:06.513: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 8.029676794s
Apr 26 12:17:08.514: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 10.030401077s
Apr 26 12:17:10.513: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 12.029398132s
Apr 26 12:17:12.516: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 14.032188191s
Apr 26 12:17:14.514: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 16.030489243s
Apr 26 12:17:16.514: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 18.030305209s
Apr 26 12:17:18.512: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 20.028087031s
Apr 26 12:17:20.513: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=false. Elapsed: 22.029345293s
Apr 26 12:17:22.513: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.028912652s
STEP: Saw pod success 04/26/24 12:17:22.513
Apr 26 12:17:22.513: INFO: Pod "pod-subpath-test-secret-kmbp" satisfied condition "Succeeded or Failed"
Apr 26 12:17:22.519: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-subpath-test-secret-kmbp container test-container-subpath-secret-kmbp: <nil>
STEP: delete the pod 04/26/24 12:17:22.535
Apr 26 12:17:22.580: INFO: Waiting for pod pod-subpath-test-secret-kmbp to disappear
Apr 26 12:17:22.609: INFO: Pod pod-subpath-test-secret-kmbp no longer exists
STEP: Deleting pod pod-subpath-test-secret-kmbp 04/26/24 12:17:22.609
Apr 26 12:17:22.609: INFO: Deleting pod "pod-subpath-test-secret-kmbp" in namespace "subpath-2026"
[AfterEach] [sig-storage] Subpath
  test/e2e/framework/framework.go:187
Apr 26 12:17:22.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2026" for this suite. 04/26/24 12:17:22.626
{"msg":"PASSED [sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]","completed":314,"skipped":5747,"failed":0}
------------------------------
â€¢ [SLOW TEST] [24.237 seconds]
[sig-storage] Subpath
test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  test/e2e/storage/subpath.go:36
    should support subpaths with secret pod [Conformance]
    test/e2e/storage/subpath.go:60

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:16:58.396
    Apr 26 12:16:58.397: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename subpath 04/26/24 12:16:58.398
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:16:58.434
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:16:58.44
    [BeforeEach] Atomic writer volumes
      test/e2e/storage/subpath.go:40
    STEP: Setting up data 04/26/24 12:16:58.446
    [It] should support subpaths with secret pod [Conformance]
      test/e2e/storage/subpath.go:60
    STEP: Creating pod pod-subpath-test-secret-kmbp 04/26/24 12:16:58.469
    STEP: Creating a pod to test atomic-volume-subpath 04/26/24 12:16:58.469
    Apr 26 12:16:58.484: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-kmbp" in namespace "subpath-2026" to be "Succeeded or Failed"
    Apr 26 12:16:58.506: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Pending", Reason="", readiness=false. Elapsed: 22.466967ms
    Apr 26 12:17:00.517: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 2.032870625s
    Apr 26 12:17:02.514: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 4.030001949s
    Apr 26 12:17:04.512: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 6.028150167s
    Apr 26 12:17:06.513: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 8.029676794s
    Apr 26 12:17:08.514: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 10.030401077s
    Apr 26 12:17:10.513: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 12.029398132s
    Apr 26 12:17:12.516: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 14.032188191s
    Apr 26 12:17:14.514: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 16.030489243s
    Apr 26 12:17:16.514: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 18.030305209s
    Apr 26 12:17:18.512: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=true. Elapsed: 20.028087031s
    Apr 26 12:17:20.513: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Running", Reason="", readiness=false. Elapsed: 22.029345293s
    Apr 26 12:17:22.513: INFO: Pod "pod-subpath-test-secret-kmbp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.028912652s
    STEP: Saw pod success 04/26/24 12:17:22.513
    Apr 26 12:17:22.513: INFO: Pod "pod-subpath-test-secret-kmbp" satisfied condition "Succeeded or Failed"
    Apr 26 12:17:22.519: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-subpath-test-secret-kmbp container test-container-subpath-secret-kmbp: <nil>
    STEP: delete the pod 04/26/24 12:17:22.535
    Apr 26 12:17:22.580: INFO: Waiting for pod pod-subpath-test-secret-kmbp to disappear
    Apr 26 12:17:22.609: INFO: Pod pod-subpath-test-secret-kmbp no longer exists
    STEP: Deleting pod pod-subpath-test-secret-kmbp 04/26/24 12:17:22.609
    Apr 26 12:17:22.609: INFO: Deleting pod "pod-subpath-test-secret-kmbp" in namespace "subpath-2026"
    [AfterEach] [sig-storage] Subpath
      test/e2e/framework/framework.go:187
    Apr 26 12:17:22.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "subpath-2026" for this suite. 04/26/24 12:17:22.626
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:17:22.64
Apr 26 12:17:22.640: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 12:17:22.641
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:17:22.672
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:17:22.677
[It] updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390
STEP: set up a multi version CRD 04/26/24 12:17:22.682
Apr 26 12:17:22.683: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: rename a version 04/26/24 12:17:29.238
STEP: check the new version name is served 04/26/24 12:17:29.265
STEP: check the old version name is removed 04/26/24 12:17:31.994
STEP: check the other version is not changed 04/26/24 12:17:33.333
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:17:38.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-570" for this suite. 04/26/24 12:17:38.309
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]","completed":315,"skipped":5791,"failed":0}
------------------------------
â€¢ [SLOW TEST] [15.676 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:390

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:17:22.64
    Apr 26 12:17:22.640: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 12:17:22.641
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:17:22.672
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:17:22.677
    [It] updates the published spec when one version gets renamed [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:390
    STEP: set up a multi version CRD 04/26/24 12:17:22.682
    Apr 26 12:17:22.683: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: rename a version 04/26/24 12:17:29.238
    STEP: check the new version name is served 04/26/24 12:17:29.265
    STEP: check the old version name is removed 04/26/24 12:17:31.994
    STEP: check the other version is not changed 04/26/24 12:17:33.333
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:17:38.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-570" for this suite. 04/26/24 12:17:38.309
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Discovery
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:17:38.322
Apr 26 12:17:38.322: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename discovery 04/26/24 12:17:38.323
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:17:38.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:17:38.352
[BeforeEach] [sig-api-machinery] Discovery
  test/e2e/apimachinery/discovery.go:43
STEP: Setting up server cert 04/26/24 12:17:38.371
[It] should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122
Apr 26 12:17:38.742: INFO: Checking APIGroup: apiregistration.k8s.io
Apr 26 12:17:38.745: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
Apr 26 12:17:38.745: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
Apr 26 12:17:38.745: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
Apr 26 12:17:38.745: INFO: Checking APIGroup: apps
Apr 26 12:17:38.748: INFO: PreferredVersion.GroupVersion: apps/v1
Apr 26 12:17:38.748: INFO: Versions found [{apps/v1 v1}]
Apr 26 12:17:38.748: INFO: apps/v1 matches apps/v1
Apr 26 12:17:38.748: INFO: Checking APIGroup: events.k8s.io
Apr 26 12:17:38.751: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
Apr 26 12:17:38.751: INFO: Versions found [{events.k8s.io/v1 v1}]
Apr 26 12:17:38.751: INFO: events.k8s.io/v1 matches events.k8s.io/v1
Apr 26 12:17:38.751: INFO: Checking APIGroup: authentication.k8s.io
Apr 26 12:17:38.754: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
Apr 26 12:17:38.755: INFO: Versions found [{authentication.k8s.io/v1 v1}]
Apr 26 12:17:38.755: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
Apr 26 12:17:38.755: INFO: Checking APIGroup: authorization.k8s.io
Apr 26 12:17:38.759: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
Apr 26 12:17:38.759: INFO: Versions found [{authorization.k8s.io/v1 v1}]
Apr 26 12:17:38.759: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
Apr 26 12:17:38.759: INFO: Checking APIGroup: autoscaling
Apr 26 12:17:38.762: INFO: PreferredVersion.GroupVersion: autoscaling/v2
Apr 26 12:17:38.762: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
Apr 26 12:17:38.762: INFO: autoscaling/v2 matches autoscaling/v2
Apr 26 12:17:38.762: INFO: Checking APIGroup: batch
Apr 26 12:17:38.765: INFO: PreferredVersion.GroupVersion: batch/v1
Apr 26 12:17:38.765: INFO: Versions found [{batch/v1 v1}]
Apr 26 12:17:38.765: INFO: batch/v1 matches batch/v1
Apr 26 12:17:38.765: INFO: Checking APIGroup: certificates.k8s.io
Apr 26 12:17:38.768: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
Apr 26 12:17:38.768: INFO: Versions found [{certificates.k8s.io/v1 v1}]
Apr 26 12:17:38.768: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
Apr 26 12:17:38.768: INFO: Checking APIGroup: networking.k8s.io
Apr 26 12:17:38.771: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
Apr 26 12:17:38.771: INFO: Versions found [{networking.k8s.io/v1 v1}]
Apr 26 12:17:38.771: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
Apr 26 12:17:38.771: INFO: Checking APIGroup: policy
Apr 26 12:17:38.773: INFO: PreferredVersion.GroupVersion: policy/v1
Apr 26 12:17:38.773: INFO: Versions found [{policy/v1 v1}]
Apr 26 12:17:38.773: INFO: policy/v1 matches policy/v1
Apr 26 12:17:38.773: INFO: Checking APIGroup: rbac.authorization.k8s.io
Apr 26 12:17:38.775: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
Apr 26 12:17:38.775: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
Apr 26 12:17:38.775: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
Apr 26 12:17:38.775: INFO: Checking APIGroup: storage.k8s.io
Apr 26 12:17:38.778: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
Apr 26 12:17:38.778: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
Apr 26 12:17:38.778: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
Apr 26 12:17:38.778: INFO: Checking APIGroup: admissionregistration.k8s.io
Apr 26 12:17:38.780: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
Apr 26 12:17:38.780: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
Apr 26 12:17:38.780: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
Apr 26 12:17:38.780: INFO: Checking APIGroup: apiextensions.k8s.io
Apr 26 12:17:38.783: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
Apr 26 12:17:38.783: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
Apr 26 12:17:38.783: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
Apr 26 12:17:38.783: INFO: Checking APIGroup: scheduling.k8s.io
Apr 26 12:17:38.785: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
Apr 26 12:17:38.785: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
Apr 26 12:17:38.785: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
Apr 26 12:17:38.785: INFO: Checking APIGroup: coordination.k8s.io
Apr 26 12:17:38.788: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
Apr 26 12:17:38.788: INFO: Versions found [{coordination.k8s.io/v1 v1}]
Apr 26 12:17:38.788: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
Apr 26 12:17:38.788: INFO: Checking APIGroup: node.k8s.io
Apr 26 12:17:38.790: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
Apr 26 12:17:38.790: INFO: Versions found [{node.k8s.io/v1 v1}]
Apr 26 12:17:38.790: INFO: node.k8s.io/v1 matches node.k8s.io/v1
Apr 26 12:17:38.790: INFO: Checking APIGroup: discovery.k8s.io
Apr 26 12:17:38.792: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
Apr 26 12:17:38.792: INFO: Versions found [{discovery.k8s.io/v1 v1}]
Apr 26 12:17:38.792: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
Apr 26 12:17:38.792: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
Apr 26 12:17:38.794: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
Apr 26 12:17:38.794: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
Apr 26 12:17:38.794: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
Apr 26 12:17:38.794: INFO: Checking APIGroup: crd.projectcalico.org
Apr 26 12:17:38.797: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
Apr 26 12:17:38.797: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
Apr 26 12:17:38.797: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
Apr 26 12:17:38.797: INFO: Checking APIGroup: snapshot.storage.k8s.io
Apr 26 12:17:38.799: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
Apr 26 12:17:38.799: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1}]
Apr 26 12:17:38.799: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
Apr 26 12:17:38.799: INFO: Checking APIGroup: metrics.k8s.io
Apr 26 12:17:38.802: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
Apr 26 12:17:38.802: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
Apr 26 12:17:38.802: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
[AfterEach] [sig-api-machinery] Discovery
  test/e2e/framework/framework.go:187
Apr 26 12:17:38.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "discovery-693" for this suite. 04/26/24 12:17:38.815
{"msg":"PASSED [sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]","completed":316,"skipped":5830,"failed":0}
------------------------------
â€¢ [0.499 seconds]
[sig-api-machinery] Discovery
test/e2e/apimachinery/framework.go:23
  should validate PreferredVersion for each APIGroup [Conformance]
  test/e2e/apimachinery/discovery.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:17:38.322
    Apr 26 12:17:38.322: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename discovery 04/26/24 12:17:38.323
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:17:38.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:17:38.352
    [BeforeEach] [sig-api-machinery] Discovery
      test/e2e/apimachinery/discovery.go:43
    STEP: Setting up server cert 04/26/24 12:17:38.371
    [It] should validate PreferredVersion for each APIGroup [Conformance]
      test/e2e/apimachinery/discovery.go:122
    Apr 26 12:17:38.742: INFO: Checking APIGroup: apiregistration.k8s.io
    Apr 26 12:17:38.745: INFO: PreferredVersion.GroupVersion: apiregistration.k8s.io/v1
    Apr 26 12:17:38.745: INFO: Versions found [{apiregistration.k8s.io/v1 v1}]
    Apr 26 12:17:38.745: INFO: apiregistration.k8s.io/v1 matches apiregistration.k8s.io/v1
    Apr 26 12:17:38.745: INFO: Checking APIGroup: apps
    Apr 26 12:17:38.748: INFO: PreferredVersion.GroupVersion: apps/v1
    Apr 26 12:17:38.748: INFO: Versions found [{apps/v1 v1}]
    Apr 26 12:17:38.748: INFO: apps/v1 matches apps/v1
    Apr 26 12:17:38.748: INFO: Checking APIGroup: events.k8s.io
    Apr 26 12:17:38.751: INFO: PreferredVersion.GroupVersion: events.k8s.io/v1
    Apr 26 12:17:38.751: INFO: Versions found [{events.k8s.io/v1 v1}]
    Apr 26 12:17:38.751: INFO: events.k8s.io/v1 matches events.k8s.io/v1
    Apr 26 12:17:38.751: INFO: Checking APIGroup: authentication.k8s.io
    Apr 26 12:17:38.754: INFO: PreferredVersion.GroupVersion: authentication.k8s.io/v1
    Apr 26 12:17:38.755: INFO: Versions found [{authentication.k8s.io/v1 v1}]
    Apr 26 12:17:38.755: INFO: authentication.k8s.io/v1 matches authentication.k8s.io/v1
    Apr 26 12:17:38.755: INFO: Checking APIGroup: authorization.k8s.io
    Apr 26 12:17:38.759: INFO: PreferredVersion.GroupVersion: authorization.k8s.io/v1
    Apr 26 12:17:38.759: INFO: Versions found [{authorization.k8s.io/v1 v1}]
    Apr 26 12:17:38.759: INFO: authorization.k8s.io/v1 matches authorization.k8s.io/v1
    Apr 26 12:17:38.759: INFO: Checking APIGroup: autoscaling
    Apr 26 12:17:38.762: INFO: PreferredVersion.GroupVersion: autoscaling/v2
    Apr 26 12:17:38.762: INFO: Versions found [{autoscaling/v2 v2} {autoscaling/v1 v1} {autoscaling/v2beta2 v2beta2}]
    Apr 26 12:17:38.762: INFO: autoscaling/v2 matches autoscaling/v2
    Apr 26 12:17:38.762: INFO: Checking APIGroup: batch
    Apr 26 12:17:38.765: INFO: PreferredVersion.GroupVersion: batch/v1
    Apr 26 12:17:38.765: INFO: Versions found [{batch/v1 v1}]
    Apr 26 12:17:38.765: INFO: batch/v1 matches batch/v1
    Apr 26 12:17:38.765: INFO: Checking APIGroup: certificates.k8s.io
    Apr 26 12:17:38.768: INFO: PreferredVersion.GroupVersion: certificates.k8s.io/v1
    Apr 26 12:17:38.768: INFO: Versions found [{certificates.k8s.io/v1 v1}]
    Apr 26 12:17:38.768: INFO: certificates.k8s.io/v1 matches certificates.k8s.io/v1
    Apr 26 12:17:38.768: INFO: Checking APIGroup: networking.k8s.io
    Apr 26 12:17:38.771: INFO: PreferredVersion.GroupVersion: networking.k8s.io/v1
    Apr 26 12:17:38.771: INFO: Versions found [{networking.k8s.io/v1 v1}]
    Apr 26 12:17:38.771: INFO: networking.k8s.io/v1 matches networking.k8s.io/v1
    Apr 26 12:17:38.771: INFO: Checking APIGroup: policy
    Apr 26 12:17:38.773: INFO: PreferredVersion.GroupVersion: policy/v1
    Apr 26 12:17:38.773: INFO: Versions found [{policy/v1 v1}]
    Apr 26 12:17:38.773: INFO: policy/v1 matches policy/v1
    Apr 26 12:17:38.773: INFO: Checking APIGroup: rbac.authorization.k8s.io
    Apr 26 12:17:38.775: INFO: PreferredVersion.GroupVersion: rbac.authorization.k8s.io/v1
    Apr 26 12:17:38.775: INFO: Versions found [{rbac.authorization.k8s.io/v1 v1}]
    Apr 26 12:17:38.775: INFO: rbac.authorization.k8s.io/v1 matches rbac.authorization.k8s.io/v1
    Apr 26 12:17:38.775: INFO: Checking APIGroup: storage.k8s.io
    Apr 26 12:17:38.778: INFO: PreferredVersion.GroupVersion: storage.k8s.io/v1
    Apr 26 12:17:38.778: INFO: Versions found [{storage.k8s.io/v1 v1} {storage.k8s.io/v1beta1 v1beta1}]
    Apr 26 12:17:38.778: INFO: storage.k8s.io/v1 matches storage.k8s.io/v1
    Apr 26 12:17:38.778: INFO: Checking APIGroup: admissionregistration.k8s.io
    Apr 26 12:17:38.780: INFO: PreferredVersion.GroupVersion: admissionregistration.k8s.io/v1
    Apr 26 12:17:38.780: INFO: Versions found [{admissionregistration.k8s.io/v1 v1}]
    Apr 26 12:17:38.780: INFO: admissionregistration.k8s.io/v1 matches admissionregistration.k8s.io/v1
    Apr 26 12:17:38.780: INFO: Checking APIGroup: apiextensions.k8s.io
    Apr 26 12:17:38.783: INFO: PreferredVersion.GroupVersion: apiextensions.k8s.io/v1
    Apr 26 12:17:38.783: INFO: Versions found [{apiextensions.k8s.io/v1 v1}]
    Apr 26 12:17:38.783: INFO: apiextensions.k8s.io/v1 matches apiextensions.k8s.io/v1
    Apr 26 12:17:38.783: INFO: Checking APIGroup: scheduling.k8s.io
    Apr 26 12:17:38.785: INFO: PreferredVersion.GroupVersion: scheduling.k8s.io/v1
    Apr 26 12:17:38.785: INFO: Versions found [{scheduling.k8s.io/v1 v1}]
    Apr 26 12:17:38.785: INFO: scheduling.k8s.io/v1 matches scheduling.k8s.io/v1
    Apr 26 12:17:38.785: INFO: Checking APIGroup: coordination.k8s.io
    Apr 26 12:17:38.788: INFO: PreferredVersion.GroupVersion: coordination.k8s.io/v1
    Apr 26 12:17:38.788: INFO: Versions found [{coordination.k8s.io/v1 v1}]
    Apr 26 12:17:38.788: INFO: coordination.k8s.io/v1 matches coordination.k8s.io/v1
    Apr 26 12:17:38.788: INFO: Checking APIGroup: node.k8s.io
    Apr 26 12:17:38.790: INFO: PreferredVersion.GroupVersion: node.k8s.io/v1
    Apr 26 12:17:38.790: INFO: Versions found [{node.k8s.io/v1 v1}]
    Apr 26 12:17:38.790: INFO: node.k8s.io/v1 matches node.k8s.io/v1
    Apr 26 12:17:38.790: INFO: Checking APIGroup: discovery.k8s.io
    Apr 26 12:17:38.792: INFO: PreferredVersion.GroupVersion: discovery.k8s.io/v1
    Apr 26 12:17:38.792: INFO: Versions found [{discovery.k8s.io/v1 v1}]
    Apr 26 12:17:38.792: INFO: discovery.k8s.io/v1 matches discovery.k8s.io/v1
    Apr 26 12:17:38.792: INFO: Checking APIGroup: flowcontrol.apiserver.k8s.io
    Apr 26 12:17:38.794: INFO: PreferredVersion.GroupVersion: flowcontrol.apiserver.k8s.io/v1beta2
    Apr 26 12:17:38.794: INFO: Versions found [{flowcontrol.apiserver.k8s.io/v1beta2 v1beta2} {flowcontrol.apiserver.k8s.io/v1beta1 v1beta1}]
    Apr 26 12:17:38.794: INFO: flowcontrol.apiserver.k8s.io/v1beta2 matches flowcontrol.apiserver.k8s.io/v1beta2
    Apr 26 12:17:38.794: INFO: Checking APIGroup: crd.projectcalico.org
    Apr 26 12:17:38.797: INFO: PreferredVersion.GroupVersion: crd.projectcalico.org/v1
    Apr 26 12:17:38.797: INFO: Versions found [{crd.projectcalico.org/v1 v1}]
    Apr 26 12:17:38.797: INFO: crd.projectcalico.org/v1 matches crd.projectcalico.org/v1
    Apr 26 12:17:38.797: INFO: Checking APIGroup: snapshot.storage.k8s.io
    Apr 26 12:17:38.799: INFO: PreferredVersion.GroupVersion: snapshot.storage.k8s.io/v1
    Apr 26 12:17:38.799: INFO: Versions found [{snapshot.storage.k8s.io/v1 v1}]
    Apr 26 12:17:38.799: INFO: snapshot.storage.k8s.io/v1 matches snapshot.storage.k8s.io/v1
    Apr 26 12:17:38.799: INFO: Checking APIGroup: metrics.k8s.io
    Apr 26 12:17:38.802: INFO: PreferredVersion.GroupVersion: metrics.k8s.io/v1beta1
    Apr 26 12:17:38.802: INFO: Versions found [{metrics.k8s.io/v1beta1 v1beta1}]
    Apr 26 12:17:38.802: INFO: metrics.k8s.io/v1beta1 matches metrics.k8s.io/v1beta1
    [AfterEach] [sig-api-machinery] Discovery
      test/e2e/framework/framework.go:187
    Apr 26 12:17:38.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "discovery-693" for this suite. 04/26/24 12:17:38.815
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] InitContainer [NodeConformance]
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:17:38.823
Apr 26 12:17:38.823: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename init-container 04/26/24 12:17:38.823
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:17:38.857
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:17:38.862
[BeforeEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/common/node/init_container.go:164
[It] should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176
STEP: creating the pod 04/26/24 12:17:38.867
Apr 26 12:17:38.867: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [sig-node] InitContainer [NodeConformance]
  test/e2e/framework/framework.go:187
Apr 26 12:17:44.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3587" for this suite. 04/26/24 12:17:44.03
{"msg":"PASSED [sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]","completed":317,"skipped":5855,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.214 seconds]
[sig-node] InitContainer [NodeConformance]
test/e2e/common/node/framework.go:23
  should invoke init containers on a RestartNever pod [Conformance]
  test/e2e/common/node/init_container.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:17:38.823
    Apr 26 12:17:38.823: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename init-container 04/26/24 12:17:38.823
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:17:38.857
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:17:38.862
    [BeforeEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/common/node/init_container.go:164
    [It] should invoke init containers on a RestartNever pod [Conformance]
      test/e2e/common/node/init_container.go:176
    STEP: creating the pod 04/26/24 12:17:38.867
    Apr 26 12:17:38.867: INFO: PodSpec: initContainers in spec.initContainers
    [AfterEach] [sig-node] InitContainer [NodeConformance]
      test/e2e/framework/framework.go:187
    Apr 26 12:17:44.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "init-container-3587" for this suite. 04/26/24 12:17:44.03
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl logs
  should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:17:44.037
Apr 26 12:17:44.037: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 12:17:44.039
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:17:44.056
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:17:44.062
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1570
STEP: creating an pod 04/26/24 12:17:44.068
Apr 26 12:17:44.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr 26 12:17:44.143: INFO: stderr: ""
Apr 26 12:17:44.143: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  test/e2e/kubectl/kubectl.go:1590
STEP: Waiting for log generator to start. 04/26/24 12:17:44.144
Apr 26 12:17:44.144: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr 26 12:17:44.144: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-3795" to be "running and ready, or succeeded"
Apr 26 12:17:44.150: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.93881ms
Apr 26 12:17:44.150: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j' to be 'Running' but was 'Pending'
Apr 26 12:17:46.157: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.013467394s
Apr 26 12:17:46.157: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr 26 12:17:46.157: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings 04/26/24 12:17:46.157
Apr 26 12:17:46.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 logs logs-generator logs-generator'
Apr 26 12:17:46.248: INFO: stderr: ""
Apr 26 12:17:46.248: INFO: stdout: "I0426 12:17:44.756381       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/5mjv 227\nI0426 12:17:44.956823       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/jtr 503\nI0426 12:17:45.157175       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/6lh 339\nI0426 12:17:45.356431       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/xbq4 547\nI0426 12:17:45.556743       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/x8pn 544\nI0426 12:17:45.757175       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/wvj 289\nI0426 12:17:45.956496       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/2d4q 585\nI0426 12:17:46.157004       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/dlsv 376\n"
STEP: limiting log lines 04/26/24 12:17:46.248
Apr 26 12:17:46.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 logs logs-generator logs-generator --tail=1'
Apr 26 12:17:46.323: INFO: stderr: ""
Apr 26 12:17:46.323: INFO: stdout: "I0426 12:17:46.157004       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/dlsv 376\n"
Apr 26 12:17:46.323: INFO: got output "I0426 12:17:46.157004       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/dlsv 376\n"
STEP: limiting log bytes 04/26/24 12:17:46.323
Apr 26 12:17:46.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 logs logs-generator logs-generator --limit-bytes=1'
Apr 26 12:17:46.453: INFO: stderr: ""
Apr 26 12:17:46.453: INFO: stdout: "I"
Apr 26 12:17:46.453: INFO: got output "I"
STEP: exposing timestamps 04/26/24 12:17:46.453
Apr 26 12:17:46.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 logs logs-generator logs-generator --tail=1 --timestamps'
Apr 26 12:17:46.531: INFO: stderr: ""
Apr 26 12:17:46.531: INFO: stdout: "2024-04-26T12:17:46.357614971Z I0426 12:17:46.357363       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/qtfb 242\n"
Apr 26 12:17:46.531: INFO: got output "2024-04-26T12:17:46.357614971Z I0426 12:17:46.357363       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/qtfb 242\n"
STEP: restricting to a time range 04/26/24 12:17:46.531
Apr 26 12:17:49.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 logs logs-generator logs-generator --since=1s'
Apr 26 12:17:49.177: INFO: stderr: ""
Apr 26 12:17:49.177: INFO: stdout: "I0426 12:17:48.357074       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/24g9 382\nI0426 12:17:48.557481       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/xl2 336\nI0426 12:17:48.756921       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/8x4 268\nI0426 12:17:48.957328       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/k4x 203\nI0426 12:17:49.156660       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/gdn 296\n"
Apr 26 12:17:49.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 logs logs-generator logs-generator --since=24h'
Apr 26 12:17:49.277: INFO: stderr: ""
Apr 26 12:17:49.277: INFO: stdout: "I0426 12:17:44.756381       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/5mjv 227\nI0426 12:17:44.956823       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/jtr 503\nI0426 12:17:45.157175       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/6lh 339\nI0426 12:17:45.356431       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/xbq4 547\nI0426 12:17:45.556743       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/x8pn 544\nI0426 12:17:45.757175       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/wvj 289\nI0426 12:17:45.956496       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/2d4q 585\nI0426 12:17:46.157004       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/dlsv 376\nI0426 12:17:46.357363       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/qtfb 242\nI0426 12:17:46.556603       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/2rlm 362\nI0426 12:17:46.757043       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/dmjz 295\nI0426 12:17:46.957450       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/9kd7 356\nI0426 12:17:47.156868       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/5hlv 356\nI0426 12:17:47.357241       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/zth 397\nI0426 12:17:47.556543       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/6r9 432\nI0426 12:17:47.756912       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/f6v2 369\nI0426 12:17:47.957328       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/zdgp 489\nI0426 12:17:48.156670       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/4bs 289\nI0426 12:17:48.357074       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/24g9 382\nI0426 12:17:48.557481       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/xl2 336\nI0426 12:17:48.756921       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/8x4 268\nI0426 12:17:48.957328       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/k4x 203\nI0426 12:17:49.156660       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/gdn 296\n"
[AfterEach] Kubectl logs
  test/e2e/kubectl/kubectl.go:1575
Apr 26 12:17:49.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 delete pod logs-generator'
Apr 26 12:17:50.530: INFO: stderr: ""
Apr 26 12:17:50.530: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 12:17:50.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3795" for this suite. 04/26/24 12:17:50.545
{"msg":"PASSED [sig-cli] Kubectl client Kubectl logs should be able to retrieve and filter logs  [Conformance]","completed":318,"skipped":5857,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.516 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl logs
  test/e2e/kubectl/kubectl.go:1567
    should be able to retrieve and filter logs  [Conformance]
    test/e2e/kubectl/kubectl.go:1590

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:17:44.037
    Apr 26 12:17:44.037: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 12:17:44.039
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:17:44.056
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:17:44.062
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1570
    STEP: creating an pod 04/26/24 12:17:44.068
    Apr 26 12:17:44.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 run logs-generator --image=registry.k8s.io/e2e-test-images/agnhost:2.40 --restart=Never --pod-running-timeout=2m0s -- logs-generator --log-lines-total 100 --run-duration 20s'
    Apr 26 12:17:44.143: INFO: stderr: ""
    Apr 26 12:17:44.143: INFO: stdout: "pod/logs-generator created\n"
    [It] should be able to retrieve and filter logs  [Conformance]
      test/e2e/kubectl/kubectl.go:1590
    STEP: Waiting for log generator to start. 04/26/24 12:17:44.144
    Apr 26 12:17:44.144: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
    Apr 26 12:17:44.144: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-3795" to be "running and ready, or succeeded"
    Apr 26 12:17:44.150: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 5.93881ms
    Apr 26 12:17:44.150: INFO: Error evaluating pod condition running and ready, or succeeded: want pod 'logs-generator' on 'shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j' to be 'Running' but was 'Pending'
    Apr 26 12:17:46.157: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.013467394s
    Apr 26 12:17:46.157: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
    Apr 26 12:17:46.157: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
    STEP: checking for a matching strings 04/26/24 12:17:46.157
    Apr 26 12:17:46.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 logs logs-generator logs-generator'
    Apr 26 12:17:46.248: INFO: stderr: ""
    Apr 26 12:17:46.248: INFO: stdout: "I0426 12:17:44.756381       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/5mjv 227\nI0426 12:17:44.956823       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/jtr 503\nI0426 12:17:45.157175       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/6lh 339\nI0426 12:17:45.356431       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/xbq4 547\nI0426 12:17:45.556743       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/x8pn 544\nI0426 12:17:45.757175       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/wvj 289\nI0426 12:17:45.956496       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/2d4q 585\nI0426 12:17:46.157004       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/dlsv 376\n"
    STEP: limiting log lines 04/26/24 12:17:46.248
    Apr 26 12:17:46.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 logs logs-generator logs-generator --tail=1'
    Apr 26 12:17:46.323: INFO: stderr: ""
    Apr 26 12:17:46.323: INFO: stdout: "I0426 12:17:46.157004       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/dlsv 376\n"
    Apr 26 12:17:46.323: INFO: got output "I0426 12:17:46.157004       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/dlsv 376\n"
    STEP: limiting log bytes 04/26/24 12:17:46.323
    Apr 26 12:17:46.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 logs logs-generator logs-generator --limit-bytes=1'
    Apr 26 12:17:46.453: INFO: stderr: ""
    Apr 26 12:17:46.453: INFO: stdout: "I"
    Apr 26 12:17:46.453: INFO: got output "I"
    STEP: exposing timestamps 04/26/24 12:17:46.453
    Apr 26 12:17:46.453: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 logs logs-generator logs-generator --tail=1 --timestamps'
    Apr 26 12:17:46.531: INFO: stderr: ""
    Apr 26 12:17:46.531: INFO: stdout: "2024-04-26T12:17:46.357614971Z I0426 12:17:46.357363       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/qtfb 242\n"
    Apr 26 12:17:46.531: INFO: got output "2024-04-26T12:17:46.357614971Z I0426 12:17:46.357363       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/qtfb 242\n"
    STEP: restricting to a time range 04/26/24 12:17:46.531
    Apr 26 12:17:49.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 logs logs-generator logs-generator --since=1s'
    Apr 26 12:17:49.177: INFO: stderr: ""
    Apr 26 12:17:49.177: INFO: stdout: "I0426 12:17:48.357074       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/24g9 382\nI0426 12:17:48.557481       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/xl2 336\nI0426 12:17:48.756921       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/8x4 268\nI0426 12:17:48.957328       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/k4x 203\nI0426 12:17:49.156660       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/gdn 296\n"
    Apr 26 12:17:49.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 logs logs-generator logs-generator --since=24h'
    Apr 26 12:17:49.277: INFO: stderr: ""
    Apr 26 12:17:49.277: INFO: stdout: "I0426 12:17:44.756381       1 logs_generator.go:76] 0 POST /api/v1/namespaces/kube-system/pods/5mjv 227\nI0426 12:17:44.956823       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/jtr 503\nI0426 12:17:45.157175       1 logs_generator.go:76] 2 GET /api/v1/namespaces/default/pods/6lh 339\nI0426 12:17:45.356431       1 logs_generator.go:76] 3 GET /api/v1/namespaces/default/pods/xbq4 547\nI0426 12:17:45.556743       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/ns/pods/x8pn 544\nI0426 12:17:45.757175       1 logs_generator.go:76] 5 POST /api/v1/namespaces/default/pods/wvj 289\nI0426 12:17:45.956496       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/2d4q 585\nI0426 12:17:46.157004       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/dlsv 376\nI0426 12:17:46.357363       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/qtfb 242\nI0426 12:17:46.556603       1 logs_generator.go:76] 9 POST /api/v1/namespaces/kube-system/pods/2rlm 362\nI0426 12:17:46.757043       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/dmjz 295\nI0426 12:17:46.957450       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/9kd7 356\nI0426 12:17:47.156868       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/5hlv 356\nI0426 12:17:47.357241       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/zth 397\nI0426 12:17:47.556543       1 logs_generator.go:76] 14 GET /api/v1/namespaces/default/pods/6r9 432\nI0426 12:17:47.756912       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/f6v2 369\nI0426 12:17:47.957328       1 logs_generator.go:76] 16 GET /api/v1/namespaces/ns/pods/zdgp 489\nI0426 12:17:48.156670       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/4bs 289\nI0426 12:17:48.357074       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/ns/pods/24g9 382\nI0426 12:17:48.557481       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/xl2 336\nI0426 12:17:48.756921       1 logs_generator.go:76] 20 GET /api/v1/namespaces/ns/pods/8x4 268\nI0426 12:17:48.957328       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/k4x 203\nI0426 12:17:49.156660       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/gdn 296\n"
    [AfterEach] Kubectl logs
      test/e2e/kubectl/kubectl.go:1575
    Apr 26 12:17:49.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-3795 delete pod logs-generator'
    Apr 26 12:17:50.530: INFO: stderr: ""
    Apr 26 12:17:50.530: INFO: stdout: "pod \"logs-generator\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 12:17:50.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-3795" for this suite. 04/26/24 12:17:50.545
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSS
------------------------------
[sig-network] EndpointSlice
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:17:50.556
Apr 26 12:17:50.556: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename endpointslice 04/26/24 12:17:50.557
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:17:50.575
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:17:50.581
[BeforeEach] [sig-network] EndpointSlice
  test/e2e/network/endpointslice.go:51
[It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101
[AfterEach] [sig-network] EndpointSlice
  test/e2e/framework/framework.go:187
Apr 26 12:17:52.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "endpointslice-4655" for this suite. 04/26/24 12:17:52.773
{"msg":"PASSED [sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]","completed":319,"skipped":5865,"failed":0}
------------------------------
â€¢ [2.225 seconds]
[sig-network] EndpointSlice
test/e2e/network/common/framework.go:23
  should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
  test/e2e/network/endpointslice.go:101

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:17:50.556
    Apr 26 12:17:50.556: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename endpointslice 04/26/24 12:17:50.557
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:17:50.575
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:17:50.581
    [BeforeEach] [sig-network] EndpointSlice
      test/e2e/network/endpointslice.go:51
    [It] should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]
      test/e2e/network/endpointslice.go:101
    [AfterEach] [sig-network] EndpointSlice
      test/e2e/framework/framework.go:187
    Apr 26 12:17:52.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "endpointslice-4655" for this suite. 04/26/24 12:17:52.773
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:17:52.787
Apr 26 12:17:52.787: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 12:17:52.788
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:17:52.804
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:17:52.809
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 04/26/24 12:17:52.815
Apr 26 12:17:52.815: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:17:54.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:18:04.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2121" for this suite. 04/26/24 12:18:04.575
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]","completed":320,"skipped":5909,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.795 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:356

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:17:52.787
    Apr 26 12:17:52.787: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 12:17:52.788
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:17:52.804
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:17:52.809
    [It] works for multiple CRDs of same group and version but different kinds [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:356
    STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation 04/26/24 12:17:52.815
    Apr 26 12:17:52.815: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:17:54.993: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:18:04.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-2121" for this suite. 04/26/24 12:18:04.575
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:18:04.583
Apr 26 12:18:04.583: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 12:18:04.584
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:04.631
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:04.638
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216
STEP: Creating a pod to test emptydir 0777 on node default medium 04/26/24 12:18:04.643
Apr 26 12:18:04.657: INFO: Waiting up to 5m0s for pod "pod-40e923e3-380b-469b-b960-d32bec38ec96" in namespace "emptydir-3524" to be "Succeeded or Failed"
Apr 26 12:18:04.683: INFO: Pod "pod-40e923e3-380b-469b-b960-d32bec38ec96": Phase="Pending", Reason="", readiness=false. Elapsed: 26.502951ms
Apr 26 12:18:06.693: INFO: Pod "pod-40e923e3-380b-469b-b960-d32bec38ec96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035874483s
Apr 26 12:18:08.690: INFO: Pod "pod-40e923e3-380b-469b-b960-d32bec38ec96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033566427s
STEP: Saw pod success 04/26/24 12:18:08.691
Apr 26 12:18:08.691: INFO: Pod "pod-40e923e3-380b-469b-b960-d32bec38ec96" satisfied condition "Succeeded or Failed"
Apr 26 12:18:08.695: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-40e923e3-380b-469b-b960-d32bec38ec96 container test-container: <nil>
STEP: delete the pod 04/26/24 12:18:08.709
Apr 26 12:18:08.751: INFO: Waiting for pod pod-40e923e3-380b-469b-b960-d32bec38ec96 to disappear
Apr 26 12:18:08.756: INFO: Pod pod-40e923e3-380b-469b-b960-d32bec38ec96 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 12:18:08.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3524" for this suite. 04/26/24 12:18:08.775
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":321,"skipped":5912,"failed":0}
------------------------------
â€¢ [4.229 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:216

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:18:04.583
    Apr 26 12:18:04.583: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 12:18:04.584
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:04.631
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:04.638
    [It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:216
    STEP: Creating a pod to test emptydir 0777 on node default medium 04/26/24 12:18:04.643
    Apr 26 12:18:04.657: INFO: Waiting up to 5m0s for pod "pod-40e923e3-380b-469b-b960-d32bec38ec96" in namespace "emptydir-3524" to be "Succeeded or Failed"
    Apr 26 12:18:04.683: INFO: Pod "pod-40e923e3-380b-469b-b960-d32bec38ec96": Phase="Pending", Reason="", readiness=false. Elapsed: 26.502951ms
    Apr 26 12:18:06.693: INFO: Pod "pod-40e923e3-380b-469b-b960-d32bec38ec96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035874483s
    Apr 26 12:18:08.690: INFO: Pod "pod-40e923e3-380b-469b-b960-d32bec38ec96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033566427s
    STEP: Saw pod success 04/26/24 12:18:08.691
    Apr 26 12:18:08.691: INFO: Pod "pod-40e923e3-380b-469b-b960-d32bec38ec96" satisfied condition "Succeeded or Failed"
    Apr 26 12:18:08.695: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j pod pod-40e923e3-380b-469b-b960-d32bec38ec96 container test-container: <nil>
    STEP: delete the pod 04/26/24 12:18:08.709
    Apr 26 12:18:08.751: INFO: Waiting for pod pod-40e923e3-380b-469b-b960-d32bec38ec96 to disappear
    Apr 26 12:18:08.756: INFO: Pod pod-40e923e3-380b-469b-b960-d32bec38ec96 no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 12:18:08.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-3524" for this suite. 04/26/24 12:18:08.775
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace
  should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:18:08.812
Apr 26 12:18:08.813: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 12:18:08.814
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:08.836
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:08.842
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[BeforeEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1732
[It] should update a single-container pod's image  [Conformance]
  test/e2e/kubectl/kubectl.go:1745
STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/26/24 12:18:08.847
Apr 26 12:18:08.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7830 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
Apr 26 12:18:08.923: INFO: stderr: ""
Apr 26 12:18:08.923: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running 04/26/24 12:18:08.923
STEP: verifying the pod e2e-test-httpd-pod was created 04/26/24 12:18:13.975
Apr 26 12:18:13.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7830 get pod e2e-test-httpd-pod -o json'
Apr 26 12:18:14.049: INFO: stderr: ""
Apr 26 12:18:14.049: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"13c50dc30092dc4ab4a8020b006bb03699c632310cb8e8f3ab00217f4f9a59c9\",\n            \"cni.projectcalico.org/podIP\": \"100.96.4.46/32\",\n            \"cni.projectcalico.org/podIPs\": \"100.96.4.46/32\"\n        },\n        \"creationTimestamp\": \"2024-04-26T12:18:08Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-7830\",\n        \"resourceVersion\": \"47567\",\n        \"uid\": \"6c35332e-4776-44a3-934e-3478168f74ae\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"env\": [\n                    {\n                        \"name\": \"KUBERNETES_SERVICE_HOST\",\n                        \"value\": \"api.conf-125.thomas.internal.emk.fuga.cloud\"\n                    }\n                ],\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-zwx2x\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-zwx2x\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-26T12:18:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-26T12:18:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-26T12:18:10Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-26T12:18:08Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://22c3deb2c4a1134ef0e095f7a918b63212d0a9035c69ba85e4926cd76dda9343\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-04-26T12:18:09Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.91\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.4.46\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.96.4.46\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-04-26T12:18:08Z\"\n    }\n}\n"
STEP: replace the image in the pod 04/26/24 12:18:14.05
Apr 26 12:18:14.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7830 replace -f -'
Apr 26 12:18:14.414: INFO: stderr: ""
Apr 26 12:18:14.414: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 04/26/24 12:18:14.414
[AfterEach] Kubectl replace
  test/e2e/kubectl/kubectl.go:1736
Apr 26 12:18:14.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7830 delete pods e2e-test-httpd-pod'
Apr 26 12:18:16.145: INFO: stderr: ""
Apr 26 12:18:16.145: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 12:18:16.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7830" for this suite. 04/26/24 12:18:16.158
{"msg":"PASSED [sig-cli] Kubectl client Kubectl replace should update a single-container pod's image  [Conformance]","completed":322,"skipped":5919,"failed":0}
------------------------------
â€¢ [SLOW TEST] [7.354 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl replace
  test/e2e/kubectl/kubectl.go:1729
    should update a single-container pod's image  [Conformance]
    test/e2e/kubectl/kubectl.go:1745

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:18:08.812
    Apr 26 12:18:08.813: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 12:18:08.814
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:08.836
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:08.842
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [BeforeEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1732
    [It] should update a single-container pod's image  [Conformance]
      test/e2e/kubectl/kubectl.go:1745
    STEP: running the image registry.k8s.io/e2e-test-images/httpd:2.4.38-2 04/26/24 12:18:08.847
    Apr 26 12:18:08.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7830 run e2e-test-httpd-pod --image=registry.k8s.io/e2e-test-images/httpd:2.4.38-2 --pod-running-timeout=2m0s --labels=run=e2e-test-httpd-pod'
    Apr 26 12:18:08.923: INFO: stderr: ""
    Apr 26 12:18:08.923: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
    STEP: verifying the pod e2e-test-httpd-pod is running 04/26/24 12:18:08.923
    STEP: verifying the pod e2e-test-httpd-pod was created 04/26/24 12:18:13.975
    Apr 26 12:18:13.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7830 get pod e2e-test-httpd-pod -o json'
    Apr 26 12:18:14.049: INFO: stderr: ""
    Apr 26 12:18:14.049: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/containerID\": \"13c50dc30092dc4ab4a8020b006bb03699c632310cb8e8f3ab00217f4f9a59c9\",\n            \"cni.projectcalico.org/podIP\": \"100.96.4.46/32\",\n            \"cni.projectcalico.org/podIPs\": \"100.96.4.46/32\"\n        },\n        \"creationTimestamp\": \"2024-04-26T12:18:08Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-7830\",\n        \"resourceVersion\": \"47567\",\n        \"uid\": \"6c35332e-4776-44a3-934e-3478168f74ae\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"env\": [\n                    {\n                        \"name\": \"KUBERNETES_SERVICE_HOST\",\n                        \"value\": \"api.conf-125.thomas.internal.emk.fuga.cloud\"\n                    }\n                ],\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"kube-api-access-zwx2x\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh\",\n        \"preemptionPolicy\": \"PreemptLowerPriority\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"kube-api-access-zwx2x\",\n                \"projected\": {\n                    \"defaultMode\": 420,\n                    \"sources\": [\n                        {\n                            \"serviceAccountToken\": {\n                                \"expirationSeconds\": 3607,\n                                \"path\": \"token\"\n                            }\n                        },\n                        {\n                            \"configMap\": {\n                                \"items\": [\n                                    {\n                                        \"key\": \"ca.crt\",\n                                        \"path\": \"ca.crt\"\n                                    }\n                                ],\n                                \"name\": \"kube-root-ca.crt\"\n                            }\n                        },\n                        {\n                            \"downwardAPI\": {\n                                \"items\": [\n                                    {\n                                        \"fieldRef\": {\n                                            \"apiVersion\": \"v1\",\n                                            \"fieldPath\": \"metadata.namespace\"\n                                        },\n                                        \"path\": \"namespace\"\n                                    }\n                                ]\n                            }\n                        }\n                    ]\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-26T12:18:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-26T12:18:10Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-26T12:18:10Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2024-04-26T12:18:08Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://22c3deb2c4a1134ef0e095f7a918b63212d0a9035c69ba85e4926cd76dda9343\",\n                \"image\": \"registry.k8s.io/e2e-test-images/httpd:2.4.38-2\",\n                \"imageID\": \"registry.k8s.io/e2e-test-images/httpd@sha256:1b9d1b2f36cb2dbee1960e82a9344aeb11bd4c4c03abf5e1853e0559c23855e3\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2024-04-26T12:18:09Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.91\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.96.4.46\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.96.4.46\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2024-04-26T12:18:08Z\"\n    }\n}\n"
    STEP: replace the image in the pod 04/26/24 12:18:14.05
    Apr 26 12:18:14.051: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7830 replace -f -'
    Apr 26 12:18:14.414: INFO: stderr: ""
    Apr 26 12:18:14.414: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
    STEP: verifying the pod e2e-test-httpd-pod has the right image registry.k8s.io/e2e-test-images/busybox:1.29-2 04/26/24 12:18:14.414
    [AfterEach] Kubectl replace
      test/e2e/kubectl/kubectl.go:1736
    Apr 26 12:18:14.420: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-7830 delete pods e2e-test-httpd-pod'
    Apr 26 12:18:16.145: INFO: stderr: ""
    Apr 26 12:18:16.145: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 12:18:16.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-7830" for this suite. 04/26/24 12:18:16.158
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:18:16.167
Apr 26 12:18:16.167: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename replication-controller 04/26/24 12:18:16.168
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:16.184
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:16.192
[BeforeEach] [sig-apps] ReplicationController
  test/e2e/apps/rc.go:56
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82
Apr 26 12:18:16.213: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 04/26/24 12:18:17.233
STEP: Checking rc "condition-test" has the desired failure condition set 04/26/24 12:18:17.239
STEP: Scaling down rc "condition-test" to satisfy pod quota 04/26/24 12:18:18.255
Apr 26 12:18:18.273: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set 04/26/24 12:18:18.273
[AfterEach] [sig-apps] ReplicationController
  test/e2e/framework/framework.go:187
Apr 26 12:18:18.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6168" for this suite. 04/26/24 12:18:18.301
{"msg":"PASSED [sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]","completed":323,"skipped":5931,"failed":0}
------------------------------
â€¢ [2.149 seconds]
[sig-apps] ReplicationController
test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  test/e2e/apps/rc.go:82

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:18:16.167
    Apr 26 12:18:16.167: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename replication-controller 04/26/24 12:18:16.168
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:16.184
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:16.192
    [BeforeEach] [sig-apps] ReplicationController
      test/e2e/apps/rc.go:56
    [It] should surface a failure condition on a common issue like exceeded quota [Conformance]
      test/e2e/apps/rc.go:82
    Apr 26 12:18:16.213: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
    STEP: Creating rc "condition-test" that asks for more than the allowed pod quota 04/26/24 12:18:17.233
    STEP: Checking rc "condition-test" has the desired failure condition set 04/26/24 12:18:17.239
    STEP: Scaling down rc "condition-test" to satisfy pod quota 04/26/24 12:18:18.255
    Apr 26 12:18:18.273: INFO: Updating replication controller "condition-test"
    STEP: Checking rc "condition-test" has no failure condition set 04/26/24 12:18:18.273
    [AfterEach] [sig-apps] ReplicationController
      test/e2e/framework/framework.go:187
    Apr 26 12:18:18.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "replication-controller-6168" for this suite. 04/26/24 12:18:18.301
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:18:18.319
Apr 26 12:18:18.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 12:18:18.32
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:18.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:18.402
[It] pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226
STEP: Creating Pod 04/26/24 12:18:18.408
Apr 26 12:18:18.433: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-8a40df81-f028-4018-a937-aa375a79bdd8" in namespace "emptydir-1364" to be "running"
Apr 26 12:18:18.439: INFO: Pod "pod-sharedvolume-8a40df81-f028-4018-a937-aa375a79bdd8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.079405ms
Apr 26 12:18:20.446: INFO: Pod "pod-sharedvolume-8a40df81-f028-4018-a937-aa375a79bdd8": Phase="Running", Reason="", readiness=false. Elapsed: 2.013335698s
Apr 26 12:18:20.446: INFO: Pod "pod-sharedvolume-8a40df81-f028-4018-a937-aa375a79bdd8" satisfied condition "running"
STEP: Reading file content from the nginx-container 04/26/24 12:18:20.446
Apr 26 12:18:20.446: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-1364 PodName:pod-sharedvolume-8a40df81-f028-4018-a937-aa375a79bdd8 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:18:20.446: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:18:20.447: INFO: ExecWithOptions: Clientset creation
Apr 26 12:18:20.447: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/emptydir-1364/pods/pod-sharedvolume-8a40df81-f028-4018-a937-aa375a79bdd8/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
Apr 26 12:18:20.921: INFO: Exec stderr: ""
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 12:18:20.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1364" for this suite. 04/26/24 12:18:20.938
{"msg":"PASSED [sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]","completed":324,"skipped":5953,"failed":0}
------------------------------
â€¢ [2.627 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  pod should support shared volumes between containers [Conformance]
  test/e2e/common/storage/empty_dir.go:226

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:18:18.319
    Apr 26 12:18:18.319: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 12:18:18.32
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:18.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:18.402
    [It] pod should support shared volumes between containers [Conformance]
      test/e2e/common/storage/empty_dir.go:226
    STEP: Creating Pod 04/26/24 12:18:18.408
    Apr 26 12:18:18.433: INFO: Waiting up to 5m0s for pod "pod-sharedvolume-8a40df81-f028-4018-a937-aa375a79bdd8" in namespace "emptydir-1364" to be "running"
    Apr 26 12:18:18.439: INFO: Pod "pod-sharedvolume-8a40df81-f028-4018-a937-aa375a79bdd8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.079405ms
    Apr 26 12:18:20.446: INFO: Pod "pod-sharedvolume-8a40df81-f028-4018-a937-aa375a79bdd8": Phase="Running", Reason="", readiness=false. Elapsed: 2.013335698s
    Apr 26 12:18:20.446: INFO: Pod "pod-sharedvolume-8a40df81-f028-4018-a937-aa375a79bdd8" satisfied condition "running"
    STEP: Reading file content from the nginx-container 04/26/24 12:18:20.446
    Apr 26 12:18:20.446: INFO: ExecWithOptions {Command:[/bin/sh -c cat /usr/share/volumeshare/shareddata.txt] Namespace:emptydir-1364 PodName:pod-sharedvolume-8a40df81-f028-4018-a937-aa375a79bdd8 ContainerName:busybox-main-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:18:20.446: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:18:20.447: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:18:20.447: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/emptydir-1364/pods/pod-sharedvolume-8a40df81-f028-4018-a937-aa375a79bdd8/exec?command=%2Fbin%2Fsh&command=-c&command=cat+%2Fusr%2Fshare%2Fvolumeshare%2Fshareddata.txt&container=busybox-main-container&container=busybox-main-container&stderr=true&stdout=true)
    Apr 26 12:18:20.921: INFO: Exec stderr: ""
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 12:18:20.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-1364" for this suite. 04/26/24 12:18:20.938
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] RuntimeClass
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[BeforeEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:18:20.95
Apr 26 12:18:20.950: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename runtimeclass 04/26/24 12:18:20.951
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:20.967
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:20.973
[It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55
[AfterEach] [sig-node] RuntimeClass
  test/e2e/framework/framework.go:187
Apr 26 12:18:20.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "runtimeclass-1500" for this suite. 04/26/24 12:18:21.005
{"msg":"PASSED [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]","completed":325,"skipped":5988,"failed":0}
------------------------------
â€¢ [0.063 seconds]
[sig-node] RuntimeClass
test/e2e/common/node/framework.go:23
  should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
  test/e2e/common/node/runtimeclass.go:55

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:18:20.95
    Apr 26 12:18:20.950: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename runtimeclass 04/26/24 12:18:20.951
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:20.967
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:20.973
    [It] should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]
      test/e2e/common/node/runtimeclass.go:55
    [AfterEach] [sig-node] RuntimeClass
      test/e2e/framework/framework.go:187
    Apr 26 12:18:20.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "runtimeclass-1500" for this suite. 04/26/24 12:18:21.005
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:18:21.015
Apr 26 12:18:21.016: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 12:18:21.017
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:21.032
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:21.038
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 12:18:21.057
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 12:18:21.151
STEP: Deploying the webhook pod 04/26/24 12:18:21.157
STEP: Wait for the deployment to be ready 04/26/24 12:18:21.197
Apr 26 12:18:21.212: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 12:18:23.232
STEP: Verifying the service has paired with the endpoint 04/26/24 12:18:23.252
Apr 26 12:18:24.252: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655
STEP: Listing all of the created validation webhooks 04/26/24 12:18:24.333
STEP: Creating a configMap that should be mutated 04/26/24 12:18:24.468
STEP: Deleting the collection of validation webhooks 04/26/24 12:18:24.985
STEP: Creating a configMap that should not be mutated 04/26/24 12:18:25.04
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:18:25.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8915" for this suite. 04/26/24 12:18:25.068
STEP: Destroying namespace "webhook-8915-markers" for this suite. 04/26/24 12:18:25.075
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]","completed":326,"skipped":6002,"failed":0}
------------------------------
â€¢ [4.114 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  test/e2e/apimachinery/webhook.go:655

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:18:21.015
    Apr 26 12:18:21.016: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 12:18:21.017
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:21.032
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:21.038
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 12:18:21.057
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 12:18:21.151
    STEP: Deploying the webhook pod 04/26/24 12:18:21.157
    STEP: Wait for the deployment to be ready 04/26/24 12:18:21.197
    Apr 26 12:18:21.212: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 12:18:23.232
    STEP: Verifying the service has paired with the endpoint 04/26/24 12:18:23.252
    Apr 26 12:18:24.252: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] listing mutating webhooks should work [Conformance]
      test/e2e/apimachinery/webhook.go:655
    STEP: Listing all of the created validation webhooks 04/26/24 12:18:24.333
    STEP: Creating a configMap that should be mutated 04/26/24 12:18:24.468
    STEP: Deleting the collection of validation webhooks 04/26/24 12:18:24.985
    STEP: Creating a configMap that should not be mutated 04/26/24 12:18:25.04
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:18:25.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8915" for this suite. 04/26/24 12:18:25.068
    STEP: Destroying namespace "webhook-8915-markers" for this suite. 04/26/24 12:18:25.075
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] Certificates API [Privileged:ClusterAdmin]
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
[BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:18:25.133
Apr 26 12:18:25.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename certificates 04/26/24 12:18:25.135
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:25.154
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:25.161
[It] should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200
STEP: getting /apis 04/26/24 12:18:25.385
STEP: getting /apis/certificates.k8s.io 04/26/24 12:18:25.392
STEP: getting /apis/certificates.k8s.io/v1 04/26/24 12:18:25.395
STEP: creating 04/26/24 12:18:25.399
STEP: getting 04/26/24 12:18:25.423
STEP: listing 04/26/24 12:18:25.428
STEP: watching 04/26/24 12:18:25.436
Apr 26 12:18:25.436: INFO: starting watch
STEP: patching 04/26/24 12:18:25.439
STEP: updating 04/26/24 12:18:25.45
Apr 26 12:18:25.458: INFO: waiting for watch events with expected annotations
Apr 26 12:18:25.458: INFO: saw patched and updated annotations
STEP: getting /approval 04/26/24 12:18:25.458
STEP: patching /approval 04/26/24 12:18:25.465
STEP: updating /approval 04/26/24 12:18:25.472
STEP: getting /status 04/26/24 12:18:25.48
STEP: patching /status 04/26/24 12:18:25.485
STEP: updating /status 04/26/24 12:18:25.493
STEP: deleting 04/26/24 12:18:25.504
STEP: deleting a collection 04/26/24 12:18:25.525
[AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:18:25.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "certificates-3999" for this suite. 04/26/24 12:18:25.561
{"msg":"PASSED [sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]","completed":327,"skipped":6043,"failed":0}
------------------------------
â€¢ [0.436 seconds]
[sig-auth] Certificates API [Privileged:ClusterAdmin]
test/e2e/auth/framework.go:23
  should support CSR API operations [Conformance]
  test/e2e/auth/certificates.go:200

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:18:25.133
    Apr 26 12:18:25.134: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename certificates 04/26/24 12:18:25.135
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:25.154
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:25.161
    [It] should support CSR API operations [Conformance]
      test/e2e/auth/certificates.go:200
    STEP: getting /apis 04/26/24 12:18:25.385
    STEP: getting /apis/certificates.k8s.io 04/26/24 12:18:25.392
    STEP: getting /apis/certificates.k8s.io/v1 04/26/24 12:18:25.395
    STEP: creating 04/26/24 12:18:25.399
    STEP: getting 04/26/24 12:18:25.423
    STEP: listing 04/26/24 12:18:25.428
    STEP: watching 04/26/24 12:18:25.436
    Apr 26 12:18:25.436: INFO: starting watch
    STEP: patching 04/26/24 12:18:25.439
    STEP: updating 04/26/24 12:18:25.45
    Apr 26 12:18:25.458: INFO: waiting for watch events with expected annotations
    Apr 26 12:18:25.458: INFO: saw patched and updated annotations
    STEP: getting /approval 04/26/24 12:18:25.458
    STEP: patching /approval 04/26/24 12:18:25.465
    STEP: updating /approval 04/26/24 12:18:25.472
    STEP: getting /status 04/26/24 12:18:25.48
    STEP: patching /status 04/26/24 12:18:25.485
    STEP: updating /status 04/26/24 12:18:25.493
    STEP: deleting 04/26/24 12:18:25.504
    STEP: deleting a collection 04/26/24 12:18:25.525
    [AfterEach] [sig-auth] Certificates API [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:18:25.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "certificates-3999" for this suite. 04/26/24 12:18:25.561
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
[BeforeEach] [sig-network] DNS
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:18:25.571
Apr 26 12:18:25.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename dns 04/26/24 12:18:25.573
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:25.587
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:25.592
[It] should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248
STEP: Creating a test headless service 04/26/24 12:18:25.598
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7393.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7393.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
 04/26/24 12:18:25.605
STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7393.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7393.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
 04/26/24 12:18:25.605
STEP: creating a pod to probe DNS 04/26/24 12:18:25.605
STEP: submitting the pod to kubernetes 04/26/24 12:18:25.605
Apr 26 12:18:25.619: INFO: Waiting up to 15m0s for pod "dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b" in namespace "dns-7393" to be "running"
Apr 26 12:18:25.624: INFO: Pod "dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.437116ms
Apr 26 12:18:27.634: INFO: Pod "dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014653884s
Apr 26 12:18:29.631: INFO: Pod "dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011383293s
Apr 26 12:18:31.632: INFO: Pod "dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b": Phase="Running", Reason="", readiness=true. Elapsed: 6.012338498s
Apr 26 12:18:31.632: INFO: Pod "dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b" satisfied condition "running"
STEP: retrieving the pod 04/26/24 12:18:31.632
STEP: looking for the results for each expected name from probers 04/26/24 12:18:31.638
Apr 26 12:18:31.837: INFO: DNS probes using dns-7393/dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b succeeded

STEP: deleting the pod 04/26/24 12:18:31.837
STEP: deleting the test headless service 04/26/24 12:18:31.863
[AfterEach] [sig-network] DNS
  test/e2e/framework/framework.go:187
Apr 26 12:18:31.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7393" for this suite. 04/26/24 12:18:31.897
{"msg":"PASSED [sig-network] DNS should provide DNS for pods for Hostname [Conformance]","completed":328,"skipped":6062,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.333 seconds]
[sig-network] DNS
test/e2e/network/common/framework.go:23
  should provide DNS for pods for Hostname [Conformance]
  test/e2e/network/dns.go:248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] DNS
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:18:25.571
    Apr 26 12:18:25.572: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename dns 04/26/24 12:18:25.573
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:25.587
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:25.592
    [It] should provide DNS for pods for Hostname [Conformance]
      test/e2e/network/dns.go:248
    STEP: Creating a test headless service 04/26/24 12:18:25.598
    STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7393.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-7393.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;sleep 1; done
     04/26/24 12:18:25.605
    STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-7393.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-7393.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;sleep 1; done
     04/26/24 12:18:25.605
    STEP: creating a pod to probe DNS 04/26/24 12:18:25.605
    STEP: submitting the pod to kubernetes 04/26/24 12:18:25.605
    Apr 26 12:18:25.619: INFO: Waiting up to 15m0s for pod "dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b" in namespace "dns-7393" to be "running"
    Apr 26 12:18:25.624: INFO: Pod "dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.437116ms
    Apr 26 12:18:27.634: INFO: Pod "dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014653884s
    Apr 26 12:18:29.631: INFO: Pod "dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011383293s
    Apr 26 12:18:31.632: INFO: Pod "dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b": Phase="Running", Reason="", readiness=true. Elapsed: 6.012338498s
    Apr 26 12:18:31.632: INFO: Pod "dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b" satisfied condition "running"
    STEP: retrieving the pod 04/26/24 12:18:31.632
    STEP: looking for the results for each expected name from probers 04/26/24 12:18:31.638
    Apr 26 12:18:31.837: INFO: DNS probes using dns-7393/dns-test-9ffb7eaf-0c2d-4801-90a9-6e1001a53b6b succeeded

    STEP: deleting the pod 04/26/24 12:18:31.837
    STEP: deleting the test headless service 04/26/24 12:18:31.863
    [AfterEach] [sig-network] DNS
      test/e2e/framework/framework.go:187
    Apr 26 12:18:31.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "dns-7393" for this suite. 04/26/24 12:18:31.897
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial]
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:18:31.905
Apr 26 12:18:31.905: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename sched-pred 04/26/24 12:18:31.906
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:31.93
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:31.937
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:92
Apr 26 12:18:31.943: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 26 12:18:31.981: INFO: Waiting for terminating namespaces to be deleted...
Apr 26 12:18:31.988: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh before test
Apr 26 12:18:32.027: INFO: apiserver-proxy-qltrf from kube-system started at 2024-04-26 11:55:36 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.027: INFO: 	Container proxy ready: true, restart count 0
Apr 26 12:18:32.027: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 12:18:32.027: INFO: calico-node-nj95n from kube-system started at 2024-04-26 11:55:36 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.027: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 12:18:32.027: INFO: csi-driver-node-fp59p from kube-system started at 2024-04-26 11:55:36 +0000 UTC (3 container statuses recorded)
Apr 26 12:18:32.027: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 12:18:32.027: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 12:18:32.027: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 12:18:32.027: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-lsz8x from kube-system started at 2024-04-26 11:55:36 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.027: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 12:18:32.027: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 12:18:32.027: INFO: node-exporter-nssqr from kube-system started at 2024-04-26 11:55:36 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.027: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 12:18:32.027: INFO: node-problem-detector-7vd2p from kube-system started at 2024-04-26 11:55:36 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.027: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 12:18:32.027: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-n89vg from sonobuoy started at 2024-04-26 11:55:36 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.027: INFO: 	Container sonobuoy-worker ready: false, restart count 8
Apr 26 12:18:32.027: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 12:18:32.027: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw before test
Apr 26 12:18:32.073: INFO: apiserver-proxy-hzh4l from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.073: INFO: 	Container proxy ready: true, restart count 0
Apr 26 12:18:32.073: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 12:18:32.073: INFO: blackbox-exporter-754b59454b-9cprw from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.073: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 26 12:18:32.073: INFO: calico-node-m9nm9 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.073: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 12:18:32.073: INFO: calico-typha-deploy-84df84b854-fv5zl from kube-system started at 2024-04-26 09:50:55 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.073: INFO: 	Container calico-typha ready: true, restart count 0
Apr 26 12:18:32.073: INFO: coredns-86858b4d85-f7j7b from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.073: INFO: 	Container coredns ready: true, restart count 0
Apr 26 12:18:32.073: INFO: csi-driver-node-9wpbg from kube-system started at 2024-04-26 09:50:15 +0000 UTC (3 container statuses recorded)
Apr 26 12:18:32.073: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 12:18:32.073: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 12:18:32.073: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 12:18:32.073: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-z47h4 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.073: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 12:18:32.073: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 12:18:32.073: INFO: metrics-server-56cf547447-db2cf from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.073: INFO: 	Container metrics-server ready: true, restart count 0
Apr 26 12:18:32.073: INFO: node-exporter-mg7sm from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.073: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 12:18:32.073: INFO: node-problem-detector-w7mph from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.073: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 12:18:32.073: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-pkmm6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.073: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 12:18:32.073: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 12:18:32.073: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j before test
Apr 26 12:18:32.113: INFO: apiserver-proxy-qmgq4 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.113: INFO: 	Container proxy ready: true, restart count 0
Apr 26 12:18:32.113: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 12:18:32.113: INFO: calico-node-tddjl from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.113: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 12:18:32.113: INFO: csi-driver-node-xcdg9 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (3 container statuses recorded)
Apr 26 12:18:32.113: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 12:18:32.113: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 12:18:32.113: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 12:18:32.113: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-fpkn8 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.113: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 12:18:32.113: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 12:18:32.113: INFO: node-exporter-bdrxz from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.113: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 12:18:32.113: INFO: node-problem-detector-mmsx4 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.113: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 12:18:32.113: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-xznr8 from sonobuoy started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.113: INFO: 	Container sonobuoy-worker ready: false, restart count 12
Apr 26 12:18:32.113: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 12:18:32.113: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp before test
Apr 26 12:18:32.153: INFO: apiserver-proxy-hzgtj from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.153: INFO: 	Container proxy ready: true, restart count 0
Apr 26 12:18:32.153: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 12:18:32.153: INFO: calico-node-49gs5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.153: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 12:18:32.153: INFO: csi-driver-node-thmzv from kube-system started at 2024-04-26 09:50:09 +0000 UTC (3 container statuses recorded)
Apr 26 12:18:32.153: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 12:18:32.153: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 12:18:32.153: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 12:18:32.153: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-8h68w from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.153: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 12:18:32.153: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 12:18:32.153: INFO: node-exporter-mzmd5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.153: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 12:18:32.153: INFO: node-problem-detector-x8jsh from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.153: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 12:18:32.153: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-t2fb5 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.153: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 12:18:32.153: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 26 12:18:32.153: INFO: 
Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w before test
Apr 26 12:18:32.204: INFO: apiserver-proxy-8bxw2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container proxy ready: true, restart count 0
Apr 26 12:18:32.205: INFO: 	Container sidecar ready: true, restart count 0
Apr 26 12:18:32.205: INFO: blackbox-exporter-754b59454b-tqxxm from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container blackbox-exporter ready: true, restart count 0
Apr 26 12:18:32.205: INFO: calico-kube-controllers-5bfbd9c84c-ggxxm from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 26 12:18:32.205: INFO: calico-node-nfp6q from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container calico-node ready: true, restart count 0
Apr 26 12:18:32.205: INFO: calico-node-vertical-autoscaler-6b85ccc474-scqt5 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container autoscaler ready: true, restart count 0
Apr 26 12:18:32.205: INFO: calico-typha-deploy-84df84b854-grtfl from kube-system started at 2024-04-26 11:04:13 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container calico-typha ready: true, restart count 0
Apr 26 12:18:32.205: INFO: calico-typha-horizontal-autoscaler-765f9c86fd-x4mrd from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container autoscaler ready: true, restart count 0
Apr 26 12:18:32.205: INFO: calico-typha-vertical-autoscaler-8657c6b4fc-d6gnw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container autoscaler ready: true, restart count 0
Apr 26 12:18:32.205: INFO: coredns-86858b4d85-m4dg4 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container coredns ready: true, restart count 0
Apr 26 12:18:32.205: INFO: csi-driver-node-f4f5r from kube-system started at 2024-04-26 09:50:05 +0000 UTC (3 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container csi-driver ready: true, restart count 0
Apr 26 12:18:32.205: INFO: 	Container csi-liveness-probe ready: true, restart count 0
Apr 26 12:18:32.205: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
Apr 26 12:18:32.205: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-82vtz from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container conntrack-fix ready: true, restart count 0
Apr 26 12:18:32.205: INFO: 	Container kube-proxy ready: true, restart count 0
Apr 26 12:18:32.205: INFO: metrics-server-56cf547447-sl4zk from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container metrics-server ready: true, restart count 0
Apr 26 12:18:32.205: INFO: node-exporter-r2wm2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container node-exporter ready: true, restart count 0
Apr 26 12:18:32.205: INFO: node-problem-detector-8w59w from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container node-problem-detector ready: true, restart count 0
Apr 26 12:18:32.205: INFO: vpn-shoot-849b6d5c85-z42mw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container vpn-shoot ready: true, restart count 0
Apr 26 12:18:32.205: INFO: sonobuoy from sonobuoy started at 2024-04-26 10:56:56 +0000 UTC (1 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 26 12:18:32.205: INFO: sonobuoy-e2e-job-ce2c772167a64049 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container e2e ready: true, restart count 0
Apr 26 12:18:32.205: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 12:18:32.205: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-6bgn6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
Apr 26 12:18:32.205: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 26 12:18:32.205: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438
STEP: Trying to schedule Pod with nonempty NodeSelector. 04/26/24 12:18:32.205
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.17c9d3b61a6220b7], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] 04/26/24 12:18:32.287
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/framework/framework.go:187
Apr 26 12:18:33.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7070" for this suite. 04/26/24 12:18:33.3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  test/e2e/scheduling/predicates.go:83
{"msg":"PASSED [sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching  [Conformance]","completed":329,"skipped":6064,"failed":0}
------------------------------
â€¢ [1.404 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
test/e2e/scheduling/framework.go:40
  validates that NodeSelector is respected if not matching  [Conformance]
  test/e2e/scheduling/predicates.go:438

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:18:31.905
    Apr 26 12:18:31.905: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename sched-pred 04/26/24 12:18:31.906
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:31.93
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:31.937
    [BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:92
    Apr 26 12:18:31.943: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
    Apr 26 12:18:31.981: INFO: Waiting for terminating namespaces to be deleted...
    Apr 26 12:18:31.988: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh before test
    Apr 26 12:18:32.027: INFO: apiserver-proxy-qltrf from kube-system started at 2024-04-26 11:55:36 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.027: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 12:18:32.027: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 12:18:32.027: INFO: calico-node-nj95n from kube-system started at 2024-04-26 11:55:36 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.027: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 12:18:32.027: INFO: csi-driver-node-fp59p from kube-system started at 2024-04-26 11:55:36 +0000 UTC (3 container statuses recorded)
    Apr 26 12:18:32.027: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 12:18:32.027: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 12:18:32.027: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 12:18:32.027: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-lsz8x from kube-system started at 2024-04-26 11:55:36 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.027: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 12:18:32.027: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 12:18:32.027: INFO: node-exporter-nssqr from kube-system started at 2024-04-26 11:55:36 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.027: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 12:18:32.027: INFO: node-problem-detector-7vd2p from kube-system started at 2024-04-26 11:55:36 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.027: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 12:18:32.027: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-n89vg from sonobuoy started at 2024-04-26 11:55:36 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.027: INFO: 	Container sonobuoy-worker ready: false, restart count 8
    Apr 26 12:18:32.027: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 12:18:32.027: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-n2zbw before test
    Apr 26 12:18:32.073: INFO: apiserver-proxy-hzh4l from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.073: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: blackbox-exporter-754b59454b-9cprw from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.073: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: calico-node-m9nm9 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.073: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: calico-typha-deploy-84df84b854-fv5zl from kube-system started at 2024-04-26 09:50:55 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.073: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: coredns-86858b4d85-f7j7b from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.073: INFO: 	Container coredns ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: csi-driver-node-9wpbg from kube-system started at 2024-04-26 09:50:15 +0000 UTC (3 container statuses recorded)
    Apr 26 12:18:32.073: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-z47h4 from kube-system started at 2024-04-26 09:50:15 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.073: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: metrics-server-56cf547447-db2cf from kube-system started at 2024-04-26 09:50:51 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.073: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: node-exporter-mg7sm from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.073: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: node-problem-detector-w7mph from kube-system started at 2024-04-26 09:50:15 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.073: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-pkmm6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.073: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 12:18:32.073: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-khw5j before test
    Apr 26 12:18:32.113: INFO: apiserver-proxy-qmgq4 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.113: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 12:18:32.113: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 12:18:32.113: INFO: calico-node-tddjl from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.113: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 12:18:32.113: INFO: csi-driver-node-xcdg9 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (3 container statuses recorded)
    Apr 26 12:18:32.113: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 12:18:32.113: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 12:18:32.113: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 12:18:32.113: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-fpkn8 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.113: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 12:18:32.113: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 12:18:32.113: INFO: node-exporter-bdrxz from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.113: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 12:18:32.113: INFO: node-problem-detector-mmsx4 from kube-system started at 2024-04-26 11:35:28 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.113: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 12:18:32.113: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-xznr8 from sonobuoy started at 2024-04-26 11:35:28 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.113: INFO: 	Container sonobuoy-worker ready: false, restart count 12
    Apr 26 12:18:32.113: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 12:18:32.113: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp before test
    Apr 26 12:18:32.153: INFO: apiserver-proxy-hzgtj from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.153: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 12:18:32.153: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 12:18:32.153: INFO: calico-node-49gs5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.153: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 12:18:32.153: INFO: csi-driver-node-thmzv from kube-system started at 2024-04-26 09:50:09 +0000 UTC (3 container statuses recorded)
    Apr 26 12:18:32.153: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 12:18:32.153: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 12:18:32.153: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 12:18:32.153: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-8h68w from kube-system started at 2024-04-26 09:50:09 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.153: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 12:18:32.153: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 12:18:32.153: INFO: node-exporter-mzmd5 from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.153: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 12:18:32.153: INFO: node-problem-detector-x8jsh from kube-system started at 2024-04-26 09:50:09 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.153: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 12:18:32.153: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-t2fb5 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.153: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 12:18:32.153: INFO: 	Container systemd-logs ready: true, restart count 0
    Apr 26 12:18:32.153: INFO: 
    Logging pods the apiserver thinks is on node shoot--thomas--conf-125-worker-6a5hr-1-z3-b96b6-slf4w before test
    Apr 26 12:18:32.204: INFO: apiserver-proxy-8bxw2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container proxy ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: 	Container sidecar ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: blackbox-exporter-754b59454b-tqxxm from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container blackbox-exporter ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: calico-kube-controllers-5bfbd9c84c-ggxxm from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container calico-kube-controllers ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: calico-node-nfp6q from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container calico-node ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: calico-node-vertical-autoscaler-6b85ccc474-scqt5 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: calico-typha-deploy-84df84b854-grtfl from kube-system started at 2024-04-26 11:04:13 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container calico-typha ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: calico-typha-horizontal-autoscaler-765f9c86fd-x4mrd from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: calico-typha-vertical-autoscaler-8657c6b4fc-d6gnw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container autoscaler ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: coredns-86858b4d85-m4dg4 from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container coredns ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: csi-driver-node-f4f5r from kube-system started at 2024-04-26 09:50:05 +0000 UTC (3 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container csi-driver ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: 	Container csi-liveness-probe ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: 	Container csi-node-driver-registrar ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: kube-proxy-worker-6a5hr-1-v1.25.16-82vtz from kube-system started at 2024-04-26 09:50:05 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container conntrack-fix ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: 	Container kube-proxy ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: metrics-server-56cf547447-sl4zk from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container metrics-server ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: node-exporter-r2wm2 from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container node-exporter ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: node-problem-detector-8w59w from kube-system started at 2024-04-26 09:50:05 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container node-problem-detector ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: vpn-shoot-849b6d5c85-z42mw from kube-system started at 2024-04-26 09:50:47 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container vpn-shoot ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: sonobuoy from sonobuoy started at 2024-04-26 10:56:56 +0000 UTC (1 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container kube-sonobuoy ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: sonobuoy-e2e-job-ce2c772167a64049 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container e2e ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: sonobuoy-systemd-logs-daemon-set-fec07c39516746ea-6bgn6 from sonobuoy started at 2024-04-26 10:57:00 +0000 UTC (2 container statuses recorded)
    Apr 26 12:18:32.205: INFO: 	Container sonobuoy-worker ready: true, restart count 0
    Apr 26 12:18:32.205: INFO: 	Container systemd-logs ready: true, restart count 0
    [It] validates that NodeSelector is respected if not matching  [Conformance]
      test/e2e/scheduling/predicates.go:438
    STEP: Trying to schedule Pod with nonempty NodeSelector. 04/26/24 12:18:32.205
    STEP: Considering event: 
    Type = [Warning], Name = [restricted-pod.17c9d3b61a6220b7], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match Pod's node affinity/selector. preemption: 0/5 nodes are available: 5 Preemption is not helpful for scheduling.] 04/26/24 12:18:32.287
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/framework/framework.go:187
    Apr 26 12:18:33.284: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "sched-pred-7070" for this suite. 04/26/24 12:18:33.3
    [AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
      test/e2e/scheduling/predicates.go:83
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:18:33.311
Apr 26 12:18:33.311: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 12:18:33.312
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:33.328
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:33.333
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193
Apr 26 12:18:33.341: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/26/24 12:18:35.574
Apr 26 12:18:35.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-9801 --namespace=crd-publish-openapi-9801 create -f -'
Apr 26 12:18:36.112: INFO: stderr: ""
Apr 26 12:18:36.112: INFO: stdout: "e2e-test-crd-publish-openapi-6040-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 26 12:18:36.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-9801 --namespace=crd-publish-openapi-9801 delete e2e-test-crd-publish-openapi-6040-crds test-cr'
Apr 26 12:18:36.225: INFO: stderr: ""
Apr 26 12:18:36.225: INFO: stdout: "e2e-test-crd-publish-openapi-6040-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr 26 12:18:36.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-9801 --namespace=crd-publish-openapi-9801 apply -f -'
Apr 26 12:18:36.625: INFO: stderr: ""
Apr 26 12:18:36.625: INFO: stdout: "e2e-test-crd-publish-openapi-6040-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 26 12:18:36.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-9801 --namespace=crd-publish-openapi-9801 delete e2e-test-crd-publish-openapi-6040-crds test-cr'
Apr 26 12:18:36.696: INFO: stderr: ""
Apr 26 12:18:36.696: INFO: stdout: "e2e-test-crd-publish-openapi-6040-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR 04/26/24 12:18:36.696
Apr 26 12:18:36.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-9801 explain e2e-test-crd-publish-openapi-6040-crds'
Apr 26 12:18:36.844: INFO: stderr: ""
Apr 26 12:18:36.844: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6040-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:18:39.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9801" for this suite. 04/26/24 12:18:39.231
{"msg":"PASSED [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]","completed":330,"skipped":6078,"failed":0}
------------------------------
â€¢ [SLOW TEST] [5.927 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  test/e2e/apimachinery/crd_publish_openapi.go:193

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:18:33.311
    Apr 26 12:18:33.311: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename crd-publish-openapi 04/26/24 12:18:33.312
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:33.328
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:33.333
    [It] works for CRD preserving unknown fields at the schema root [Conformance]
      test/e2e/apimachinery/crd_publish_openapi.go:193
    Apr 26 12:18:33.341: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: kubectl validation (kubectl create and apply) allows request with any unknown properties 04/26/24 12:18:35.574
    Apr 26 12:18:35.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-9801 --namespace=crd-publish-openapi-9801 create -f -'
    Apr 26 12:18:36.112: INFO: stderr: ""
    Apr 26 12:18:36.112: INFO: stdout: "e2e-test-crd-publish-openapi-6040-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Apr 26 12:18:36.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-9801 --namespace=crd-publish-openapi-9801 delete e2e-test-crd-publish-openapi-6040-crds test-cr'
    Apr 26 12:18:36.225: INFO: stderr: ""
    Apr 26 12:18:36.225: INFO: stdout: "e2e-test-crd-publish-openapi-6040-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    Apr 26 12:18:36.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-9801 --namespace=crd-publish-openapi-9801 apply -f -'
    Apr 26 12:18:36.625: INFO: stderr: ""
    Apr 26 12:18:36.625: INFO: stdout: "e2e-test-crd-publish-openapi-6040-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
    Apr 26 12:18:36.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-9801 --namespace=crd-publish-openapi-9801 delete e2e-test-crd-publish-openapi-6040-crds test-cr'
    Apr 26 12:18:36.696: INFO: stderr: ""
    Apr 26 12:18:36.696: INFO: stdout: "e2e-test-crd-publish-openapi-6040-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
    STEP: kubectl explain works to explain CR 04/26/24 12:18:36.696
    Apr 26 12:18:36.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=crd-publish-openapi-9801 explain e2e-test-crd-publish-openapi-6040-crds'
    Apr 26 12:18:36.844: INFO: stderr: ""
    Apr 26 12:18:36.844: INFO: stdout: "KIND:     e2e-test-crd-publish-openapi-6040-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
    [AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:18:39.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-publish-openapi-9801" for this suite. 04/26/24 12:18:39.231
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:18:39.245
Apr 26 12:18:39.245: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 12:18:39.246
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:39.265
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:39.27
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204
STEP: Creating secret with name s-test-opt-del-6a5f694b-80f4-41b5-8095-a3742b6abd76 04/26/24 12:18:39.287
STEP: Creating secret with name s-test-opt-upd-41e507e2-fb51-4f24-87ce-05087b90ea9d 04/26/24 12:18:39.309
STEP: Creating the pod 04/26/24 12:18:39.314
Apr 26 12:18:39.328: INFO: Waiting up to 5m0s for pod "pod-secrets-00f9f734-9896-4b63-ba0b-a58094ab1017" in namespace "secrets-9602" to be "running and ready"
Apr 26 12:18:39.332: INFO: Pod "pod-secrets-00f9f734-9896-4b63-ba0b-a58094ab1017": Phase="Pending", Reason="", readiness=false. Elapsed: 4.815706ms
Apr 26 12:18:39.332: INFO: The phase of Pod pod-secrets-00f9f734-9896-4b63-ba0b-a58094ab1017 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:18:41.340: INFO: Pod "pod-secrets-00f9f734-9896-4b63-ba0b-a58094ab1017": Phase="Running", Reason="", readiness=true. Elapsed: 2.01202082s
Apr 26 12:18:41.340: INFO: The phase of Pod pod-secrets-00f9f734-9896-4b63-ba0b-a58094ab1017 is Running (Ready = true)
Apr 26 12:18:41.340: INFO: Pod "pod-secrets-00f9f734-9896-4b63-ba0b-a58094ab1017" satisfied condition "running and ready"
STEP: Deleting secret s-test-opt-del-6a5f694b-80f4-41b5-8095-a3742b6abd76 04/26/24 12:18:41.586
STEP: Updating secret s-test-opt-upd-41e507e2-fb51-4f24-87ce-05087b90ea9d 04/26/24 12:18:41.593
STEP: Creating secret with name s-test-opt-create-d43d9bfa-d379-4d12-aed1-4df5d578befc 04/26/24 12:18:41.6
STEP: waiting to observe update in volume 04/26/24 12:18:41.605
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 26 12:18:45.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9602" for this suite. 04/26/24 12:18:45.912
{"msg":"PASSED [sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]","completed":331,"skipped":6120,"failed":0}
------------------------------
â€¢ [SLOW TEST] [6.673 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:204

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:18:39.245
    Apr 26 12:18:39.245: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 12:18:39.246
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:39.265
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:39.27
    [It] optional updates should be reflected in volume [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:204
    STEP: Creating secret with name s-test-opt-del-6a5f694b-80f4-41b5-8095-a3742b6abd76 04/26/24 12:18:39.287
    STEP: Creating secret with name s-test-opt-upd-41e507e2-fb51-4f24-87ce-05087b90ea9d 04/26/24 12:18:39.309
    STEP: Creating the pod 04/26/24 12:18:39.314
    Apr 26 12:18:39.328: INFO: Waiting up to 5m0s for pod "pod-secrets-00f9f734-9896-4b63-ba0b-a58094ab1017" in namespace "secrets-9602" to be "running and ready"
    Apr 26 12:18:39.332: INFO: Pod "pod-secrets-00f9f734-9896-4b63-ba0b-a58094ab1017": Phase="Pending", Reason="", readiness=false. Elapsed: 4.815706ms
    Apr 26 12:18:39.332: INFO: The phase of Pod pod-secrets-00f9f734-9896-4b63-ba0b-a58094ab1017 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:18:41.340: INFO: Pod "pod-secrets-00f9f734-9896-4b63-ba0b-a58094ab1017": Phase="Running", Reason="", readiness=true. Elapsed: 2.01202082s
    Apr 26 12:18:41.340: INFO: The phase of Pod pod-secrets-00f9f734-9896-4b63-ba0b-a58094ab1017 is Running (Ready = true)
    Apr 26 12:18:41.340: INFO: Pod "pod-secrets-00f9f734-9896-4b63-ba0b-a58094ab1017" satisfied condition "running and ready"
    STEP: Deleting secret s-test-opt-del-6a5f694b-80f4-41b5-8095-a3742b6abd76 04/26/24 12:18:41.586
    STEP: Updating secret s-test-opt-upd-41e507e2-fb51-4f24-87ce-05087b90ea9d 04/26/24 12:18:41.593
    STEP: Creating secret with name s-test-opt-create-d43d9bfa-d379-4d12-aed1-4df5d578befc 04/26/24 12:18:41.6
    STEP: waiting to observe update in volume 04/26/24 12:18:41.605
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 12:18:45.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-9602" for this suite. 04/26/24 12:18:45.912
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic]
  should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:18:45.919
Apr 26 12:18:45.919: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename statefulset 04/26/24 12:18:45.92
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:45.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:45.945
[BeforeEach] [sig-apps] StatefulSet
  test/e2e/apps/statefulset.go:96
[BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:111
STEP: Creating service test in namespace statefulset-4321 04/26/24 12:18:45.956
[It] should list, patch and delete a collection of StatefulSets [Conformance]
  test/e2e/apps/statefulset.go:906
Apr 26 12:18:46.007: INFO: Found 0 stateful pods, waiting for 1
Apr 26 12:18:56.017: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: patching the StatefulSet 04/26/24 12:18:56.028
W0426 12:18:56.036739      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
Apr 26 12:18:56.064: INFO: Found 1 stateful pods, waiting for 2
Apr 26 12:19:06.076: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 26 12:19:06.076: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
STEP: Listing all StatefulSets 04/26/24 12:19:06.086
STEP: Delete all of the StatefulSets 04/26/24 12:19:06.09
STEP: Verify that StatefulSets have been deleted 04/26/24 12:19:06.099
[AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:122
Apr 26 12:19:06.104: INFO: Deleting all statefulset in ns statefulset-4321
[AfterEach] [sig-apps] StatefulSet
  test/e2e/framework/framework.go:187
Apr 26 12:19:06.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4321" for this suite. 04/26/24 12:19:06.138
{"msg":"PASSED [sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]","completed":332,"skipped":6144,"failed":0}
------------------------------
â€¢ [SLOW TEST] [20.230 seconds]
[sig-apps] StatefulSet
test/e2e/apps/framework.go:23
  Basic StatefulSet functionality [StatefulSetBasic]
  test/e2e/apps/statefulset.go:101
    should list, patch and delete a collection of StatefulSets [Conformance]
    test/e2e/apps/statefulset.go:906

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:18:45.919
    Apr 26 12:18:45.919: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename statefulset 04/26/24 12:18:45.92
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:18:45.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:18:45.945
    [BeforeEach] [sig-apps] StatefulSet
      test/e2e/apps/statefulset.go:96
    [BeforeEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:111
    STEP: Creating service test in namespace statefulset-4321 04/26/24 12:18:45.956
    [It] should list, patch and delete a collection of StatefulSets [Conformance]
      test/e2e/apps/statefulset.go:906
    Apr 26 12:18:46.007: INFO: Found 0 stateful pods, waiting for 1
    Apr 26 12:18:56.017: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    STEP: patching the StatefulSet 04/26/24 12:18:56.028
    W0426 12:18:56.036739      23 warnings.go:70] unknown field "spec.template.spec.TerminationGracePeriodSeconds"
    Apr 26 12:18:56.064: INFO: Found 1 stateful pods, waiting for 2
    Apr 26 12:19:06.076: INFO: Waiting for pod test-ss-0 to enter Running - Ready=true, currently Running - Ready=true
    Apr 26 12:19:06.076: INFO: Waiting for pod test-ss-1 to enter Running - Ready=true, currently Running - Ready=true
    STEP: Listing all StatefulSets 04/26/24 12:19:06.086
    STEP: Delete all of the StatefulSets 04/26/24 12:19:06.09
    STEP: Verify that StatefulSets have been deleted 04/26/24 12:19:06.099
    [AfterEach] Basic StatefulSet functionality [StatefulSetBasic]
      test/e2e/apps/statefulset.go:122
    Apr 26 12:19:06.104: INFO: Deleting all statefulset in ns statefulset-4321
    [AfterEach] [sig-apps] StatefulSet
      test/e2e/framework/framework.go:187
    Apr 26 12:19:06.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "statefulset-4321" for this suite. 04/26/24 12:19:06.138
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
[BeforeEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:19:06.15
Apr 26 12:19:06.150: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename emptydir 04/26/24 12:19:06.151
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:19:06.167
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:19:06.174
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176
STEP: Creating a pod to test emptydir 0666 on node default medium 04/26/24 12:19:06.181
Apr 26 12:19:06.193: INFO: Waiting up to 5m0s for pod "pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b" in namespace "emptydir-2623" to be "Succeeded or Failed"
Apr 26 12:19:06.202: INFO: Pod "pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.662768ms
Apr 26 12:19:08.209: INFO: Pod "pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015659328s
Apr 26 12:19:10.210: INFO: Pod "pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017104252s
STEP: Saw pod success 04/26/24 12:19:10.21
Apr 26 12:19:10.210: INFO: Pod "pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b" satisfied condition "Succeeded or Failed"
Apr 26 12:19:10.216: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b container test-container: <nil>
STEP: delete the pod 04/26/24 12:19:10.267
Apr 26 12:19:10.282: INFO: Waiting for pod pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b to disappear
Apr 26 12:19:10.300: INFO: Pod pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  test/e2e/framework/framework.go:187
Apr 26 12:19:10.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2623" for this suite. 04/26/24 12:19:10.311
{"msg":"PASSED [sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]","completed":333,"skipped":6156,"failed":0}
------------------------------
â€¢ [4.168 seconds]
[sig-storage] EmptyDir volumes
test/e2e/common/storage/framework.go:23
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/storage/empty_dir.go:176

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:19:06.15
    Apr 26 12:19:06.150: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename emptydir 04/26/24 12:19:06.151
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:19:06.167
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:19:06.174
    [It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/storage/empty_dir.go:176
    STEP: Creating a pod to test emptydir 0666 on node default medium 04/26/24 12:19:06.181
    Apr 26 12:19:06.193: INFO: Waiting up to 5m0s for pod "pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b" in namespace "emptydir-2623" to be "Succeeded or Failed"
    Apr 26 12:19:06.202: INFO: Pod "pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b": Phase="Pending", Reason="", readiness=false. Elapsed: 8.662768ms
    Apr 26 12:19:08.209: INFO: Pod "pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015659328s
    Apr 26 12:19:10.210: INFO: Pod "pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017104252s
    STEP: Saw pod success 04/26/24 12:19:10.21
    Apr 26 12:19:10.210: INFO: Pod "pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b" satisfied condition "Succeeded or Failed"
    Apr 26 12:19:10.216: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b container test-container: <nil>
    STEP: delete the pod 04/26/24 12:19:10.267
    Apr 26 12:19:10.282: INFO: Waiting for pod pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b to disappear
    Apr 26 12:19:10.300: INFO: Pod pod-62633a7f-638c-4350-9b59-26d5e9ea4e1b no longer exists
    [AfterEach] [sig-storage] EmptyDir volumes
      test/e2e/framework/framework.go:187
    Apr 26 12:19:10.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "emptydir-2623" for this suite. 04/26/24 12:19:10.311
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:19:10.318
Apr 26 12:19:10.318: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename webhook 04/26/24 12:19:10.32
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:19:10.344
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:19:10.362
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:89
STEP: Setting up server cert 04/26/24 12:19:10.383
STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 12:19:11.003
STEP: Deploying the webhook pod 04/26/24 12:19:11.013
STEP: Wait for the deployment to be ready 04/26/24 12:19:11.027
Apr 26 12:19:11.039: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service 04/26/24 12:19:13.06
STEP: Verifying the service has paired with the endpoint 04/26/24 12:19:13.076
Apr 26 12:19:14.077: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507
STEP: Creating a mutating webhook configuration 04/26/24 12:19:14.083
STEP: Updating a mutating webhook configuration's rules to not include the create operation 04/26/24 12:19:14.214
STEP: Creating a configMap that should not be mutated 04/26/24 12:19:14.222
STEP: Patching a mutating webhook configuration's rules to include the create operation 04/26/24 12:19:14.233
STEP: Creating a configMap that should be mutated 04/26/24 12:19:14.242
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:19:14.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8600" for this suite. 04/26/24 12:19:14.436
STEP: Destroying namespace "webhook-8600-markers" for this suite. 04/26/24 12:19:14.442
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/webhook.go:104
{"msg":"PASSED [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]","completed":334,"skipped":6163,"failed":0}
------------------------------
â€¢ [4.194 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  test/e2e/apimachinery/webhook.go:507

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:19:10.318
    Apr 26 12:19:10.318: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename webhook 04/26/24 12:19:10.32
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:19:10.344
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:19:10.362
    [BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:89
    STEP: Setting up server cert 04/26/24 12:19:10.383
    STEP: Create role binding to let webhook read extension-apiserver-authentication 04/26/24 12:19:11.003
    STEP: Deploying the webhook pod 04/26/24 12:19:11.013
    STEP: Wait for the deployment to be ready 04/26/24 12:19:11.027
    Apr 26 12:19:11.039: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
    STEP: Deploying the webhook service 04/26/24 12:19:13.06
    STEP: Verifying the service has paired with the endpoint 04/26/24 12:19:13.076
    Apr 26 12:19:14.077: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
    [It] patching/updating a mutating webhook should work [Conformance]
      test/e2e/apimachinery/webhook.go:507
    STEP: Creating a mutating webhook configuration 04/26/24 12:19:14.083
    STEP: Updating a mutating webhook configuration's rules to not include the create operation 04/26/24 12:19:14.214
    STEP: Creating a configMap that should not be mutated 04/26/24 12:19:14.222
    STEP: Patching a mutating webhook configuration's rules to include the create operation 04/26/24 12:19:14.233
    STEP: Creating a configMap that should be mutated 04/26/24 12:19:14.242
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:19:14.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "webhook-8600" for this suite. 04/26/24 12:19:14.436
    STEP: Destroying namespace "webhook-8600-markers" for this suite. 04/26/24 12:19:14.442
    [AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/webhook.go:104
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
[BeforeEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:19:14.513
Apr 26 12:19:14.514: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-lifecycle-hook 04/26/24 12:19:14.514
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:19:14.533
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:19:14.539
[BeforeEach] when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:55
STEP: create the container to handle the HTTPGet hook request. 04/26/24 12:19:14.561
Apr 26 12:19:14.574: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7421" to be "running and ready"
Apr 26 12:19:14.583: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 8.44474ms
Apr 26 12:19:14.583: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:19:16.590: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.015993564s
Apr 26 12:19:16.590: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
Apr 26 12:19:16.590: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  test/e2e/common/node/lifecycle_hook.go:97
STEP: create the pod with lifecycle hook 04/26/24 12:19:16.595
Apr 26 12:19:16.604: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-7421" to be "running and ready"
Apr 26 12:19:16.619: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 15.650769ms
Apr 26 12:19:16.619: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:19:18.627: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.022954735s
Apr 26 12:19:18.627: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
Apr 26 12:19:18.627: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
STEP: check poststart hook 04/26/24 12:19:18.636
STEP: delete the pod with lifecycle hook 04/26/24 12:19:18.689
Apr 26 12:19:18.700: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 26 12:19:18.707: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 26 12:19:20.707: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 26 12:19:20.714: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 26 12:19:22.707: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 26 12:19:22.713: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [sig-node] Container Lifecycle Hook
  test/e2e/framework/framework.go:187
Apr 26 12:19:22.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7421" for this suite. 04/26/24 12:19:22.726
{"msg":"PASSED [sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]","completed":335,"skipped":6199,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.218 seconds]
[sig-node] Container Lifecycle Hook
test/e2e/common/node/framework.go:23
  when create a pod with lifecycle hook
  test/e2e/common/node/lifecycle_hook.go:46
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    test/e2e/common/node/lifecycle_hook.go:97

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:19:14.513
    Apr 26 12:19:14.514: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-lifecycle-hook 04/26/24 12:19:14.514
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:19:14.533
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:19:14.539
    [BeforeEach] when create a pod with lifecycle hook
      test/e2e/common/node/lifecycle_hook.go:55
    STEP: create the container to handle the HTTPGet hook request. 04/26/24 12:19:14.561
    Apr 26 12:19:14.574: INFO: Waiting up to 5m0s for pod "pod-handle-http-request" in namespace "container-lifecycle-hook-7421" to be "running and ready"
    Apr 26 12:19:14.583: INFO: Pod "pod-handle-http-request": Phase="Pending", Reason="", readiness=false. Elapsed: 8.44474ms
    Apr 26 12:19:14.583: INFO: The phase of Pod pod-handle-http-request is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:19:16.590: INFO: Pod "pod-handle-http-request": Phase="Running", Reason="", readiness=true. Elapsed: 2.015993564s
    Apr 26 12:19:16.590: INFO: The phase of Pod pod-handle-http-request is Running (Ready = true)
    Apr 26 12:19:16.590: INFO: Pod "pod-handle-http-request" satisfied condition "running and ready"
    [It] should execute poststart exec hook properly [NodeConformance] [Conformance]
      test/e2e/common/node/lifecycle_hook.go:97
    STEP: create the pod with lifecycle hook 04/26/24 12:19:16.595
    Apr 26 12:19:16.604: INFO: Waiting up to 5m0s for pod "pod-with-poststart-exec-hook" in namespace "container-lifecycle-hook-7421" to be "running and ready"
    Apr 26 12:19:16.619: INFO: Pod "pod-with-poststart-exec-hook": Phase="Pending", Reason="", readiness=false. Elapsed: 15.650769ms
    Apr 26 12:19:16.619: INFO: The phase of Pod pod-with-poststart-exec-hook is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:19:18.627: INFO: Pod "pod-with-poststart-exec-hook": Phase="Running", Reason="", readiness=true. Elapsed: 2.022954735s
    Apr 26 12:19:18.627: INFO: The phase of Pod pod-with-poststart-exec-hook is Running (Ready = true)
    Apr 26 12:19:18.627: INFO: Pod "pod-with-poststart-exec-hook" satisfied condition "running and ready"
    STEP: check poststart hook 04/26/24 12:19:18.636
    STEP: delete the pod with lifecycle hook 04/26/24 12:19:18.689
    Apr 26 12:19:18.700: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 26 12:19:18.707: INFO: Pod pod-with-poststart-exec-hook still exists
    Apr 26 12:19:20.707: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 26 12:19:20.714: INFO: Pod pod-with-poststart-exec-hook still exists
    Apr 26 12:19:22.707: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
    Apr 26 12:19:22.713: INFO: Pod pod-with-poststart-exec-hook no longer exists
    [AfterEach] [sig-node] Container Lifecycle Hook
      test/e2e/framework/framework.go:187
    Apr 26 12:19:22.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-lifecycle-hook-7421" for this suite. 04/26/24 12:19:22.726
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
[BeforeEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:19:22.733
Apr 26 12:19:22.733: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename configmap 04/26/24 12:19:22.734
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:19:22.754
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:19:22.762
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44
STEP: Creating configMap configmap-5472/configmap-test-894e0801-7a06-49c0-8144-ae1ef01f22db 04/26/24 12:19:22.77
STEP: Creating a pod to test consume configMaps 04/26/24 12:19:22.776
Apr 26 12:19:22.787: INFO: Waiting up to 5m0s for pod "pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055" in namespace "configmap-5472" to be "Succeeded or Failed"
Apr 26 12:19:22.794: INFO: Pod "pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055": Phase="Pending", Reason="", readiness=false. Elapsed: 6.790128ms
Apr 26 12:19:24.801: INFO: Pod "pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013970275s
Apr 26 12:19:26.805: INFO: Pod "pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018437335s
STEP: Saw pod success 04/26/24 12:19:26.806
Apr 26 12:19:26.806: INFO: Pod "pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055" satisfied condition "Succeeded or Failed"
Apr 26 12:19:26.811: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh pod pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055 container env-test: <nil>
STEP: delete the pod 04/26/24 12:19:26.822
Apr 26 12:19:26.836: INFO: Waiting for pod pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055 to disappear
Apr 26 12:19:26.841: INFO: Pod pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055 no longer exists
[AfterEach] [sig-node] ConfigMap
  test/e2e/framework/framework.go:187
Apr 26 12:19:26.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5472" for this suite. 04/26/24 12:19:26.853
{"msg":"PASSED [sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]","completed":336,"skipped":6216,"failed":0}
------------------------------
â€¢ [4.126 seconds]
[sig-node] ConfigMap
test/e2e/common/node/framework.go:23
  should be consumable via environment variable [NodeConformance] [Conformance]
  test/e2e/common/node/configmap.go:44

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:19:22.733
    Apr 26 12:19:22.733: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename configmap 04/26/24 12:19:22.734
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:19:22.754
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:19:22.762
    [It] should be consumable via environment variable [NodeConformance] [Conformance]
      test/e2e/common/node/configmap.go:44
    STEP: Creating configMap configmap-5472/configmap-test-894e0801-7a06-49c0-8144-ae1ef01f22db 04/26/24 12:19:22.77
    STEP: Creating a pod to test consume configMaps 04/26/24 12:19:22.776
    Apr 26 12:19:22.787: INFO: Waiting up to 5m0s for pod "pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055" in namespace "configmap-5472" to be "Succeeded or Failed"
    Apr 26 12:19:22.794: INFO: Pod "pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055": Phase="Pending", Reason="", readiness=false. Elapsed: 6.790128ms
    Apr 26 12:19:24.801: INFO: Pod "pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013970275s
    Apr 26 12:19:26.805: INFO: Pod "pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018437335s
    STEP: Saw pod success 04/26/24 12:19:26.806
    Apr 26 12:19:26.806: INFO: Pod "pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055" satisfied condition "Succeeded or Failed"
    Apr 26 12:19:26.811: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh pod pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055 container env-test: <nil>
    STEP: delete the pod 04/26/24 12:19:26.822
    Apr 26 12:19:26.836: INFO: Waiting for pod pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055 to disappear
    Apr 26 12:19:26.841: INFO: Pod pod-configmaps-a76cf9a7-fdcc-4e23-8b51-327dd7c84055 no longer exists
    [AfterEach] [sig-node] ConfigMap
      test/e2e/framework/framework.go:187
    Apr 26 12:19:26.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "configmap-5472" for this suite. 04/26/24 12:19:26.853
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:19:26.861
Apr 26 12:19:26.861: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename var-expansion 04/26/24 12:19:26.862
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:19:26.879
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:19:26.885
[It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224
STEP: creating the pod with failed condition 04/26/24 12:19:26.893
Apr 26 12:19:26.906: INFO: Waiting up to 2m0s for pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720" in namespace "var-expansion-9226" to be "running"
Apr 26 12:19:26.914: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 7.876997ms
Apr 26 12:19:28.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014385052s
Apr 26 12:19:30.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015027461s
Apr 26 12:19:32.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014282291s
Apr 26 12:19:34.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014519721s
Apr 26 12:19:36.923: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 10.017420024s
Apr 26 12:19:38.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014395169s
Apr 26 12:19:40.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 14.015778016s
Apr 26 12:19:42.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 16.014295703s
Apr 26 12:19:44.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 18.014903203s
Apr 26 12:19:46.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 20.015825653s
Apr 26 12:19:48.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 22.014046799s
Apr 26 12:19:50.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 24.014427343s
Apr 26 12:19:52.938: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 26.032325276s
Apr 26 12:19:54.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 28.014708919s
Apr 26 12:19:56.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 30.014745775s
Apr 26 12:19:58.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 32.016092407s
Apr 26 12:20:00.931: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 34.025743896s
Apr 26 12:20:02.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 36.015308924s
Apr 26 12:20:04.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 38.013925723s
Apr 26 12:20:06.919: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 40.013796735s
Apr 26 12:20:08.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 42.015793689s
Apr 26 12:20:10.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 44.015817201s
Apr 26 12:20:12.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 46.016264114s
Apr 26 12:20:14.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 48.014470185s
Apr 26 12:20:16.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 50.016723139s
Apr 26 12:20:18.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 52.015415927s
Apr 26 12:20:20.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 54.015570845s
Apr 26 12:20:22.923: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 56.017438701s
Apr 26 12:20:24.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 58.016607427s
Apr 26 12:20:26.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.015831545s
Apr 26 12:20:28.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.014299734s
Apr 26 12:20:30.919: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.01370529s
Apr 26 12:20:32.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.014166059s
Apr 26 12:20:34.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.015328348s
Apr 26 12:20:36.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.016292025s
Apr 26 12:20:38.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.015835801s
Apr 26 12:20:40.924: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.018350618s
Apr 26 12:20:43.131: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.22493758s
Apr 26 12:20:44.943: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.037689008s
Apr 26 12:20:46.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.01467673s
Apr 26 12:20:48.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.014435089s
Apr 26 12:20:50.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.015050623s
Apr 26 12:20:52.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.014424326s
Apr 26 12:20:54.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.015390794s
Apr 26 12:20:56.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.016238376s
Apr 26 12:20:58.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.014578283s
Apr 26 12:21:00.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.013942379s
Apr 26 12:21:02.946: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.039929848s
Apr 26 12:21:04.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.014141811s
Apr 26 12:21:06.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.014399303s
Apr 26 12:21:08.927: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.021034643s
Apr 26 12:21:10.919: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.013144597s
Apr 26 12:21:12.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.01619047s
Apr 26 12:21:14.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.015061812s
Apr 26 12:21:16.924: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.018313055s
Apr 26 12:21:18.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.015885936s
Apr 26 12:21:20.924: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.018119641s
Apr 26 12:21:22.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.014647214s
Apr 26 12:21:24.919: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.013855359s
Apr 26 12:21:26.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.015092755s
Apr 26 12:21:26.927: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.020960338s
STEP: updating the pod 04/26/24 12:21:26.927
Apr 26 12:21:27.444: INFO: Successfully updated pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720"
STEP: waiting for pod running 04/26/24 12:21:27.444
Apr 26 12:21:27.444: INFO: Waiting up to 2m0s for pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720" in namespace "var-expansion-9226" to be "running"
Apr 26 12:21:27.512: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 67.605639ms
Apr 26 12:21:29.521: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Running", Reason="", readiness=true. Elapsed: 2.077035811s
Apr 26 12:21:29.522: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720" satisfied condition "running"
STEP: deleting the pod gracefully 04/26/24 12:21:29.522
Apr 26 12:21:29.522: INFO: Deleting pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720" in namespace "var-expansion-9226"
Apr 26 12:21:29.531: INFO: Wait up to 5m0s for pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720" to be fully deleted
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 26 12:22:01.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9226" for this suite. 04/26/24 12:22:01.616
{"msg":"PASSED [sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]","completed":337,"skipped":6247,"failed":0}
------------------------------
â€¢ [SLOW TEST] [154.761 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
  test/e2e/common/node/expansion.go:224

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:19:26.861
    Apr 26 12:19:26.861: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename var-expansion 04/26/24 12:19:26.862
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:19:26.879
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:19:26.885
    [It] should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]
      test/e2e/common/node/expansion.go:224
    STEP: creating the pod with failed condition 04/26/24 12:19:26.893
    Apr 26 12:19:26.906: INFO: Waiting up to 2m0s for pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720" in namespace "var-expansion-9226" to be "running"
    Apr 26 12:19:26.914: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 7.876997ms
    Apr 26 12:19:28.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014385052s
    Apr 26 12:19:30.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015027461s
    Apr 26 12:19:32.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014282291s
    Apr 26 12:19:34.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014519721s
    Apr 26 12:19:36.923: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 10.017420024s
    Apr 26 12:19:38.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014395169s
    Apr 26 12:19:40.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 14.015778016s
    Apr 26 12:19:42.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 16.014295703s
    Apr 26 12:19:44.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 18.014903203s
    Apr 26 12:19:46.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 20.015825653s
    Apr 26 12:19:48.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 22.014046799s
    Apr 26 12:19:50.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 24.014427343s
    Apr 26 12:19:52.938: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 26.032325276s
    Apr 26 12:19:54.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 28.014708919s
    Apr 26 12:19:56.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 30.014745775s
    Apr 26 12:19:58.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 32.016092407s
    Apr 26 12:20:00.931: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 34.025743896s
    Apr 26 12:20:02.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 36.015308924s
    Apr 26 12:20:04.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 38.013925723s
    Apr 26 12:20:06.919: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 40.013796735s
    Apr 26 12:20:08.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 42.015793689s
    Apr 26 12:20:10.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 44.015817201s
    Apr 26 12:20:12.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 46.016264114s
    Apr 26 12:20:14.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 48.014470185s
    Apr 26 12:20:16.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 50.016723139s
    Apr 26 12:20:18.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 52.015415927s
    Apr 26 12:20:20.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 54.015570845s
    Apr 26 12:20:22.923: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 56.017438701s
    Apr 26 12:20:24.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 58.016607427s
    Apr 26 12:20:26.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m0.015831545s
    Apr 26 12:20:28.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m2.014299734s
    Apr 26 12:20:30.919: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m4.01370529s
    Apr 26 12:20:32.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m6.014166059s
    Apr 26 12:20:34.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m8.015328348s
    Apr 26 12:20:36.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m10.016292025s
    Apr 26 12:20:38.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m12.015835801s
    Apr 26 12:20:40.924: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m14.018350618s
    Apr 26 12:20:43.131: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m16.22493758s
    Apr 26 12:20:44.943: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m18.037689008s
    Apr 26 12:20:46.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m20.01467673s
    Apr 26 12:20:48.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m22.014435089s
    Apr 26 12:20:50.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m24.015050623s
    Apr 26 12:20:52.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m26.014424326s
    Apr 26 12:20:54.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m28.015390794s
    Apr 26 12:20:56.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m30.016238376s
    Apr 26 12:20:58.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m32.014578283s
    Apr 26 12:21:00.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m34.013942379s
    Apr 26 12:21:02.946: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m36.039929848s
    Apr 26 12:21:04.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m38.014141811s
    Apr 26 12:21:06.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m40.014399303s
    Apr 26 12:21:08.927: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m42.021034643s
    Apr 26 12:21:10.919: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m44.013144597s
    Apr 26 12:21:12.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m46.01619047s
    Apr 26 12:21:14.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m48.015061812s
    Apr 26 12:21:16.924: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m50.018313055s
    Apr 26 12:21:18.922: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m52.015885936s
    Apr 26 12:21:20.924: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m54.018119641s
    Apr 26 12:21:22.920: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m56.014647214s
    Apr 26 12:21:24.919: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 1m58.013855359s
    Apr 26 12:21:26.921: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.015092755s
    Apr 26 12:21:26.927: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 2m0.020960338s
    STEP: updating the pod 04/26/24 12:21:26.927
    Apr 26 12:21:27.444: INFO: Successfully updated pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720"
    STEP: waiting for pod running 04/26/24 12:21:27.444
    Apr 26 12:21:27.444: INFO: Waiting up to 2m0s for pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720" in namespace "var-expansion-9226" to be "running"
    Apr 26 12:21:27.512: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Pending", Reason="", readiness=false. Elapsed: 67.605639ms
    Apr 26 12:21:29.521: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720": Phase="Running", Reason="", readiness=true. Elapsed: 2.077035811s
    Apr 26 12:21:29.522: INFO: Pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720" satisfied condition "running"
    STEP: deleting the pod gracefully 04/26/24 12:21:29.522
    Apr 26 12:21:29.522: INFO: Deleting pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720" in namespace "var-expansion-9226"
    Apr 26 12:21:29.531: INFO: Wait up to 5m0s for pod "var-expansion-dc23b7a9-8567-4258-8fab-a37b2d179720" to be fully deleted
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 26 12:22:01.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-9226" for this suite. 04/26/24 12:22:01.616
  << End Captured GinkgoWriter Output
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info
  should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:22:01.623
Apr 26 12:22:01.623: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename kubectl 04/26/24 12:22:01.625
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:01.757
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:01.764
[BeforeEach] [sig-cli] Kubectl client
  test/e2e/kubectl/kubectl.go:272
[It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
  test/e2e/kubectl/kubectl.go:1248
STEP: validating cluster-info 04/26/24 12:22:01.771
Apr 26 12:22:01.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-4950 cluster-info'
Apr 26 12:22:01.830: INFO: stderr: ""
Apr 26 12:22:01.830: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://api.conf-125.thomas.internal.emk.fuga.cloud:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  test/e2e/framework/framework.go:187
Apr 26 12:22:01.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4950" for this suite. 04/26/24 12:22:01.841
{"msg":"PASSED [sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info  [Conformance]","completed":338,"skipped":6249,"failed":0}
------------------------------
â€¢ [0.228 seconds]
[sig-cli] Kubectl client
test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  test/e2e/kubectl/kubectl.go:1242
    should check if Kubernetes control plane services is included in cluster-info  [Conformance]
    test/e2e/kubectl/kubectl.go:1248

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:22:01.623
    Apr 26 12:22:01.623: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename kubectl 04/26/24 12:22:01.625
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:01.757
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:01.764
    [BeforeEach] [sig-cli] Kubectl client
      test/e2e/kubectl/kubectl.go:272
    [It] should check if Kubernetes control plane services is included in cluster-info  [Conformance]
      test/e2e/kubectl/kubectl.go:1248
    STEP: validating cluster-info 04/26/24 12:22:01.771
    Apr 26 12:22:01.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=kubectl-4950 cluster-info'
    Apr 26 12:22:01.830: INFO: stderr: ""
    Apr 26 12:22:01.830: INFO: stdout: "\x1b[0;32mKubernetes control plane\x1b[0m is running at \x1b[0;33mhttps://api.conf-125.thomas.internal.emk.fuga.cloud:443\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
    [AfterEach] [sig-cli] Kubectl client
      test/e2e/framework/framework.go:187
    Apr 26 12:22:01.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "kubectl-4950" for this suite. 04/26/24 12:22:01.841
  << End Captured GinkgoWriter Output
------------------------------
SSSSS
------------------------------
[sig-node] Security Context when creating containers with AllowPrivilegeEscalation
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:22:01.851
Apr 26 12:22:01.852: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename security-context-test 04/26/24 12:22:01.853
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:01.92
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:01.93
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:608
Apr 26 12:22:01.991: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-c5586bc9-d359-478e-9871-cae59b20905e" in namespace "security-context-test-6353" to be "Succeeded or Failed"
Apr 26 12:22:01.998: INFO: Pod "alpine-nnp-false-c5586bc9-d359-478e-9871-cae59b20905e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.051482ms
Apr 26 12:22:04.005: INFO: Pod "alpine-nnp-false-c5586bc9-d359-478e-9871-cae59b20905e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013846784s
Apr 26 12:22:06.004: INFO: Pod "alpine-nnp-false-c5586bc9-d359-478e-9871-cae59b20905e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01343273s
Apr 26 12:22:06.005: INFO: Pod "alpine-nnp-false-c5586bc9-d359-478e-9871-cae59b20905e" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 26 12:22:06.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6353" for this suite. 04/26/24 12:22:06.031
{"msg":"PASSED [sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]","completed":339,"skipped":6254,"failed":0}
------------------------------
â€¢ [4.186 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  when creating containers with AllowPrivilegeEscalation
  test/e2e/common/node/security_context.go:554
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:608

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:22:01.851
    Apr 26 12:22:01.852: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename security-context-test 04/26/24 12:22:01.853
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:01.92
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:01.93
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:608
    Apr 26 12:22:01.991: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-c5586bc9-d359-478e-9871-cae59b20905e" in namespace "security-context-test-6353" to be "Succeeded or Failed"
    Apr 26 12:22:01.998: INFO: Pod "alpine-nnp-false-c5586bc9-d359-478e-9871-cae59b20905e": Phase="Pending", Reason="", readiness=false. Elapsed: 7.051482ms
    Apr 26 12:22:04.005: INFO: Pod "alpine-nnp-false-c5586bc9-d359-478e-9871-cae59b20905e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013846784s
    Apr 26 12:22:06.004: INFO: Pod "alpine-nnp-false-c5586bc9-d359-478e-9871-cae59b20905e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01343273s
    Apr 26 12:22:06.005: INFO: Pod "alpine-nnp-false-c5586bc9-d359-478e-9871-cae59b20905e" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 26 12:22:06.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-6353" for this suite. 04/26/24 12:22:06.031
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:22:06.04
Apr 26 12:22:06.040: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 12:22:06.041
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:06.06
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:06.066
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98
STEP: Creating secret with name secret-test-8518ae32-5578-4ee9-aa5b-c27b53678566 04/26/24 12:22:06.091
STEP: Creating a pod to test consume secrets 04/26/24 12:22:06.239
Apr 26 12:22:06.251: INFO: Waiting up to 5m0s for pod "pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee" in namespace "secrets-5393" to be "Succeeded or Failed"
Apr 26 12:22:06.282: INFO: Pod "pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee": Phase="Pending", Reason="", readiness=false. Elapsed: 31.293624ms
Apr 26 12:22:08.289: INFO: Pod "pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038494831s
Apr 26 12:22:10.289: INFO: Pod "pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038245224s
STEP: Saw pod success 04/26/24 12:22:10.289
Apr 26 12:22:10.289: INFO: Pod "pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee" satisfied condition "Succeeded or Failed"
Apr 26 12:22:10.296: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh pod pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee container secret-volume-test: <nil>
STEP: delete the pod 04/26/24 12:22:10.356
Apr 26 12:22:10.452: INFO: Waiting for pod pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee to disappear
Apr 26 12:22:10.458: INFO: Pod pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee no longer exists
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 26 12:22:10.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5393" for this suite. 04/26/24 12:22:10.501
STEP: Destroying namespace "secret-namespace-9700" for this suite. 04/26/24 12:22:10.508
{"msg":"PASSED [sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]","completed":340,"skipped":6275,"failed":0}
------------------------------
â€¢ [4.476 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  test/e2e/common/storage/secrets_volume.go:98

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:22:06.04
    Apr 26 12:22:06.040: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 12:22:06.041
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:06.06
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:06.066
    [It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
      test/e2e/common/storage/secrets_volume.go:98
    STEP: Creating secret with name secret-test-8518ae32-5578-4ee9-aa5b-c27b53678566 04/26/24 12:22:06.091
    STEP: Creating a pod to test consume secrets 04/26/24 12:22:06.239
    Apr 26 12:22:06.251: INFO: Waiting up to 5m0s for pod "pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee" in namespace "secrets-5393" to be "Succeeded or Failed"
    Apr 26 12:22:06.282: INFO: Pod "pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee": Phase="Pending", Reason="", readiness=false. Elapsed: 31.293624ms
    Apr 26 12:22:08.289: INFO: Pod "pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038494831s
    Apr 26 12:22:10.289: INFO: Pod "pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038245224s
    STEP: Saw pod success 04/26/24 12:22:10.289
    Apr 26 12:22:10.289: INFO: Pod "pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee" satisfied condition "Succeeded or Failed"
    Apr 26 12:22:10.296: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z1-68d69-b55kh pod pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee container secret-volume-test: <nil>
    STEP: delete the pod 04/26/24 12:22:10.356
    Apr 26 12:22:10.452: INFO: Waiting for pod pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee to disappear
    Apr 26 12:22:10.458: INFO: Pod pod-secrets-e7a460e3-c2c6-4cf0-b945-41352fca7fee no longer exists
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 12:22:10.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-5393" for this suite. 04/26/24 12:22:10.501
    STEP: Destroying namespace "secret-namespace-9700" for this suite. 04/26/24 12:22:10.508
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] IngressClass API
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
[BeforeEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:22:10.518
Apr 26 12:22:10.518: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename ingressclass 04/26/24 12:22:10.519
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:10.539
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:10.554
[BeforeEach] [sig-network] IngressClass API
  test/e2e/network/ingressclass.go:211
[It]  should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223
STEP: getting /apis 04/26/24 12:22:10.565
STEP: getting /apis/networking.k8s.io 04/26/24 12:22:10.573
STEP: getting /apis/networking.k8s.iov1 04/26/24 12:22:10.576
STEP: creating 04/26/24 12:22:10.58
STEP: getting 04/26/24 12:22:10.606
STEP: listing 04/26/24 12:22:10.617
STEP: watching 04/26/24 12:22:10.621
Apr 26 12:22:10.622: INFO: starting watch
STEP: patching 04/26/24 12:22:10.626
STEP: updating 04/26/24 12:22:10.632
Apr 26 12:22:10.639: INFO: waiting for watch events with expected annotations
Apr 26 12:22:10.639: INFO: saw patched and updated annotations
STEP: deleting 04/26/24 12:22:10.64
STEP: deleting a collection 04/26/24 12:22:10.694
[AfterEach] [sig-network] IngressClass API
  test/e2e/framework/framework.go:187
Apr 26 12:22:10.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "ingressclass-5885" for this suite. 04/26/24 12:22:10.722
{"msg":"PASSED [sig-network] IngressClass API  should support creating IngressClass API operations [Conformance]","completed":341,"skipped":6333,"failed":0}
------------------------------
â€¢ [0.209 seconds]
[sig-network] IngressClass API
test/e2e/network/common/framework.go:23
   should support creating IngressClass API operations [Conformance]
  test/e2e/network/ingressclass.go:223

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:22:10.518
    Apr 26 12:22:10.518: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename ingressclass 04/26/24 12:22:10.519
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:10.539
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:10.554
    [BeforeEach] [sig-network] IngressClass API
      test/e2e/network/ingressclass.go:211
    [It]  should support creating IngressClass API operations [Conformance]
      test/e2e/network/ingressclass.go:223
    STEP: getting /apis 04/26/24 12:22:10.565
    STEP: getting /apis/networking.k8s.io 04/26/24 12:22:10.573
    STEP: getting /apis/networking.k8s.iov1 04/26/24 12:22:10.576
    STEP: creating 04/26/24 12:22:10.58
    STEP: getting 04/26/24 12:22:10.606
    STEP: listing 04/26/24 12:22:10.617
    STEP: watching 04/26/24 12:22:10.621
    Apr 26 12:22:10.622: INFO: starting watch
    STEP: patching 04/26/24 12:22:10.626
    STEP: updating 04/26/24 12:22:10.632
    Apr 26 12:22:10.639: INFO: waiting for watch events with expected annotations
    Apr 26 12:22:10.639: INFO: saw patched and updated annotations
    STEP: deleting 04/26/24 12:22:10.64
    STEP: deleting a collection 04/26/24 12:22:10.694
    [AfterEach] [sig-network] IngressClass API
      test/e2e/framework/framework.go:187
    Apr 26 12:22:10.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "ingressclass-5885" for this suite. 04/26/24 12:22:10.722
  << End Captured GinkgoWriter Output
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:22:10.728
Apr 26 12:22:10.728: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename custom-resource-definition 04/26/24 12:22:10.729
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:10.746
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:10.755
[It] should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198
STEP: fetching the /apis discovery document 04/26/24 12:22:10.763
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 04/26/24 12:22:10.766
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 04/26/24 12:22:10.766
STEP: fetching the /apis/apiextensions.k8s.io discovery document 04/26/24 12:22:10.766
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 04/26/24 12:22:10.769
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 04/26/24 12:22:10.77
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 04/26/24 12:22:10.772
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:22:10.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9678" for this suite. 04/26/24 12:22:10.787
{"msg":"PASSED [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]","completed":342,"skipped":6333,"failed":0}
------------------------------
â€¢ [0.066 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  test/e2e/apimachinery/custom_resource_definition.go:198

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:22:10.728
    Apr 26 12:22:10.728: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename custom-resource-definition 04/26/24 12:22:10.729
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:10.746
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:10.755
    [It] should include custom resource definition resources in discovery documents [Conformance]
      test/e2e/apimachinery/custom_resource_definition.go:198
    STEP: fetching the /apis discovery document 04/26/24 12:22:10.763
    STEP: finding the apiextensions.k8s.io API group in the /apis discovery document 04/26/24 12:22:10.766
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document 04/26/24 12:22:10.766
    STEP: fetching the /apis/apiextensions.k8s.io discovery document 04/26/24 12:22:10.766
    STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document 04/26/24 12:22:10.769
    STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document 04/26/24 12:22:10.77
    STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document 04/26/24 12:22:10.772
    [AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:22:10.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "custom-resource-definition-9678" for this suite. 04/26/24 12:22:10.787
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Pods
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
[BeforeEach] [sig-node] Pods
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:22:10.797
Apr 26 12:22:10.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pods 04/26/24 12:22:10.799
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:10.839
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:10.845
[BeforeEach] [sig-node] Pods
  test/e2e/common/node/pods.go:193
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617
Apr 26 12:22:10.852: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: creating the pod 04/26/24 12:22:10.853
STEP: submitting the pod to kubernetes 04/26/24 12:22:10.853
Apr 26 12:22:10.865: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-00523cad-811c-46ec-bd29-d32c30e20521" in namespace "pods-220" to be "running and ready"
Apr 26 12:22:10.881: INFO: Pod "pod-logs-websocket-00523cad-811c-46ec-bd29-d32c30e20521": Phase="Pending", Reason="", readiness=false. Elapsed: 15.752811ms
Apr 26 12:22:10.881: INFO: The phase of Pod pod-logs-websocket-00523cad-811c-46ec-bd29-d32c30e20521 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:22:12.890: INFO: Pod "pod-logs-websocket-00523cad-811c-46ec-bd29-d32c30e20521": Phase="Running", Reason="", readiness=true. Elapsed: 2.024405648s
Apr 26 12:22:12.890: INFO: The phase of Pod pod-logs-websocket-00523cad-811c-46ec-bd29-d32c30e20521 is Running (Ready = true)
Apr 26 12:22:12.890: INFO: Pod "pod-logs-websocket-00523cad-811c-46ec-bd29-d32c30e20521" satisfied condition "running and ready"
[AfterEach] [sig-node] Pods
  test/e2e/framework/framework.go:187
Apr 26 12:22:13.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-220" for this suite. 04/26/24 12:22:13.097
{"msg":"PASSED [sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]","completed":343,"skipped":6361,"failed":0}
------------------------------
â€¢ [2.306 seconds]
[sig-node] Pods
test/e2e/common/node/framework.go:23
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  test/e2e/common/node/pods.go:617

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Pods
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:22:10.797
    Apr 26 12:22:10.797: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pods 04/26/24 12:22:10.799
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:10.839
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:10.845
    [BeforeEach] [sig-node] Pods
      test/e2e/common/node/pods.go:193
    [It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
      test/e2e/common/node/pods.go:617
    Apr 26 12:22:10.852: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: creating the pod 04/26/24 12:22:10.853
    STEP: submitting the pod to kubernetes 04/26/24 12:22:10.853
    Apr 26 12:22:10.865: INFO: Waiting up to 5m0s for pod "pod-logs-websocket-00523cad-811c-46ec-bd29-d32c30e20521" in namespace "pods-220" to be "running and ready"
    Apr 26 12:22:10.881: INFO: Pod "pod-logs-websocket-00523cad-811c-46ec-bd29-d32c30e20521": Phase="Pending", Reason="", readiness=false. Elapsed: 15.752811ms
    Apr 26 12:22:10.881: INFO: The phase of Pod pod-logs-websocket-00523cad-811c-46ec-bd29-d32c30e20521 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:22:12.890: INFO: Pod "pod-logs-websocket-00523cad-811c-46ec-bd29-d32c30e20521": Phase="Running", Reason="", readiness=true. Elapsed: 2.024405648s
    Apr 26 12:22:12.890: INFO: The phase of Pod pod-logs-websocket-00523cad-811c-46ec-bd29-d32c30e20521 is Running (Ready = true)
    Apr 26 12:22:12.890: INFO: Pod "pod-logs-websocket-00523cad-811c-46ec-bd29-d32c30e20521" satisfied condition "running and ready"
    [AfterEach] [sig-node] Pods
      test/e2e/framework/framework.go:187
    Apr 26 12:22:13.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pods-220" for this suite. 04/26/24 12:22:13.097
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Secrets
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
[BeforeEach] [sig-node] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:22:13.105
Apr 26 12:22:13.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 12:22:13.106
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:13.125
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:13.132
[It] should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153
STEP: creating a secret 04/26/24 12:22:13.138
STEP: listing secrets in all namespaces to ensure that there are more than zero 04/26/24 12:22:13.143
STEP: patching the secret 04/26/24 12:22:13.149
STEP: deleting the secret using a LabelSelector 04/26/24 12:22:13.161
STEP: listing secrets in all namespaces, searching for label name and value in patch 04/26/24 12:22:13.168
[AfterEach] [sig-node] Secrets
  test/e2e/framework/framework.go:187
Apr 26 12:22:13.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-310" for this suite. 04/26/24 12:22:13.187
{"msg":"PASSED [sig-node] Secrets should patch a secret [Conformance]","completed":344,"skipped":6371,"failed":0}
------------------------------
â€¢ [0.088 seconds]
[sig-node] Secrets
test/e2e/common/node/framework.go:23
  should patch a secret [Conformance]
  test/e2e/common/node/secrets.go:153

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:22:13.105
    Apr 26 12:22:13.105: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 12:22:13.106
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:13.125
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:13.132
    [It] should patch a secret [Conformance]
      test/e2e/common/node/secrets.go:153
    STEP: creating a secret 04/26/24 12:22:13.138
    STEP: listing secrets in all namespaces to ensure that there are more than zero 04/26/24 12:22:13.143
    STEP: patching the secret 04/26/24 12:22:13.149
    STEP: deleting the secret using a LabelSelector 04/26/24 12:22:13.161
    STEP: listing secrets in all namespaces, searching for label name and value in patch 04/26/24 12:22:13.168
    [AfterEach] [sig-node] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 12:22:13.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-310" for this suite. 04/26/24 12:22:13.187
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Probing container
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
[BeforeEach] [sig-node] Probing container
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:22:13.194
Apr 26 12:22:13.195: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename container-probe 04/26/24 12:22:13.196
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:13.219
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:13.228
[BeforeEach] [sig-node] Probing container
  test/e2e/common/node/container_probe.go:59
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195
STEP: Creating pod liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 in namespace container-probe-7013 04/26/24 12:22:13.237
Apr 26 12:22:13.251: INFO: Waiting up to 5m0s for pod "liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4" in namespace "container-probe-7013" to be "not pending"
Apr 26 12:22:13.362: INFO: Pod "liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4": Phase="Pending", Reason="", readiness=false. Elapsed: 110.950516ms
Apr 26 12:22:15.368: INFO: Pod "liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4": Phase="Running", Reason="", readiness=true. Elapsed: 2.117093657s
Apr 26 12:22:15.368: INFO: Pod "liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4" satisfied condition "not pending"
Apr 26 12:22:15.368: INFO: Started pod liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 in namespace container-probe-7013
STEP: checking the pod's current state and verifying that restartCount is present 04/26/24 12:22:15.368
Apr 26 12:22:15.374: INFO: Initial restart count of pod liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 is 0
Apr 26 12:22:35.556: INFO: Restart count of pod container-probe-7013/liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 is now 1 (20.182409015s elapsed)
Apr 26 12:22:55.634: INFO: Restart count of pod container-probe-7013/liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 is now 2 (40.26050224s elapsed)
Apr 26 12:23:15.730: INFO: Restart count of pod container-probe-7013/liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 is now 3 (1m0.355944714s elapsed)
Apr 26 12:23:35.807: INFO: Restart count of pod container-probe-7013/liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 is now 4 (1m20.433235007s elapsed)
Apr 26 12:24:48.082: INFO: Restart count of pod container-probe-7013/liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 is now 5 (2m32.708520953s elapsed)
STEP: deleting the pod 04/26/24 12:24:48.082
[AfterEach] [sig-node] Probing container
  test/e2e/framework/framework.go:187
Apr 26 12:24:48.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7013" for this suite. 04/26/24 12:24:48.11
{"msg":"PASSED [sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]","completed":345,"skipped":6389,"failed":0}
------------------------------
â€¢ [SLOW TEST] [154.923 seconds]
[sig-node] Probing container
test/e2e/common/node/framework.go:23
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  test/e2e/common/node/container_probe.go:195

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Probing container
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:22:13.194
    Apr 26 12:22:13.195: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename container-probe 04/26/24 12:22:13.196
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:22:13.219
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:22:13.228
    [BeforeEach] [sig-node] Probing container
      test/e2e/common/node/container_probe.go:59
    [It] should have monotonically increasing restart count [NodeConformance] [Conformance]
      test/e2e/common/node/container_probe.go:195
    STEP: Creating pod liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 in namespace container-probe-7013 04/26/24 12:22:13.237
    Apr 26 12:22:13.251: INFO: Waiting up to 5m0s for pod "liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4" in namespace "container-probe-7013" to be "not pending"
    Apr 26 12:22:13.362: INFO: Pod "liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4": Phase="Pending", Reason="", readiness=false. Elapsed: 110.950516ms
    Apr 26 12:22:15.368: INFO: Pod "liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4": Phase="Running", Reason="", readiness=true. Elapsed: 2.117093657s
    Apr 26 12:22:15.368: INFO: Pod "liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4" satisfied condition "not pending"
    Apr 26 12:22:15.368: INFO: Started pod liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 in namespace container-probe-7013
    STEP: checking the pod's current state and verifying that restartCount is present 04/26/24 12:22:15.368
    Apr 26 12:22:15.374: INFO: Initial restart count of pod liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 is 0
    Apr 26 12:22:35.556: INFO: Restart count of pod container-probe-7013/liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 is now 1 (20.182409015s elapsed)
    Apr 26 12:22:55.634: INFO: Restart count of pod container-probe-7013/liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 is now 2 (40.26050224s elapsed)
    Apr 26 12:23:15.730: INFO: Restart count of pod container-probe-7013/liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 is now 3 (1m0.355944714s elapsed)
    Apr 26 12:23:35.807: INFO: Restart count of pod container-probe-7013/liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 is now 4 (1m20.433235007s elapsed)
    Apr 26 12:24:48.082: INFO: Restart count of pod container-probe-7013/liveness-2303937f-953b-4f4b-b8e9-7a5c2a1e02b4 is now 5 (2m32.708520953s elapsed)
    STEP: deleting the pod 04/26/24 12:24:48.082
    [AfterEach] [sig-node] Probing container
      test/e2e/framework/framework.go:187
    Apr 26 12:24:48.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "container-probe-7013" for this suite. 04/26/24 12:24:48.11
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:24:48.118
Apr 26 12:24:48.118: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename gc 04/26/24 12:24:48.119
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:24:48.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:24:48.145
[It] should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370
STEP: create the rc 04/26/24 12:24:48.163
STEP: delete the rc 04/26/24 12:24:53.18
STEP: wait for the rc to be deleted 04/26/24 12:24:53.193
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 04/26/24 12:24:58.201
STEP: Gathering metrics 04/26/24 12:25:28.236
W0426 12:25:28.253047      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 26 12:25:28.253: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 26 12:25:28.253: INFO: Deleting pod "simpletest.rc-2gc99" in namespace "gc-8243"
Apr 26 12:25:28.270: INFO: Deleting pod "simpletest.rc-2gcb8" in namespace "gc-8243"
Apr 26 12:25:28.286: INFO: Deleting pod "simpletest.rc-2hnll" in namespace "gc-8243"
Apr 26 12:25:28.296: INFO: Deleting pod "simpletest.rc-2s7qr" in namespace "gc-8243"
Apr 26 12:25:28.310: INFO: Deleting pod "simpletest.rc-2twcl" in namespace "gc-8243"
Apr 26 12:25:28.326: INFO: Deleting pod "simpletest.rc-2zfmg" in namespace "gc-8243"
Apr 26 12:25:28.343: INFO: Deleting pod "simpletest.rc-42jn5" in namespace "gc-8243"
Apr 26 12:25:28.359: INFO: Deleting pod "simpletest.rc-4dfcx" in namespace "gc-8243"
Apr 26 12:25:28.394: INFO: Deleting pod "simpletest.rc-4dkhx" in namespace "gc-8243"
Apr 26 12:25:28.417: INFO: Deleting pod "simpletest.rc-5dkfw" in namespace "gc-8243"
Apr 26 12:25:28.428: INFO: Deleting pod "simpletest.rc-5tcbl" in namespace "gc-8243"
Apr 26 12:25:28.438: INFO: Deleting pod "simpletest.rc-5x96l" in namespace "gc-8243"
Apr 26 12:25:28.452: INFO: Deleting pod "simpletest.rc-6ft82" in namespace "gc-8243"
Apr 26 12:25:28.467: INFO: Deleting pod "simpletest.rc-6g6fd" in namespace "gc-8243"
Apr 26 12:25:28.478: INFO: Deleting pod "simpletest.rc-6xpl8" in namespace "gc-8243"
Apr 26 12:25:28.489: INFO: Deleting pod "simpletest.rc-77bmk" in namespace "gc-8243"
Apr 26 12:25:28.504: INFO: Deleting pod "simpletest.rc-7fm5s" in namespace "gc-8243"
Apr 26 12:25:28.536: INFO: Deleting pod "simpletest.rc-7hc7j" in namespace "gc-8243"
Apr 26 12:25:28.581: INFO: Deleting pod "simpletest.rc-7hzps" in namespace "gc-8243"
Apr 26 12:25:28.618: INFO: Deleting pod "simpletest.rc-7qcrh" in namespace "gc-8243"
Apr 26 12:25:28.652: INFO: Deleting pod "simpletest.rc-7rd7q" in namespace "gc-8243"
Apr 26 12:25:28.667: INFO: Deleting pod "simpletest.rc-82292" in namespace "gc-8243"
Apr 26 12:25:28.681: INFO: Deleting pod "simpletest.rc-8b7zl" in namespace "gc-8243"
Apr 26 12:25:28.698: INFO: Deleting pod "simpletest.rc-8lgvf" in namespace "gc-8243"
Apr 26 12:25:28.714: INFO: Deleting pod "simpletest.rc-8sw6d" in namespace "gc-8243"
Apr 26 12:25:28.727: INFO: Deleting pod "simpletest.rc-8zcnw" in namespace "gc-8243"
Apr 26 12:25:28.741: INFO: Deleting pod "simpletest.rc-94x2j" in namespace "gc-8243"
Apr 26 12:25:28.753: INFO: Deleting pod "simpletest.rc-9nrnp" in namespace "gc-8243"
Apr 26 12:25:28.765: INFO: Deleting pod "simpletest.rc-b529n" in namespace "gc-8243"
Apr 26 12:25:28.776: INFO: Deleting pod "simpletest.rc-b7wqg" in namespace "gc-8243"
Apr 26 12:25:28.798: INFO: Deleting pod "simpletest.rc-bbs2b" in namespace "gc-8243"
Apr 26 12:25:28.811: INFO: Deleting pod "simpletest.rc-blqph" in namespace "gc-8243"
Apr 26 12:25:28.821: INFO: Deleting pod "simpletest.rc-bm6pl" in namespace "gc-8243"
Apr 26 12:25:28.835: INFO: Deleting pod "simpletest.rc-bqtn9" in namespace "gc-8243"
Apr 26 12:25:28.848: INFO: Deleting pod "simpletest.rc-brzqf" in namespace "gc-8243"
Apr 26 12:25:28.864: INFO: Deleting pod "simpletest.rc-bzcwf" in namespace "gc-8243"
Apr 26 12:25:28.877: INFO: Deleting pod "simpletest.rc-cczl7" in namespace "gc-8243"
Apr 26 12:25:28.916: INFO: Deleting pod "simpletest.rc-ctcqt" in namespace "gc-8243"
Apr 26 12:25:28.932: INFO: Deleting pod "simpletest.rc-cxfq8" in namespace "gc-8243"
Apr 26 12:25:28.942: INFO: Deleting pod "simpletest.rc-cxv84" in namespace "gc-8243"
Apr 26 12:25:28.964: INFO: Deleting pod "simpletest.rc-dbxp9" in namespace "gc-8243"
Apr 26 12:25:28.976: INFO: Deleting pod "simpletest.rc-dvswv" in namespace "gc-8243"
Apr 26 12:25:28.990: INFO: Deleting pod "simpletest.rc-fktlw" in namespace "gc-8243"
Apr 26 12:25:29.001: INFO: Deleting pod "simpletest.rc-flkbc" in namespace "gc-8243"
Apr 26 12:25:29.014: INFO: Deleting pod "simpletest.rc-flzbs" in namespace "gc-8243"
Apr 26 12:25:29.026: INFO: Deleting pod "simpletest.rc-fm5dz" in namespace "gc-8243"
Apr 26 12:25:29.038: INFO: Deleting pod "simpletest.rc-ftt4l" in namespace "gc-8243"
Apr 26 12:25:29.052: INFO: Deleting pod "simpletest.rc-g6qjs" in namespace "gc-8243"
Apr 26 12:25:29.066: INFO: Deleting pod "simpletest.rc-gg894" in namespace "gc-8243"
Apr 26 12:25:29.091: INFO: Deleting pod "simpletest.rc-gpnjr" in namespace "gc-8243"
Apr 26 12:25:29.160: INFO: Deleting pod "simpletest.rc-gs8pv" in namespace "gc-8243"
Apr 26 12:25:29.183: INFO: Deleting pod "simpletest.rc-h4gzb" in namespace "gc-8243"
Apr 26 12:25:29.208: INFO: Deleting pod "simpletest.rc-htfpn" in namespace "gc-8243"
Apr 26 12:25:29.220: INFO: Deleting pod "simpletest.rc-hvjs9" in namespace "gc-8243"
Apr 26 12:25:29.229: INFO: Deleting pod "simpletest.rc-j6s4j" in namespace "gc-8243"
Apr 26 12:25:29.241: INFO: Deleting pod "simpletest.rc-jt828" in namespace "gc-8243"
Apr 26 12:25:29.250: INFO: Deleting pod "simpletest.rc-jxwf7" in namespace "gc-8243"
Apr 26 12:25:29.266: INFO: Deleting pod "simpletest.rc-k7qdv" in namespace "gc-8243"
Apr 26 12:25:29.279: INFO: Deleting pod "simpletest.rc-krvr6" in namespace "gc-8243"
Apr 26 12:25:29.293: INFO: Deleting pod "simpletest.rc-l2vjh" in namespace "gc-8243"
Apr 26 12:25:29.305: INFO: Deleting pod "simpletest.rc-lh7xh" in namespace "gc-8243"
Apr 26 12:25:29.316: INFO: Deleting pod "simpletest.rc-lqftf" in namespace "gc-8243"
Apr 26 12:25:29.327: INFO: Deleting pod "simpletest.rc-mzbzm" in namespace "gc-8243"
Apr 26 12:25:29.338: INFO: Deleting pod "simpletest.rc-n7j62" in namespace "gc-8243"
Apr 26 12:25:29.350: INFO: Deleting pod "simpletest.rc-njq2s" in namespace "gc-8243"
Apr 26 12:25:29.378: INFO: Deleting pod "simpletest.rc-nmmfd" in namespace "gc-8243"
Apr 26 12:25:29.419: INFO: Deleting pod "simpletest.rc-p2lgl" in namespace "gc-8243"
Apr 26 12:25:29.437: INFO: Deleting pod "simpletest.rc-p85sl" in namespace "gc-8243"
Apr 26 12:25:29.452: INFO: Deleting pod "simpletest.rc-pd4tj" in namespace "gc-8243"
Apr 26 12:25:29.468: INFO: Deleting pod "simpletest.rc-pnkq5" in namespace "gc-8243"
Apr 26 12:25:29.514: INFO: Deleting pod "simpletest.rc-q9627" in namespace "gc-8243"
Apr 26 12:25:29.539: INFO: Deleting pod "simpletest.rc-qgr24" in namespace "gc-8243"
Apr 26 12:25:29.583: INFO: Deleting pod "simpletest.rc-qpj82" in namespace "gc-8243"
Apr 26 12:25:29.632: INFO: Deleting pod "simpletest.rc-qtxw8" in namespace "gc-8243"
Apr 26 12:25:29.644: INFO: Deleting pod "simpletest.rc-qv59b" in namespace "gc-8243"
Apr 26 12:25:29.657: INFO: Deleting pod "simpletest.rc-qwxk6" in namespace "gc-8243"
Apr 26 12:25:29.669: INFO: Deleting pod "simpletest.rc-rcrfz" in namespace "gc-8243"
Apr 26 12:25:29.685: INFO: Deleting pod "simpletest.rc-rm5vv" in namespace "gc-8243"
Apr 26 12:25:29.718: INFO: Deleting pod "simpletest.rc-rpvln" in namespace "gc-8243"
Apr 26 12:25:29.767: INFO: Deleting pod "simpletest.rc-rv7cx" in namespace "gc-8243"
Apr 26 12:25:29.818: INFO: Deleting pod "simpletest.rc-rwjz2" in namespace "gc-8243"
Apr 26 12:25:29.865: INFO: Deleting pod "simpletest.rc-shvhx" in namespace "gc-8243"
Apr 26 12:25:29.917: INFO: Deleting pod "simpletest.rc-smvmp" in namespace "gc-8243"
Apr 26 12:25:29.963: INFO: Deleting pod "simpletest.rc-ss8nc" in namespace "gc-8243"
Apr 26 12:25:30.016: INFO: Deleting pod "simpletest.rc-sssdb" in namespace "gc-8243"
Apr 26 12:25:30.064: INFO: Deleting pod "simpletest.rc-stnhn" in namespace "gc-8243"
Apr 26 12:25:30.116: INFO: Deleting pod "simpletest.rc-sx7r9" in namespace "gc-8243"
Apr 26 12:25:30.165: INFO: Deleting pod "simpletest.rc-t49kp" in namespace "gc-8243"
Apr 26 12:25:30.218: INFO: Deleting pod "simpletest.rc-t7f6b" in namespace "gc-8243"
Apr 26 12:25:30.266: INFO: Deleting pod "simpletest.rc-t8kg6" in namespace "gc-8243"
Apr 26 12:25:30.319: INFO: Deleting pod "simpletest.rc-v9j6m" in namespace "gc-8243"
Apr 26 12:25:30.373: INFO: Deleting pod "simpletest.rc-vs46b" in namespace "gc-8243"
Apr 26 12:25:30.415: INFO: Deleting pod "simpletest.rc-vsvkl" in namespace "gc-8243"
Apr 26 12:25:30.488: INFO: Deleting pod "simpletest.rc-whrz8" in namespace "gc-8243"
Apr 26 12:25:30.517: INFO: Deleting pod "simpletest.rc-x4gbr" in namespace "gc-8243"
Apr 26 12:25:30.597: INFO: Deleting pod "simpletest.rc-xf8qt" in namespace "gc-8243"
Apr 26 12:25:30.613: INFO: Deleting pod "simpletest.rc-xhr7z" in namespace "gc-8243"
Apr 26 12:25:30.664: INFO: Deleting pod "simpletest.rc-xlm27" in namespace "gc-8243"
Apr 26 12:25:30.722: INFO: Deleting pod "simpletest.rc-xmw29" in namespace "gc-8243"
Apr 26 12:25:30.766: INFO: Deleting pod "simpletest.rc-zsmmr" in namespace "gc-8243"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 26 12:25:30.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8243" for this suite. 04/26/24 12:25:30.861
{"msg":"PASSED [sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Conformance]","completed":346,"skipped":6401,"failed":0}
------------------------------
â€¢ [SLOW TEST] [42.803 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  test/e2e/apimachinery/garbage_collector.go:370

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:24:48.118
    Apr 26 12:24:48.118: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename gc 04/26/24 12:24:48.119
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:24:48.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:24:48.145
    [It] should orphan pods created by rc if delete options say so [Conformance]
      test/e2e/apimachinery/garbage_collector.go:370
    STEP: create the rc 04/26/24 12:24:48.163
    STEP: delete the rc 04/26/24 12:24:53.18
    STEP: wait for the rc to be deleted 04/26/24 12:24:53.193
    STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods 04/26/24 12:24:58.201
    STEP: Gathering metrics 04/26/24 12:25:28.236
    W0426 12:25:28.253047      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 26 12:25:28.253: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Apr 26 12:25:28.253: INFO: Deleting pod "simpletest.rc-2gc99" in namespace "gc-8243"
    Apr 26 12:25:28.270: INFO: Deleting pod "simpletest.rc-2gcb8" in namespace "gc-8243"
    Apr 26 12:25:28.286: INFO: Deleting pod "simpletest.rc-2hnll" in namespace "gc-8243"
    Apr 26 12:25:28.296: INFO: Deleting pod "simpletest.rc-2s7qr" in namespace "gc-8243"
    Apr 26 12:25:28.310: INFO: Deleting pod "simpletest.rc-2twcl" in namespace "gc-8243"
    Apr 26 12:25:28.326: INFO: Deleting pod "simpletest.rc-2zfmg" in namespace "gc-8243"
    Apr 26 12:25:28.343: INFO: Deleting pod "simpletest.rc-42jn5" in namespace "gc-8243"
    Apr 26 12:25:28.359: INFO: Deleting pod "simpletest.rc-4dfcx" in namespace "gc-8243"
    Apr 26 12:25:28.394: INFO: Deleting pod "simpletest.rc-4dkhx" in namespace "gc-8243"
    Apr 26 12:25:28.417: INFO: Deleting pod "simpletest.rc-5dkfw" in namespace "gc-8243"
    Apr 26 12:25:28.428: INFO: Deleting pod "simpletest.rc-5tcbl" in namespace "gc-8243"
    Apr 26 12:25:28.438: INFO: Deleting pod "simpletest.rc-5x96l" in namespace "gc-8243"
    Apr 26 12:25:28.452: INFO: Deleting pod "simpletest.rc-6ft82" in namespace "gc-8243"
    Apr 26 12:25:28.467: INFO: Deleting pod "simpletest.rc-6g6fd" in namespace "gc-8243"
    Apr 26 12:25:28.478: INFO: Deleting pod "simpletest.rc-6xpl8" in namespace "gc-8243"
    Apr 26 12:25:28.489: INFO: Deleting pod "simpletest.rc-77bmk" in namespace "gc-8243"
    Apr 26 12:25:28.504: INFO: Deleting pod "simpletest.rc-7fm5s" in namespace "gc-8243"
    Apr 26 12:25:28.536: INFO: Deleting pod "simpletest.rc-7hc7j" in namespace "gc-8243"
    Apr 26 12:25:28.581: INFO: Deleting pod "simpletest.rc-7hzps" in namespace "gc-8243"
    Apr 26 12:25:28.618: INFO: Deleting pod "simpletest.rc-7qcrh" in namespace "gc-8243"
    Apr 26 12:25:28.652: INFO: Deleting pod "simpletest.rc-7rd7q" in namespace "gc-8243"
    Apr 26 12:25:28.667: INFO: Deleting pod "simpletest.rc-82292" in namespace "gc-8243"
    Apr 26 12:25:28.681: INFO: Deleting pod "simpletest.rc-8b7zl" in namespace "gc-8243"
    Apr 26 12:25:28.698: INFO: Deleting pod "simpletest.rc-8lgvf" in namespace "gc-8243"
    Apr 26 12:25:28.714: INFO: Deleting pod "simpletest.rc-8sw6d" in namespace "gc-8243"
    Apr 26 12:25:28.727: INFO: Deleting pod "simpletest.rc-8zcnw" in namespace "gc-8243"
    Apr 26 12:25:28.741: INFO: Deleting pod "simpletest.rc-94x2j" in namespace "gc-8243"
    Apr 26 12:25:28.753: INFO: Deleting pod "simpletest.rc-9nrnp" in namespace "gc-8243"
    Apr 26 12:25:28.765: INFO: Deleting pod "simpletest.rc-b529n" in namespace "gc-8243"
    Apr 26 12:25:28.776: INFO: Deleting pod "simpletest.rc-b7wqg" in namespace "gc-8243"
    Apr 26 12:25:28.798: INFO: Deleting pod "simpletest.rc-bbs2b" in namespace "gc-8243"
    Apr 26 12:25:28.811: INFO: Deleting pod "simpletest.rc-blqph" in namespace "gc-8243"
    Apr 26 12:25:28.821: INFO: Deleting pod "simpletest.rc-bm6pl" in namespace "gc-8243"
    Apr 26 12:25:28.835: INFO: Deleting pod "simpletest.rc-bqtn9" in namespace "gc-8243"
    Apr 26 12:25:28.848: INFO: Deleting pod "simpletest.rc-brzqf" in namespace "gc-8243"
    Apr 26 12:25:28.864: INFO: Deleting pod "simpletest.rc-bzcwf" in namespace "gc-8243"
    Apr 26 12:25:28.877: INFO: Deleting pod "simpletest.rc-cczl7" in namespace "gc-8243"
    Apr 26 12:25:28.916: INFO: Deleting pod "simpletest.rc-ctcqt" in namespace "gc-8243"
    Apr 26 12:25:28.932: INFO: Deleting pod "simpletest.rc-cxfq8" in namespace "gc-8243"
    Apr 26 12:25:28.942: INFO: Deleting pod "simpletest.rc-cxv84" in namespace "gc-8243"
    Apr 26 12:25:28.964: INFO: Deleting pod "simpletest.rc-dbxp9" in namespace "gc-8243"
    Apr 26 12:25:28.976: INFO: Deleting pod "simpletest.rc-dvswv" in namespace "gc-8243"
    Apr 26 12:25:28.990: INFO: Deleting pod "simpletest.rc-fktlw" in namespace "gc-8243"
    Apr 26 12:25:29.001: INFO: Deleting pod "simpletest.rc-flkbc" in namespace "gc-8243"
    Apr 26 12:25:29.014: INFO: Deleting pod "simpletest.rc-flzbs" in namespace "gc-8243"
    Apr 26 12:25:29.026: INFO: Deleting pod "simpletest.rc-fm5dz" in namespace "gc-8243"
    Apr 26 12:25:29.038: INFO: Deleting pod "simpletest.rc-ftt4l" in namespace "gc-8243"
    Apr 26 12:25:29.052: INFO: Deleting pod "simpletest.rc-g6qjs" in namespace "gc-8243"
    Apr 26 12:25:29.066: INFO: Deleting pod "simpletest.rc-gg894" in namespace "gc-8243"
    Apr 26 12:25:29.091: INFO: Deleting pod "simpletest.rc-gpnjr" in namespace "gc-8243"
    Apr 26 12:25:29.160: INFO: Deleting pod "simpletest.rc-gs8pv" in namespace "gc-8243"
    Apr 26 12:25:29.183: INFO: Deleting pod "simpletest.rc-h4gzb" in namespace "gc-8243"
    Apr 26 12:25:29.208: INFO: Deleting pod "simpletest.rc-htfpn" in namespace "gc-8243"
    Apr 26 12:25:29.220: INFO: Deleting pod "simpletest.rc-hvjs9" in namespace "gc-8243"
    Apr 26 12:25:29.229: INFO: Deleting pod "simpletest.rc-j6s4j" in namespace "gc-8243"
    Apr 26 12:25:29.241: INFO: Deleting pod "simpletest.rc-jt828" in namespace "gc-8243"
    Apr 26 12:25:29.250: INFO: Deleting pod "simpletest.rc-jxwf7" in namespace "gc-8243"
    Apr 26 12:25:29.266: INFO: Deleting pod "simpletest.rc-k7qdv" in namespace "gc-8243"
    Apr 26 12:25:29.279: INFO: Deleting pod "simpletest.rc-krvr6" in namespace "gc-8243"
    Apr 26 12:25:29.293: INFO: Deleting pod "simpletest.rc-l2vjh" in namespace "gc-8243"
    Apr 26 12:25:29.305: INFO: Deleting pod "simpletest.rc-lh7xh" in namespace "gc-8243"
    Apr 26 12:25:29.316: INFO: Deleting pod "simpletest.rc-lqftf" in namespace "gc-8243"
    Apr 26 12:25:29.327: INFO: Deleting pod "simpletest.rc-mzbzm" in namespace "gc-8243"
    Apr 26 12:25:29.338: INFO: Deleting pod "simpletest.rc-n7j62" in namespace "gc-8243"
    Apr 26 12:25:29.350: INFO: Deleting pod "simpletest.rc-njq2s" in namespace "gc-8243"
    Apr 26 12:25:29.378: INFO: Deleting pod "simpletest.rc-nmmfd" in namespace "gc-8243"
    Apr 26 12:25:29.419: INFO: Deleting pod "simpletest.rc-p2lgl" in namespace "gc-8243"
    Apr 26 12:25:29.437: INFO: Deleting pod "simpletest.rc-p85sl" in namespace "gc-8243"
    Apr 26 12:25:29.452: INFO: Deleting pod "simpletest.rc-pd4tj" in namespace "gc-8243"
    Apr 26 12:25:29.468: INFO: Deleting pod "simpletest.rc-pnkq5" in namespace "gc-8243"
    Apr 26 12:25:29.514: INFO: Deleting pod "simpletest.rc-q9627" in namespace "gc-8243"
    Apr 26 12:25:29.539: INFO: Deleting pod "simpletest.rc-qgr24" in namespace "gc-8243"
    Apr 26 12:25:29.583: INFO: Deleting pod "simpletest.rc-qpj82" in namespace "gc-8243"
    Apr 26 12:25:29.632: INFO: Deleting pod "simpletest.rc-qtxw8" in namespace "gc-8243"
    Apr 26 12:25:29.644: INFO: Deleting pod "simpletest.rc-qv59b" in namespace "gc-8243"
    Apr 26 12:25:29.657: INFO: Deleting pod "simpletest.rc-qwxk6" in namespace "gc-8243"
    Apr 26 12:25:29.669: INFO: Deleting pod "simpletest.rc-rcrfz" in namespace "gc-8243"
    Apr 26 12:25:29.685: INFO: Deleting pod "simpletest.rc-rm5vv" in namespace "gc-8243"
    Apr 26 12:25:29.718: INFO: Deleting pod "simpletest.rc-rpvln" in namespace "gc-8243"
    Apr 26 12:25:29.767: INFO: Deleting pod "simpletest.rc-rv7cx" in namespace "gc-8243"
    Apr 26 12:25:29.818: INFO: Deleting pod "simpletest.rc-rwjz2" in namespace "gc-8243"
    Apr 26 12:25:29.865: INFO: Deleting pod "simpletest.rc-shvhx" in namespace "gc-8243"
    Apr 26 12:25:29.917: INFO: Deleting pod "simpletest.rc-smvmp" in namespace "gc-8243"
    Apr 26 12:25:29.963: INFO: Deleting pod "simpletest.rc-ss8nc" in namespace "gc-8243"
    Apr 26 12:25:30.016: INFO: Deleting pod "simpletest.rc-sssdb" in namespace "gc-8243"
    Apr 26 12:25:30.064: INFO: Deleting pod "simpletest.rc-stnhn" in namespace "gc-8243"
    Apr 26 12:25:30.116: INFO: Deleting pod "simpletest.rc-sx7r9" in namespace "gc-8243"
    Apr 26 12:25:30.165: INFO: Deleting pod "simpletest.rc-t49kp" in namespace "gc-8243"
    Apr 26 12:25:30.218: INFO: Deleting pod "simpletest.rc-t7f6b" in namespace "gc-8243"
    Apr 26 12:25:30.266: INFO: Deleting pod "simpletest.rc-t8kg6" in namespace "gc-8243"
    Apr 26 12:25:30.319: INFO: Deleting pod "simpletest.rc-v9j6m" in namespace "gc-8243"
    Apr 26 12:25:30.373: INFO: Deleting pod "simpletest.rc-vs46b" in namespace "gc-8243"
    Apr 26 12:25:30.415: INFO: Deleting pod "simpletest.rc-vsvkl" in namespace "gc-8243"
    Apr 26 12:25:30.488: INFO: Deleting pod "simpletest.rc-whrz8" in namespace "gc-8243"
    Apr 26 12:25:30.517: INFO: Deleting pod "simpletest.rc-x4gbr" in namespace "gc-8243"
    Apr 26 12:25:30.597: INFO: Deleting pod "simpletest.rc-xf8qt" in namespace "gc-8243"
    Apr 26 12:25:30.613: INFO: Deleting pod "simpletest.rc-xhr7z" in namespace "gc-8243"
    Apr 26 12:25:30.664: INFO: Deleting pod "simpletest.rc-xlm27" in namespace "gc-8243"
    Apr 26 12:25:30.722: INFO: Deleting pod "simpletest.rc-xmw29" in namespace "gc-8243"
    Apr 26 12:25:30.766: INFO: Deleting pod "simpletest.rc-zsmmr" in namespace "gc-8243"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 26 12:25:30.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-8243" for this suite. 04/26/24 12:25:30.861
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] CronJob
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
[BeforeEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:25:30.922
Apr 26 12:25:30.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename cronjob 04/26/24 12:25:30.923
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:25:30.939
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:25:30.946
[It] should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69
STEP: Creating a cronjob 04/26/24 12:25:30.953
STEP: Ensuring more than one job is running at a time 04/26/24 12:25:30.959
STEP: Ensuring at least two running jobs exists by listing jobs explicitly 04/26/24 12:27:00.965
STEP: Removing cronjob 04/26/24 12:27:00.969
[AfterEach] [sig-apps] CronJob
  test/e2e/framework/framework.go:187
Apr 26 12:27:00.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "cronjob-9244" for this suite. 04/26/24 12:27:00.987
{"msg":"PASSED [sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]","completed":347,"skipped":6415,"failed":0}
------------------------------
â€¢ [SLOW TEST] [90.072 seconds]
[sig-apps] CronJob
test/e2e/apps/framework.go:23
  should schedule multiple jobs concurrently [Conformance]
  test/e2e/apps/cronjob.go:69

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:25:30.922
    Apr 26 12:25:30.922: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename cronjob 04/26/24 12:25:30.923
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:25:30.939
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:25:30.946
    [It] should schedule multiple jobs concurrently [Conformance]
      test/e2e/apps/cronjob.go:69
    STEP: Creating a cronjob 04/26/24 12:25:30.953
    STEP: Ensuring more than one job is running at a time 04/26/24 12:25:30.959
    STEP: Ensuring at least two running jobs exists by listing jobs explicitly 04/26/24 12:27:00.965
    STEP: Removing cronjob 04/26/24 12:27:00.969
    [AfterEach] [sig-apps] CronJob
      test/e2e/framework/framework.go:187
    Apr 26 12:27:00.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "cronjob-9244" for this suite. 04/26/24 12:27:00.987
  << End Captured GinkgoWriter Output
------------------------------
S
------------------------------
[sig-api-machinery] Watchers
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
[BeforeEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:27:00.995
Apr 26 12:27:00.995: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename watch 04/26/24 12:27:00.996
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:01.024
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:01.031
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191
STEP: creating a watch on configmaps 04/26/24 12:27:01.037
STEP: creating a new configmap 04/26/24 12:27:01.04
STEP: modifying the configmap once 04/26/24 12:27:01.051
STEP: closing the watch once it receives two notifications 04/26/24 12:27:01.059
Apr 26 12:27:01.059: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8130  dbdb63a8-540d-4c46-a458-bce68e7b38b7 51099 0 2024-04-26 12:27:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-26 12:27:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 12:27:01.059: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8130  dbdb63a8-540d-4c46-a458-bce68e7b38b7 51100 0 2024-04-26 12:27:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-26 12:27:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
STEP: modifying the configmap a second time, while the watch is closed 04/26/24 12:27:01.06
STEP: creating a new watch on configmaps from the last resource version observed by the first watch 04/26/24 12:27:01.069
STEP: deleting the configmap 04/26/24 12:27:01.072
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 04/26/24 12:27:01.077
Apr 26 12:27:01.078: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8130  dbdb63a8-540d-4c46-a458-bce68e7b38b7 51101 0 2024-04-26 12:27:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-26 12:27:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
Apr 26 12:27:01.078: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8130  dbdb63a8-540d-4c46-a458-bce68e7b38b7 51102 0 2024-04-26 12:27:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-26 12:27:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
[AfterEach] [sig-api-machinery] Watchers
  test/e2e/framework/framework.go:187
Apr 26 12:27:01.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8130" for this suite. 04/26/24 12:27:01.089
{"msg":"PASSED [sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]","completed":348,"skipped":6416,"failed":0}
------------------------------
â€¢ [0.101 seconds]
[sig-api-machinery] Watchers
test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  test/e2e/apimachinery/watch.go:191

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:27:00.995
    Apr 26 12:27:00.995: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename watch 04/26/24 12:27:00.996
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:01.024
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:01.031
    [It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
      test/e2e/apimachinery/watch.go:191
    STEP: creating a watch on configmaps 04/26/24 12:27:01.037
    STEP: creating a new configmap 04/26/24 12:27:01.04
    STEP: modifying the configmap once 04/26/24 12:27:01.051
    STEP: closing the watch once it receives two notifications 04/26/24 12:27:01.059
    Apr 26 12:27:01.059: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8130  dbdb63a8-540d-4c46-a458-bce68e7b38b7 51099 0 2024-04-26 12:27:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-26 12:27:01 +0000 UTC FieldsV1 {"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 12:27:01.059: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8130  dbdb63a8-540d-4c46-a458-bce68e7b38b7 51100 0 2024-04-26 12:27:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-26 12:27:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},Immutable:nil,}
    STEP: modifying the configmap a second time, while the watch is closed 04/26/24 12:27:01.06
    STEP: creating a new watch on configmaps from the last resource version observed by the first watch 04/26/24 12:27:01.069
    STEP: deleting the configmap 04/26/24 12:27:01.072
    STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed 04/26/24 12:27:01.077
    Apr 26 12:27:01.078: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8130  dbdb63a8-540d-4c46-a458-bce68e7b38b7 51101 0 2024-04-26 12:27:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-26 12:27:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    Apr 26 12:27:01.078: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8130  dbdb63a8-540d-4c46-a458-bce68e7b38b7 51102 0 2024-04-26 12:27:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] [] [{e2e.test Update v1 2024-04-26 12:27:01 +0000 UTC FieldsV1 {"f:data":{".":{},"f:mutation":{}},"f:metadata":{"f:labels":{".":{},"f:watch-this-configmap":{}}}} }]},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},Immutable:nil,}
    [AfterEach] [sig-api-machinery] Watchers
      test/e2e/framework/framework.go:187
    Apr 26 12:27:01.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "watch-8130" for this suite. 04/26/24 12:27:01.089
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[BeforeEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:27:01.097
Apr 26 12:27:01.097: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename secrets 04/26/24 12:27:01.098
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:01.114
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:01.121
[It] should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385
[AfterEach] [sig-storage] Secrets
  test/e2e/framework/framework.go:187
Apr 26 12:27:01.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2617" for this suite. 04/26/24 12:27:01.187
{"msg":"PASSED [sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]","completed":349,"skipped":6431,"failed":0}
------------------------------
â€¢ [0.096 seconds]
[sig-storage] Secrets
test/e2e/common/storage/framework.go:23
  should be immutable if `immutable` field is set [Conformance]
  test/e2e/common/storage/secrets_volume.go:385

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:27:01.097
    Apr 26 12:27:01.097: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename secrets 04/26/24 12:27:01.098
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:01.114
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:01.121
    [It] should be immutable if `immutable` field is set [Conformance]
      test/e2e/common/storage/secrets_volume.go:385
    [AfterEach] [sig-storage] Secrets
      test/e2e/framework/framework.go:187
    Apr 26 12:27:01.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "secrets-2617" for this suite. 04/26/24 12:27:01.187
  << End Captured GinkgoWriter Output
------------------------------
[sig-apps] Job
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:27:01.194
Apr 26 12:27:01.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename job 04/26/24 12:27:01.195
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:01.225
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:01.233
[It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194
STEP: Creating Indexed job 04/26/24 12:27:01.239
STEP: Ensuring job reaches completions 04/26/24 12:27:01.246
STEP: Ensuring pods with index for job exist 04/26/24 12:27:09.253
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 26 12:27:09.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6607" for this suite. 04/26/24 12:27:09.272
{"msg":"PASSED [sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]","completed":350,"skipped":6431,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.087 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
  test/e2e/apps/job.go:194

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:27:01.194
    Apr 26 12:27:01.194: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename job 04/26/24 12:27:01.195
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:01.225
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:01.233
    [It] should create pods for an Indexed job with completion indexes and specified hostname [Conformance]
      test/e2e/apps/job.go:194
    STEP: Creating Indexed job 04/26/24 12:27:01.239
    STEP: Ensuring job reaches completions 04/26/24 12:27:01.246
    STEP: Ensuring pods with index for job exist 04/26/24 12:27:09.253
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 26 12:27:09.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-6607" for this suite. 04/26/24 12:27:09.272
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:27:09.281
Apr 26 12:27:09.281: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename projected 04/26/24 12:27:09.282
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:09.301
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:09.308
[BeforeEach] [sig-storage] Projected downwardAPI
  test/e2e/common/storage/projected_downwardapi.go:43
[It] should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161
STEP: Creating the pod 04/26/24 12:27:09.315
Apr 26 12:27:09.327: INFO: Waiting up to 5m0s for pod "annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac" in namespace "projected-9170" to be "running and ready"
Apr 26 12:27:09.336: INFO: Pod "annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac": Phase="Pending", Reason="", readiness=false. Elapsed: 8.120925ms
Apr 26 12:27:09.336: INFO: The phase of Pod annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:27:11.342: INFO: Pod "annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac": Phase="Running", Reason="", readiness=true. Elapsed: 2.014623774s
Apr 26 12:27:11.342: INFO: The phase of Pod annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac is Running (Ready = true)
Apr 26 12:27:11.342: INFO: Pod "annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac" satisfied condition "running and ready"
Apr 26 12:27:11.921: INFO: Successfully updated pod "annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac"
[AfterEach] [sig-storage] Projected downwardAPI
  test/e2e/framework/framework.go:187
Apr 26 12:27:13.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9170" for this suite. 04/26/24 12:27:13.968
{"msg":"PASSED [sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]","completed":351,"skipped":6444,"failed":0}
------------------------------
â€¢ [4.693 seconds]
[sig-storage] Projected downwardAPI
test/e2e/common/storage/framework.go:23
  should update annotations on modification [NodeConformance] [Conformance]
  test/e2e/common/storage/projected_downwardapi.go:161

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:27:09.281
    Apr 26 12:27:09.281: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename projected 04/26/24 12:27:09.282
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:09.301
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:09.308
    [BeforeEach] [sig-storage] Projected downwardAPI
      test/e2e/common/storage/projected_downwardapi.go:43
    [It] should update annotations on modification [NodeConformance] [Conformance]
      test/e2e/common/storage/projected_downwardapi.go:161
    STEP: Creating the pod 04/26/24 12:27:09.315
    Apr 26 12:27:09.327: INFO: Waiting up to 5m0s for pod "annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac" in namespace "projected-9170" to be "running and ready"
    Apr 26 12:27:09.336: INFO: Pod "annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac": Phase="Pending", Reason="", readiness=false. Elapsed: 8.120925ms
    Apr 26 12:27:09.336: INFO: The phase of Pod annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:27:11.342: INFO: Pod "annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac": Phase="Running", Reason="", readiness=true. Elapsed: 2.014623774s
    Apr 26 12:27:11.342: INFO: The phase of Pod annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac is Running (Ready = true)
    Apr 26 12:27:11.342: INFO: Pod "annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac" satisfied condition "running and ready"
    Apr 26 12:27:11.921: INFO: Successfully updated pod "annotationupdate0ae9ec61-2044-4a06-bbb0-a2affbcd8dac"
    [AfterEach] [sig-storage] Projected downwardAPI
      test/e2e/framework/framework.go:187
    Apr 26 12:27:13.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "projected-9170" for this suite. 04/26/24 12:27:13.968
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Variable Expansion
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
[BeforeEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:27:13.977
Apr 26 12:27:13.977: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename var-expansion 04/26/24 12:27:13.977
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:14.001
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:14.009
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43
STEP: Creating a pod to test env composition 04/26/24 12:27:14.015
Apr 26 12:27:14.028: INFO: Waiting up to 5m0s for pod "var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112" in namespace "var-expansion-1828" to be "Succeeded or Failed"
Apr 26 12:27:14.057: INFO: Pod "var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112": Phase="Pending", Reason="", readiness=false. Elapsed: 29.116486ms
Apr 26 12:27:16.066: INFO: Pod "var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03820413s
Apr 26 12:27:18.067: INFO: Pod "var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038859878s
STEP: Saw pod success 04/26/24 12:27:18.067
Apr 26 12:27:18.067: INFO: Pod "var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112" satisfied condition "Succeeded or Failed"
Apr 26 12:27:18.077: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112 container dapi-container: <nil>
STEP: delete the pod 04/26/24 12:27:18.093
Apr 26 12:27:18.103: INFO: Waiting for pod var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112 to disappear
Apr 26 12:27:18.107: INFO: Pod var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112 no longer exists
[AfterEach] [sig-node] Variable Expansion
  test/e2e/framework/framework.go:187
Apr 26 12:27:18.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1828" for this suite. 04/26/24 12:27:18.115
{"msg":"PASSED [sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]","completed":352,"skipped":6499,"failed":0}
------------------------------
â€¢ [4.144 seconds]
[sig-node] Variable Expansion
test/e2e/common/node/framework.go:23
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  test/e2e/common/node/expansion.go:43

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:27:13.977
    Apr 26 12:27:13.977: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename var-expansion 04/26/24 12:27:13.977
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:14.001
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:14.009
    [It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
      test/e2e/common/node/expansion.go:43
    STEP: Creating a pod to test env composition 04/26/24 12:27:14.015
    Apr 26 12:27:14.028: INFO: Waiting up to 5m0s for pod "var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112" in namespace "var-expansion-1828" to be "Succeeded or Failed"
    Apr 26 12:27:14.057: INFO: Pod "var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112": Phase="Pending", Reason="", readiness=false. Elapsed: 29.116486ms
    Apr 26 12:27:16.066: INFO: Pod "var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03820413s
    Apr 26 12:27:18.067: INFO: Pod "var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038859878s
    STEP: Saw pod success 04/26/24 12:27:18.067
    Apr 26 12:27:18.067: INFO: Pod "var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112" satisfied condition "Succeeded or Failed"
    Apr 26 12:27:18.077: INFO: Trying to get logs from node shoot--thomas--conf-125-worker-6a5hr-1-z2-598bf-s48fp pod var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112 container dapi-container: <nil>
    STEP: delete the pod 04/26/24 12:27:18.093
    Apr 26 12:27:18.103: INFO: Waiting for pod var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112 to disappear
    Apr 26 12:27:18.107: INFO: Pod var-expansion-7e67f8bc-4833-49ca-bafc-142915be7112 no longer exists
    [AfterEach] [sig-node] Variable Expansion
      test/e2e/framework/framework.go:187
    Apr 26 12:27:18.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "var-expansion-1828" for this suite. 04/26/24 12:27:18.115
  << End Captured GinkgoWriter Output
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
[BeforeEach] [sig-network] Networking
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:27:18.123
Apr 26 12:27:18.123: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename pod-network-test 04/26/24 12:27:18.124
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:18.138
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:18.145
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/network/networking.go:122
STEP: Performing setup for networking test in namespace pod-network-test-2039 04/26/24 12:27:18.152
STEP: creating a selector 04/26/24 12:27:18.152
STEP: Creating the service pods in kubernetes 04/26/24 12:27:18.153
Apr 26 12:27:18.153: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
Apr 26 12:27:18.242: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2039" to be "running and ready"
Apr 26 12:27:18.258: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 15.165222ms
Apr 26 12:27:18.258: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:27:20.265: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.02204863s
Apr 26 12:27:20.265: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 12:27:22.266: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.023275114s
Apr 26 12:27:22.266: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 12:27:24.263: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.020927808s
Apr 26 12:27:24.263: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 12:27:26.271: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.028852801s
Apr 26 12:27:26.272: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 12:27:28.264: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.021791795s
Apr 26 12:27:28.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
Apr 26 12:27:30.265: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.022695014s
Apr 26 12:27:30.265: INFO: The phase of Pod netserver-0 is Running (Ready = true)
Apr 26 12:27:30.265: INFO: Pod "netserver-0" satisfied condition "running and ready"
Apr 26 12:27:30.269: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2039" to be "running and ready"
Apr 26 12:27:30.273: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.592716ms
Apr 26 12:27:30.274: INFO: The phase of Pod netserver-1 is Running (Ready = true)
Apr 26 12:27:30.274: INFO: Pod "netserver-1" satisfied condition "running and ready"
Apr 26 12:27:30.284: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2039" to be "running and ready"
Apr 26 12:27:30.293: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 9.47124ms
Apr 26 12:27:30.293: INFO: The phase of Pod netserver-2 is Running (Ready = true)
Apr 26 12:27:30.293: INFO: Pod "netserver-2" satisfied condition "running and ready"
Apr 26 12:27:30.300: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-2039" to be "running and ready"
Apr 26 12:27:30.321: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 20.82966ms
Apr 26 12:27:30.321: INFO: The phase of Pod netserver-3 is Running (Ready = true)
Apr 26 12:27:30.321: INFO: Pod "netserver-3" satisfied condition "running and ready"
Apr 26 12:27:30.328: INFO: Waiting up to 5m0s for pod "netserver-4" in namespace "pod-network-test-2039" to be "running and ready"
Apr 26 12:27:30.343: INFO: Pod "netserver-4": Phase="Running", Reason="", readiness=true. Elapsed: 14.639496ms
Apr 26 12:27:30.343: INFO: The phase of Pod netserver-4 is Running (Ready = true)
Apr 26 12:27:30.343: INFO: Pod "netserver-4" satisfied condition "running and ready"
STEP: Creating test pods 04/26/24 12:27:30.348
Apr 26 12:27:30.397: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2039" to be "running"
Apr 26 12:27:30.415: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 17.668509ms
Apr 26 12:27:32.439: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.041583085s
Apr 26 12:27:32.439: INFO: Pod "test-container-pod" satisfied condition "running"
Apr 26 12:27:32.444: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-2039" to be "running"
Apr 26 12:27:32.449: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.69536ms
Apr 26 12:27:32.449: INFO: Pod "host-test-container-pod" satisfied condition "running"
Apr 26 12:27:32.454: INFO: Setting MaxTries for pod polling to 55 for networking test based on endpoint count 5
Apr 26 12:27:32.454: INFO: Going to poll 100.96.4.75 on port 8081 at least 0 times, with a maximum of 55 tries before failing
Apr 26 12:27:32.459: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.4.75 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2039 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:27:32.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:27:32.460: INFO: ExecWithOptions: Clientset creation
Apr 26 12:27:32.460: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-2039/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.4.75+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 26 12:27:33.845: INFO: Found all 1 expected endpoints: [netserver-0]
Apr 26 12:27:33.845: INFO: Going to poll 100.96.2.116 on port 8081 at least 0 times, with a maximum of 55 tries before failing
Apr 26 12:27:33.852: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.2.116 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2039 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:27:33.852: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:27:33.852: INFO: ExecWithOptions: Clientset creation
Apr 26 12:27:33.853: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-2039/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.2.116+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 26 12:27:35.350: INFO: Found all 1 expected endpoints: [netserver-1]
Apr 26 12:27:35.350: INFO: Going to poll 100.96.3.111 on port 8081 at least 0 times, with a maximum of 55 tries before failing
Apr 26 12:27:35.356: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.3.111 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2039 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:27:35.356: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:27:35.357: INFO: ExecWithOptions: Clientset creation
Apr 26 12:27:35.357: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-2039/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.3.111+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 26 12:27:36.865: INFO: Found all 1 expected endpoints: [netserver-2]
Apr 26 12:27:36.865: INFO: Going to poll 100.96.1.54 on port 8081 at least 0 times, with a maximum of 55 tries before failing
Apr 26 12:27:36.873: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.1.54 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2039 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:27:36.873: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:27:36.873: INFO: ExecWithOptions: Clientset creation
Apr 26 12:27:36.873: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-2039/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.1.54+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 26 12:27:38.376: INFO: Found all 1 expected endpoints: [netserver-3]
Apr 26 12:27:38.376: INFO: Going to poll 100.96.0.119 on port 8081 at least 0 times, with a maximum of 55 tries before failing
Apr 26 12:27:38.382: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.0.119 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2039 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
Apr 26 12:27:38.382: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
Apr 26 12:27:38.383: INFO: ExecWithOptions: Clientset creation
Apr 26 12:27:38.383: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-2039/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.0.119+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
Apr 26 12:27:39.902: INFO: Found all 1 expected endpoints: [netserver-4]
[AfterEach] [sig-network] Networking
  test/e2e/framework/framework.go:187
Apr 26 12:27:39.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2039" for this suite. 04/26/24 12:27:39.914
{"msg":"PASSED [sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]","completed":353,"skipped":6502,"failed":0}
------------------------------
â€¢ [SLOW TEST] [21.798 seconds]
[sig-network] Networking
test/e2e/common/network/framework.go:23
  Granular Checks: Pods
  test/e2e/common/network/networking.go:32
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/network/networking.go:122

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Networking
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:27:18.123
    Apr 26 12:27:18.123: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename pod-network-test 04/26/24 12:27:18.124
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:18.138
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:18.145
    [It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/network/networking.go:122
    STEP: Performing setup for networking test in namespace pod-network-test-2039 04/26/24 12:27:18.152
    STEP: creating a selector 04/26/24 12:27:18.152
    STEP: Creating the service pods in kubernetes 04/26/24 12:27:18.153
    Apr 26 12:27:18.153: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
    Apr 26 12:27:18.242: INFO: Waiting up to 5m0s for pod "netserver-0" in namespace "pod-network-test-2039" to be "running and ready"
    Apr 26 12:27:18.258: INFO: Pod "netserver-0": Phase="Pending", Reason="", readiness=false. Elapsed: 15.165222ms
    Apr 26 12:27:18.258: INFO: The phase of Pod netserver-0 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:27:20.265: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 2.02204863s
    Apr 26 12:27:20.265: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 12:27:22.266: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 4.023275114s
    Apr 26 12:27:22.266: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 12:27:24.263: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 6.020927808s
    Apr 26 12:27:24.263: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 12:27:26.271: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 8.028852801s
    Apr 26 12:27:26.272: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 12:27:28.264: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=false. Elapsed: 10.021791795s
    Apr 26 12:27:28.264: INFO: The phase of Pod netserver-0 is Running (Ready = false)
    Apr 26 12:27:30.265: INFO: Pod "netserver-0": Phase="Running", Reason="", readiness=true. Elapsed: 12.022695014s
    Apr 26 12:27:30.265: INFO: The phase of Pod netserver-0 is Running (Ready = true)
    Apr 26 12:27:30.265: INFO: Pod "netserver-0" satisfied condition "running and ready"
    Apr 26 12:27:30.269: INFO: Waiting up to 5m0s for pod "netserver-1" in namespace "pod-network-test-2039" to be "running and ready"
    Apr 26 12:27:30.273: INFO: Pod "netserver-1": Phase="Running", Reason="", readiness=true. Elapsed: 4.592716ms
    Apr 26 12:27:30.274: INFO: The phase of Pod netserver-1 is Running (Ready = true)
    Apr 26 12:27:30.274: INFO: Pod "netserver-1" satisfied condition "running and ready"
    Apr 26 12:27:30.284: INFO: Waiting up to 5m0s for pod "netserver-2" in namespace "pod-network-test-2039" to be "running and ready"
    Apr 26 12:27:30.293: INFO: Pod "netserver-2": Phase="Running", Reason="", readiness=true. Elapsed: 9.47124ms
    Apr 26 12:27:30.293: INFO: The phase of Pod netserver-2 is Running (Ready = true)
    Apr 26 12:27:30.293: INFO: Pod "netserver-2" satisfied condition "running and ready"
    Apr 26 12:27:30.300: INFO: Waiting up to 5m0s for pod "netserver-3" in namespace "pod-network-test-2039" to be "running and ready"
    Apr 26 12:27:30.321: INFO: Pod "netserver-3": Phase="Running", Reason="", readiness=true. Elapsed: 20.82966ms
    Apr 26 12:27:30.321: INFO: The phase of Pod netserver-3 is Running (Ready = true)
    Apr 26 12:27:30.321: INFO: Pod "netserver-3" satisfied condition "running and ready"
    Apr 26 12:27:30.328: INFO: Waiting up to 5m0s for pod "netserver-4" in namespace "pod-network-test-2039" to be "running and ready"
    Apr 26 12:27:30.343: INFO: Pod "netserver-4": Phase="Running", Reason="", readiness=true. Elapsed: 14.639496ms
    Apr 26 12:27:30.343: INFO: The phase of Pod netserver-4 is Running (Ready = true)
    Apr 26 12:27:30.343: INFO: Pod "netserver-4" satisfied condition "running and ready"
    STEP: Creating test pods 04/26/24 12:27:30.348
    Apr 26 12:27:30.397: INFO: Waiting up to 5m0s for pod "test-container-pod" in namespace "pod-network-test-2039" to be "running"
    Apr 26 12:27:30.415: INFO: Pod "test-container-pod": Phase="Pending", Reason="", readiness=false. Elapsed: 17.668509ms
    Apr 26 12:27:32.439: INFO: Pod "test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 2.041583085s
    Apr 26 12:27:32.439: INFO: Pod "test-container-pod" satisfied condition "running"
    Apr 26 12:27:32.444: INFO: Waiting up to 5m0s for pod "host-test-container-pod" in namespace "pod-network-test-2039" to be "running"
    Apr 26 12:27:32.449: INFO: Pod "host-test-container-pod": Phase="Running", Reason="", readiness=true. Elapsed: 4.69536ms
    Apr 26 12:27:32.449: INFO: Pod "host-test-container-pod" satisfied condition "running"
    Apr 26 12:27:32.454: INFO: Setting MaxTries for pod polling to 55 for networking test based on endpoint count 5
    Apr 26 12:27:32.454: INFO: Going to poll 100.96.4.75 on port 8081 at least 0 times, with a maximum of 55 tries before failing
    Apr 26 12:27:32.459: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.4.75 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2039 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:27:32.459: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:27:32.460: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:27:32.460: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-2039/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.4.75+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 26 12:27:33.845: INFO: Found all 1 expected endpoints: [netserver-0]
    Apr 26 12:27:33.845: INFO: Going to poll 100.96.2.116 on port 8081 at least 0 times, with a maximum of 55 tries before failing
    Apr 26 12:27:33.852: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.2.116 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2039 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:27:33.852: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:27:33.852: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:27:33.853: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-2039/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.2.116+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 26 12:27:35.350: INFO: Found all 1 expected endpoints: [netserver-1]
    Apr 26 12:27:35.350: INFO: Going to poll 100.96.3.111 on port 8081 at least 0 times, with a maximum of 55 tries before failing
    Apr 26 12:27:35.356: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.3.111 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2039 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:27:35.356: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:27:35.357: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:27:35.357: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-2039/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.3.111+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 26 12:27:36.865: INFO: Found all 1 expected endpoints: [netserver-2]
    Apr 26 12:27:36.865: INFO: Going to poll 100.96.1.54 on port 8081 at least 0 times, with a maximum of 55 tries before failing
    Apr 26 12:27:36.873: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.1.54 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2039 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:27:36.873: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:27:36.873: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:27:36.873: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-2039/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.1.54+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 26 12:27:38.376: INFO: Found all 1 expected endpoints: [netserver-3]
    Apr 26 12:27:38.376: INFO: Going to poll 100.96.0.119 on port 8081 at least 0 times, with a maximum of 55 tries before failing
    Apr 26 12:27:38.382: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.96.0.119 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2039 PodName:host-test-container-pod ContainerName:agnhost-container Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false Quiet:false}
    Apr 26 12:27:38.382: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    Apr 26 12:27:38.383: INFO: ExecWithOptions: Clientset creation
    Apr 26 12:27:38.383: INFO: ExecWithOptions: execute(POST https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/pod-network-test-2039/pods/host-test-container-pod/exec?command=%2Fbin%2Fsh&command=-c&command=echo+hostName+%7C+nc+-w+1+-u+100.96.0.119+8081+%7C+grep+-v+%27%5E%5Cs%2A%24%27&container=agnhost-container&container=agnhost-container&stderr=true&stdout=true)
    Apr 26 12:27:39.902: INFO: Found all 1 expected endpoints: [netserver-4]
    [AfterEach] [sig-network] Networking
      test/e2e/framework/framework.go:187
    Apr 26 12:27:39.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "pod-network-test-2039" for this suite. 04/26/24 12:27:39.914
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:27:39.923
Apr 26 12:27:39.923: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename crd-webhook 04/26/24 12:27:39.924
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:39.938
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:39.944
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:128
STEP: Setting up server cert 04/26/24 12:27:39.951
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/26/24 12:27:40.074
STEP: Deploying the custom resource conversion webhook pod 04/26/24 12:27:40.082
STEP: Wait for the deployment to be ready 04/26/24 12:27:40.096
Apr 26 12:27:40.107: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Apr 26 12:27:42.128: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 12, 27, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 12, 27, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 12, 27, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 12, 27, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service 04/26/24 12:27:44.135
STEP: Verifying the service has paired with the endpoint 04/26/24 12:27:44.15
Apr 26 12:27:45.150: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149
Apr 26 12:27:45.155: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Creating a v1 custom resource 04/26/24 12:27:47.908
STEP: v2 custom resource should be converted 04/26/24 12:27:47.914
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/framework/framework.go:187
Apr 26 12:27:48.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3951" for this suite. 04/26/24 12:27:48.492
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  test/e2e/apimachinery/crd_conversion_webhook.go:139
{"msg":"PASSED [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]","completed":354,"skipped":6515,"failed":0}
------------------------------
â€¢ [SLOW TEST] [8.603 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  test/e2e/apimachinery/crd_conversion_webhook.go:149

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:27:39.923
    Apr 26 12:27:39.923: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename crd-webhook 04/26/24 12:27:39.924
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:39.938
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:39.944
    [BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:128
    STEP: Setting up server cert 04/26/24 12:27:39.951
    STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication 04/26/24 12:27:40.074
    STEP: Deploying the custom resource conversion webhook pod 04/26/24 12:27:40.082
    STEP: Wait for the deployment to be ready 04/26/24 12:27:40.096
    Apr 26 12:27:40.107: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
    Apr 26 12:27:42.128: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:time.Date(2024, time.April, 26, 12, 27, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 12, 27, 40, 0, time.Local), Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:time.Date(2024, time.April, 26, 12, 27, 40, 0, time.Local), LastTransitionTime:time.Date(2024, time.April, 26, 12, 27, 40, 0, time.Local), Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-59dfc5db8d\" is progressing."}}, CollisionCount:(*int32)(nil)}
    STEP: Deploying the webhook service 04/26/24 12:27:44.135
    STEP: Verifying the service has paired with the endpoint 04/26/24 12:27:44.15
    Apr 26 12:27:45.150: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
    [It] should be able to convert from CR v1 to CR v2 [Conformance]
      test/e2e/apimachinery/crd_conversion_webhook.go:149
    Apr 26 12:27:45.155: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Creating a v1 custom resource 04/26/24 12:27:47.908
    STEP: v2 custom resource should be converted 04/26/24 12:27:47.914
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/framework/framework.go:187
    Apr 26 12:27:48.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "crd-webhook-3951" for this suite. 04/26/24 12:27:48.492
    [AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
      test/e2e/apimachinery/crd_conversion_webhook.go:139
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
[BeforeEach] [sig-network] Services
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:27:48.527
Apr 26 12:27:48.527: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename services 04/26/24 12:27:48.528
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:48.55
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:48.556
[BeforeEach] [sig-network] Services
  test/e2e/network/service.go:758
[It] should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791
STEP: creating service endpoint-test2 in namespace services-1124 04/26/24 12:27:48.563
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1124 to expose endpoints map[] 04/26/24 12:27:48.578
Apr 26 12:27:48.590: INFO: successfully validated that service endpoint-test2 in namespace services-1124 exposes endpoints map[]
STEP: Creating pod pod1 in namespace services-1124 04/26/24 12:27:48.59
Apr 26 12:27:48.603: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-1124" to be "running and ready"
Apr 26 12:27:48.610: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.99308ms
Apr 26 12:27:48.610: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:27:50.616: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012788234s
Apr 26 12:27:50.616: INFO: The phase of Pod pod1 is Running (Ready = true)
Apr 26 12:27:50.616: INFO: Pod "pod1" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1124 to expose endpoints map[pod1:[80]] 04/26/24 12:27:50.621
Apr 26 12:27:50.635: INFO: successfully validated that service endpoint-test2 in namespace services-1124 exposes endpoints map[pod1:[80]]
STEP: Checking if the Service forwards traffic to pod1 04/26/24 12:27:50.635
Apr 26 12:27:50.635: INFO: Creating new exec pod
Apr 26 12:27:50.643: INFO: Waiting up to 5m0s for pod "execpods9zwz" in namespace "services-1124" to be "running"
Apr 26 12:27:50.651: INFO: Pod "execpods9zwz": Phase="Pending", Reason="", readiness=false. Elapsed: 7.526121ms
Apr 26 12:27:52.657: INFO: Pod "execpods9zwz": Phase="Running", Reason="", readiness=true. Elapsed: 2.013641132s
Apr 26 12:27:52.657: INFO: Pod "execpods9zwz" satisfied condition "running"
Apr 26 12:27:53.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1124 exec execpods9zwz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 26 12:27:54.237: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 26 12:27:54.237: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 12:27:54.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1124 exec execpods9zwz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.249.251 80'
Apr 26 12:27:54.703: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.249.251 80\nConnection to 100.67.249.251 80 port [tcp/http] succeeded!\n"
Apr 26 12:27:54.703: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Creating pod pod2 in namespace services-1124 04/26/24 12:27:54.703
Apr 26 12:27:54.715: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-1124" to be "running and ready"
Apr 26 12:27:54.719: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.38186ms
Apr 26 12:27:54.719: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
Apr 26 12:27:56.725: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010446343s
Apr 26 12:27:56.725: INFO: The phase of Pod pod2 is Running (Ready = true)
Apr 26 12:27:56.725: INFO: Pod "pod2" satisfied condition "running and ready"
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1124 to expose endpoints map[pod1:[80] pod2:[80]] 04/26/24 12:27:56.73
Apr 26 12:27:56.753: INFO: successfully validated that service endpoint-test2 in namespace services-1124 exposes endpoints map[pod1:[80] pod2:[80]]
STEP: Checking if the Service forwards traffic to pod1 and pod2 04/26/24 12:27:56.753
Apr 26 12:27:57.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1124 exec execpods9zwz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 26 12:27:58.265: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 26 12:27:58.265: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 12:27:58.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1124 exec execpods9zwz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.249.251 80'
Apr 26 12:27:58.783: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.249.251 80\nConnection to 100.67.249.251 80 port [tcp/http] succeeded!\n"
Apr 26 12:27:58.783: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod1 in namespace services-1124 04/26/24 12:27:58.783
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1124 to expose endpoints map[pod2:[80]] 04/26/24 12:27:58.863
Apr 26 12:27:58.893: INFO: successfully validated that service endpoint-test2 in namespace services-1124 exposes endpoints map[pod2:[80]]
STEP: Checking if the Service forwards traffic to pod2 04/26/24 12:27:58.893
Apr 26 12:27:59.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1124 exec execpods9zwz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
Apr 26 12:28:02.923: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
Apr 26 12:28:02.923: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
Apr 26 12:28:02.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1124 exec execpods9zwz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.249.251 80'
Apr 26 12:28:03.319: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.249.251 80\nConnection to 100.67.249.251 80 port [tcp/http] succeeded!\n"
Apr 26 12:28:03.319: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
STEP: Deleting pod pod2 in namespace services-1124 04/26/24 12:28:03.319
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1124 to expose endpoints map[] 04/26/24 12:28:03.332
Apr 26 12:28:03.343: INFO: successfully validated that service endpoint-test2 in namespace services-1124 exposes endpoints map[]
[AfterEach] [sig-network] Services
  test/e2e/framework/framework.go:187
Apr 26 12:28:03.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1124" for this suite. 04/26/24 12:28:03.365
[AfterEach] [sig-network] Services
  test/e2e/network/service.go:762
{"msg":"PASSED [sig-network] Services should serve a basic endpoint from pods  [Conformance]","completed":355,"skipped":6530,"failed":0}
------------------------------
â€¢ [SLOW TEST] [14.843 seconds]
[sig-network] Services
test/e2e/network/common/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  test/e2e/network/service.go:791

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-network] Services
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:27:48.527
    Apr 26 12:27:48.527: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename services 04/26/24 12:27:48.528
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:27:48.55
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:27:48.556
    [BeforeEach] [sig-network] Services
      test/e2e/network/service.go:758
    [It] should serve a basic endpoint from pods  [Conformance]
      test/e2e/network/service.go:791
    STEP: creating service endpoint-test2 in namespace services-1124 04/26/24 12:27:48.563
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1124 to expose endpoints map[] 04/26/24 12:27:48.578
    Apr 26 12:27:48.590: INFO: successfully validated that service endpoint-test2 in namespace services-1124 exposes endpoints map[]
    STEP: Creating pod pod1 in namespace services-1124 04/26/24 12:27:48.59
    Apr 26 12:27:48.603: INFO: Waiting up to 5m0s for pod "pod1" in namespace "services-1124" to be "running and ready"
    Apr 26 12:27:48.610: INFO: Pod "pod1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.99308ms
    Apr 26 12:27:48.610: INFO: The phase of Pod pod1 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:27:50.616: INFO: Pod "pod1": Phase="Running", Reason="", readiness=true. Elapsed: 2.012788234s
    Apr 26 12:27:50.616: INFO: The phase of Pod pod1 is Running (Ready = true)
    Apr 26 12:27:50.616: INFO: Pod "pod1" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1124 to expose endpoints map[pod1:[80]] 04/26/24 12:27:50.621
    Apr 26 12:27:50.635: INFO: successfully validated that service endpoint-test2 in namespace services-1124 exposes endpoints map[pod1:[80]]
    STEP: Checking if the Service forwards traffic to pod1 04/26/24 12:27:50.635
    Apr 26 12:27:50.635: INFO: Creating new exec pod
    Apr 26 12:27:50.643: INFO: Waiting up to 5m0s for pod "execpods9zwz" in namespace "services-1124" to be "running"
    Apr 26 12:27:50.651: INFO: Pod "execpods9zwz": Phase="Pending", Reason="", readiness=false. Elapsed: 7.526121ms
    Apr 26 12:27:52.657: INFO: Pod "execpods9zwz": Phase="Running", Reason="", readiness=true. Elapsed: 2.013641132s
    Apr 26 12:27:52.657: INFO: Pod "execpods9zwz" satisfied condition "running"
    Apr 26 12:27:53.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1124 exec execpods9zwz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 26 12:27:54.237: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 26 12:27:54.237: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 12:27:54.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1124 exec execpods9zwz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.249.251 80'
    Apr 26 12:27:54.703: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.249.251 80\nConnection to 100.67.249.251 80 port [tcp/http] succeeded!\n"
    Apr 26 12:27:54.703: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Creating pod pod2 in namespace services-1124 04/26/24 12:27:54.703
    Apr 26 12:27:54.715: INFO: Waiting up to 5m0s for pod "pod2" in namespace "services-1124" to be "running and ready"
    Apr 26 12:27:54.719: INFO: Pod "pod2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.38186ms
    Apr 26 12:27:54.719: INFO: The phase of Pod pod2 is Pending, waiting for it to be Running (with Ready = true)
    Apr 26 12:27:56.725: INFO: Pod "pod2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010446343s
    Apr 26 12:27:56.725: INFO: The phase of Pod pod2 is Running (Ready = true)
    Apr 26 12:27:56.725: INFO: Pod "pod2" satisfied condition "running and ready"
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1124 to expose endpoints map[pod1:[80] pod2:[80]] 04/26/24 12:27:56.73
    Apr 26 12:27:56.753: INFO: successfully validated that service endpoint-test2 in namespace services-1124 exposes endpoints map[pod1:[80] pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod1 and pod2 04/26/24 12:27:56.753
    Apr 26 12:27:57.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1124 exec execpods9zwz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 26 12:27:58.265: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 26 12:27:58.265: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 12:27:58.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1124 exec execpods9zwz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.249.251 80'
    Apr 26 12:27:58.783: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.249.251 80\nConnection to 100.67.249.251 80 port [tcp/http] succeeded!\n"
    Apr 26 12:27:58.783: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod1 in namespace services-1124 04/26/24 12:27:58.783
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1124 to expose endpoints map[pod2:[80]] 04/26/24 12:27:58.863
    Apr 26 12:27:58.893: INFO: successfully validated that service endpoint-test2 in namespace services-1124 exposes endpoints map[pod2:[80]]
    STEP: Checking if the Service forwards traffic to pod2 04/26/24 12:27:58.893
    Apr 26 12:27:59.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1124 exec execpods9zwz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 endpoint-test2 80'
    Apr 26 12:28:02.923: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 endpoint-test2 80\nConnection to endpoint-test2 80 port [tcp/http] succeeded!\n"
    Apr 26 12:28:02.923: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    Apr 26 12:28:02.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-3912933062 --namespace=services-1124 exec execpods9zwz -- /bin/sh -x -c echo hostName | nc -v -t -w 2 100.67.249.251 80'
    Apr 26 12:28:03.319: INFO: stderr: "+ echo hostName\n+ nc -v -t -w 2 100.67.249.251 80\nConnection to 100.67.249.251 80 port [tcp/http] succeeded!\n"
    Apr 26 12:28:03.319: INFO: stdout: "HTTP/1.1 400 Bad Request\r\nContent-Type: text/plain; charset=utf-8\r\nConnection: close\r\n\r\n400 Bad Request"
    STEP: Deleting pod pod2 in namespace services-1124 04/26/24 12:28:03.319
    STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1124 to expose endpoints map[] 04/26/24 12:28:03.332
    Apr 26 12:28:03.343: INFO: successfully validated that service endpoint-test2 in namespace services-1124 exposes endpoints map[]
    [AfterEach] [sig-network] Services
      test/e2e/framework/framework.go:187
    Apr 26 12:28:03.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "services-1124" for this suite. 04/26/24 12:28:03.365
    [AfterEach] [sig-network] Services
      test/e2e/network/service.go:762
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
[BeforeEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:28:03.371
Apr 26 12:28:03.371: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename gc 04/26/24 12:28:03.372
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:28:03.418
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:28:03.428
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735
STEP: create the rc1 04/26/24 12:28:03.446
STEP: create the rc2 04/26/24 12:28:03.453
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 04/26/24 12:28:08.466
STEP: delete the rc simpletest-rc-to-be-deleted 04/26/24 12:28:09.04
STEP: wait for the rc to be deleted 04/26/24 12:28:09.048
Apr 26 12:28:14.073: INFO: 70 pods remaining
Apr 26 12:28:14.073: INFO: 70 pods has nil DeletionTimestamp
Apr 26 12:28:14.073: INFO: 
STEP: Gathering metrics 04/26/24 12:28:19.068
W0426 12:28:19.099482      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
Apr 26 12:28:19.099: INFO: For apiserver_request_total:
For apiserver_request_latency_seconds:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

Apr 26 12:28:19.099: INFO: Deleting pod "simpletest-rc-to-be-deleted-2kw2s" in namespace "gc-2792"
Apr 26 12:28:19.145: INFO: Deleting pod "simpletest-rc-to-be-deleted-2npg2" in namespace "gc-2792"
Apr 26 12:28:19.173: INFO: Deleting pod "simpletest-rc-to-be-deleted-2q849" in namespace "gc-2792"
Apr 26 12:28:19.201: INFO: Deleting pod "simpletest-rc-to-be-deleted-4742z" in namespace "gc-2792"
Apr 26 12:28:19.220: INFO: Deleting pod "simpletest-rc-to-be-deleted-4cgjn" in namespace "gc-2792"
Apr 26 12:28:19.247: INFO: Deleting pod "simpletest-rc-to-be-deleted-4s255" in namespace "gc-2792"
Apr 26 12:28:19.262: INFO: Deleting pod "simpletest-rc-to-be-deleted-4std7" in namespace "gc-2792"
Apr 26 12:28:19.273: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vzt9" in namespace "gc-2792"
Apr 26 12:28:19.286: INFO: Deleting pod "simpletest-rc-to-be-deleted-575pb" in namespace "gc-2792"
Apr 26 12:28:19.298: INFO: Deleting pod "simpletest-rc-to-be-deleted-5fkqr" in namespace "gc-2792"
Apr 26 12:28:19.313: INFO: Deleting pod "simpletest-rc-to-be-deleted-5kzp2" in namespace "gc-2792"
Apr 26 12:28:19.327: INFO: Deleting pod "simpletest-rc-to-be-deleted-5n2f5" in namespace "gc-2792"
Apr 26 12:28:19.339: INFO: Deleting pod "simpletest-rc-to-be-deleted-5ttx6" in namespace "gc-2792"
Apr 26 12:28:19.356: INFO: Deleting pod "simpletest-rc-to-be-deleted-5z7db" in namespace "gc-2792"
Apr 26 12:28:19.368: INFO: Deleting pod "simpletest-rc-to-be-deleted-5zcqm" in namespace "gc-2792"
Apr 26 12:28:19.386: INFO: Deleting pod "simpletest-rc-to-be-deleted-679w9" in namespace "gc-2792"
Apr 26 12:28:19.402: INFO: Deleting pod "simpletest-rc-to-be-deleted-6br4h" in namespace "gc-2792"
Apr 26 12:28:19.418: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hwgj" in namespace "gc-2792"
Apr 26 12:28:19.480: INFO: Deleting pod "simpletest-rc-to-be-deleted-6qk7j" in namespace "gc-2792"
Apr 26 12:28:19.519: INFO: Deleting pod "simpletest-rc-to-be-deleted-6r75q" in namespace "gc-2792"
Apr 26 12:28:19.530: INFO: Deleting pod "simpletest-rc-to-be-deleted-77cdn" in namespace "gc-2792"
Apr 26 12:28:19.542: INFO: Deleting pod "simpletest-rc-to-be-deleted-7hw4w" in namespace "gc-2792"
Apr 26 12:28:19.556: INFO: Deleting pod "simpletest-rc-to-be-deleted-7xfj2" in namespace "gc-2792"
Apr 26 12:28:19.571: INFO: Deleting pod "simpletest-rc-to-be-deleted-82lsj" in namespace "gc-2792"
Apr 26 12:28:19.604: INFO: Deleting pod "simpletest-rc-to-be-deleted-89fg7" in namespace "gc-2792"
Apr 26 12:28:19.614: INFO: Deleting pod "simpletest-rc-to-be-deleted-94tkk" in namespace "gc-2792"
Apr 26 12:28:19.626: INFO: Deleting pod "simpletest-rc-to-be-deleted-9jj7t" in namespace "gc-2792"
Apr 26 12:28:19.638: INFO: Deleting pod "simpletest-rc-to-be-deleted-9k4cs" in namespace "gc-2792"
Apr 26 12:28:19.651: INFO: Deleting pod "simpletest-rc-to-be-deleted-9r5dw" in namespace "gc-2792"
Apr 26 12:28:19.664: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rdzv" in namespace "gc-2792"
Apr 26 12:28:19.676: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rzfm" in namespace "gc-2792"
Apr 26 12:28:19.692: INFO: Deleting pod "simpletest-rc-to-be-deleted-9s4v7" in namespace "gc-2792"
Apr 26 12:28:19.711: INFO: Deleting pod "simpletest-rc-to-be-deleted-9t8d8" in namespace "gc-2792"
Apr 26 12:28:19.720: INFO: Deleting pod "simpletest-rc-to-be-deleted-9zgcb" in namespace "gc-2792"
Apr 26 12:28:19.731: INFO: Deleting pod "simpletest-rc-to-be-deleted-b7h2n" in namespace "gc-2792"
Apr 26 12:28:19.744: INFO: Deleting pod "simpletest-rc-to-be-deleted-bc5rj" in namespace "gc-2792"
Apr 26 12:28:19.799: INFO: Deleting pod "simpletest-rc-to-be-deleted-bgwd5" in namespace "gc-2792"
Apr 26 12:28:19.837: INFO: Deleting pod "simpletest-rc-to-be-deleted-bs62n" in namespace "gc-2792"
Apr 26 12:28:19.852: INFO: Deleting pod "simpletest-rc-to-be-deleted-btvbx" in namespace "gc-2792"
Apr 26 12:28:19.867: INFO: Deleting pod "simpletest-rc-to-be-deleted-bwbxg" in namespace "gc-2792"
Apr 26 12:28:19.878: INFO: Deleting pod "simpletest-rc-to-be-deleted-cjrjt" in namespace "gc-2792"
Apr 26 12:28:19.889: INFO: Deleting pod "simpletest-rc-to-be-deleted-cl8p6" in namespace "gc-2792"
Apr 26 12:28:19.922: INFO: Deleting pod "simpletest-rc-to-be-deleted-clrhm" in namespace "gc-2792"
Apr 26 12:28:19.975: INFO: Deleting pod "simpletest-rc-to-be-deleted-cps9k" in namespace "gc-2792"
Apr 26 12:28:20.004: INFO: Deleting pod "simpletest-rc-to-be-deleted-cs648" in namespace "gc-2792"
Apr 26 12:28:20.047: INFO: Deleting pod "simpletest-rc-to-be-deleted-csbg5" in namespace "gc-2792"
Apr 26 12:28:20.102: INFO: Deleting pod "simpletest-rc-to-be-deleted-d69bf" in namespace "gc-2792"
Apr 26 12:28:20.155: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddgx6" in namespace "gc-2792"
Apr 26 12:28:20.177: INFO: Deleting pod "simpletest-rc-to-be-deleted-f68jq" in namespace "gc-2792"
Apr 26 12:28:20.227: INFO: Deleting pod "simpletest-rc-to-be-deleted-fsqh5" in namespace "gc-2792"
[AfterEach] [sig-api-machinery] Garbage collector
  test/e2e/framework/framework.go:187
Apr 26 12:28:20.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2792" for this suite. 04/26/24 12:28:20.249
{"msg":"PASSED [sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]","completed":356,"skipped":6555,"failed":0}
------------------------------
â€¢ [SLOW TEST] [16.883 seconds]
[sig-api-machinery] Garbage collector
test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  test/e2e/apimachinery/garbage_collector.go:735

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:28:03.371
    Apr 26 12:28:03.371: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename gc 04/26/24 12:28:03.372
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:28:03.418
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:28:03.428
    [It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
      test/e2e/apimachinery/garbage_collector.go:735
    STEP: create the rc1 04/26/24 12:28:03.446
    STEP: create the rc2 04/26/24 12:28:03.453
    STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well 04/26/24 12:28:08.466
    STEP: delete the rc simpletest-rc-to-be-deleted 04/26/24 12:28:09.04
    STEP: wait for the rc to be deleted 04/26/24 12:28:09.048
    Apr 26 12:28:14.073: INFO: 70 pods remaining
    Apr 26 12:28:14.073: INFO: 70 pods has nil DeletionTimestamp
    Apr 26 12:28:14.073: INFO: 
    STEP: Gathering metrics 04/26/24 12:28:19.068
    W0426 12:28:19.099482      23 metrics_grabber.go:151] Can't find kube-controller-manager pod. Grabbing metrics from kube-controller-manager is disabled.
    Apr 26 12:28:19.099: INFO: For apiserver_request_total:
    For apiserver_request_latency_seconds:
    For apiserver_init_events_total:
    For garbage_collector_attempt_to_delete_queue_latency:
    For garbage_collector_attempt_to_delete_work_duration:
    For garbage_collector_attempt_to_orphan_queue_latency:
    For garbage_collector_attempt_to_orphan_work_duration:
    For garbage_collector_dirty_processing_latency_microseconds:
    For garbage_collector_event_processing_latency_microseconds:
    For garbage_collector_graph_changes_queue_latency:
    For garbage_collector_graph_changes_work_duration:
    For garbage_collector_orphan_processing_latency_microseconds:
    For namespace_queue_latency:
    For namespace_queue_latency_sum:
    For namespace_queue_latency_count:
    For namespace_retries:
    For namespace_work_duration:
    For namespace_work_duration_sum:
    For namespace_work_duration_count:
    For function_duration_seconds:
    For errors_total:
    For evicted_pods_total:

    Apr 26 12:28:19.099: INFO: Deleting pod "simpletest-rc-to-be-deleted-2kw2s" in namespace "gc-2792"
    Apr 26 12:28:19.145: INFO: Deleting pod "simpletest-rc-to-be-deleted-2npg2" in namespace "gc-2792"
    Apr 26 12:28:19.173: INFO: Deleting pod "simpletest-rc-to-be-deleted-2q849" in namespace "gc-2792"
    Apr 26 12:28:19.201: INFO: Deleting pod "simpletest-rc-to-be-deleted-4742z" in namespace "gc-2792"
    Apr 26 12:28:19.220: INFO: Deleting pod "simpletest-rc-to-be-deleted-4cgjn" in namespace "gc-2792"
    Apr 26 12:28:19.247: INFO: Deleting pod "simpletest-rc-to-be-deleted-4s255" in namespace "gc-2792"
    Apr 26 12:28:19.262: INFO: Deleting pod "simpletest-rc-to-be-deleted-4std7" in namespace "gc-2792"
    Apr 26 12:28:19.273: INFO: Deleting pod "simpletest-rc-to-be-deleted-4vzt9" in namespace "gc-2792"
    Apr 26 12:28:19.286: INFO: Deleting pod "simpletest-rc-to-be-deleted-575pb" in namespace "gc-2792"
    Apr 26 12:28:19.298: INFO: Deleting pod "simpletest-rc-to-be-deleted-5fkqr" in namespace "gc-2792"
    Apr 26 12:28:19.313: INFO: Deleting pod "simpletest-rc-to-be-deleted-5kzp2" in namespace "gc-2792"
    Apr 26 12:28:19.327: INFO: Deleting pod "simpletest-rc-to-be-deleted-5n2f5" in namespace "gc-2792"
    Apr 26 12:28:19.339: INFO: Deleting pod "simpletest-rc-to-be-deleted-5ttx6" in namespace "gc-2792"
    Apr 26 12:28:19.356: INFO: Deleting pod "simpletest-rc-to-be-deleted-5z7db" in namespace "gc-2792"
    Apr 26 12:28:19.368: INFO: Deleting pod "simpletest-rc-to-be-deleted-5zcqm" in namespace "gc-2792"
    Apr 26 12:28:19.386: INFO: Deleting pod "simpletest-rc-to-be-deleted-679w9" in namespace "gc-2792"
    Apr 26 12:28:19.402: INFO: Deleting pod "simpletest-rc-to-be-deleted-6br4h" in namespace "gc-2792"
    Apr 26 12:28:19.418: INFO: Deleting pod "simpletest-rc-to-be-deleted-6hwgj" in namespace "gc-2792"
    Apr 26 12:28:19.480: INFO: Deleting pod "simpletest-rc-to-be-deleted-6qk7j" in namespace "gc-2792"
    Apr 26 12:28:19.519: INFO: Deleting pod "simpletest-rc-to-be-deleted-6r75q" in namespace "gc-2792"
    Apr 26 12:28:19.530: INFO: Deleting pod "simpletest-rc-to-be-deleted-77cdn" in namespace "gc-2792"
    Apr 26 12:28:19.542: INFO: Deleting pod "simpletest-rc-to-be-deleted-7hw4w" in namespace "gc-2792"
    Apr 26 12:28:19.556: INFO: Deleting pod "simpletest-rc-to-be-deleted-7xfj2" in namespace "gc-2792"
    Apr 26 12:28:19.571: INFO: Deleting pod "simpletest-rc-to-be-deleted-82lsj" in namespace "gc-2792"
    Apr 26 12:28:19.604: INFO: Deleting pod "simpletest-rc-to-be-deleted-89fg7" in namespace "gc-2792"
    Apr 26 12:28:19.614: INFO: Deleting pod "simpletest-rc-to-be-deleted-94tkk" in namespace "gc-2792"
    Apr 26 12:28:19.626: INFO: Deleting pod "simpletest-rc-to-be-deleted-9jj7t" in namespace "gc-2792"
    Apr 26 12:28:19.638: INFO: Deleting pod "simpletest-rc-to-be-deleted-9k4cs" in namespace "gc-2792"
    Apr 26 12:28:19.651: INFO: Deleting pod "simpletest-rc-to-be-deleted-9r5dw" in namespace "gc-2792"
    Apr 26 12:28:19.664: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rdzv" in namespace "gc-2792"
    Apr 26 12:28:19.676: INFO: Deleting pod "simpletest-rc-to-be-deleted-9rzfm" in namespace "gc-2792"
    Apr 26 12:28:19.692: INFO: Deleting pod "simpletest-rc-to-be-deleted-9s4v7" in namespace "gc-2792"
    Apr 26 12:28:19.711: INFO: Deleting pod "simpletest-rc-to-be-deleted-9t8d8" in namespace "gc-2792"
    Apr 26 12:28:19.720: INFO: Deleting pod "simpletest-rc-to-be-deleted-9zgcb" in namespace "gc-2792"
    Apr 26 12:28:19.731: INFO: Deleting pod "simpletest-rc-to-be-deleted-b7h2n" in namespace "gc-2792"
    Apr 26 12:28:19.744: INFO: Deleting pod "simpletest-rc-to-be-deleted-bc5rj" in namespace "gc-2792"
    Apr 26 12:28:19.799: INFO: Deleting pod "simpletest-rc-to-be-deleted-bgwd5" in namespace "gc-2792"
    Apr 26 12:28:19.837: INFO: Deleting pod "simpletest-rc-to-be-deleted-bs62n" in namespace "gc-2792"
    Apr 26 12:28:19.852: INFO: Deleting pod "simpletest-rc-to-be-deleted-btvbx" in namespace "gc-2792"
    Apr 26 12:28:19.867: INFO: Deleting pod "simpletest-rc-to-be-deleted-bwbxg" in namespace "gc-2792"
    Apr 26 12:28:19.878: INFO: Deleting pod "simpletest-rc-to-be-deleted-cjrjt" in namespace "gc-2792"
    Apr 26 12:28:19.889: INFO: Deleting pod "simpletest-rc-to-be-deleted-cl8p6" in namespace "gc-2792"
    Apr 26 12:28:19.922: INFO: Deleting pod "simpletest-rc-to-be-deleted-clrhm" in namespace "gc-2792"
    Apr 26 12:28:19.975: INFO: Deleting pod "simpletest-rc-to-be-deleted-cps9k" in namespace "gc-2792"
    Apr 26 12:28:20.004: INFO: Deleting pod "simpletest-rc-to-be-deleted-cs648" in namespace "gc-2792"
    Apr 26 12:28:20.047: INFO: Deleting pod "simpletest-rc-to-be-deleted-csbg5" in namespace "gc-2792"
    Apr 26 12:28:20.102: INFO: Deleting pod "simpletest-rc-to-be-deleted-d69bf" in namespace "gc-2792"
    Apr 26 12:28:20.155: INFO: Deleting pod "simpletest-rc-to-be-deleted-ddgx6" in namespace "gc-2792"
    Apr 26 12:28:20.177: INFO: Deleting pod "simpletest-rc-to-be-deleted-f68jq" in namespace "gc-2792"
    Apr 26 12:28:20.227: INFO: Deleting pod "simpletest-rc-to-be-deleted-fsqh5" in namespace "gc-2792"
    [AfterEach] [sig-api-machinery] Garbage collector
      test/e2e/framework/framework.go:187
    Apr 26 12:28:20.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "gc-2792" for this suite. 04/26/24 12:28:20.249
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1
  A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
[BeforeEach] version v1
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:28:20.256
Apr 26 12:28:20.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename proxy 04/26/24 12:28:20.258
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:28:20.28
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:28:20.301
[It] A set of valid responses are returned for both pod and service Proxy [Conformance]
  test/e2e/network/proxy.go:380
Apr 26 12:28:20.327: INFO: Creating pod...
Apr 26 12:28:20.353: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7302" to be "running"
Apr 26 12:28:20.374: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 20.424172ms
Apr 26 12:28:22.381: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.027472659s
Apr 26 12:28:22.381: INFO: Pod "agnhost" satisfied condition "running"
Apr 26 12:28:22.381: INFO: Creating service...
Apr 26 12:28:22.395: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=DELETE
Apr 26 12:28:22.473: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 26 12:28:22.473: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=OPTIONS
Apr 26 12:28:22.528: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 26 12:28:22.528: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=PATCH
Apr 26 12:28:22.537: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 26 12:28:22.538: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=POST
Apr 26 12:28:22.551: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 26 12:28:22.551: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=PUT
Apr 26 12:28:22.560: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 26 12:28:22.560: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=DELETE
Apr 26 12:28:22.568: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
Apr 26 12:28:22.568: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=OPTIONS
Apr 26 12:28:22.577: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
Apr 26 12:28:22.578: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=PATCH
Apr 26 12:28:22.629: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
Apr 26 12:28:22.629: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=POST
Apr 26 12:28:22.685: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
Apr 26 12:28:22.685: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=PUT
Apr 26 12:28:22.697: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
Apr 26 12:28:22.697: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=GET
Apr 26 12:28:22.701: INFO: http.Client request:GET StatusCode:301
Apr 26 12:28:22.701: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=GET
Apr 26 12:28:22.708: INFO: http.Client request:GET StatusCode:301
Apr 26 12:28:22.708: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=HEAD
Apr 26 12:28:22.713: INFO: http.Client request:HEAD StatusCode:301
Apr 26 12:28:22.713: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=HEAD
Apr 26 12:28:22.719: INFO: http.Client request:HEAD StatusCode:301
[AfterEach] version v1
  test/e2e/framework/framework.go:187
Apr 26 12:28:22.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7302" for this suite. 04/26/24 12:28:22.732
{"msg":"PASSED [sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]","completed":357,"skipped":6595,"failed":0}
------------------------------
â€¢ [2.481 seconds]
[sig-network] Proxy
test/e2e/network/common/framework.go:23
  version v1
  test/e2e/network/proxy.go:74
    A set of valid responses are returned for both pod and service Proxy [Conformance]
    test/e2e/network/proxy.go:380

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] version v1
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:28:20.256
    Apr 26 12:28:20.256: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename proxy 04/26/24 12:28:20.258
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:28:20.28
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:28:20.301
    [It] A set of valid responses are returned for both pod and service Proxy [Conformance]
      test/e2e/network/proxy.go:380
    Apr 26 12:28:20.327: INFO: Creating pod...
    Apr 26 12:28:20.353: INFO: Waiting up to 5m0s for pod "agnhost" in namespace "proxy-7302" to be "running"
    Apr 26 12:28:20.374: INFO: Pod "agnhost": Phase="Pending", Reason="", readiness=false. Elapsed: 20.424172ms
    Apr 26 12:28:22.381: INFO: Pod "agnhost": Phase="Running", Reason="", readiness=true. Elapsed: 2.027472659s
    Apr 26 12:28:22.381: INFO: Pod "agnhost" satisfied condition "running"
    Apr 26 12:28:22.381: INFO: Creating service...
    Apr 26 12:28:22.395: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=DELETE
    Apr 26 12:28:22.473: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 26 12:28:22.473: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=OPTIONS
    Apr 26 12:28:22.528: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 26 12:28:22.528: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=PATCH
    Apr 26 12:28:22.537: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 26 12:28:22.538: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=POST
    Apr 26 12:28:22.551: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 26 12:28:22.551: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=PUT
    Apr 26 12:28:22.560: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 26 12:28:22.560: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=DELETE
    Apr 26 12:28:22.568: INFO: http.Client request:DELETE | StatusCode:200 | Response:foo | Method:DELETE
    Apr 26 12:28:22.568: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=OPTIONS
    Apr 26 12:28:22.577: INFO: http.Client request:OPTIONS | StatusCode:200 | Response:foo | Method:OPTIONS
    Apr 26 12:28:22.578: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=PATCH
    Apr 26 12:28:22.629: INFO: http.Client request:PATCH | StatusCode:200 | Response:foo | Method:PATCH
    Apr 26 12:28:22.629: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=POST
    Apr 26 12:28:22.685: INFO: http.Client request:POST | StatusCode:200 | Response:foo | Method:POST
    Apr 26 12:28:22.685: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=PUT
    Apr 26 12:28:22.697: INFO: http.Client request:PUT | StatusCode:200 | Response:foo | Method:PUT
    Apr 26 12:28:22.697: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=GET
    Apr 26 12:28:22.701: INFO: http.Client request:GET StatusCode:301
    Apr 26 12:28:22.701: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=GET
    Apr 26 12:28:22.708: INFO: http.Client request:GET StatusCode:301
    Apr 26 12:28:22.708: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/pods/agnhost/proxy?method=HEAD
    Apr 26 12:28:22.713: INFO: http.Client request:HEAD StatusCode:301
    Apr 26 12:28:22.713: INFO: Starting http.Client for https://api.conf-125.thomas.internal.emk.fuga.cloud:443/api/v1/namespaces/proxy-7302/services/e2e-proxy-test-service/proxy?method=HEAD
    Apr 26 12:28:22.719: INFO: http.Client request:HEAD StatusCode:301
    [AfterEach] version v1
      test/e2e/framework/framework.go:187
    Apr 26 12:28:22.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "proxy-7302" for this suite. 04/26/24 12:28:22.732
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Security Context When creating a container with runAsUser
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
[BeforeEach] [sig-node] Security Context
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:28:22.739
Apr 26 12:28:22.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename security-context-test 04/26/24 12:28:22.74
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:28:22.761
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:28:22.767
[BeforeEach] [sig-node] Security Context
  test/e2e/common/node/security_context.go:49
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  test/e2e/common/node/security_context.go:346
Apr 26 12:28:22.783: INFO: Waiting up to 5m0s for pod "busybox-user-65534-c300d999-4712-4754-8097-6c6b237c2140" in namespace "security-context-test-2912" to be "Succeeded or Failed"
Apr 26 12:28:22.791: INFO: Pod "busybox-user-65534-c300d999-4712-4754-8097-6c6b237c2140": Phase="Pending", Reason="", readiness=false. Elapsed: 7.933815ms
Apr 26 12:28:24.798: INFO: Pod "busybox-user-65534-c300d999-4712-4754-8097-6c6b237c2140": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015409644s
Apr 26 12:28:26.798: INFO: Pod "busybox-user-65534-c300d999-4712-4754-8097-6c6b237c2140": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015577185s
Apr 26 12:28:26.798: INFO: Pod "busybox-user-65534-c300d999-4712-4754-8097-6c6b237c2140" satisfied condition "Succeeded or Failed"
[AfterEach] [sig-node] Security Context
  test/e2e/framework/framework.go:187
Apr 26 12:28:26.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2912" for this suite. 04/26/24 12:28:26.81
{"msg":"PASSED [sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]","completed":358,"skipped":6629,"failed":0}
------------------------------
â€¢ [4.078 seconds]
[sig-node] Security Context
test/e2e/common/node/framework.go:23
  When creating a container with runAsUser
  test/e2e/common/node/security_context.go:308
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    test/e2e/common/node/security_context.go:346

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-node] Security Context
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:28:22.739
    Apr 26 12:28:22.739: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename security-context-test 04/26/24 12:28:22.74
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:28:22.761
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:28:22.767
    [BeforeEach] [sig-node] Security Context
      test/e2e/common/node/security_context.go:49
    [It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
      test/e2e/common/node/security_context.go:346
    Apr 26 12:28:22.783: INFO: Waiting up to 5m0s for pod "busybox-user-65534-c300d999-4712-4754-8097-6c6b237c2140" in namespace "security-context-test-2912" to be "Succeeded or Failed"
    Apr 26 12:28:22.791: INFO: Pod "busybox-user-65534-c300d999-4712-4754-8097-6c6b237c2140": Phase="Pending", Reason="", readiness=false. Elapsed: 7.933815ms
    Apr 26 12:28:24.798: INFO: Pod "busybox-user-65534-c300d999-4712-4754-8097-6c6b237c2140": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015409644s
    Apr 26 12:28:26.798: INFO: Pod "busybox-user-65534-c300d999-4712-4754-8097-6c6b237c2140": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015577185s
    Apr 26 12:28:26.798: INFO: Pod "busybox-user-65534-c300d999-4712-4754-8097-6c6b237c2140" satisfied condition "Succeeded or Failed"
    [AfterEach] [sig-node] Security Context
      test/e2e/framework/framework.go:187
    Apr 26 12:28:26.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "security-context-test-2912" for this suite. 04/26/24 12:28:26.81
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
[BeforeEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:28:26.821
Apr 26 12:28:26.821: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename resourcequota 04/26/24 12:28:26.822
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:28:26.838
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:28:26.845
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90
STEP: Counting existing ResourceQuota 04/26/24 12:28:26.852
STEP: Creating a ResourceQuota 04/26/24 12:28:31.86
STEP: Ensuring resource quota status is calculated 04/26/24 12:28:31.866
STEP: Creating a Service 04/26/24 12:28:33.872
STEP: Creating a NodePort Service 04/26/24 12:28:33.9
STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 04/26/24 12:28:33.983
STEP: Ensuring resource quota status captures service creation 04/26/24 12:28:34.047
STEP: Deleting Services 04/26/24 12:28:36.056
STEP: Ensuring resource quota status released usage 04/26/24 12:28:36.083
[AfterEach] [sig-api-machinery] ResourceQuota
  test/e2e/framework/framework.go:187
Apr 26 12:28:38.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-476" for this suite. 04/26/24 12:28:38.105
{"msg":"PASSED [sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]","completed":359,"skipped":6667,"failed":0}
------------------------------
â€¢ [SLOW TEST] [11.290 seconds]
[sig-api-machinery] ResourceQuota
test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  test/e2e/apimachinery/resource_quota.go:90

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:28:26.821
    Apr 26 12:28:26.821: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename resourcequota 04/26/24 12:28:26.822
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:28:26.838
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:28:26.845
    [It] should create a ResourceQuota and capture the life of a service. [Conformance]
      test/e2e/apimachinery/resource_quota.go:90
    STEP: Counting existing ResourceQuota 04/26/24 12:28:26.852
    STEP: Creating a ResourceQuota 04/26/24 12:28:31.86
    STEP: Ensuring resource quota status is calculated 04/26/24 12:28:31.866
    STEP: Creating a Service 04/26/24 12:28:33.872
    STEP: Creating a NodePort Service 04/26/24 12:28:33.9
    STEP: Not allowing a LoadBalancer Service with NodePort to be created that exceeds remaining quota 04/26/24 12:28:33.983
    STEP: Ensuring resource quota status captures service creation 04/26/24 12:28:34.047
    STEP: Deleting Services 04/26/24 12:28:36.056
    STEP: Ensuring resource quota status released usage 04/26/24 12:28:36.083
    [AfterEach] [sig-api-machinery] ResourceQuota
      test/e2e/framework/framework.go:187
    Apr 26 12:28:38.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "resourcequota-476" for this suite. 04/26/24 12:28:38.105
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Job
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
[BeforeEach] [sig-apps] Job
  test/e2e/framework/framework.go:186
STEP: Creating a kubernetes client 04/26/24 12:28:38.112
Apr 26 12:28:38.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
STEP: Building a namespace api object, basename job 04/26/24 12:28:38.115
STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:28:38.129
STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:28:38.136
[It] should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464
STEP: Creating a job 04/26/24 12:28:38.145
STEP: Ensure pods equal to paralellism count is attached to the job 04/26/24 12:28:38.15
STEP: patching /status 04/26/24 12:28:40.162
STEP: updating /status 04/26/24 12:28:40.169
STEP: get /status 04/26/24 12:28:40.216
[AfterEach] [sig-apps] Job
  test/e2e/framework/framework.go:187
Apr 26 12:28:40.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4614" for this suite. 04/26/24 12:28:40.245
{"msg":"PASSED [sig-apps] Job should apply changes to a job status [Conformance]","completed":360,"skipped":6678,"failed":0}
------------------------------
â€¢ [2.138 seconds]
[sig-apps] Job
test/e2e/apps/framework.go:23
  should apply changes to a job status [Conformance]
  test/e2e/apps/job.go:464

  Begin Captured GinkgoWriter Output >>
    [BeforeEach] [sig-apps] Job
      test/e2e/framework/framework.go:186
    STEP: Creating a kubernetes client 04/26/24 12:28:38.112
    Apr 26 12:28:38.112: INFO: >>> kubeConfig: /tmp/kubeconfig-3912933062
    STEP: Building a namespace api object, basename job 04/26/24 12:28:38.115
    STEP: Waiting for a default service account to be provisioned in namespace 04/26/24 12:28:38.129
    STEP: Waiting for kube-root-ca.crt to be provisioned in namespace 04/26/24 12:28:38.136
    [It] should apply changes to a job status [Conformance]
      test/e2e/apps/job.go:464
    STEP: Creating a job 04/26/24 12:28:38.145
    STEP: Ensure pods equal to paralellism count is attached to the job 04/26/24 12:28:38.15
    STEP: patching /status 04/26/24 12:28:40.162
    STEP: updating /status 04/26/24 12:28:40.169
    STEP: get /status 04/26/24 12:28:40.216
    [AfterEach] [sig-apps] Job
      test/e2e/framework/framework.go:187
    Apr 26 12:28:40.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
    STEP: Destroying namespace "job-4614" for this suite. 04/26/24 12:28:40.245
  << End Captured GinkgoWriter Output
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
{"msg":"Test Suite completed","completed":360,"skipped":6706,"failed":0}
Apr 26 12:28:40.256: INFO: Running AfterSuite actions on all nodes
Apr 26 12:28:40.256: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
Apr 26 12:28:40.256: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
Apr 26 12:28:40.256: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
Apr 26 12:28:40.256: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
Apr 26 12:28:40.257: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
Apr 26 12:28:40.257: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
Apr 26 12:28:40.257: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
[SynchronizedAfterSuite] TOP-LEVEL
  test/e2e/e2e.go:87
Apr 26 12:28:40.257: INFO: Running AfterSuite actions on node 1
Apr 26 12:28:40.257: INFO: Skipping dumping logs from cluster
------------------------------
[SynchronizedAfterSuite] PASSED [0.001 seconds]
[SynchronizedAfterSuite] 
test/e2e/e2e.go:87

  Begin Captured GinkgoWriter Output >>
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Apr 26 12:28:40.256: INFO: Running AfterSuite actions on all nodes
    Apr 26 12:28:40.256: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func20.2
    Apr 26 12:28:40.256: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func10.2
    Apr 26 12:28:40.256: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage.glob..func9.2
    Apr 26 12:28:40.256: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func17.3
    Apr 26 12:28:40.257: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func9.2
    Apr 26 12:28:40.257: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func4.2
    Apr 26 12:28:40.257: INFO: Running Cleanup Action: k8s.io/kubernetes/test/e2e/storage/vsphere.glob..func1.3
    [SynchronizedAfterSuite] TOP-LEVEL
      test/e2e/e2e.go:87
    Apr 26 12:28:40.257: INFO: Running AfterSuite actions on node 1
    Apr 26 12:28:40.257: INFO: Skipping dumping logs from cluster
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146
[ReportAfterSuite] TOP-LEVEL
  test/e2e/e2e_test.go:146
------------------------------
[ReportAfterSuite] PASSED [0.000 seconds]
[ReportAfterSuite] Kubernetes e2e suite report
test/e2e/e2e_test.go:146

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/e2e_test.go:146
  << End Captured GinkgoWriter Output
------------------------------
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559
[ReportAfterSuite] TOP-LEVEL
  test/e2e/framework/test_context.go:559
------------------------------
[ReportAfterSuite] PASSED [0.037 seconds]
[ReportAfterSuite] Kubernetes e2e JUnit report
test/e2e/framework/test_context.go:559

  Begin Captured GinkgoWriter Output >>
    [ReportAfterSuite] TOP-LEVEL
      test/e2e/framework/test_context.go:559
  << End Captured GinkgoWriter Output
------------------------------

Ran 360 of 7066 Specs in 5486.786 seconds
SUCCESS! -- 360 Passed | 0 Failed | 0 Pending | 6706 Skipped
PASS

Ginkgo ran 1 suite in 1h31m27.387317373s
Test Suite Passed
[38;5;228mYou're using deprecated Ginkgo functionality:[0m
[38;5;228m=============================================[0m
  [38;5;11m--noColor is deprecated, use --no-color instead[0m
  [1mLearn more at:[0m [38;5;14m[4mhttps://onsi.github.io/ginkgo/MIGRATING_TO_V2#changed-command-line-flags[0m

[38;5;243mTo silence deprecations that can be silenced set the following environment variable:[0m
  [38;5;243mACK_GINKGO_DEPRECATIONS=2.1.6[0m

